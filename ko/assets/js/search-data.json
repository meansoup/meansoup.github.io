{"0": {
    "doc": "IEEE 754 부동 소수점 계산, floating point calculation",
    "title": "1 is not exactly 1",
    "content": "오늘 다뤄볼 내용은, 컴퓨터 연산에 있어서 컴퓨터가 명확하게 나타내지 못하는 수들에 대해 다뤄보려고 한다. 다소 길지만 끝까지 읽으면 분명 도움이 될 것이다. 개발자 기술 면접에서도 단골로 차용되는 주제이다. | 실제로 나도 기술 면접에서 이 주제로 면접을 봤었고 굉장히 좋은 평을 들었다. | 어디가서 부동 소수점 계산 면접을 보게된다면 이 자료면 충분할 것이다. | . ",
    "url": "/docs/computer/floating-point#1-is-not-exactly-1",
    
    "relUrl": "/docs/computer/floating-point#1-is-not-exactly-1"
  },"1": {
    "doc": "IEEE 754 부동 소수점 계산, floating point calculation",
    "title": "Java Code",
    "content": "@Test void test() { System.out.println(0.1 * 10); System.out.println(0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1); } . 위의 코드를 보면, 하나는 0.1에 10을 곱한 값을 출력하고, 하나는 0.1을 10번 더한 값을 출력한다. 직관적으로 계산해보면, 두 값은 모두 1이 된다. 하지만 결과값을 보면 다음과 같다. 1.0 0.9999999999999999 . ",
    "url": "/docs/computer/floating-point#java-code",
    
    "relUrl": "/docs/computer/floating-point#java-code"
  },"2": {
    "doc": "IEEE 754 부동 소수점 계산, floating point calculation",
    "title": "컴퓨터에서의 floating 저장",
    "content": "이유를 살펴보기 전에 알아야 할 것이 있다! 바로 컴퓨터가 어떻게 실수(float, double)들을 저장하는 지에 대한 것이다. 이 부분은 어떻게 보면 좀 깊은 내용을 다루는 것일 수 있다. 모두가 알다시피 컴퓨터는 0과 1만 저장할 수 있다. 즉 2진법으로 숫자를 저장한다는 것인데, 이는 정수를 저장하는데 있어서는 모든 수를 표현할 수 있지만, 소수를 저장하는데 문제가 생기게 된다. 예시 . \\(0.01_2 = 0.25\\) 를 의미. | 2진수 0.01은 10진수 0.25와 같다. | . 이런식으로 계산하다보면 . \\(0.1_2 = 0.5\\) \\(0.01_2 = 0.25\\) \\(0.001_2 = 0.125\\) \\(0.0001_2 = 0.0625\\) … . 와 같은 식으로 이진수가 표현이 된다. ",
    "url": "/docs/computer/floating-point#%EC%BB%B4%ED%93%A8%ED%84%B0%EC%97%90%EC%84%9C%EC%9D%98-floating-%EC%A0%80%EC%9E%A5",
    
    "relUrl": "/docs/computer/floating-point#컴퓨터에서의-floating-저장"
  },"3": {
    "doc": "IEEE 754 부동 소수점 계산, floating point calculation",
    "title": "0.3을 컴퓨터에 저장하기",
    "content": "그런데 문제는 \\(0.3\\) 을 표현하는데 생긴다. \\(0.01_2 + 0.0001_2 = 0.28125\\) 이고, 따라서 \\(0.3 = 0.0101...._2\\) 가 될 수 있다. 하지만, \\(0.3\\) 은 2진수로 정확하게 나타낼 수 없다. 그 이유는 \\(0.3\\) 을 2로 계속 곱하여도, 값이 정리되지 않는 부분에서도 확인할 수 있다. (이 부분은 다소 수학적 부분) . 2진수를 10진수로 변환할 때는, 2를 계속해서 곱하면서 일의 자리 숫자가 1이 될 경우, 2진수에서 1을 표시하고 계속해서 연산한다. 이는 곱한 결과가 0.0, 즉 나머지가 없을 때까지 계속해서 진행한다. 예시 . \\(0.5 * 2 = 1.0\\) \\(0.5 = 0.1_2\\) . | 10진수 0.5와 2진수 0.1이 같음을 확인할 수 있다. | . 동일하게, \\(0.25 * 2^2 = 1.0\\) \\(0.25 = 0.01_2\\) . 그럼 \\(0.1\\) 을 2진수로 바꿔보도록 하자. | \\(0.1 * 2 = 0.2\\) , \\(0.0..._2\\) . | 2를 곱해도 1의 자리 숫자가 0 이므로 0.0 | . | \\(0.2 * 2 = 0.4\\) , \\(0.00..._2\\) . | 2를 곱해도 1의 자리 숫자가 0 이므로 0.00 | . | \\(0.4 * 2 = 0.8\\) , \\(0.000..._2\\) . | 2를 곱해도 1의 자리 숫자가 0 이므로 0.000 | . | \\(0.8 * 2 = 1.6\\) , \\(0.0001..._2\\) . | 2를 곱하니 1의 자리 숫자가 1 이므로 \\(0.0001\\) | . | \\(0.6 * 2 = 1.2\\) , \\(0.00011..._2\\) . | 위에서 1의 자리 숫자를 뺀 0.6을 base로 2를 곱한다 | 2를 곱하니 1의 자리 숫자가 1 이므로 \\(0.00011\\) | . | \\(0.2 * 2 = 0.4\\) , \\(0.000110..._2\\) | . 이런 식으로 0.1에 맞는 2진수를 계산할 수 있다. 위 계산 식을 통해 0.1은 2진수로 완벽하게 나타낼 수 없는 무한소수(2진수에서)가 되는 것을 확인할 수 있다. 위의 수식을 통해, 0.1과 0.3을 비롯한 여러 숫자들이 2진수로 명확하게(유한소수로) 나타낼 수 없는 것을 확인할 수 있다. ",
    "url": "/docs/computer/floating-point#03%EC%9D%84-%EC%BB%B4%ED%93%A8%ED%84%B0%EC%97%90-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/computer/floating-point#03을-컴퓨터에-저장하기"
  },"4": {
    "doc": "IEEE 754 부동 소수점 계산, floating point calculation",
    "title": "IEEE standard 754",
    "content": "그렇다면 컴퓨터는 어떻게 0.3, 0.1이란 수를 표현할 수 있을까? IEEE standard 754 표준을 보면 이를 알 수 있다. IEEE 754에서는 실수에 대해 이렇게 표기하도록 명시한다. 일반적으로 float 타입이 32bit, double 타입이 64bit이므로, single precision이 float 타입, double precision이 double 타입이라고 생각할 수 있다. sign bit: 말 그대로 음수인지, 양수인지에 대한 표현. fraction: 소수점에 대해 1을 제외한 소수점 자리의 값을 나타냄. exponent: 지수부에 대한 값. 아래의 수식을 보시면 더 직관적으로 이해할 수 있을 것이다. sign bit는 음수와 양수의 구분을 하고 있다. fraction은 다소 이해가 되지 않을 수 있는데, 값이 \\(1.1011_2\\) 이라면, fraction은 1을 제외한 소수점 부분인 1011을 의미한다. exponent는 bias를 빼줌으로써 계산한다. ",
    "url": "/docs/computer/floating-point#ieee-standard-754",
    
    "relUrl": "/docs/computer/floating-point#ieee-standard-754"
  },"5": {
    "doc": "IEEE 754 부동 소수점 계산, floating point calculation",
    "title": "실수의 덧셈 연산",
    "content": "이러한 실수의 저장 속에서 실수의 연산을 컴퓨터가 어떻게 하는지에 대해 집중할 필요가 있다. 다시 우리의 목적을 상기해보면 우리는 덧셈을 했을 경우와 곱셈을 했을 경우의 차이에 대해 보고 있었다. 먼저 실수의 덧셈에 대해 확인해 보자. 우리가 생각하고 계산하는 그대로 컴퓨터도 계산한다. | 먼저 exponent(지수부)를 맞춰준다 | 두 수를 더한다 | scientific-notation으로 다시 정리한다. | 계산한 후의 값이 1의 자리 숫자에 1이 오도록 연산을 맞춰주는 것을 말한다. | scientific-notation을 사용해야 1을 제외한 fraction 값을 구할 수 있다. | . | . 예시 . \\(1.01*2^2\\) 와 \\(1.11*2^0\\) 를 더해보자. | \\(1.11*2^0 = 0.0111*2^2\\) . | \\(2^2\\) 의 exponent에 맞추어 지수부를 \\(2\\) 로 맞춰준다. | . | \\(1.01*2^2 + 0.0111*2^2 = 1.1011*2^2\\) . | 두 수를 더해준다 | . | \\(10.0011 * 2^2 = 1.00011*2^3\\) . | scientific-notation을 적용한다 | . | . ",
    "url": "/docs/computer/floating-point#%EC%8B%A4%EC%88%98%EC%9D%98-%EB%8D%A7%EC%85%88-%EC%97%B0%EC%82%B0",
    
    "relUrl": "/docs/computer/floating-point#실수의-덧셈-연산"
  },"6": {
    "doc": "IEEE 754 부동 소수점 계산, floating point calculation",
    "title": "실수의 곱셈 연산",
    "content": "다음은 실수의 곱셈이다. 곰셉은 조금 더 복잡하지만, 간단한 수준의 연산으로 정리된다. | 먼저 두 수의 exponent를 더해 준다. | 두 수를 곱한다. | 그리고 덧셈과 마찬가지로 scientific-notation으로 정리하여 exponent를 다시 계산한다. | . 예시 . \\(1.01*2^2\\) 와 \\(1.11*2^0\\) 를 곱해보자. | \\(2 + 0 = 2\\) . | 지수부(exponent)를 더해준다. | . | \\(1.01 * 1.11 = 10.0011\\) . | 두 수를 곱해준다. | . | \\(10.0011 * 2^2 = 1.00011*2^3\\) . | scientific-notation을 적용한다 | . | . 이렇게 덧셈과 곱셈에서의 연산 방식과 차이를 볼 수 있다. 두 연산 방식 모두, double형 기준에서 52bit의 fraction을 초과하는 부분에서 그 이하의 값에 대한 처리가 필요하다는 것을 알 수 있다. | fraction은 제한적이지만, 실수를 2진수로 저장하면 무제한적이게 길어지기 때문에! | . ",
    "url": "/docs/computer/floating-point#%EC%8B%A4%EC%88%98%EC%9D%98-%EA%B3%B1%EC%85%88-%EC%97%B0%EC%82%B0",
    
    "relUrl": "/docs/computer/floating-point#실수의-곱셈-연산"
  },"7": {
    "doc": "IEEE 754 부동 소수점 계산, floating point calculation",
    "title": "IEEE 754 &amp; JAVA specification",
    "content": "IEEE754에서는 위와 같은 실수의 처리에 대해 여러가지 방법을 제시힌다. rounding이라고 하는데, 아래와 같은 rounding 방식들을 제시한다. round to zero, round up, round down, round even, round to nearest . 이 중에서도 JAVA는 JAVA specification에서 다음과 같이 round 처리를 밝힌다. round to nearest: 가까운 곳으로 rounding 하는 방식. 예를 들어서 확실히 이해해보자. ",
    "url": "/docs/computer/floating-point#ieee-754--java-specification",
    
    "relUrl": "/docs/computer/floating-point#ieee-754--java-specification"
  },"8": {
    "doc": "IEEE 754 부동 소수점 계산, floating point calculation",
    "title": "0.1 * 10",
    "content": "0.1과 10의 곱을 나타내면 다음과 같다. 먼저 2진수로 바꿔준 뒤, 이에 대한 52번째 자리까지(fraction이 52bit이기 때문) 계산한 후, 남는 부분을 Round to nearest 처리 해준다. 여기서 nearest는, 값을 버려서 0으로 내림하는 것보다, 1로 올림하는 것이 뒤의 … 값에서 따져봤을 때 더 가까운 값이므로 올려준다. 수식을 정리하면 아래와 같다. \\(0.1\\) \\(= 0.00011001100110011001100110011001100110011001100110011001...\\) \\(= 0.00011001100110011001100110011001100110011001100110011010\\) (Round to nearest) \\(= 1.1001100110011001100110011001100110011001100110011010 *2^{-4}\\) . \\(10\\) \\(= 1010\\) \\(= 1.01 * 2^3\\) . \\(0.1 * 10\\) \\(= (1.1001100110011001100110011001100110011001100110011010 *2^{-4}) * (1.01 *2^3)\\) \\(= 10.00000000000000000000000000000000000000000000000000001 *2^{-1}\\) \\(= 1.0000000000000000000000000000000000000000000000000000\\) (Round to nearest) \\(= 1\\) . JAVA specification에서 밝히는 규칙을 그대로 따라온 결과, 0.1*10이 1임을 볼 수 있다. ",
    "url": "/docs/computer/floating-point#01--10",
    
    "relUrl": "/docs/computer/floating-point#01--10"
  },"9": {
    "doc": "IEEE 754 부동 소수점 계산, floating point calculation",
    "title": "0.1 + 0.1 + …",
    "content": "그렇다면 덧셈의 경우는 어떨까? 보기 좋게 0을 붙여서 scientific-notation form으로 자리수를 맞췄다. 또 헷갈리지 않기 위해 10자리씩 숫자를 나눠 두었다. | 0.1 + 반복 수 | 저장되는 값 | . | 1 (0.1) | 0.0001 1001100110 0110011001 1001100110 0110011001 1001100110 10 | . | 2 (0.1 + 0.1) | 00.001 1001100110 0110011001 1001100110 0110011001 1001100110 10 | . | 3 | 000.01 0011001100 1100110011 0011001100 1100110011 0011001101 00 | . | 4 | 000.01 1001100110 0110011001 1001100110 0110011001 1001100110 10 | . | 5 | 0000.1 0000000000 0000000000 0000000000 0000000000 0000000000 00 | . | 6 | 0000.1 0011001100 1100110011 0011001100 1100110011 0011001100 11 | . | 7 | 0000.1 0110011001 1001100110 0110011001 1001100110 0110011001 10 | . | 8 | 0000.1 1001100110 0110011001 1001100110 0110011001 1001100110 01 | . | 9 | 0000.1 1100110011 0011001100 1100110011 0011001100 1100110011 00 | . | 10 | 0000.1 1111111111 1111111111 1111111111 1111111111 1111111111 11 | . 0.11111111111111111111111111111111111111111111111111111 (2) = 0.99999999999999988897769753748434595763683319091796875 . 첫 공백은 각각 fraction 앞의 1을 제외한 수부터 10칸씩을 나타낸다. 따라서 52칸, 52bit의 fraction을 갖는 것을 볼 수 있다. 여기서의 연산에서도, 52bit를 넘어갈 경우 round to nearest를 적용했다. 9번의 연산에 모두 표현하지 못한 점에 대해선 양해가 필요할 것 같다. (힘듦) . | 논리적으로 이해가 되긴 하니까? | . 주의할 점은 \\(0.1 + 0.1\\)이 \\(0.2\\) 가 아니라는 점이다. \\(0.1 != 0.1\\) 이기 때문이고, 위에서부터 0.1, 0.1 + 0.1, 0.1 + 0.1 + 0.1을 이어나가 마지막 값이 0.1을 열번 더한 값을 확인할 수 있다. 이 값을 계산기로 계산해보면, 0.9999999... 의 값을 확인할 수 있다. 덧셈의 경우 어렵지 않지만 헷갈릴 수 있다. 한 번의 연산이 일어날 경우, 52bit로 소수점이 잘리며 rounding이 이뤄지는 점에 주목할 필요 가 있다. 위의 연산을 보면, 자리 수가 소수점 넷째 자리에서 첫째 자리까지 바뀌면서, 0.1은 계속해서 넷째 자리이기 때문에, 값의 결과는 계속해서 52bit를 초과하게 되고, 이에 대한 round to nearest가 계속해서 이뤄지게 된다. ",
    "url": "/docs/computer/floating-point#01--01--",
    
    "relUrl": "/docs/computer/floating-point#01--01--"
  },"10": {
    "doc": "IEEE 754 부동 소수점 계산, floating point calculation",
    "title": "코드 및 결과 확인",
    "content": "floating point의 0.1 값을 아래 java 코드로 확인할 수 있다. @Test void test() { double float0_1 = 0.1; System.out.println(float0_1); System.out.println(new BigDecimal(float0_1)); byte[] bts = toByteArray(float0_1); for(int i=0; i&lt;bts.length; i++){ String s1 = String.format(\"%8s\", Integer.toBinaryString(bts[i] &amp; 0xFF)).replace(' ', '0'); System.out.print(s1); } } public static byte[] toByteArray(double value) { byte[] bts = new byte[8]; ByteBuffer.wrap(bts).putDouble(value); return bts; } . 0.1 (0.1을 print) 0.1000000000000000055511151231257827021181583404541015625 (0.1을 bigdecimal로 명확하게 print) 0011111110111001100110011001100110011001100110011001100110011010 (0.1의 byte를 출력) . ",
    "url": "/docs/computer/floating-point#%EC%BD%94%EB%93%9C-%EB%B0%8F-%EA%B2%B0%EA%B3%BC-%ED%99%95%EC%9D%B8",
    
    "relUrl": "/docs/computer/floating-point#코드-및-결과-확인"
  },"11": {
    "doc": "IEEE 754 부동 소수점 계산, floating point calculation",
    "title": "결과",
    "content": "결과적으로 이 글에서는 다음과 같은 내용을 다뤘다. | 컴퓨터는 소수들에 대해 정확한 표기를 할 수 없다. | 컴퓨터가 소수를 표기하기 위해 위와 같은 방식을 사용한다. | IEEE 754에선 소수의 연산을 위한 방식을 표준화하고 있다. | JAVA는 소수의 연산에 round to nearest를 사용한다. | 0.1은 0.1이 아니다. | 0.1 * 10과 0.1 + … + 0.1(10번) 의 값은 다르다. | 이를 증명하는 방법들. | . 이와 관련해서 C나 다른 언어에서는 다른 값을 보일 수 있다는 것도 참고해야 한다. 언어마다 IEEE 754에서 보이는 round 규칙 중 다른 것을 택하기 때문이다. ",
    "url": "/docs/computer/floating-point#%EA%B2%B0%EA%B3%BC",
    
    "relUrl": "/docs/computer/floating-point#결과"
  },"12": {
    "doc": "IEEE 754 부동 소수점 계산, floating point calculation",
    "title": "IEEE 754 부동 소수점 계산, floating point calculation",
    "content": " ",
    "url": "/docs/computer/floating-point",
    
    "relUrl": "/docs/computer/floating-point"
  },"13": {
    "doc": "kivy app & game book ch2",
    "title": "kivy app & game book ch2",
    "content": "coordinate space . 일종의 그림이 그려지는 도화지? 같은 개념이다. coordinate space는 제한되지 않으며, bottom-left corner of the screeon을 origin으로 한다. canvas . widget에 vector shape를 그릴 수 있다. canvas에 그리는게 아니라, canvas는 coordinate space에 그리는 명령들의 집합이 canvas이다. 모든 widget은 각각 Canvas를 포함한다. 모든 widget은 동일한 coordiante space를 공유한다. coordiante space는 windows나 screen size에 제한되지 않다. canvas는 canvas.before, canvas, canvas.after의 세 객체를 가진다. canvas.after는 가장 마지막에 호출되어 다른 widget들 위에 생성된다. vertax instruction . inherit from the VertexInstruction. 어떤걸 그릴 건지에 대한 것, 기본적인 모양에 대한 명령어이다. (Line, Rectangle, Triangle, Point) 이걸 통해 coordinate space에 vector shape의 그림을 그린다. | instruction | description | . | Rectangle |   | . | Ellipse | 부채꼴 같은 것. 0도가 12시 angle_start, angle_end 로 부채꼴을 그릴 수 있음 segments 는 몇 개의 선으로 원을 그리는지에 대한 것 즉, 무제한의 선으로 원을 그려야 정확한 원. default=180 segments : 3으로 하면 삼각형 | . | Triangle | x,y points 3개 -&gt; 삼각형 | . | Quad | points 4개 -&gt; 사각형 | . | Line | points 2개 -&gt; 선 (2개씩 여러 개로 여러 선 그릴 수 있음) | . | Point | points 1개 -&gt; 점 (여러 개로 여러 점 찍을 수 있음) | . | Bezier | 곡선. points를 attractors로 사용. (math formalism.. 수학적) dash_length 는 점선의 길이, dash_offset 은 점선 사이의 거리 | . | Mesh | 삼각형의 조합으로 이루어지며, 굉장히 수학적 | . context instruction . inhefit from the CntextInstruction. 어디에, 어떻게 그릴지에 대한 것이다. (Color, Rotate, Translate, Scale) vertax가 선, 원, 네모를 그린다면 contex는 색상, 회전, 크기 등.. 이걸 통해 coordinate space에 변화를 준다. | instruction | description | . | source: 'kivy.png' | 이미지를 넣을 수 있음 | . | Color: rgba: | color 설정 가능이미지가 있다고 해도 필터 같은 느낌으로 해당 컬러를 갖게 됨. | . | Rotate: angle: | 회전 Rotate: axis: - 어떤 축으로 할지 축을 지정 | . | Translate: x: or y: | 이동. 회전 상태라면, x, y의 방향이 반대가 됨 | . | Scale: xyz: | 각 축에 대한 size를 비율로 지정. 0.5배를 했다면, 원상복구를 위해선 2배를 해줘야 함 | . push &amp; pop matrix . PushMatrix: PushMatrix, which will save the current coordinate space context PopMatrix: PopMatrix, which return the context to its original state. 즉, 이 사이에 context instruction을 쓰면 다른애들 영향 x. | canvas에서 적용, canvas.after에서 해제하는 방식으로도 사용한다. canvas: PushMatrix: Translate: xy: self.x,self.y canvas.after: PopMatrix: . | . context instruction + . Color, Rotate, Translate, Scale은 모두 설정하면 그 다음부터 coordinate space에 영향을 계속 미치게 된다. (그래서 push &amp; pop matrix가 존재) 모든 적용을 회피하기 위해선 RelativeLayout 하위에서 적용하면 된다. | RelativeLayout은 내부적으로 widget의 position 등을 결정하기 때문 | RelativeLayout은 내부에 PushMatrix, PopMatrix를 가지고 있음 | . widget 속의 각 widget들은 각각 canvas.before, canvas, canvas.after를 가진다. (layout도 widget의 일종이고) canvas.before에는 별도의 Push/PopMatrix가 있어 여기서 구현하면 canvas 전에 cotext를 원상 복구한다. ",
    "url": "/docs/kivy/app-game-book-2",
    
    "relUrl": "/docs/kivy/app-game-book-2"
  },"14": {
    "doc": "kivy app & game book ch3",
    "title": "kivy app & game book ch3",
    "content": "id .kv 내에서만 접근 가능한 아이디다. 보통 맨 앞에 _를 붙이지만, 구분하기 위한 권고사항이지 필수는 아니다 . attribute . 어떤 widget에 attribute를 생성하고, id를 여기 넣어주면 그 attribute로 접근할 수 있다. &lt;ComicCreator&gt;: AnchorLayout: ... ToolBox: id: _tool_box drawing_space: _drawing_space AnchorLayout: ... DrawingSpace: id: _drawing_space . commiccreator.kv의 ToolBox에서 drawing_space attribute는 _drawing_space(id)를 가지고 있으며, python에서 drawing_space로 여기에 접근 가능하다. root도 동일한 방식이다. etc. root: base widget in the rule hierarchy self: current widget app: the instance of the application . Touch event . touch event는 mouse, finger touch, magic pen touch으로 나뉘며, 아래 event는 mouse, finger touch에서 사용 가능하다. | on_touch_down: new touch start | on_touch_move: the touch is moved | on_touch_up: the touch ends | . 각 touch event는 parameter(touch)로 여러 정보를 갖는 MotionEvent를 받는다. def on_touch_down(self, touch): if self.collide_point(touch.x, touch.y): self.select() return True return super(DraggableWidget, self).on_touch_down(touch) . event가 진행되면 True를 return하고, event가 widget 밖으로 나가면, children에 전달해 return을 받는다. 유사하게 super.on_touch_~ 으로 chidren의 event를 신경쓸 수 있다. collide_point . 모든 widget이 app(coordinate space)에서 발생하는 touch event(MotionEvent)를 받지만, 그 event가 특정 widget에서 발생하는지 확인하는 보편적인 방법이다. dynamic create/deleate canvas . with self.canvas: self.selected = Line(rectangle=(0, 0, self.width, self.height), dash_offset=2) . with self.canvas를 통해 canvas에 instructions를 넣을 수 있다. Line instance를 self.selected에 넣어서 언제든 삭제할 수 있도록 구현할 수 있다. if self.selected: self.canvas.remove(self.selected) self.selected = None . self.canvas.remove(self.selected)를 통해 canvas에 self.selected를 지울 수 있다. localizing coordinates . to_parent() 같이, 현재 widget에서 구현하지만, 움직일 공간이 parent, 혹은 parent’s parent와 같은 경우 coordinates의 범위를 지정해주는 것. RelativeLayout은 coordinate의 위치 값들이 다 다르기 때문에 이런 방법이 필요하다. | RelativeLayout이 아닌 layout들은 그 상위에 대해 절대적인 coordinate 값을 가지고 있음 . | to_parent(): transform relative coordinates inside RelativeLayout to the parent of RelativeLayout. 부모의 coordinate에 접근할 수 있다. | to_local(): transform the coordinates of parent of RelativeLayout to RelativeLayout | to_window(): transform the coordinates of the current widget to absolute coordinate with respect to the window | to_widget(): transform the absolute coordinates to coordinates within the parent of the current widget | .py와 .kv 연결 . layout.add_widget(w)으로 layout에 widget을 더해준다. #:import toolbox toolbox으로 toolbox를 .kv에 import 한다. (.kv에서도 python code를 import할 수 있다.) . comiccreator.py comiccreator.kv (얘가 toolbox를 사용) - toolbox.py - toolbox.kv . 위와 같이, commiccreator가 main이 되고 toolbox를 사용하는 상황에서 . | comiccreator.py에서 comiccreator.kv를 사용하고 (kv에서 자동으로) | commiccreator는 toolbox.kv를 내부적으로 사용하고 (.py에서 Builder.load_file로 load) | toolbox.kv는 toolbox.py의 구현을 사용한다 (.kv에서 #:import toolbox toolbox로 import) | . 즉, toolbox.py가 main이었다면 import를 안해도 .kv를 가져갔겠지만, toolbox가 main이 아니라 사용되는 상황에서, .py를 import 해줘야 했음. bind/unbind . binding에는 2가지 방법이 존재한다. 1. at .py, it works for every instance about this class . python에서는 bind하면 전체 적용되는 것을 피하기 위해 touch_down의 경우 overriding하여 사용하고, 나머지에 대해 bind 하는 방식을 사용한다. (we didn’t want the on_touch_move, on_touch_up events active all the time.) move와 up은 touch_down이 발생한 이후에 발생할 수 있으므로, 이 이벤트들을 항상 active 상태에 두는 것이 아니라, touch_down시에 bind를 통해 관리하도록 하는 것이다. def on_touch_down(self, touch): ... self.draw(ds, x, y) def draw(self, ds, x, y): ... ds.bind(on_touch_move=self.update_figure) ds.bind(on_touch_up=self.end_figure) def update_figure(self, ds, touch): def end_figure(self, ds, touch): . 2. at .kv, it works only for this instance . 특정 instance에 대해 bind하기 때문에 collide_point를 사용할 필요가 없다. | Button: on_press:와 on_release: | . &lt;GeneralOptions&gt;: Button: text: 'Clear' on_press: root.clear(*args) # clear, remove는 .py의 GeneralOptions에 구현된 함수 Button: text: 'Remove' on_release: root.remove(*args) . | ToggleButton: on_state - .py에서 ‘down’, ‘normal’로 구분 | . etc . | clear_widgets(): 모든 widget을 지움 | remove_widget(x.children[0]): 가장 최근에 추가된 widget을 지움 | . Kivy property . property가 정의되면 Kivy는 내부적으로 property와 연관된 event를 생성하고, 이 event는 ‘on_property_name’ method와 연결된다. translation = ListProperty(None) def on_translation(self, instance, value): . 따라서, property에 값을 넣어주면 on_property 가 자동으로 실행 된다. | 이는 kivy에서 굉장히 중요한 개념으로, 내부적으로 많이 사용됨. | 다른 클래스에서 특정 property를 바꿈으로써 on_property를 trigger할 수 있음. | . center_x도 property를 내부적으로 사용하는 것이다.kv의 vertex instruction의 attribute도 내부적으로 property로 사용 된다. python property와 혼동해서는 안된다. Kivy Property는 항상 attribute 지만, attribute가 모두 Kivy Property는 아니다. | attribute: used to describe variables(references, objects, instances) that belongs to class | . class StatusBar(BoxLayout): counter = NumericProperty(0) previous_counter = 0 . kivy property는 static attribute로 선언되나, internally transformed to attribute instansces. | counter는 static하게 선언되나 attribute instances가 되고, previous_counter는 static attribute로 되어 all StatusBar가 share.. | class name(StatusBar.previous_counter)이나 __class__(__class_.previous_counter)로 바로 접근 가능 | . | __init__ 안에서 선언되는 것들은 instance 임. 즉 not shared.. | . Kivy property . BoundedNumericProperty: set the maximum and minimum values AliasProperty: extend the properties, create our own properties NumericProperty StringProperty ListProperty DictProperty ObjectProperty StringProperty . ",
    "url": "/docs/kivy/app-game-book-3",
    
    "relUrl": "/docs/kivy/app-game-book-3"
  },"15": {
    "doc": "kivy app & game book ch4",
    "title": "kivy app & game book ch4",
    "content": "ScreenManager . ScreenManager는 여러 device에서 screen을 적절하게 조절할 수 있게 해준다. multiple screen을 갖도록 해주며 screen간 switch를 쉽게 해준다. ScreenManager는 항상 Screen widget을 가져아하고, 다른 Widget을 가질 수 없다. Screen으로 사용되는 곳에도 명시가 필요하다. @Screen으로 상속해주어야 한다. Screen은 manager attribute를 갖고, 이를 통해 접근할 수 있다. name property를 Screen에 명시하여 screen을 변경할 수 있다. | 예를 들어 root.current = 'comicscreen'을 통해 comicscreen으로 switch 함. | 여기서 root는 ScreenManager 이고, current는 active screen 임. | . | 유사하게 current = 'colorscreen'으로 colorscreen으로 switch 할 수 있음. comiccreator.kv에서 각 항목들에 대해 id, root를 부여하는 이유 | . ScreenManager를 사용하게 되면 ScreenManager가 Screen들을 통제하게 되는 구조가 되기 때문에 .py에서 kivyApp이 빌드하는 최상위가 Manager가 되야 한다. Color . 동적으로 coloring 하기 위한 방법이다. canvas.add와 with ---.canvas:를 통해 color를 추가할 수 있다. canvas.add(Color(1,0,0,1)) with canvas: Color(1,0,0,1) . canvas.before.add를 사용하면 Color instruction이 Canvas에 추가한 다른 instructions보다 먼저 적용되도록 할 수 있다. transision . screen을 switch 할 때 어떤 animation이 보이는가에 대한 것이다. etc . load_file은 .kv를 include하는 것이며, 이와 유사하게 load_string으로 .kv를 python file에서 사용할 수 있다. stencilView . 특정 영역에만 이벤트를 처리하기 위해서 collide_points와 같은 방법을 사용했었는데, 이건 group mode나 resize 같은 상황에서 완벽하지 않다. 따라서 StencilView를 쓰는데, StencilView는 drawing area를 해당 view의 공간까지로 제한하며, 밖에 그려진 것들은 숨겨진다. | drawingspace를 제한하기 위해 StencilView를 상속하도록 함. | DrawingSpace(RelativeLayout)을 DrawingSpace(stencilView)로 변경. | 참 여기서 DrawingSpace는 예제에서 만들어낸 클래스! | . | . StencilView는 RelativeLayout이 아니므로, StencilView class는 relative coordinates를 사용할 수 없다. 즉, 여기서 사용한다면 상위의 RelativeLayout을 사용하게 되는 것이며, 일반적으로 drawing은 relative coordinates를 사용하는 것이 좋으므로 RelativeLayout안에 DrawingSpace을 사용하도록 한다. | DrawingSpace(RelativeLayout)와 같은 동작을 원한다면 RelativeLayout을 가질 수 있도록 RelativeLayout으로 DrawingSpace를 감싸도록 한다. 이렇게 되면 RelativeLayout이 원하는 위치와 사이즈를 갖도록 설정해주어야 한다. RelativeLayout: DrawingSpace: . | . scatter . scale, rotate와 같은 기능들을 가지고 있는 class. 두 손가락으로 scale과 rotate를 할 수 있도록 구현되어 있고, mobile에서도 사용가능하다. scatter도 RelativeLayout처럼 relative coordinates를 사용한다. scatter 적용 . | DraggableWidget이 Scatter를 상속하도록 함. | scatter가 event를 받을 수 있도록 on_touch_down에 super.on_touch_down를 추가 함. | scatter가 pos property에 대한 on_pos method를 지원하므로 on_touch_move 대신 사용. | scatter는 rotation과 scale property를 또한 지원하며, on_rotation, on_scale 사용. | . property 활용 . property의 활용은 하나의 변경이 다른 widget에 영향을 미칠 때 효과적으로 사용할 수 있다. 예를들어 하나의 widget이 rotation이 변경되면, on_rotation 함수가 호출되는데, 이 함수 내부에서 연관된 widget들의 rotation을 변경하여 on_rotation을 호출할 수 있다. gesture . kivy 에서는 gesture를 저장할 수 있는데, gesture를 string으로 저장함. on_touch_down, on_touch_move, on_touch_up 마다 point를 저장하여 string으로 변환하는 방식이다. | gesture = Gesture()로 Gesture를 생성하고 | gesture.add_stroke(self.points)로 points를 넣고 . | self.points += [touch.pos]로 points가 기록되어 있음 | . | gesture.normalize()로 default number로 바꾸고 | GestureDatabase.gesture_to_str(gesture)로 string으로 출력하여 확인하도록 함. | . kivy 에서 저장한 gesture를 활용하는 방식. | str_to_gesture로 저장해둔 string gesture를 gesture로 바꿈 | GestureDataBase.add_gesture로 gesture를 database에 추가 | on_touch_down, on_touch_move, on_touch_up에 대한 함수 구현. | 각 함수에서 [touch.pos]를 저장하고, on_touch_up에서 GestureDatabase.find를 통해 database에서 저장된 gesture가 있는지 찾도록 함. | . | 찾은 값과, database에 넣은 gesture가 일치하는지 확인하여 사용. | 여기서는 discriminate를 통해 해당 그림들을 그리도록 하였음. | . | . behavior . 특정 widget의 classic behavior를 다른 behavior에 사용할 수 있다. 예를 들어, ButtonBehavior(on_press, onRelease를 사용하기 위한)를 Label이나 Image widget에 사용할 수 있다. behavior는 widget의 appearance를 바꾸는 것이 아니라, functionallity만 넣어주는 것이다. multiple inheritance를 통해 사용할 수 있지만, touch가 중복되거나, 동일 property를 갖는 경우에 대해 조심해서 사용해야 한다. 현재는 아래의 Behavior만 사용할 수 있다. | ButtonBehavior | ToggleButtonBehavior | DragBehavior | . style . Window: window를 import 하여, 몇 가지 application window와 global parameter, event를 설정할 수 있다. clearcolor property 를 통해 backgrond color를 설정할 수 있다. bold: bold property로 폰트 설정할 수 있다. background_normal, background_down: background_normal과 background_down property를 통해, Button의 background image를 설정할 수 있다. &lt;Label&gt;, &lt;Button&gt;과 같이 widget에 대한 적용을 하면 코드 전체의 Label에 영향을 미칠 수 있다. | set할 때의 순서도 중요함. Button을 먼저 set하면, Label 것이 overwrite. | . Factory . 새로운 class를 등록할 수 있다. 말 그대로 정말 만들어내는 것. Factory.register()으로, kivy에서 ‘name’으로 사용할 수 있는 class를 등록할 수 있다. 등록된 name은 .kv에서 사용 가능하다. Factory.unregister()으로, 등록된 name을 해제할 수도 있다. | Line을 unregister로 해제하고, register로 새로만든 Line을 등록함으로써 Line을 재정의하는 방식으로도 사용할 수 있다. | kwargs parameter가 Line의 모든 property를 가지고 있는데, 여기서 kwargs['width']를 사용하여 Line의 두께를 바꿀 수 있음. | . | . ",
    "url": "/docs/kivy/app-game-book-4",
    
    "relUrl": "/docs/kivy/app-game-book-4"
  },"16": {
    "doc": "kivy app & game book ch5",
    "title": "combining animation",
    "content": "+ , &amp; 을 통해 animation을 combine할 수 있다. | + : one after another. | * : at the same time. | . Animation1 &amp;= Animation2 으로 2가 1과 동시에 수행되도록 할 수 있고, Animation1 += Animation2 으로 2가 1이 수행된 이후에 수행되도록 할 수 있다. + 의 동작은 on_complete로 animation을 연결한 것과 유사하지만, on_complete에서 animation 두 개를 연결해 loop를 만든 것과 같은 동작을 수행할 수는 없다. ",
    "url": "/docs/kivy/app-game-book-5#combining-animation",
    
    "relUrl": "/docs/kivy/app-game-book-5#combining-animation"
  },"17": {
    "doc": "kivy app & game book ch5",
    "title": "kivy app & game book ch5",
    "content": "Atlas . 여러 image를 처리하기 위한 방법으로, sprite로도 알려져 있다.(오호 sprite는 unity에서 낯익다) application image들을 하나의 큰 image로 group화 하여 request를 줄이는 방식이다. 쉽게 말하면 img1~100을 받을 때 100번 req 해야하는데, 이걸 이어 붙이고 좌표를 보내서 1번의 req로 받겠다! 하나의 큰 atlas 이미지와 각 이미지에 대한 좌표들을 json file로 저장하는 작업을 내부적으로 해준다. atlas 이미지를 생성하기 위해 pillow library가 필요하며 아래와 같은 명령어로 실행함 . | python -m kivy.atlas invasion 100 *.png (basename, size, img list) | basename.png, basename.atlas(json format) 이 생성됨 | . atlas 이미지를 사용하기 위해서 kv에서는 source: atlas://src/path/imgfile와 같이 사용한다. SoundLoader . kivy에서 sound effect를 사용하기 위해서 SoundLoader를 사용한다. SoundLoader.load('soundfile.wav')와 같이 soundfile을 load하면 Sound class를 return하고 이를 .play()를 통해 재생시킬 수 있다. Animation . 목적지까지 움직이는 것과 같은 간단한 animation을 설정하는데 사용한다. default로 period를 1초로 갖는다. on_start, on_progress, on_complete의 3개의 event를 bind 해서 사용한다. 여기서 progress는 진행 정도를 말한다. animation instance의 parameter는 적용할 widget의 어떤 property도 될 수 있다. | 이게 무슨말이냐면 Animation(font_size=72, d=2) 같이 font_size를 설정할 수도 있고 property는 다된다는 거다 transition으로 목적지까지의 transition의 모양을 설정할 수 있다. on_complete를 통해 두 개의 animation을 연결할 수 있다. 이 방식은 on_complete 즉 종료되면 다른 animation을 실행하도록 하는 방식이다. | . Automatic bind . pos: self.parent.pos를 layout에 선언함으로써 parent가 움직일때, child도 움직이도록 할 수 있다. | 이렇게 parent가 바뀔 때, child가 따라서 pos가 바뀌게 할 수 있는데, 이 pos의 변화와 parent가 아닌 다른 event에 의한 pos의 변화가 겹쳐서 발생하면 문제가 생길 수 있음. 따라서 parent의 pos 변화를 받도록 하는 widget을 만들고, 실제 widget은 마음대로 움직이도록 함 | . scheduling . kivy Clock을 import하여 사용한다. schedule_interval 을 통해 주기적으로 해당 함수를 실행할 수 있다. (단위는 초) schedule_once 를 통해 한 번만 해당 함수를 실행할 수도 있다. 마찬가지로 unschedule을 통해 schedule을 해제할 수 있다. multi-touch . 모든 kivy widget과 component는 multi-touch를 지원한다. kivy는 각 touch에 대한 data들을 제공하여 이를 활용해 multi-touch를 구현할 수 있도록 한다. collide_point로, touch.pos가 어디에 있는지를 통해 touch를 구분하도록 한다. on_touch_down, on_touch_move, on_touch_up은 모두 같은 touch reference를 사용하기 때문에 이를 통해 touch를 구분할 수 있다. touch.ud (user data)를 활용하여 down을 어디서 했는지 구분하는 등으로 사용 가능함. keyboard . Window.request_keyboard 를 통해 keyboard를 받는데, paremeter 중 하나로 keyboard가 closed될 때 수행될 함수를 넣어주며, 보통 unbind를 넣는다. bind(on_key_down=) 를 통해, key를 누를 때 수행 될 함수를 구현하여 bind 해 준다. mobile device에서는 keyboard를 사용하지 않아야 할 수도 있다. 어떤 event에 bind 할 수 있는 method의 개수는 제한이 없다. ",
    "url": "/docs/kivy/app-game-book-5",
    
    "relUrl": "/docs/kivy/app-game-book-5"
  },"18": {
    "doc": "kivy app & game book ch6",
    "title": "kivy app & game book ch6",
    "content": "video widget . kivy 에서는 video widget을 제공한다. property: . | allow_stretch - True이면, screen size에 맞게 video가 커질 수 있다. | color - play 중이지 않을 때 덮어쓰는 색상. | source - 재생할 비디오 위치. | #:set A B를 통해 kv에서 주소를 define하여 사용할 수 있다. | . | . 일반적으로 Factory를 통해 재정의하여 사용하는데, property를 활용하여 재정의 함. | on_state에서 state가 변경될 때 호출되며 (state는 play, pause, stop을 가짐) | on_eos는 end of stream 일때 호출되며 | _on_load는 video가 memory로 load될 때, ready to play일 때 실행 됨. | . AsyncImage . AsyncImage는 Image와 달리 image가 loading 되는 동안 program을 사용할 수 있도록 한다. 큰 이미지를 받을 때 사용될 수 있다. etc . 이외에 sidebar, ScrollView와 같은 kivy widget들의 활용이 있다. ",
    "url": "/docs/kivy/app-game-book-6",
    
    "relUrl": "/docs/kivy/app-game-book-6"
  },"19": {
    "doc": "kivy",
    "title": "kivy",
    "content": "Widget Parameter: kivy widget constructor parametor를 추가하고 싶을 때, property 명시하기 위해 keyword argument를 사용한다. font: 한글폰트등의 폰트 적용 방법. 폰트도 하나의 StringProperty이다. font_name으로 적용한다. | 눈누에서 무료폰트를 확인할 수 있음. | . connect .kv with .py: self.ids.~으로 접근하는 경우도 있으며, layout_content=ObjectProperty(None)와 같이 Property를 생성하면, 해당 .kv 클래스에서 동일 name으로 사용하는 방식도 있다. dynamic added scroll view: scroll view에 들어갈 widget들이 많을 때, 그걸 동적으로 추가하고 넣어주는 코드가 필요하다. 인스타나 페북도 그런 것들의 일종이고.. 이거 없으면 kivy는 한 번에 다 보여주려고 하면서 죽어버린다. mark up: markup=True와 함께, text에 부분적으로 color, font 등의 수정을 할 수 있다. 그니까 책에서 배운건 text 전체에 적용되는데, 이건 딱 그 일부분만 적용되도록 할 수 있다는 것이다. action bar: action bar를 top: root.height로 위치 설정을 하였을 때, 윈도우에서 제대로 설정 되었지만, 안드로이드에서는 위에 상태표시줄까지 위치로 잡아 그만큼 잘리는 현상이 발생하였다. 해당 코드를 pos_hint: {'top': 1}로 해결할 수 있다. label size . label의 text에 따라 label size가 조절되지 않아 엄청 못생기고 밉게 보이는 경우에 대한 해답을 각각 .py, .kv에서 찾았다. label의 text에 따라 size를 조절해주는 코드 . l.bind(width=lambda s, w: s.setter('text_size')(s, (w, None))) l.bind(texture_size=l.setter('size')) . width에 따라 s(label)의 text_size를 setter로 (w, None)으로 설정. 즉, text_size를 width로 설정하는 것 . kv 파일에서 text에 따라 size를 조절해주도록 하는 코드 . text_size: self.width, None size_hint: 1, None height: self.texture_size[1] . 와 같이, text_size를 width로 맞추고, height를 width로 정해진 texture_size의 값으로 설정. 주의사항: 위와 같은 size 조절은 bind로 발생함. 즉 width와 texture_size가 변경될 때 dynamic하게 코드를 변경하는 것. 따라서 위와 같은 코드 바로 뒤에 l.height와 같은 코드를 사용해도 height를 구할 수 없음. | 실제로 scrollview 구현 중 height에 따른 scroll 위치를 적용하는데 애를 먹음. | l.bind(height=self.lavel_height_changed)와 같이, height에 bind를 통해 원하는 값들을 처리할 수 있음. | . ",
    "url": "/docs/kivy/kivy-etc",
    
    "relUrl": "/docs/kivy/kivy-etc"
  },"20": {
    "doc": "TDD 01",
    "title": "TDD 01",
    "content": "TDD 공부 시작 . 최근 회사에서 안드로이드 F/W의 모듈 추가와 수정을 하면서 단위 테스트가 필요한 경우가 많았다. TDD라는 말이 그 전부터도 한참 많이 들어왔던 단어인데, 최근들어 공부해야 겠다는 생각이 들었다. 결국 단위 모듈 테스트라면 파이썬에선 __main__으로 되는 것 아닌가 싶기도 한데.. 켄트 백이 쓴 Test-Driven Development: By Example을 번역한 책을 기준으로 TDD 공부를 시작하였다. 이 책은 예제를 위주로 다루고 있고, chapter에 따른 내용들은 내 맘대로 이름을 붙여 정리해보았다. TDD . 테스트 주도 개발은 단순한 두 가지 규칙만을 따른다. | 오직 자동화된 테스트가 실패한 경우에만 새로운 코드를 작성한다. | 중복을 제거한다. | . 위 규칙들에서 아래와 같은 함의를 갖는다. | 매 결정사항에 대해 피드백을 제공하는 실행 가능한 코드를 기반으로 하는 유기적인 설계를 해야한다. | 직접 테스트를 작성한다. | 개발 환경은 작은 변화에도 빠르게 반응할 수 있어야 한다1. | 쉬운 테스트를 위해 응집도는 높고 결합도는 낮은 컴포넌트들로 구성되게 설계해야 한다2. | . 프로그래밍 순서 . | 실패하는 작은 테스트를 작성한다. 처음에는 컴파일조차 되지 않을 수 있다. | 빨리 테스트가 통과하게끔 만든다. 코드가 개판이어도 좋다. | 리팩토링을 통해 테스트를 통과하게 만든 문제들을 제거한다. | . 이런 코드 방식으로 다음과 같은 함의를 가질 수 있다. | 결함을 감소시켜 품질보증을 능동적으로 할 수 있다. | 고약한 예외 상황의 숫자를 충분히 낮출 수 있다면 프로젝트 매니저가 정확히 추정하여 고객을 매일의 개발 과정에 참여시킬 수 있다3. | 깔끔하고 쉽게 이해가능한 코드로 기술적인 대화가 분명해질 수 있다면 협력하기 더 쉬워질 것이다. | . TDD가 필요한 이유 . 용기를 주기 때문이다. 불확실함으로 인한 두려움은 망설이게하고 / 커뮤니케이션을 줄이고 / 피드백을 피하게 한다. 불학실함을 이기고 구체적인 학습을 통해 분명하게 커뮤니케이션하고/ 구체적인 피드백을 받아야 한다. TDD를 하는 것은 톱니바퀴를 만드는 것과 같고, 하나가 작동하면 걔는 영원히 작동하는 것이다. TDD란 프로그래밍 중 내린 결정과 그 결정에 대한 비드백 사이의 간격을 인지하고, 이 간격을 통제할 수 있게 해주는 기술이다. 결국 TDD는, 단순하게 시작하고, 자동화된 테스트를 만들고, 새로운 설계에 대한 도입을 위해 리팩토링 하는 것이다. | 따라서 컴파일 등의 과정이 최소화된 파이썬 등의 언어가 제일 적합하다. &#8617; . | 실제 안드로이드 F/W에서는 클래스 간의 결합도가 높아 단일 모듈 테스트가 굉장히 어렵거나 불가능한 항목이 많았다. &#8617; . | 특정 상황에서만 나오는 예외 케이스에 대해 고객의 요구사항을 테스트에 추가한다는 말로 보인다. 항상 이슈가 되는 건 100% 발생 이슈가 아니라 발견할 수 없는 특정 상황 이슈니까. &#8617; . | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-01",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-01"
  },"21": {
    "doc": "TDD 02",
    "title": "chapter 1",
    "content": "이 책은 예제를 통해 개념을 설명해가고 있다. 첫 번째 예제는 다음과 같다. 계속 강조했듯이, 우선 테스트를 만든다. (여기선 Junit을 사용) . public void testMultiplication() { Dollar five = new Dollar(5); five.times(2); assertEquals(10, five.amount); } . 얼마나 테스트를 먼저 만드냐면, 위 코드는 컴파일이 되지 않는데, 이유는 아래와 같다. (이게 코드냐! 싶다) . | Dollar 클래스가 없음 | 생성자가 없음 | times 함수 없음 | amount 필드 없음 | . TDD에서는 우선 위처럼 테스트를 만들고 아래의 문제점들을 찾아 하나씩 해결하는 방식이다. 여기서 위 문제들을 해결해서 컴파일이 되게 만든다. 딱히 예제가 필요하지 않을 것 같다. 컴파일이 되게 만들었다면, 테스트를 통과하게 만들어야 한다. 처음엔 테스트를 빠르게 통과하게 만드는데, 어느정도냐면 임의의 값에 대한 테스트 성공이 아니라, 특정 테스트 값에 대해 성공하도록 수정해도 된다1. multiple(5, 2) def multiple (int a, int b): return 10 . 의존성과 중복 . 목표는 코드를 바꾸지 않으면서 의미있는 테스트를 추가하는 것인데, 현재 이것은 불가능하다. TDD에서 중요한 것은 코드의 중복을 제거함으로써 의존성을 줄이고 하나의 코드 수정으로 적용될 수 있도록 하는 것이다. ",
    "url": "/docs/extreme-programming/tdd/tdd-book-02#chapter-1",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-02#chapter-1"
  },"22": {
    "doc": "TDD 02",
    "title": "chater 2",
    "content": "TDD의 구체적 기본원리 . TDD 기본원리를 조금더 확인해 보면 . | 재빨리 필요한 모든 요소를 포함한 테스트를 하나 추가한다. | 실행 가능하게 만든다. 깔끔하고 단순한 해법이 명백하다면 그 것을 사용하고, 그렇지 않다면 이전에 했던 것처럼 최대한 빨리 테스트를 통과하게 한다. 여기서 핵심은 테스트를 통과만 할 수 있는 더러운 코드를 잠시는 작성해도 된다는 것이다. | 올바르게 만든다. 위에서 저지른 죄를 되돌리고 중복을 제거한다. 해야할 것들을 리스트 업한다. | . TDD vs ADD . 코딩의 방향은 작동하는 깔끔한 코드를 얻는 것이다. Test-Driven Development (TDD): 작동하는 코드를 먼저 만들고 깔끔한 코드로 수정하는 방식. Architecture-Driven Development (ADD): 깔끔한 코드를 먼저 만들고 작동하는 코드를 만드는 방식. 오류 제어하기 . 설계상의 결함이나 부작용, 코드상 꺼림찍한 느낌이 있다면 이를 테스트로 변환하고 테스트를 수정하는 것이 TDD의 일반적인 주제이다. 부족한 부분을 보완하기 위해 테스트를 수정하고 이후에 다시 코드를 수정할 수 있도록 한다. ",
    "url": "/docs/extreme-programming/tdd/tdd-book-02#chater-2",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-02#chater-2"
  },"23": {
    "doc": "TDD 02",
    "title": "chapter 3",
    "content": "value object pattern . 값 객체 패턴이라고 번역되는 이 패턴의 가장 큰 특징은 객체의 인스턴스 변수가 생성자를 통해 설정된 후에는 결코 변하지 않는다는 것이다. 값 객체는 별칭 문제에 대해 걱정할 필요가 없다는 장점이 있다. 하나의 수표에 $5를 설정하고, 다른 수표에서 $5를 설정했을 때, 두 번째 수표의 값을 수정했을 때 첫 번째 수표의 값이 변하게 되는 문제를 별칭 문제라고 한다. 값 객체에서는 위와 같은 상황에서 누군가 $7를 원한다면 새로운 객체를 만들어야 한다. 또 값 객체는 모든 연산에 대해 새 객체를 반환해야 하며, 따라서 equals()를 구현하여 반환된 값들을 판별해야 한다. Dollar라는 객체에 대해 assertTrue(new Dollar(5).equals(new Dollar(5)))를 만족할 수 있도록 equals()의 구현이 필요하다. TDD 기본원리에서 배운 무작정 통과를 사용하면 다음과 같이 테스트를 통과할 수 있을 것이다. public boolean equals(Object object) { return true;} . 삼각측량 . 라디오 신호를 수신국 A, B가 감지하고 있을 때, 각 수신국 사이의 거리를 알고 있고 신호의 방향을 알고 있다면 이를 통해 신호의 거리와 방위를 계산하는 계산법이다. 코드에 적용하면 두 개 이상의 예제로 코드를 일반화 하는 방법이다. 어떻게 리팩토링을 해야하는지 감이 오지 않을 때, 설계를 어떻게 해야할지 떠오르지 않을 때 삼각측량을 통해 문제를 다른 방향에서 생각해볼 수 있다. 삼각측량 적용 . 아래와 같이 테스트를 추가하여 삼각측량을 할 수 있을 것이다. 그러면 return true로 해결할 수 없고, 실제 값을 비교하도록 하는 수정이 비로소 이루어진다. public void testEquality() { assertTrue(new Dollar(5).equals(new Dollar(5))); assertFalse(new Dollar(5).equals(new Dollar(6))); } public boolean equals(Object object) { Dollar = dollar = (Dollar) object; return amount == dollar.amount; } . 위 코드는 Equals(null)을 고려하지 않았지만, 괜찮다. 리스트 업하고 나중에 확인하자. 디자인 패턴 적용 과정 . | 디자인 패턴(값 객체)가 하나의 또 다른 오퍼레이션을 암시한다는 것을 보았다. | 해당 오퍼레이션을 테스트했다. | 오퍼레이션을 간단히 구현하였다. | 테스트를 추가하였다. (삼각측량) | 리팩토링했다. | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-02#chapter-3",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-02#chapter-3"
  },"24": {
    "doc": "TDD 02",
    "title": "chapter 4",
    "content": "수정한 코드를 통해 테스트를 수정할 수 있다. chapter 1의 코드를 수정해본다. Dollar.equals()가 구현되었고, times()는 값 객체 패턴에 따라 새로운 값을 return하게 되었으므로 아래와 같이 테스트와 코드의 결합도를 낮추는 방향으로 수정될 수 있다. public void testMultiplication() { Dollar five = new Dollar(5); assertEquals(new Dollar(10), five.times(2)); } . 수정 사항은 보다 명확하게 의도를 알 수 있으며, Dollar.amount를 사용하지 않아 변수를 private으로 변경할 수 있게 되었다. TDD의 생각 . 완벽함을 위해 노력하지 않는다. 모든 것을 두 번 말함으로써(code와 test로) 자신감을 가지고 결함을 낮추기를 희망한다. 때로 결함이 생길 수 있지만, 그럴 땐 테스트를 어떻게 작성해야 했는지에 대한 교훈을 얻고 다시 시작한다. 여태까지 . | 오직 테스트를 향상시키기 위해서만 개발된 기능을 사용했다. | 두 테스트가 동시에 실패하면 망한다는 점을 인식했다. | 위험 요소가 있음에도 계속 진행했다. | 테스트와 코드 사이의 결합도를 낮추기 위해, 테스트하는 객체의 새 기능을 사용했다. | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-02#chapter-4",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-02#chapter-4"
  },"25": {
    "doc": "TDD 02",
    "title": "chapter 5",
    "content": "골치아픈 큰 요구사항과 테스트 . $5 + 10CHF = $10 (환율이 2:1 일 경우) 위 요구사항의 테스트에 대해 어떻게 접근할 것인가? 우선 Dollar 테스트를 복사한 후 수정하여 사용해보도록 한다. public void testFrancMultiplication() { Franc five = new Franc(5); assertEquals(new Franc(10), five.times(2)); assertEquals(new Franc(15), five.times(3)); } . 위 테스트를 통과하기 위해 어떻게 해야할까? 한 번에 통과하기는 어려울 것이다. 빠르고 쉽게 통과하기 위해, (TDD의 정신이다) 다시 Dollar 코드를 복사하여 Franc로 바꾸는 방법을 사용하도록 한다2. 더럽고 지저분하고 마음이 찝찝하다. 이런 코드를 짠다니 싶지만, TDD 구체적 기본원리를 확인한다. 우선 실행이 되고 테스트를 통과하는 코드를 만들고, 중복 제거와 같은 더러운 코드를 없애는 일은 그 다음임을 기억한다. 검토해보면 . | 큰 테스트를 공략할 수 없다. 그래서 진전을 나타낼 수 있는 자그마한 테스트를 만들었다. | 뻔뻔스럽게도 중복을 만들고 조금 고쳐 테스트를 작성했다. | 설상가상으로 모델 코드까지 복사하고 수정하여 테스트를 통과했다. | 중복이 사라지기 전에는 집에 가지 않겠다고 약속했다. | . | 이 단계가 너무 작고 이상해보여도 TDD의 핵심은 이런 작은 단계를 밟을 줄 아는 능력을 가지는 것이라고 한다. 일이 꼬일 경우 차근차근 해결해갈 수 있는 능력을 가질 수 있는 능력. &#8617; . | 중요한 점은 Dollar 코드를 복사하기 이전에 Ch3, Ch4를 통해 코드를 단순화 해놓은 점이 큰 도움이 되었다는 것. &#8617; . | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-02#chapter-5",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-02#chapter-5"
  },"26": {
    "doc": "TDD 02",
    "title": "TDD 02",
    "content": "1부 화폐 예제 . TDD의 기본원리 . | 재빨리 테스트를 하나 추가한다. | 모든 테스트를 실행하고 추가한 것이 실패하는지 확인한다. | 코드를 바꾼다. | 성공을 확인한다. | 리팩토링을 통해 중복을 제거한다. | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-02",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-02"
  },"27": {
    "doc": "Token Passing Operator in C++",
    "title": "Token Passing Operator in C++",
    "content": "일하면서 신가하게 본 cpp 코드에 대해서 정리해보려고 한다. 오늘 처음 본 것은 아닌데, Token pasting operator라는 이전엔 듣도 보도 못한 operator가 있더라. token passing operator란 . MS docs에 정의된 내용을 보면, 전처리 연산자로 @define과 함께 사용되는 operator이다1. 토큰을 다른데 붙여서 사용한다는건데, 예제를 보지 않으면 선뜻 이해하기 어려운 개념이다. 실제 처음 코드를 봤을 땐, 이런 문법이 있나 싶더라.. 기본 예제 . #include &lt;stdio.h&gt; #define token(base, postfix) base##postfix int main(void) { int testval = 5000; printf(\"%d\", token(test, val)); return 0; } . 가장 기본적인 예제는 위와 같다. base에 postfix를 붙여주는 방식으로 token passing operator가 사용된다. 이런 코드는 응용해서 사용하면 이해하기 불편할 수 있지만 새로운 사용성을 제시한다. 응용 예제 . #define TO_VALID(name) { \\ name##_valid = true; \\ } #define PUT_IF_VALID(name, value) { \\ if(name##_valid) { \\ name = value; \\ } \\ } int test; int game; bool test_valid = false; bool game_valid = false; TO_VALID(test); PUT_IF_VALID(test, 5000); PUT_IF_VALID(game, 5000); . 위와 같이 define을 함수화시켜서 서로 다른 여러 개의 name에 대해 접근할 수 있다. 주의 사항 . | define의 option처럼 사용되는 것으로, 일반문에서 사용할 수 없다. | 기본적으로 사용되는 변수들은 이미 정의되어 있어야 한다. | 아래와 같은 코드도 사용가능하지만, 추천하지 않는다. #define VAL_NAME(base, postfix) base##postfix int token(test, val) = 3; printf(\"%d\", testval); . | . | 여기에 나온 #, #@ operator들은 개념이 정말 쉬운데, 내 리눅스 pc에서는 빌드되지 않더라..(왜지?) 사실 그닥 사용성이 애매한 operator들일 것 같아(실제로 의미있게 쓰이는데가 있는지도 잘 모르겠다) 이번 포스팅에 정리하지 않는다. &#8617; . | . ",
    "url": "/docs/algorithm/language/cpp/token-passing-operator",
    
    "relUrl": "/docs/algorithm/language/cpp/token-passing-operator"
  },"28": {
    "doc": "TDD 03",
    "title": "chapter 6",
    "content": "죄 지우기 . 이 전에(ch5) 저지른 죄(복붙!)를 청소해야 한다. 가능한 방법은 Franc이 dollar를 상속하거나, 공통 부모를 갖도록 하는 방법이 있을 것이다. 프랑이 달러를 상속해? 말도 안되보이고, 실제 구현해보면 얻을 이득이 없다는 것을 깨달을 것이다. 공통 분모를 갖는 방향으로 수정을 해 나간다. class Money { protected int amount; } class Dollar extends Money { } . 죄 지우기2 . ch3에서 만든 equals()는 Dollar와 Franc에 모두 남아있을 것이다. 이 함수를 Dollar class에서 지우고, Money class에서 아래와 같이 수정한다. public boolean equals(Object object) { Money money = (Money) Object; return amount == money.amount; } . 그러면 뭐가 안됐나 보니까, Franc.equals()에 대한 테스트가 없었으므로 ch3에서 수정한 테스트 코드도 아래와 같이 수정해준다. public void testEquality() { assertTrue(new Dollar(5).equals(new Dollar(5))); assertFalse(new Dollar(5).equals(new Dollar(6))); assertTrue(new Franc(5).equals(new Franc(5))); assertFalse(new Franc(5).equals(new Franc(6))); } . 왜 하는지 모르겠더라도 이런 테스트들을 작성한 후에 코드를 수정하도록 해야한다. 작성하고 보니, Dollar와 Franc가 거의 동일한 테스트를 중복해서 하고 있다. 이런 죄들을 반드시 지워야만 한다. Franc도 Dollarclass와 동일하게 equals()를 고칠 수 있고, 결국 Money class의 equals와 동일한 함수가 나와 코드를 제거할 수 있을 것이다. 근데 참 찝찝하다.. Franc와 Dollar의 비교는 어찌할 것인가.. 일단 뒤로 미루도록 한다. 여태까지 . | 공통된 코드를 첫 번째 클래스(Dollar)에서 상위 클래스(Money)로 단계적으로 옮겼다. | 두 번째 클래스(Franc)도 Money의 하위 클래스로 만들었다. | 불필요한 구현을 제거하기 전에 두 equals() 구현을 일치시켰다. | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-03#chapter-6",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-03#chapter-6"
  },"29": {
    "doc": "TDD 03",
    "title": "chapter 7",
    "content": "미뤄둔 죄 . 앞서 미뤄둔 죄를 해결하기 위한 테스트를 작성한다. public void testEquality() { assertTrue(new Dollar(5).equals(new Dollar(5))); assertFalse(new Dollar(5).equals(new Dollar(6))); assertTrue(new Franc(5).equals(new Franc(5))); assertFalse(new Franc(5).equals(new Dollar(6))); } . 당연히 테스트는 실패한다. 우선 빠르게 문제를 해결하면 아래와 같이 수정할 수 있다. public boolean equals(Object object) { Money money = (Money) object; return amount == money.amount &amp;&amp; getClass().equals(money.getClass()); } . 여태까지 . | 결함을 끄집어내서 테스트로 만들었다. | 완벽하지 않지만 봐줄만하게 테스트를 통과시켰다. | 더 많은 동기가 있기 전에 더 많은 설계를 도입하지 않기로 했다. | . 그런데 참.. 한 챕터에 별로 하는게 없는 것 같다. ",
    "url": "/docs/extreme-programming/tdd/tdd-book-03#chapter-7",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-03#chapter-7"
  },"30": {
    "doc": "TDD 03",
    "title": "chapter 8",
    "content": "Money class의 하위 클래스 Dollar, Franc가 하는 일이 별로 없으므로, 아예 제거하고 싶다. 이를 제거하기 위해서 단계적으로 진행해본다. Method 통합 . //Franc class Franc times(int multi) { return new Franc(amount * multi); } //Dollar class Dollar times(int multi) { return new Dollar(amount * multi); } //Money class abstract Money times(int multi); . 이렇게 method 선언이라도 공통부로 옮김으로써, 다음 단계에서 times를 Money class 단에서 쓸 수 있어 통합할 수 있게 된다. Factory Method . 하위 클래스에 대한 직접적인 참조가 적어진다면 하위 클래스를 제거하기 위한 방향이라고 볼 수 있다. Money class에 Dollar를 반환하는 Factory Method를 도입할 수 있다. // Money Class static Dollar dollar(int amount) { return new Dollar(amount); } public void testMultiplication() { Money five = Money.dollar(5); assertEquals(Money.dollar(10), five.times(2)); assertEquals(Money.dollar(15), five.times(3)); } // testFrancMultiplication()도 동일하게 남아 있음. public void testEquality() { assertTrue(Money.dollar(5).equals(Money.dollar(5))); assertFalse(Money.dollar(5).equals(Money.dollar(6))); assertTrue(Money.franc(5).equals(Money.franc(5))); assertFalse(Money.franc(5).equals(Money.franc(6))); assertFalse(Money.dollar(5).equals(Money.franc(5))); } . | five의 생성이 Money의 Factory Method를 참조한다. | Dollar에 대한 참조가 사라지길 바라므로, Dollar five = ~를 Money five = ~로 바꾼다. | 앗.. Money.times() 를 구현해야 된다. | assertEquals에서 사용하는 Dollar의 생성도 Factory Method를 참조한다. | 이제 어떤 client code도 Dollar라는 이름의 하위 클래스가 있다는 사실을 알지 못한다. | 하위 클래스의 존재를 테스트에서 분리하여 어떤 모델 코드에도 영향을 주지 않고 상속 구조를 변경할 수 있게 되었다. | . 여태까지 . | times()의 메서드 서명부를 통일시킴으로써 중복 제거를 향해 한 단계 더 전진했다. | 최소한의 method 선언부라도 공통 superclass로 옮겼다. | Factory method를 통해 테스트 코드에서 콘크리트 하위 클래스의 존재 사실을 분리했다. | 하위 클래스가 사라지면서 몇몇 테스트가 불필요한 여분의 것이 된다고 생각했지만 일단 뒀다. (testFrancMultiplication) | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-03#chapter-8",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-03#chapter-8"
  },"31": {
    "doc": "TDD 03",
    "title": "chapter 9",
    "content": "할 일 목록 체크 . TDD를 진행하면서 TDD의 기본은 빠른 구현과 테스트 통과, 코드 중복 제거에 있기 때문에, 하나의 일을 해냄으로써 파생되는 할 일들을 계속해서 목록화 하여 관리하는 것이 필요하다. 예를 들면 현재까지 할일은 다음과 같다. | $5 + 10CHF = $10 (환율이 2:1 이라면) | Money의 반올림? | hashCode() | Equal null | Equal Object | Dollar/Franc 중복 | 공용 times | 통화? | testFancMultiplication 제거 | . 할 일 목록에서 귀찮고 불필요한 하위 클래스를 제거하는데 도움이 될 것을 찾아본다. 통화 개념을 도입해보면 어떨까? 통화 개념을 어떻게 구현하길 원하는가? 아니, 통화 개념을 어떻게 테스트하길 원하는가? . 통화개념 . 통화 개념을 위해 복잡한 객체들을 사용하고, 필요한 만큼 만들어지도록 하기 위해 경량 팩토리(flyweight factories)를 사용할 수 있지만, 우선 문자열을 대신 쓰도록 한다. // 통화개념을 위한 간단한 테스트 public void testCurrency() { assertEquals(\"USD\", Money.dollar(1).currency()); assertEquals(\"CHF\", Money.franc(1).currency()); } . // 통화개념을 위한 테스트 작성 후 테스트 통과를 위한 코드 // Money class abstract String currency(); // Dollar class, Franc도 똑같다. String currency() { return \"USD\"; } . 통화개념 refactoring . Dollar와 Franc를 모두 통합할 수 있는 동일한 구현이 가능할까? 리팩토링이 가능하지 않을까? . //Dollar class, Franc도 똑같다. private String currency; Dollar(int amount) { this.amount = amount; currency = \"USD\"; } String currency() { return currency; } . 위와 같이 Dollar와 Franc의 구현이 끝나면, currency와 currency()를 Money로 가져올 수 있다. // Money class protected String currency; String currency() { return currency; } . 통화개념 refactoring 2 . 문자열 USD와 CHF를 정적 팩토리 메서드로 옮긴다면 두 생성자가 동일해질 것이고 공통 구현을 만들 수 있을 것이다. 우선 constructor에 인자를 추가한다. // Dollar class Dollar(int amount, String currency) { this.amount = amount; this.currency = \"USD\"; } . 그러면 constructor를 호출하는 곳에 에러가 발생하고, 이를 수정한다. // Money class static Money Dollar(int amount) { return new Dollar(amount, null); } // Dollar class Money times(int multi) { return new Dollar(amount * multi, null); } . 이제 factory method가 “USD”를 전달할 수 있다. // Money class static Money dollar(int amount) { return new Dollar(amount, \"USD\"); } // Dollar class, Franc도 똑같다. Dollar(int amount, String currency) { this.amount = amount; this.currency = currency; } . 이렇게 작은 단계를 밟아가는 것이(한 방에 해도 되는데) 꼭 이렇게 해야하는 것은 아니다. 하지만, 중요한 점은 이렇게도 일할 수 있는 능력이 있어야 한다는 것이다. 얼마나의 보폭으로 작업할지는 직접 판단하며 줄였나 들였다 해야한다. 통화개념 refactoring 3 . 지금의 수정을 확인하면 Dollar와 Franc의 constructor가 동일하다. 즉 상위 클래스로 옮길 수 있다. // Money class Money(int amount, String currency) { this.amount = amount; this.currency = currency; } // Dollar class, Franc도 똑같다. Dollar(int amount, STring currency) { super(amount, currency); } . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-03#chapter-9",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-03#chapter-9"
  },"32": {
    "doc": "TDD 03",
    "title": "chapter 10",
    "content": "times() . 9장의 times()를 보면 Dollar의 currency는 항상 Dollar이므로 아래와 같이 수정할 수 있다. // Dollar class, Franc도 똑같다. Money times(int multi) { return new Dollar(amount * multi, currency); } . 근데, Dollar를 갖는지, Money를 갖는지가 중요한가? 이런 질문에 시스템 기반으로 깊은 생각이 필요할 것이다. 하지만 우리가 가지고 있는 테스트 코드들을 통해 컴퓨터에게 10초 이내의 답을 얻을 수도 있을 것이다. 수정하고 테스트를 돌려 컴퓨터에게 답을 얻자. TDD에서 가끔은 컴퓨터가 10초면 대답할 수 있는 것을 엔지니어가 몇 분 동안 고민하지 않고 테스트를 하기도 한다. 컴퓨터에게 답 얻기 . // Dollar class Money times(int multi) { return new Money(amount * multi, currency); } . 위와 같이 수정을 진행하고, 컴퓨터에게 오류가 있는지 묻는다. 오류: . | Money를 콘크리트 클래스로 바꿔야 한다. | 그 후, 다시하면 이해하기 어려운 에러 메세지들이 출력된다. (test fail error) | 에러 메세지를 이해하기 쉽게 toString()을 정의한다. // Money class public String toString() { return amount + \" \" + currency; } . | 아니 테스트 없이 코드를 생성한다고?? 말이 되는가? . | 원래는 테스트 작성 후 toString()을 작성하는 것이 맞다. 하지만, . | 화면의 결과를 보려던 참이다. | toString()은 디버그 출력에만 쓰이기 때문에 잘못 구현되어도 리스크는 적다. | 이미 에러 상태인데 새로운 테스트를 작성하는 것은 좋지 않을 것 같다. | . | . | 이렇게 조금 더 구체적으로 오류의 방향들을 찾아갈 수 있다. | . times refactoring . 위에서 에러가 되는 이유는 chapter 7에서 구현한 equals() 함수에 있다. equals()에서는 class가 같은 지를 확인하고 있는데, 정말 해야할 것은 class가 같은 것이 아니라, currency가 같은 지에 대한 판단이다. currency의 판단에 대한 test를 작성하고 싶지만, 이미 에러가 난 상태에서 테스트를 작성하지 않는 것이 좋을 것 같다. times refactoring 2 . 차근차근 단계를 밟아간다. | 컴퓨터에게 답 얻기에서 수정한 코드를 다시 times()에서 수정한 원래 코드로 돌려는다. | test가 다시 통과한다. | currencyt가 같은 지를 체크할 수 있는 새로운 테스트를 작성한다. public void testDifferentClassEquality() { assertTrue(new Money(10, \"USD\").equals(new Dollar(10, \"USD\"))); } . | 실패한다. equals() 코드가 클래스가 아니라 currency를 비교하도록 해야할 것 같다. | equals를 수정한다. // Money class public boolean equals(Object object) { Money money = (Money) object; return amount == money.amount &amp;&amp; currency().equals(money.currency()); } . | test가 통과한다. | Dollar.times()가 Money를 return하도록 수정한다. // Dollar class, Franc도 똑같다. Money times(int multi) { return new Money(amount * multi, currency); } . | test가 통과한다. | 동일한 구현이 Franc(“CHF”)에서도 적용되는 것을 확인한다. | 7번에서 구현한 함수를 상위 클래스(Money)로 끌어 올린다. | . 여태까지 . | 두 times()를 일치시키기 위해 그 함수들이 호출하는 다른 함수들을 맞추어주고 상수를 변수로 바꿔주었다. | 단지 디버깅을 위해 테스트 없이 toString()을 작성했다. | Dollar 대신 Money를 반환하는 변경을 시도한 뒤 그것이 잘 작동할지를 테스트가 말하도록 했다. | 실험해본 것을 되돌리고 또 다른 테스트를 작성했다. 테스트를 작동했더니, 실험도 제대로 작동했다. | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-03#chapter-10",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-03#chapter-10"
  },"33": {
    "doc": "TDD 03",
    "title": "TDD 03",
    "content": " ",
    "url": "/docs/extreme-programming/tdd/tdd-book-03",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-03"
  },"34": {
    "doc": "TDD 04",
    "title": "chapter 11",
    "content": "여태까지의 작업들로, 하위 클래스 Dollar, Franc에는 이제 생성자 밖에 남지 않았다. 생성자 때문에 하위 클래스가 있을 필요는 없으므로 하위클래스를 제거한다. 하위 클래스 제거 . 코드의 의미를 변경하지 않으면서, 하위 클래스에 대한 참조를 상위 클래스에 대한 참조로 변경할 수 있다. 먼저 factory method를 고치도록 한다. // Money class, franc 에 대한 factory class도 동일하게 수정 static Money dollar(int amount) { return new Money(amount, \"USD\"); } . 이렇게 되면, Franc는 지울 수 있는데, 다른 테스트에서 new Dollar를 사용하는 곳이 남아있다. testDifferentClassEquality()에서 동치성 비교에 사용하고 있었다. testEquality()에서 충분히 테스트 되고 있는 것 같다. 사실상 Money class로 통합되었으므로 과한 테스트를 수정해 아래와 같이 중복을 지울 수 있겠다. public void testEquaility() { assertTrue(Money.dollar(5).equals(Money.dollar(5))); assertFalse(Money.dollar(5).equals(Money.dollar(6))); assertFalse(Money.dollar(5).equals(Money.franc(5))); } . 삭제 및 정리의 근거: . | testDifferentClassEquality() 는 클래스 대신 currency를 비교하도록 하는 코드로, 여러 클래스가 존재할 경우 의미가 있다. 클래스를 지우는 현재에 의미가 없는 테스트이다. | Dollar와 Franc에 대한 별도의 테스트가 존재하지만, 클래스가 두 개 일때는 차이가 있을 수 있었지만, 통합된 로직상에서 별도의 테스트는 필요 없다. | . 여태까지 . | 하위 클래스를 삭제했다. | 기존 구조에 필요했지만, 변경된 구조에서 필요없는 테스트도 삭제했다. | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-04#chapter-11",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-04#chapter-11"
  },"35": {
    "doc": "TDD 04",
    "title": "chapter 12",
    "content": "우리의 할일 목록엔 $5 +10CHF = $10 (환율 2:1인 경우)와 같은 덧셈이 있다. 전체 더하기 기능을 어떻게 시작해야 할지 모르겠으니, $5 + $5 = $10과 같은 간단한 예부터 시작해보자. 간단한 덧셈 . 당연히 테스트부터 만든다. public void testSimpleAddition() { Money sum = Money.dollar(5).plus(Money.dollar(5)); assertEquals(Money.dollar(10), sum); } . plus에 대한 구현은, 이전에 배운 것처럼 우선은 사기(가짜 구현) 치듯 Money.dollar(10)을 return할 수도 있겠지만, 어떻게 해야할 지가 명확하므로 구현해버린다. Money plus(Money addend) { return new Money(amount + addend.amount, currency); } . 환율 고려 . 환율을 고려한 덧셈의 방식에는 여러가지 방식이 있을 것이다. Money와 비슷하게 동작하지만, 두 Money의 합을 나타내는 객체를 만드는 것.. 저자는 여기서 두 가지 메타포를 생각했다. | Money의 합을 지갑처럼 가지고 있어, 서로 다른 금액과 통화가 존재 | 각 통화와 금액을 환율에 맞춰 수식으로 존재 | . 두 번째 방법으로 진행한다. 이럴 경우 Money가 수식의 가장 작은 단위가 될 것이며, 연산의 결과로 Expression들이 생기고, 그 중 하나에 더한 값이 나올 것이다. 환율 고려 2 . TDD 논리에 따라 테스트를 작성해 나간다. 테스트 작성이 제일 중요한 듯 하다. | 환율을 적용함으로써 얻어지는 reduced를 사용한다. public void testSimpleAddition() { ... assertEquals(Money.dollar(10), reduced); } . | 환율이 적용되는 곳은 bank니까 public void testSimpleAddition() { ... Money reduced = bank.reduce(sum, \"USD\"); assertEquals(Money.dollar(10), reduced); } . | 왜 Money가 아닌 Bank가 reduce()를 맡아야 하는가? | . | Expression(여기선 Money들의 수식)는 여기서 핵심이고, 핵심이 되는 객체가 다른 부분에 대해서 될 수 있는 한 모르도록 해야, 유연하고, 테스트하기 쉽고, 재활용이나 이해하기 쉽다. | Expression과 관련된 오퍼레이션이 많을 것이고, 모든 오퍼레이션을 Expression에만 추가하면 무한히 커질 수 있기 때문이다. | 만약 Bank가 별 필요가 없다면, 기꺼이 Expression으로 구현을 옮길 수도 있다. | . | 당장은 bank가 할 건 없다. 객체 하나만 있으면 된다. public void testSimpleAddition() { ... Bank bank = new Bank(); Money reduced = bank.reduce(sum, \"USD\"); assertEquals(Money.dollar(10), reduced); } . | 두 Money의 합은 Expression이어야 한다. public void testSimpleAddition() { ... Expression sum = five.plus(five); Bank bank = new Bank(); Money reduced = bank.reduce(sum, \"USD\"); assertEquals(Money.dollar(10), reduced); } . | $5 만들기. public void testSimpleAddition() { Money five = Money.dollar(5); Expression sum = five.plus(five); Bank bank = new Bank(); Money reduced = bank.reduce(sum, \"USD\"); assertEquals(Money.dollar(10), reduced); } . | . 컴파일하기 . 와.. 이걸 컴파일 해야한다. | Expression이 필요하다. cllass보다 inteface가 가벼우니까 interface로 만든다. interface Expression | Money.plus()가 Expression을 구현해야 한다. Expression에는 아직 아무 구현도 없으니까.. Class Money implements Expression | Bank class와 reduce() 함수가 필요하다. class Bank Money reduce(Expression source, String to) { return null; } . | 이제 컴파일이 되고, 테스트가 바로 실패한다. | 오.. 이제 가짜 구현을 할 수 있다. | 가짜! Money reduce(Expression source, String to) { return Money.dollar(10); } . | 테스트 통과! 리팩토링할 준비가 되었다. | . 여태까지 . | 큰 테스트($5 + 10CHF)를 작은 테스트($5 + $5)로 줄여서 발전을 보일 수 있었다. | 필요한 계산(Expression)에 대한 가능한 메타포들을 신중히 생각해보았다. | 새 메타포를 기반으로 기존의 테스트를 재 작성했다. | 테스트를 빠르게 컴파일했다. | 테스트를 실행했다. | 진짜 구현을 위한 리팩토링을 기다린다. | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-04#chapter-12",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-04#chapter-12"
  },"36": {
    "doc": "TDD 04",
    "title": "chapter 13",
    "content": "모든 중복을 제거해야 테스트를 완료했다고 말할 수 있다. 코드 중복은 없더라도, 데이터 중복이 있을 경우에도 제거해주어야 한다. 가짜구현 Money.dollar(10)은 테스트 코드에 있는 five.plus(five)와 데이터 중복이라고 볼 수 있다. 우리는 Money들에 대한 연산을 수식으로 존재하게 만들어 주기로 했으므로 덧셈의 결과가 Money가 아닌 수식으로 존재해야 한다. Sum . plus에 대한 연산의 결과는 Money를 반환하였지만, 이건 엄연히 말하면 수식으로 존재하는 것이 아니고, Sum과 같은 Expression으로 존재해야 한다1. 두 Money의 합은 Sum이어야 한다. public void testPlusReturnsSum() { Money five = Money.dollar(5); Expression result = five.plus(five); Sum sum = (Sum) result; assertEquals(five, sum.augend); assertEquals(five, sum.addend); } . 우선 테스트를 작성했다. 이 테스트는 오래가지 못할 것이다. 연산의 외부 행위가 아닌 내부 구현에 너무 깊게 관여하기 때문이다. 그래도, 테스트를 통과하면 우선 한 걸음 나아간 것이다. 실행해보면 에러가 계속 날거고, 통과하기 위해 아래와 같은 수정이 필요하다. // Sum class 생성 class Sum { Money augend; Money addend; } // Money class Expression plus(Money addend) { return new Sum(this, addend); } . 또, Sum의 생성자도 필요하고, Sum은 Expression이어야 한다. // Sum class class Sum implements Expression Sum(Money augend, addend) { this.augend = augend; this.addend = addend; } . 이제, testSimpleAddition()에서 Bank.reduce()는 Sum을 전달받는다. sum으로 받는 통화가 모두 같고, reduce로 얻을 통화도 같다면, 결과는 sum의 money들을 합친 값이어야 한다. public void testReduceSum() { Expression sum = new Sum(Money.dollar(3), Money.dollar(4)); Bank bank = new Bank(); Money result = bank.reduce(sum, \"USD\"); assertEquals(Money.dollar(7), result); } . 테스트에 대한 코드는, . //Bank class Money reduce(Expression source, String to) { Sum sum = (Sum) source; int amount = sum.augend.amount + sum.addend.amount; return new Money(amount, to); } . 와 같이 구현될 수 있을텐데 이 코드는 두 가지 이유로 지저분하다2. | 캐스팅(형변환), 이 코드는 모든 Expression에 대해 작동해야 한다. | 두 단계에 거친 reference. | . 아래와 같이 메서드를 Sum 내부로 옮길 수 있을 것이다. //Bank class Money reduce(Expression source, String to) { Sum sum = (Sum) source; return sum.reduce(to); } //Sum class public Money reduce(String to) { int amount = augend.amount + addend.amount; return new Money(amount, to); } . reduce . 위의 테스트는 통과했고, 위 코드에 더 할 것이 명확하지 않으니 새로운 할 일을 확인하여 테스트를 생성한다. reduce(Money)의 경우에 대한 테스트이다. public void testReduceMoney() { Bank bank = new Bank(); Money result = bank.reduce(Money.dollar(1), \"USD\"); assertEquals(Money.dollar(1), result); } . 해결 코드: . | 지저분하다. //Bank class Money reduce(Expression source, String to) { if (source instanceof Money) return (Money) source; Sum sum = (Sum) source; return sum.reduce(to); } . | 한 걸음3. //Bank class Money reduce(Expression source, String to) { if (source instanceof Money) return (Money) source.reduce(to); Sum sum = (Sum) source; return sum.reduce(to); } //Money class public Money reduce(String to) { return this; } . | 깔끔하다. //Expression Money reduce(String to); // Bank class Money reduce(Expression source, String to) { return source.reduce(to); } . | . 여태까지 . | 중복이 제거되기 전까지 테스트를 통과한 것으로 치지 않았다. | 앞으로 필요할 것으로 예상되는 객체(Sum)의 생성을 강요하기 위한 테스트를 작성했다. | 빠른 솓도로 객체 구현을 시작했따. | 한 곳에서 캐스팅을 이용해 구현했다가, 테스트 통과 후 적당한 자리로 코드를 옮겼다. | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-04#chapter-13",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-04#chapter-13"
  },"37": {
    "doc": "TDD 04",
    "title": "chapter 14",
    "content": "환전 . 단순한 변환을 생각하면 2Franc이 있는데 이것을 Dollar로 바꾼다고 생각해보자. 자 테스트는 이미 만들었다. public void testReduceMoneyDifferentCurrency()) { Bank bank = new bank(); bank.addRate(\"CHF\", \"USD\", 2); Money result = bank.reduce(Money.franc(2), \"USD\"); assertEquals(Money.dollar(1), result); } . 테스트 통과를 위해 아래와 같은 코드를 작성할 수 있다. //Money class public Money reduce (string to) { int rate = (currency.equals(\"CHF\") &amp;&amp; to.equals(\"USD\")) ? 2 : 1; return new (Money(amount / rate, to)); } . 문제는, Money가 환율을 알아선 안된다는 것. Bank가 알아야할 부분이고, 각 객체가 해야할 역할에 정확하고 독립적이어야 한다. Bank가 환율을 알도록하고, money에서는 이 값을 가져다가 사용하도록 한다. //Bank int rate (String from, String to) { return (from.equals(\"CHF\") &amp;&amp; to.equals(\"USD\")) ? 2 : 1; } //Money public Money reduce(Bank bank, String to) { int rate = bank.rate(currency, to); return new Money(amount / rate, to); } . 여태까지 . | 필요할 것이라 생각되는 인자를 빠르게 추가했다. | 코드와 테스트 사이에 있는 데이터 중복을 제거한다. | 자바의 기본 동작에도 의구심이 든다면 테스트를 작성한다. | . | 그니까, sum 안에 두 값이 있다면, sum은 두 값의 합이라는 식을 나타내는 객체가 되는 것이니까. 현재의 plus는 수식이 완료된 값을 반환하므로 구현하기로 한 방향과 맞지 않다. &#8617; . | TDD지만 객체지향적 개념을 배워가는 것 같다. 이런 개념들이 기본적으로 필요하단 말이겠지. &#8617; . | 이렇게 느리고 맘에 안들게 한 걸음씩 밟아가야 하는 것인가.. &#8617; . | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-04#chapter-14",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-04#chapter-14"
  },"38": {
    "doc": "TDD 04",
    "title": "TDD 04",
    "content": " ",
    "url": "/docs/extreme-programming/tdd/tdd-book-04",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-04"
  },"39": {
    "doc": "TDD 05",
    "title": "chapter 15",
    "content": "하나씩 원하는 테스트를 작성한다. 이 테스트는 생각이 나는대로 수도 코드처럼 코드를 작성한다. 컴파일과 테스트를 통과하는 방향으로 수정해나가는 것이기 때문에, 컴파일 에러가 날 수 있다. 컴파일 에러가 나는 것을 두려워하는 것이 아니라, 중요한 것은 한 번에 하나씩 확실하게(완벽하라는 건 아니다. 빠르게가 더 중요하니까) 고쳐나가는 것이다. 우리가 할 일이 무엇인지를 알려주는 것이 컴파일과 테스트이다. 중복을 제거하고 상속이나 범용성을 가질 수 있는 코드들을 변경하면서 다시 고치는 것이다. 변경 후에 영향을 미치는 다른 부분들을 컴파일러가 알려주면 그 부분도 수정한다. ",
    "url": "/docs/extreme-programming/tdd/tdd-book-05#chapter-15",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-05#chapter-15"
  },"40": {
    "doc": "TDD 05",
    "title": "chapter 16",
    "content": "테스트도, 차후에 읽을 때 이해하기 좋게 코드를 짠다. 효율적인 TDD . | TDD를 쓰고 개발량이 증가한다. | TDD를 쓰고 동일 기능을 구현하는데 필요한 라인 수가 감소한다. | 디버깅, 통합 작업, 다른 사람한테 설명하는데 걸리는 시간 등을 합친 것보다 경제적이다. | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-05#chapter-16",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-05#chapter-16"
  },"41": {
    "doc": "TDD 05",
    "title": "chapter 17",
    "content": "이 장에서는 어떻게 해 나가야 하는지와 테스트를 돌아본다. 다음에 해야할 일은 무엇일까? 생각이 들 때 . | SmallLint 같은 code critic 프로그램을 실행하는 것도 좋다. | 내가 놓친 것을 잡아줄 수 있기 때문에. | . | 어떤 테스트들이 추가로 더 필요할까? 생각하는 것. | 실패해야하는 테스트가 성공하는 경우. | 실패해야하는 테스트가 실패하는 경우. | . | 막무가내로 개발하며 해야할 일을 적어놓은 리스트를 비우느 ㄴ것. | 말과 개념이 잘 통하는지 확인 | 현재 설계로 제거하기 어려운 중복이 있는지 확인. | . 메타포 . 메타포는 클래스 명 등을 정하는 아이디어와도 같은 것인데, 메타포를 통해 설계가 완전히 바뀔 수 있다. 즉, 중요하다. 이 책에서 예시를들고 있는 expression을 통한 통화 계산은 나도 생각을 못한 것이었는데, 저자도 10 ~ 20번의 금전 관련 프로그램에 대한 설계들을 통해 얻은 통찰이라고 한다. 코드와 테스트 비교 . | 코드와 테스트 사이에 비슷한 수준의 함수 개수와 라인 수가 유지 된다. | 테스트 코드는 공통된 테스트를 뽑아내는 작업으로 라인 수를 줄일 수 있다. | . | 코드 복잡도를 보면 테스트 코드는 코드 복잡도가 1이다. | 분기나 반복이 전혀 없기 때문이다. | . | . 테스트의 질 . TDD의 부산물로 자연스레 생기는 테스트들은 시스템과 함께 유지되야 할 만큼 유용하다. 하지만 이 테스트들이 다른 종류의 테스트를 대체할 수는 없다. | 성능 테스트 | 스트레스 테스트 | 사용성 테스트 | . 테스트의 질을 가늠하는 지표 . | 명령문 커버리지(statement coverage) . | TDD는 100%의 명령문 커버리지를 따르게 되는데, 모든 함수들이 테스트 케이스에 의해 검증된다는 것을 의미한다. JProbe를 통해 확인할 수도 있다. | . | 결함 삽입(defect insertion) . | 코드의 내용을 바꾼 후 테스트가 실패하는지 보는 것이다. 수동으로 할 수 있지만 Jester를 통해 확인할 수도 있다. | 그니까 테스트 통과하려고 거짓말 한 것들을 거르기 위한 것으로 보인다. | . | . 테스트 커버리지를 향상시키는 법 . | 더 많은 테스트 케이스를 작성하는 것. | 예를 들면 TDD 개발자는 6개의 테스트를 작성한다면, 전문 테스터는 65개의 테스트를 작성한다. | . | 프로그램의 로직을 단순화 하는 것. | 코드를 줄여서 테스트가 다양한 경우를 다루게 한다. | . | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-05#chapter-17",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-05#chapter-17"
  },"42": {
    "doc": "TDD 05",
    "title": "TDD 05",
    "content": "이전까지는 예제 없이 정리가(설명이) 안되는 것들이 많았지만, 이제는 구체적인 예제는 없이 TDD의 개념과 진행 방향에 대해서만 정리하도록 한다. ",
    "url": "/docs/extreme-programming/tdd/tdd-book-05",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-05"
  },"43": {
    "doc": "TDD 06",
    "title": "chapter 18",
    "content": "크기를 넓혀서 테스트 뿐 아니라 테스트 프레임워크를 만들어 테스트를 해보도록 한다. 테스트 프레임워크를 만드는데도, 가장 먼저 할 일은 테스트를 작성하는 것이다. 파이썬을 사용한다고해도, 이전에 배웠던 TDD의 기본 로직은 변하지 않는다. 똑같이 테스트와 구현, 중복 제거를 진행한다. getattr . 파이썬에선 메서드의 이름을 함수처럼 다룰 수 있는데, 이를 활용해 테스트 코드를 보다 간단히 할 수 있다. class wasRun: def __init(self, name): self.wasRun = None self.name = name def run(self): method = getattr(self, self.name) method() def testMethod(self): self.wasRun = 1 test = wasRun(\"testMethod\") test.run() . 위와 같은 코드에서, testMethod를 name으로 넣고, run()에서 getattr()를 통해 받아서 실행하게 할 수 있다. 이 후 run() 코드를 상위 클래스에 두어 모든 테스트에서 run()을 통해 테스트를 진행할 수 있도록 구현할 수 있다. TestCaseTest . class TestCase: def __init__(self, name): self.name = name def run(self): method = getattr(self, self.name) method() class WasRun(TestCase): def __init__(self, name): self.wasRun = None TestCase.__init__(self, name) def testMethod(self): self.wasRun = 1 class TestCaseTest(TestCase): def testRunning(self): test = wasRun(\"testMethod\") assert(not test.wasRun) test.run() assert(test.wasRun) TestCaseTest(\"testRunning\").run() . 처음 완성한 테스트는 위와 같다. test가 run했는지를 확인하기 위한 테스트인데, test F/W을 만드는데 test를 하고 있는 미묘한 상황이다. ",
    "url": "/docs/extreme-programming/tdd/tdd-book-06#chapter-18",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-06#chapter-18"
  },"44": {
    "doc": "TDD 06",
    "title": "chapter 19",
    "content": "3A (pattern) . 테스트를 작성하다보면 발견하게되는 공통된 패턴. | arrange(준비) - 객체를 생성한다. | act(행동) - 어떤 자극을 준다. | assert(확인) - 결과를 검사한다. | . 성능과 격리 . 테스트를 작성하다보면 3A 패턴을 확인하게되고, 여러 테스트에서 1번 arrange가 동일하게 사용되는 경우를 확인할 수 있다. 예를 들면, 7과 9의 사칙연산에서 각 사칙연산 테스트는 4개지만, 7과 9는 모든 테스트에서 사용된다. 이러한 객체들을 새로 생성하는가에 대해 두 가지 제약이 상충한다. | 성능 - 테스트가 될 수 있는한 빨리 실행되길 원함. 여러 테스트에서 같은 객체를 사용한다면, 하나의 객체 생성으로 모든 테스트에서 사용하게 함. | 격리 - 하나의 테스트의 성공과 실패가 다른 테스트에 영향을 주지 않길 원함. | . 이런 제약에서 당연히 테스트 커플링을 만들지 않는 방향으로 가는 것이 좋다. 테스트 커플링이 발생하면, A 테스트 후 B 테스트시 성공하더라도 B 테스트 후 A 테스트 시 실패하는 등 예기치 못한 동작들이 발생하기 쉽다. ",
    "url": "/docs/extreme-programming/tdd/tdd-book-06#chapter-19",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-06#chapter-19"
  },"45": {
    "doc": "TDD 06",
    "title": "chapter 20",
    "content": "중복이 여러 개 생길 때까지 기다리는 것이 아니라 바로바로 중복이 나올 때마다 리팩토링을 한다. (켄트 백 방식) . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-06#chapter-20",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-06#chapter-20"
  },"46": {
    "doc": "TDD 06",
    "title": "chapter 21",
    "content": "테스트 구현 순서 . | 테스트를 통해 얻을 수 있는 것이 있고, 테스트를 만들 수 잇다는 확신이 드는 것부터 만든다. | 테스트를 하나 성공시켰는데, 그 다음 테스트를 만들면서 문제가 생기면 다시 돌아가서 생각해보도록 한다. | 모든 테스트가 성공하던 시점을 체크포인트로 삼는 것. | . | . 필요한 것을 빠르게 . TDD의 기본은 필요한 것들을 빠르게 만드는 것이다. 진짜가 될 가짜 구현을 만드는 것. | 어떤 것이 필요한지를 확인한다. | 예를들면 Test에 testBrokenMethod()를 예상하여 만든다. | . | 필요한 것을 빠르게 만든다. | test broken 상태는 많은 경우와 처리방식이 있겠지만, raise Exception 같이 핸들링하지 않고 우선 빠르게 생성한다. 아직 예외를 잡고 고치지 않았지만, 분명 선언을 한다는 것이 중요하다. | . | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-06#chapter-21",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-06#chapter-21"
  },"47": {
    "doc": "TDD 06",
    "title": "chapter 23",
    "content": "collecting parameter . 매개변수 수집이라고 번역된 이 패턴은 메서드가 매개변수를 받아서 처리하는 것. 예를 들면, 아래와 같은 코드처럼 적용이 된다. (별 것도 아닌데 거창하게 적어놨다..) . | 장점은 run()이 명시적으로 return하지 않아도 된다는 점이다. | 하지만 저 목적보단 메서드가 명확한지, 논리적인지가 중요하다. 여기선 run()이 할당하는 부분과, 할당 후 테스트를 수행하는 부분으로 나뉘는데 이는 좋지 않으므로 할당을 위에서 해주는 방식으로 수정한다. ```python #1 def run(self): result = TestResult() … #use | . #2 def run(self, result): … #use ``` . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-06#chapter-23",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-06#chapter-23"
  },"48": {
    "doc": "TDD 06",
    "title": "chapter 24",
    "content": "xUnit . xUnit은 30개 이상의 프로그래밍 언어에 포팅되어 있고, 아마 사용하려는 언어에 이미 되어있을 것. 앞선 실습처럼 xUnit을 직접 구현함으로써 얻을 수 있는 것이 있다. | 숙달: 직접 만들어보면, xUnit을 이해하기 쉬움. | 탐험: 새로운 언어를 접할 때, 간단한 xUnit을 만듦으로서 기능들을 경험. | . | 마틴 파울러: 소프트웨어 공학 역사에 이토록 많은 사람이 이렇게 짧은 코드로 이토록 큰 은혜를 입은 적이 없었다. | . TDD python . 하나 하나 따라가지 않았지만, python에서 TDD를 사용하는 방법은 java에서와 유사했다. 동일하게 TDD의 원칙에 따라 테스트와 함께 코드를 작성해나갔고, 다른점은 python의 언어 특징에 맞게 리팩토링 및 수정이 진행되었다는 점이다. ",
    "url": "/docs/extreme-programming/tdd/tdd-book-06#chapter-24",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-06#chapter-24"
  },"49": {
    "doc": "TDD 06",
    "title": "TDD 06",
    "content": "통화 예시는 이제 끝났다. 이제는 xUnit에 대한 예시를 위해 python에서의 TDD의 좀 더 교묘한 활용을 보게된다. ",
    "url": "/docs/extreme-programming/tdd/tdd-book-06",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-06"
  },"50": {
    "doc": "TDD 07 (테스트 패턴)",
    "title": "테스팅 패턴",
    "content": "격리된 테스트 . 테스트끼리 서로 아무 영향도 미치지 않아야 한다. | 테스트 결과를 보면, 여러 개의 fail이 맨 처음 하나의 fail로부터 비롯되는 경우가 많은데, 이는 잘못된 테스트이다. | 문제가 하나면 fail은 하나여야 한다. | . | 일부 테스트 실행을 위해, 선행 테스트가 실행되어야 하는 경우 이는 잘못된 테스트이다. | 문제가 실행 순서에 상관없이 작동할 수 있어야 한다. | . | 주어진 문제를 작은 단위로 분리한다. | 때론 매우 많은 노력이 필요한 작업이지만, 각 테스트를 실행하기 위한 환경을 쉽고 빠르게 세팅하는 것. | 결과적으로 시스템이 응집도는 높고 결합도는 낮은 객체의 모음으로 구성. | . | . 전체 애플리케이션 대상의 테스트보다 작은 스케일의 테스트를 하면 독립적이기 쉽다. 테스트 목록 . 시작하기 전 작성해야 할 테스트 목록을 모두 적어둘 것. 발 디딜 곳이 확실해지기 전에 전진하지 말 것. 테스트 목록을 적어두고, ‘지금’ 할일인지, ‘나중에’ 할일인지 판단하여 결정한다. 테스트 우선 . 테스트는 대상이 되는 코드를 작성하기 직전에 작성하는 것이 좋다. 테스트를 먼저하면, 테스트하지 않음으로서 발생하는 스트레스가 줄고, 효율적인 작업이 가능하다. 단언 우선 . 단언(assert)를 테스트 작성시 가장 먼저 쓰고 시작한다. | 시스템을 개발할 때 무슨 일부터 하는가? . | 완료된 시스템이 어떨 거라고 알려주는 이야기부터 작성한다. (user story) | . | 특정 기능을 개발할 때 무슨 일부터 하는가? . | 기능이 완료되면 통과할 수 있는 테스트부터 작성한다. | . | 테스트를 개발할 때 무슨 일부터 하는가? . | 완료될 때 통과해야 할 단언부터 작성한다. | . | . 단언의 기능 . | 테스트하고자 하는 기능이 어디에 속하는지 정함. | 기존의 함수 수정할지, 새로운 메서드를 추가할지, 새로운 클래스를 만들지 정함. | 메서드의 이름을 정함. | 어떤 식으로 검사할지 정함. | 이 테스트가 제안하는 다른 테스트는 무엇이 있을지 고려함. | . 테스트 데이터 . 읽을 때 쉽고 따라가기 좋은 데이터를 사용한다. 데이터 값을 산발하는게 아니라, 데이터에 차이가 있다면 그 사이에 의미가 있어야 한다. | 1과 2 사이에 개념적 차이가 없다면 1을 사용. 시스템이 여러 입력을 다운다면, 테스트 역시 여러 입력을 반영해야 한다. 하지만 세 항목으로 가능한 테스트를 열 개를 하면 안된다. 동일한 상수의 사용을 피한다. | 예를 들어 minus()의 구현에 1-1을 쓰지말고 2-1을 사용. 혹시라도 인자의 순서가 엎어지는 것도 고려하는 테스트를 위함. | . 명백한 데이터 . 테스트 자체에 예상되는 값과 실제 값을 포함하고 이 둘 사이의 관계를 드러내기 위해 노력하라. | 예를 들면, 환율이 2:1, 수수료가 1.5%일 때 100을 환전하는 테스트를 작성할 때, . | assertEquals(new TestMoney(49.25, \"testmoney\"), result) | assertEqulas(new TestMoney(100 / 2 * (1 - 0.015), \"testmoney\"), result) | 아래와 같이 작성하면 사용된 숫자와 예상되는 결과 사이의 관계를 알 수 있고, | 어떻게 기능을 구현해야 하는지도 다시 확인하게 된다. | . | . 한 단계 테스트 . 다음 테스트를 고를 때의 기준은 새로운 무언가를 가르쳐 줄 수 있으며, 구현할 수 있다는 확신이 드는 테스트이다. ‘아는 것에서 모르는 것으로’ 라는 방향성을 가지고 테스트를 고른다. 시작 테스트 . 테스트를 맨 처음 시작할 때는, 오퍼레이션이 아무 일도 하지 않을 경우를 먼저 테스트한다. | 복잡한 수식 계산에서는, 답이 0이라거나 등 함수를 사용하지 않아도 결과가 나오는 테스트. | . 설명 테스트 . 자동화된 테스트가 널리 쓰이기 위해, 테스트를 통해 설명을 요청하고, 테스트를 통해 설명하라. | 시퀀스 다이어그램이 있다면, 이를 테스트로 작성해 보는 방법 등. | . 학습 테스트 . 외부에서 만든 소프트웨어나 API들을 사용해야할 때, API가 예상대로 작동한다는 확인을 위한 작은 테스트를 만들 수 있다. 통과한다면 API를 제대로 이해한 것이고, 실패한다면 실제 프로그램에 넣었어도 제대로 작동하지 않았을 것이다. 회귀 테스트 . 시스템에 장애가 생겼을 때 제일 먼저 해야할 일. 장애로 인해 실패하는 테스트, 통과할 경우 장애가 수정되었다고 볼 수 있는 테스트를 간단하게 작성한다. 회귀 테스트는 완벽한 선견지명이 있다면 처음 코딩할 때 작성되어야 할 테스트이다. 어떻게 하면 이 테스르를 애초에 작성할 수 있었을까 생각해본다. 시스템 장애를 쉽게 해결할 수 없다면, 리팩토링을 해야할 수 있고, 이는 설계가 마무리되지 않았다는 것이다. 방향잡기 . 키보드로 뭘 쳐야할지 안다면 . | 명백한 구현 잘 모르겠다면 | 가짜 구현 올바른 설계가 명확하지 않다면 | 삼각측량 기법 사용 그래도 잘 모른다면 | 휴식 그래도…? | 코드를 다 지워버리고 다시! | . 자식 테스트 . 지나치게 큰 테스트 케이스를 돌리는 방법. 원래 테스트 케이스의 깨지는 부분에 해당하는 작은 테스트 케이스를 작성하고, 그 작은 테스트 케이스가 실행되도록 하라. 그 후에 다시 원래의 큰 테스트 케이스를 추가하라. | 큰 테스트를 작성하면, 왜 이렇게 테스트가 클까? 어떤 방식으로 더 작게 만들 수 있었을까? | 한 번에 여러 구현이 필요한 테스트의 경우 가짜 구현이나 테스트의 일부분을 잠시 지우기도 함. | . 모의 객체 . 비용이 많이 들거나, 복잡한 리소스에 의존하는 객체를 테스트할 때 사용하는 방법이다. | 예를 들면 database, 내가 보는 안드로이드 F/W 단에서는 Phone, Tracker 등. | DB의 경우, 시작 시간이 오래걸리고, 깨끗하게 유지하기 어렵고, 원격 서버에 위치하는 등의 문제가 있는데, 이를 진짜 DB를 쓰지않고 Mock을 사용함으로써 해결. 객체의 가시성(visibility)에 대해 격려되어 있다. | . | 가독성이 좋다는 장점이 있음. | 실제 객체나 DB의 큰 구조나 데이터를 보지 않아도 되고 이해할 수 있음. | 설계 과정에서 커플링이 감소. 그치만 모의 객체가 진짜 객체와 동일하게 동작하지 않을 수 있으므로 프로젝트에 위험 요소가 하나 추가된다. | 모의 객체요 엩스트 집합을 진짜 객체가 사용 가능해질 때 그대로 적용해서 위험을 줄일 수 있음. | . 셀프 션트 . 한 객체가 다른 객체와 올바르게 대화하는지 테스트하려면 테스트 대상이 되는 객체가 원래의 대화 상대가 아니라 테스트 케이스와 대화하도록 하면 된다. 테스트 케이스에 별도의 이벤트 리스너를 만들어 사용하면, 테스트 케이스가 일종의 모의 객체처럼 사용된다. 셀프 션트 패턴은 테스트 케이스가 구현할 인터페이스(리스너)를 얻기 위해 인터페이스를 추출해야 한다. | 인터페이스 추출 vs 기존 클래스를 블랙박스 테스트 - 둘 중 더 쉬운 방법을 선택. | 추출된 인터페이스는 여러 곳에서 쓰이기도 함. | 파이썬 같은 언어는 테스트에 필요한 오퍼레이션만 구현하면 되지만, 자바 같은 언어는빈 메서드라도 인터페이스를 구현해야 함. | . 로그 문자열 . 메시지 호출 순서가 올바른지 검사하고자 할 때 로그 문자열을 사용한다. | 로그 문자열을 가지고 있다가 메시지가 호출될 때마다 그 문자열에 추가하도록 하는 방식. 특히 옵저버를 구현하고, 이벤트 통보가 원하는 순서대로 발생하는지 확인하고자 할 때 유용하다. 이벤트 통보만 확인하고, 순서는 상관없다면 문자열 집합을 저장하고 집합 비교를 수행하면 된다. | . 크래시 테스트 . 에러 코드(발생하기 힘든 에러 상황)를 어떻게 테스트하는가? 테스트되지 않은 코드는 작동하는 것이 아니다. (박력) 수많은 에러 상황을 어떻게 테스트할 것인가? 작동하길 원하는 부분에 대해서만 하면 된다. | file system에 여유 공간이 없을 경우에 대한 테스트를 원한다면, 실제로 큰 파일을 만들 수 있지만, 가짜구현을 만들어서 테스트하는 방식이다. | . 깨진 테스트 . 혼자서 프로그래밍을 할 때 프로그래밍을 깨진 상태로 끝마치는 것이 좋다. 마무리되지 않은 문장을 보면 그 전에 무슨 생각을 했었느지 떠올리게 되고, 생각의 실마리를 떠올리고 나면 문장을 마무리하고 계속 진행할 수 있다. 프로그래밍도 똑같이 테스트 케이스를 작성하고 실패를 확인하면 나중에 코딩을 할 때, 어느 작업부터 시작할지 명백히 알 수 있다. 몇 주간의 간극 후에도 개발을 그대로 이어나갈 수 있는 책갈피를 가지게 되는 것이다. 깨끗한 체크인 . 팀단위 프로그래밍을 할 때 프로그래밍을 모든 테스트가 성공한 상태로 끝마치는 것이 좋다. 내가 마지막으로 코딩한 후 무슨 일이 있을지 알 수 없기 때문에, 확신이 있는 상태로 마무리해야 한다. 테스트가 실패했다면, 작성한 코드를 완전히 이해하지 못했다는 것이고, . | 작성한 코드를 날려버리거나 | 수정하고 다시 테스트해야 한다. 테스트 통과를 위해 주석처리를 하는 말도 안되는 행동을 해서는 안된다. | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-07#%ED%85%8C%EC%8A%A4%ED%8C%85-%ED%8C%A8%ED%84%B4",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-07#테스팅-패턴"
  },"51": {
    "doc": "TDD 07 (테스트 패턴)",
    "title": "초록 막대 패턴",
    "content": "가짜로 구현하기(진짜로 만들기 전까지만) . 실패하는 테스트를 만든 후, 상수를 입력해서 테스트를 통과시킨다. | 테스트가 잘못 구현되어있는 경우 (시간을 들이지 않고) 이를 확인할 수 있음. | 리팩토링 해야하는 부분을 명확하게 찾을 수 있음. | 구체적인 예시를 갖고 시작하면 헷갈리는 일이 적음. | . 삼각측량 . 연관성 있는 테스트 두 개를 통해 구현을 증명하는 방법이다. TDD에서는 예가 두 개 이상일때에만 추상화를 하는 방식으로 보수적인 코딩을 할 수 있다. | 즉 추상적인 코드는, 두 개 이상의 예시로 삼각측량을 하고 구현을 하는 방식. 가짜구현이 감각에 의존한다면 삼각측량은 단순하지만 명확하다. | . 명백한 구현 . 어떻게 구현해야할지 확신이 든다면 위와 같은 방식을 쓰지 않고 그냥 구현해버려라. 그리고 테스트가 실패한다면 그제서야 위와 같은 방식을 사용해도 된다. 한 번에 어렵다면, 위와 같은 방식들로 ‘제대로 동작하는 코드’ 후에 ‘깨끗한 코드’ 만들기. 하나에서 여럿으로 . 컬렉션을 사용한 구현에서는, 단일 항목으로 구현하고 확장하는 방식. ",
    "url": "/docs/extreme-programming/tdd/tdd-book-07#%EC%B4%88%EB%A1%9D-%EB%A7%89%EB%8C%80-%ED%8C%A8%ED%84%B4",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-07#초록-막대-패턴"
  },"52": {
    "doc": "TDD 07 (테스트 패턴)",
    "title": "xUnit 패턴",
    "content": "xUnit 계열 테스트 프레임워크를 위한 패턴 . 단언(assertion) . 사람 대신 프로그램이 자동으로 코드가 동작하느닞에 대한 판단을 수행하도록 하라. 테스트를 완전히 자동화하려면 결과 평가에 사람의 판단을 끄집어내고, 컴퓨터가 모든 판단을 해야한다. | 판단 결과가 boolean 이어야 함. | 이 boolean이 컴퓨터에 의해 검증되어야 함. | assertEquals(), assertTrue(), assertFalse() | . 픽스처(fixture) . 여러 테스트에서 공통으로 사용되는 객체들을 생성할 때, 각 테스트 코드에 있는 지역 변수를 인스턴스 변수로 바꾸고 setUp()을 정의하여 초기화하도록 한다. | 복붙을 한다고 해도 반복 작성에 시간이 소요되는데, 이것을 단축할 수 있다. | setup에 수정이 필요한 경우, 반복 수정을 줄일 수 있다. | (-) 테스트 작성 전에 setUp()이 수행된다는 점과 어떻게 초기화되는지를 확인해야 한다. | 너무 많은 setUp 코드는 작성 전 많은 것들을 기억하게 하므로 호불호가 갈린다. | . 외부 픽스처 . 픽스처 중 외부 자원이 있을 경우 tearDown()을 통해 자원을 해제한다. tearDown()은 testMethod() 에서 무슨일이 생기든 호출된다. 하지만, setUp() 과정 중 문제가 발생하면 호출되지 않는다. 테스트의 목적 중 하나는 테스트 실행 전과 실행 후의 외부 세계가 동일하게 유지되야 하는 것이다. | 따라서 테스트 중 파일을 열었다면 꼭 테스트 끝나기전에 닫아주어야 함. | . 테스트 메서드 . 객체지향 프로그래밍 언어에서는 아래와 같이 구조 계층을 나눈다. | 모듈 | 클래스 . | 픽스처를 사용하고 이를 위해 클래스를 사용한다면, 같은 픽스처를 공유하는 메서드들이 동일한 클래스에서 작성될 것이다. | . | 메서드 . | test-로 시작하는 메서드 이름을 xUnit에서는 자동으로 테스트로 인식하고 testsuite를 생성한다. | 딱봐도 이해하기 쉬운 네이밍과, 코드. 최대한 간단하고 짧은 코드. | . | . 예외 테스트 . 예외가 발생하는 것이 정상인 경우에 대한 테스트. 예상되는 예외를 잡아서 무시하고, 예외가 발생하지 않는 경우에 테스트가 실패하게 만들면 된다. | 정확하게 원하는 종류의 예외만 잡아야 하는 것에 주의. public void testWantException() { try { // do method which is correct making exception. fail(); // fail if it is not catched } catch (WhatYouReallyWantException e) {} } . fail()은 xUnit에서 테스트 실패를 알려주기 위한 메서드이다. | . 전체 테스트 . 모든 테스트를 한번에 실행하기 위해서는 모든 테스트 슈트에 대한 모음을 작성하면 된다. | 각각의 패키지에 대해 하나씩, 그리고 전체 애플리케이션에서 패키지 테스트를 모아주는 테스트 슈트. | . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-07#xunit-%ED%8C%A8%ED%84%B4",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-07#xunit-패턴"
  },"53": {
    "doc": "TDD 07 (테스트 패턴)",
    "title": "TDD 07 (테스트 패턴)",
    "content": "TDD에서 인기있게 사용되는 패턴들에 대한 공부. TDD 트릭, 디자인 패턴, 리팩토링이 TDD와 어떤 관련이 있는지. 질문 . 어떻게 테스트할 것인가에 대해 이야기 하기 전에, 기본적인 전략에 대한 질문에 답해야 한다. | 테스트 한다는 것은 무엇을 뜻하는가? | 테스트를 언제 해야 하는가? | 테스트할 로직을 어떻게 고를 것인가? | 테스트할 데이터를 어떻게 고를 것인가? | . 그 어떤 소프트웨어 엔지니어도 아무리 작은 수정도 테스트 없이 릴리즈하지 않는다. 테스트를 하지만, 자동화된 테스트를 갖고있지 않을 뿐이다. ‘이 수정이 다른 부분에 영향을 미치지 않을까?’에 대해, 테스트하는 스트레스를 자동화 테스트에 맡기는 것이다. ",
    "url": "/docs/extreme-programming/tdd/tdd-book-07",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-07"
  },"54": {
    "doc": "TDD 08",
    "title": "디자인 패턴",
    "content": "우리가 언제나 새로운 문제를 푸는 것 같지만, 외부의 문제보다 사용하는 도구에 의한 내부의 문제를 푸는 경우가 많고, 공통의 해결책을 가진 문제를 발견하는 경우도 많다. 디자인 패턴의 성공은 객체 프로그래머들이 보는 공통성에 대한 증거이다. 카멘드 . 간단한 메서드 호출보다 복잡한 형태의 계산 작업에 대한 호출이 필요할 때, 계산 작업에 대한 객체를 생성해 이를 호출한다. 복잡한 계산 작업 호출을 위해 메서드 호출보다 객체를 사용하면 더 구체적이고 조작하기 쉬워진다. 호출 자체를 나타내는 객체를 만드는 것으로, 자바의 Runnable 인터페이스가 하나의 예이다. 값 객체 . 객체를 공유하였는데, 다른 곳에서 나도 모르게 객체의 값을 바꿀때 생기는 문제를 별칭 문제라 한다. | 두 객체가 제 삼의 다른 객체에 대한 참조를 공유하는데, 한 객체가 공유되는 객체의 상태를 변화시키는 것. | . | 현재 의존하는 객체에 대한 참조를 외부로 보내지 않는 방법. | 객체에 대한 복사본을 제공하는 방식. | 단점은 수행 시간과 메모리 공간을 차지한다는 점. 객체의 변화를 공유하고 싶은 경우에 사용할 수 없다는 점. | . | 옵저버 패턴 . | 의존하는 객체에 자신을 등록하고 객체의 상태가 변하면 통지를 받는 방법. | 흐름 이해를 어렵게하고, 로직이 지저분해질 수 있음. | . | 값 객체 . | 객체를 값처럼 사용하는 것. | 모든 오퍼레이션은 기존의 객체는 변하지 않는 값으로 두고, 새로운 객체를 반환해야 함. | 예를들면 500원 동전 두 개는 동등성을 띄지만, 동일성을 띄지는 않음. | 500원에 500원을 더하면 새로운 1000원 객체를 돌려줘야지, 500원 값 객체의 값이 1000원으로 바뀌는 것이 아님. | . | . 널 객체 . 객체의 특정 상황을 표현하고자 할 때는, 특별한 상황에 맞는 객체를 만들면 된다. 널 체크를 계속하는 것이 보기 싫은 상황에서 아래와 같은 코드들로 널 상황에서 반환하는 객체를 통해 널 체크를 하지 않을 수 있다. TestObject obj = System.getTestObject(); if (obj != null) obj.doSomething(); . 위와 같은 코드를 아래와 같이 수정한다 . // NullObject class public void doSomething() {} // TestObject class public static TestObject getTestObject() { return obj == null ? new NullObject() : obj; } TestObject obj = System.getTestObject(); ... // do something . 이런 코드는 잘못쓰이면 조건문 관련 2line을 없애고자 10line 가량을 생산해낼 수 있기 때문에, 논쟁이 있다. 템플릿 메서드 . 작업 순서는 변하지 않으면서, 각 작업 단위에 대한 개선 가능성을 열어두고 싶은 경우 이를 표현하는 방법이다. 다른 매서드들에 대한 호출로만 이루어진 메서드를 만든다. 템플릿 메서드는 고전적인 순서 등을 표현하는데 좋다. | 입력/처리/출력 | 메시지 보내기/응답 받기 템플릿 메서드는 초기 설계부터 구현하기 보다는 경험에 의해 구현되는 것이 좋다. | 두 하위 클래스의 연산 순서가 같은 것을 발견하면, 다른 부분을 추출하면서 남는 것이 템플릿 메서드 | . 플러거블 객체 . 변이(같은 종, 다른 특성)을 어떻게 나타내는가에 대하여, 조건문으로 처리할 수 있지만, 여러 곳에서 지저분한 조건문이 사용된다면 이를 객체로 변환할 수 있다. if (selected) { /* do something */} else { /* do another thing */} . 예를 들어 위와 같은 구문을 mode가 selected이냐에 따라 여러 함수에서 계속해서 처리하고 있었다면, . if (selected) mode = singleSelection(); else mode = multipleSelection(); . 과 같이 mode를 구현하는 객체들을 만들어 내부적으로 함수를 다르게 설정하면 된다. 플러거블이라는 거창한 이름이… 당연한 이런 구현에 왜 필요한가 싶다. 플러거블 셀렉터 . 인스턴스 별로 서로 다른 메서드를 동적으로 호출하는 방법. | 상속을 통해 하위 클래스를 각각 만듦. | 서로 다른 하위 클래스가 열 개가 있다면 이는 작은 변이를 다루기엔 무거운 기법. | . | switch 문을 갖는 하나의 클래스를 가짐. | 각 객체마다 값을 가지고, 이 값에 따른 switch문을 처리하는 클래스를 가지는 기법. | . | 플러거블 셀렉터 . | 리플렉션을 이용해 동적으로 메서드 호출. | 메서드를 직관적으로 추적하기 어렵기 때문에 과용해서는 안됨. | 메서드를 딱 하나 가지는 여러 하위 클래스의 뭉치들에서 사용하기 좋음. | . | . 팩토리 메서드 . 새 객체를 만들때 유연성을 원하는 경우, 생성자 대신 메서드를 통해 객체를 생성하는 방법이다. 메서드라는 인디렉션을 도입하여 유연성을 갖게되지만, 유연성이 필요한 경우에만 사용하여야하며, 그렇지 않을 때는 생성자를 사용하는 것으로 충분하다. 컴포지트 . 하나의 객체가 다른 객체 목록의 행위를 조합한 것처럼 행동하게 만들려고 할 때, 객체 집합을 나타내는 객체를 단일 객체에 대한 임포스터(사기꾼?)로 구현한다. 컴포지트 패턴은 일종의 프로그래머의 트릭이다. Folder가 Folder를 포함하고, Drawing은 Drawing을 포함하는 것 등은 실세계와 잘 들어맞지 않지만, 코드를 훨씬 단순하게 만든다. 수집 매개 변수 . log에 append하듯이, stream에 write하듯이, 이어서 사용하는 것. android phone의 dump 로그와 유사. 싱글톤 . 싱글톤은 어디서든 하나의 객체를 가져서 값을 동일하게 하는 디자인 패턴. 전역변수를 제공하지 않는 곳에서 전역변수처럼도 사용할 수 있다고 한다. ",
    "url": "/docs/extreme-programming/tdd/tdd-book-08#%EB%94%94%EC%9E%90%EC%9D%B8-%ED%8C%A8%ED%84%B4",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-08#디자인-패턴"
  },"55": {
    "doc": "TDD 08",
    "title": "리팩토링",
    "content": "아무리 큰 변화라도 작은 단계들로 변화시키는 방법. 일반적으로 리팩토링은 어떤 상황에서도 프로그램의 의미론을 변경해서 안되지만, TDD에서는 통과하는 테스트 안에서 상수를 변수로 바꾸는 등의 행동들도 리팩토링이라고 부른다. 이런 행위들이 테스트 통과에 변화를 주지 않기 때문이다. 차이점 일치시키기 . 비슷해 보이는 두 코드 조각을 합치기 위해서, 단계적으로 두 코드가 닮아가게끔 수정한다. 완전히 동일해지면 둘을 합친다. | 비슷한 반복문, 비슷한 분기, 비슷한 클래스를 동일하게 만들고 제거 리팩토링 중 추론이 길어지면 가정으로 넘어가기도 하는데, 이런 작업을 명확하게 하기 위해 작은 단계를 밟아가는 것이다. | . 변화 격리하기 . 객체나 메서드 일부만을 바꾸려고 할 때, 바꿀 부분을 격리함. 외과의가 수술부위만 두고 나머지는 천으로 가리는 것처럼.. | 메서드 추출, 객체 추출 등 | . 데이터 이주시키기 . ",
    "url": "/docs/extreme-programming/tdd/tdd-book-08#%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-08#리팩토링"
  },"56": {
    "doc": "TDD 08",
    "title": "TDD 08",
    "content": " ",
    "url": "/docs/extreme-programming/tdd/tdd-book-08",
    
    "relUrl": "/docs/extreme-programming/tdd/tdd-book-08"
  },"57": {
    "doc": "C++11",
    "title": "Lvalue, Rvalue",
    "content": "MS Docs. Rvalue Reference 참고. | lvalue: left value이자, locator value. Rvalue reference를 통해, 기존에 발생할 수 있는 문제들을 해결하고, move constructor의 기반으로 사용. int&amp; lv = 1; // error Lvalue 참조 int&amp;&amp; rv = 1; // Rvalue 참조 . | . move constructor 모두의 코드 참고 . | 즉 복사 생성자는 하나하나 싹 다 복사하는 거고, | 이동 생성자는 포인터 주소만 복사하는 것. | 그래서 이동 생성자에서 각 멤버들이 source의 멤버가 가리키는 주소를 가리키게 하고, 그 주소가 초기화(delete)되지 않도록 함. | 말 그대로 복사는 싹 복사해서 하나 더 만듦. | 말 그대로 이동은 있는건 쓱 옮김. | . &amp;&amp;의 형식 연역 . &amp;&amp;이 그렇다고 항상 Rvalue가 되는 것은 아니다. &amp;&amp;는 경우에 따라 universal reference로도 사용된다. void f(Widget&amp;&amp; param); //Rvalue reference Widget&amp;&amp; var = Widget(); //Rvalue reference auto&amp;&amp; var2 = var; //universal reference template&lt;typename T&gt; void f(std::vector&lt;T&gt;&amp;&amp; param); //Rvalue reference template&lt;typename T&gt; void f(T&amp;&amp; param); //universal reference . &amp;&amp;가 쓰이면서 Rvalue가 되는 경우를 보면 형식연역이 일어나지 않는 경우이다. 반면 아래 Type Inference에서 더 확인하겠지만 형식 연역이 일어나는 경우 즉, auto나 template에서는 입력받은 자료형에 따라 형식 연역이 일어나기 때문에 받은 param 값이 중요하다. universal reference는 초기값이 왼값이면 왼값 참조, 초기값이 오른값이면 오른값 참조를 하게된다. ",
    "url": "/docs/algorithm/language/cpp/cpp11#lvalue-rvalue",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#lvalue-rvalue"
  },"58": {
    "doc": "C++11",
    "title": "extern template",
    "content": "extern template class std::vector&lt;MyClass&gt;과 같이 template에 extern을 사용할 수 있게 되었음. ",
    "url": "/docs/algorithm/language/cpp/cpp11#extern-template",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#extern-template"
  },"59": {
    "doc": "C++11",
    "title": "Uniform Initialization",
    "content": "C++11에서 uniform initialization을 도입하여, 초기화 구문의 혼동을 완화하고, 어디서나 사용할 수 있는 초기화 구문을 도입함. 다른 초기화 방식((), =)에서 제대로 초기화되지 않는 부분들도 잘 초기화될 수 있음. 특히 서로 다른 값을 담는 STL 컨테이너를 직접 생성 후 값들을 추가했어야 하는 부분들이 쉽게 초기화 할 수 있게 되었음. class widget { private: int x{0}; // ok int y = 0; // ok int z(0); // error } std::atomic&lt;int&gt;a1{0}; // ok std::atomic&lt;int&gt;a2(0); // ok std::atomic&lt;int&gt;a3 = 0; // error double x, y; int sum{x + y}; // error. double can't be int. sum(x+ y) can do it. // C++98 Person p1{20, \"Tom\"}; Person p2{19, \"Jane\"}; // C++11 vector&lt;Person&gt; vec{ {21, \"Smith\"}, {23, \"Mary\"} }; . Member Initializer List . 생성자가 길어지는 것을 줄일 수 있고, 효율적으로 초기화시킬 수 있음. // C++98 Point(int ax, int ay) { x = ax, y = ay;} // C++11 Point(int ax, int ay) : x(ax), y(ay) {/* more if need */} . | cpp는 int n(3);과 같은 초기화가 가능하기 때문. | x(ax)대신 x{ax}도 가능. | 기존 대입식 초기화는 객체를 위한 메모리 생성/할당 후 여기에 값을 넣고 이 값을 멤버변수에 대입. | 반면 초기화 리스트는 객체의 생성과 초기화를 한번에 하기 때문에 오버헤드를 줄일 수 있음. | 반드시 초기화 리스트가 필요한 경우 (== 대입식 초기화로 안되는 경우) . | 클래스가 레퍼런스를 멤버변수로 갖는 경우 | 클래스가 non static + const 멤버 변수를 갖는 경우 | 자식 클래스가 부모 클래스의 private 변수를 초기화하는 경우 | 자식 클래스가 부모 클래스를 초기화하는 경우 | . | ex, child(int ai, int aj, int ak): parent(ai, aj), k(ak) | . | . ",
    "url": "/docs/algorithm/language/cpp/cpp11#uniform-initialization",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#uniform-initialization"
  },"60": {
    "doc": "C++11",
    "title": "Type Inference",
    "content": "C++11에서 auto와 decltype키워드가 추가되었다. auto 키워드. | auto 타입을 통해 파이썬처럼 자료형을 명시하지 않고 사용할 수 있게 되었음. | auto 타입은 항상 초기화를 필요로 하기 때문에, 코드에따라 초기화가 되지 않을 수 있어 발생하던 문제들을 보완할 수 있는 역할을 함. | 이식(다른 bit의 프로그램)성 문제에서 형식 불일치가 발생하는 경우가 없어짐. | 예를 들면 std::function객체를 사용하면 auto를 사용하는 것보다 일반적으로 메모리를 많이 사용하고 속도도 느림. | auto는 클로저를 담는 변수와 클로저와 같은 형식. std::function은 std::function 템플릿의 한 인스턴스 크기이고, 고정되어 있음. 클로저를 저장하기에 부족한 경우, 힙 메모리를 할당해서 클로저를 저장함. | . | 코드의 길이도 더 짧아짐. | . auto vs auto&amp;&amp; stackoverflow 참고. | auto는 항상 local copy. | auto&amp;는 항상 reference. | auto&amp;&amp;는 local인지 reference인지 생각하지 않음. 즉 형식연역에 따라 둘다 될 수 있음. | . decltype 키워드. decltype(declared type)은 컴파일러가 type을 결정하도록 하는 것. type을 알려주는 것. auto 키워드가 method의 return type으로 쓰일 때, return type을 알지 못하면 error가 발생함. | 그러면 후행 반환 형식으로 type을 명시하거나, decltype을 사용해야 함. auto를 사용하여 함수의 리턴 타입을 추론할 때 const나 참조형이 있다면 속성이 없어져 버리는데 decltype(auto)를 사용하면 정확히 추론된다. | . ",
    "url": "/docs/algorithm/language/cpp/cpp11#type-inference",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#type-inference"
  },"61": {
    "doc": "C++11",
    "title": "Range-based for loop",
    "content": "java에서처럼 :을 통한 for문을 사용할 수 있다. for (int i: arr) array에서 배열의 길이를 지정해주지 않아도 되며, i의 초기값을 정해주지 않아도 된다. 또한, 언제까지 순회할지를 지정하지 않아도 된다. | 이건 내가 원하는데까지 순회할 수 없다는 단점도 됨. | . 응용: . | 변경 방지: for (auto const i:arr) | . ",
    "url": "/docs/algorithm/language/cpp/cpp11#range-based-for-loop",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#range-based-for-loop"
  },"62": {
    "doc": "C++11",
    "title": "std::array",
    "content": "vector에서 지원하는 함수들을 유사하게 지원하면서, array를 만들어서 구현할 수 있또록 함. array[]와의 차이: . | std::array는 객체이기 때문에 크기를 알 수 있음. arr.size() | std::array는 index가 비어있어도 됨. | std::array는 생성시 크기를 명시해야 함. | std::array는 대입이 가능함. | . Cpp Reference 참고. | 단순히 C의 array[]를 가지고 있는 집합체로, C의 array와 동일한 성능을 내면서 size를 얻거나, 할당 지원과 같은 장점을 얻을 수 있음. | . ",
    "url": "/docs/algorithm/language/cpp/cpp11#stdarray",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#stdarray"
  },"63": {
    "doc": "C++11",
    "title": "lambda functions",
    "content": "lambda 식이 추가 되었는데, Java의 lambda 식과는 약간 다르고(뭔가 더 구시대적인 느낌?) 함수를 간단하게 만드는 것이라고 볼 수 있음. auto calc = [](int a, int b) -&gt; int {return a + b;}와 같이 사용할 수 있음. ",
    "url": "/docs/algorithm/language/cpp/cpp11#lambda-functions",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#lambda-functions"
  },"64": {
    "doc": "C++11",
    "title": "Alternative function syntax",
    "content": "후행 반환 형식이 도입되었다. 이는 함수 반환 타입을 auto 타입으로 했을 때를 위한 방식으로 도입되었는데, 어떤 타입으로 줘야할지 알지 못하므로 그 타입을 뒤에 명시하는 방식이었다. 그러나 C++14에서는 auto 타입으로 함수를 선언해도 후행 반환을 사용하지 않아도 되도록 업그레이드 되었다. 예를 들면 아래와 같다. template&lt;class Lhs, class Rhs&gt; auto adding_func(const Lhs &amp;lhs, const Rhs &amp;rhs) -&gt; decltype(lhs + rhs) {return lhs + rhs;} // auto adding_func(const Lhs &amp;lhs, cont Rhs &amp;rhs) {return lhs + rhs;} // C++14 . return value는 lhs + rhs의 타입이어야 하는데, lhs와 rhs가 아직 정의되지 않은 상태에서 아래 코드를 사용할 수 없다. decltype(lhs + rhs) adding_func(const Lhs &amp;lhs, const Rhs &amp;rhs) {return lhs + rhs;} . ",
    "url": "/docs/algorithm/language/cpp/cpp11#alternative-function-syntax",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#alternative-function-syntax"
  },"65": {
    "doc": "C++11",
    "title": "Object construction improvement",
    "content": "C++03까지는 생성자에서 다른 생성자를 호출할 수 없었다. 따라서 하나의 클래스에 다른 생성자가 동일한 구현이 필요할 경우 꼼수?처럼 함수를 만들어 호출하는 방식을 사용하였으나, C++11부터는 생성자에서 다른 생성자를 호출할 수 있게 되었다. 또한 non-static member의 초기화를 선언부에서 할 수 있게 되었다. 이 말이 뭐냐면 헤더파일에 멤버변수 선언하고, 생성자에서 초기화 하던걸 헤더파일에서 멤버변수 선언할때 초기값을 집어넣을 수 있어서 쓸데 없이 생성자에서 한 번 더쓰던걸 안써도 된다는 말이다. ",
    "url": "/docs/algorithm/language/cpp/cpp11#object-construction-improvement",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#object-construction-improvement"
  },"66": {
    "doc": "C++11",
    "title": "overrides &amp; final",
    "content": "Java에서 쓰는 애들이랑 유사하다. override와 final을 뒤에 붙이는게 특이하다. virtual 함수에만 사용할 수 잇다. Java와 마찬가지로 필수로 사용되어야 하는 것은 아니다. final: . | 하위 클래스에서 더이상 재정의할 수 없음을 컴파일러에게 알린다. | class에도 사용할 수 있다. override: | 상위 클래스의 멤버함수를 재정의해야 함을 컴파일러에게 알린다. | . override의 조건이 더 까다로워 졌기 때문에, 혹시 모를 휴먼 에러를 피하고자 override를 명시하는 것을 권장한다. override 조건: . | parent class의 함수가 virtual. | 함수의 이름이 동일. | 매개변수 현식들이 동일. | const 여부가 동일. | return 형식 동일. | 예외 명세가 호환되어야 함. | 함수들의 참조(reference) 한정사가 동일 // C++11에서 추가 . | 새로 추가된 한정사를 활용해 한정사가 다를 때마다 다른 함수나 생성자를 사용하도록 할 수 있지만, 잘 모르는 경우 이거 때문에 문제를 만들 수도 있음. | . | . ",
    "url": "/docs/algorithm/language/cpp/cpp11#overrides--final",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#overrides--final"
  },"67": {
    "doc": "C++11",
    "title": "null pointer constant",
    "content": "기존의 NULL을 대체하기 위해 nullptr이 생겼다. auto와 함께 했을 때, 타입을 알기 어려울 때 nullptr이 더 효율적으로 쓰인다. 사실 NULL도 0도 pointer가 nullptr이라는 것을 표현하기에 정확하지 않았고, NULL이 0으로 정의되어 있기 때문에 아래와 같은 문제점이 발생하기도 하였음. void f(int n); void f(char* p); f(NULL); // pointer 호출 의도로 f(p)를 의도했으나 f(n)이 호출됨. 이 nullptr은 새로 추가된 smart pointer에서도 사용되는 것으로 보임. 기존의 코드를 업그레이드 한다면, null 체크하는 부분과 초기 값 등을 모두 nullptr로 바꿔야 문제가 생기지 않을 것. ",
    "url": "/docs/algorithm/language/cpp/cpp11#null-pointer-constant",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#null-pointer-constant"
  },"68": {
    "doc": "C++11",
    "title": "enum class",
    "content": "자료형에 안전한 enum class가 생성되었다. 기존의 enum은 자료형과 상관 없는 아이들이었다. 기존의 enum은 Type에 상관 없이 int type으로 취급받아 숫자 혹은 다른 타입과 비교가 가능했다. 추가된 enum class는 이런 Type에 안전하다.(유연성은 좀 떨어져도) enum이 업그레이드 된게 아니라, enum class가 추가된 것으로 기존의 enum은 그대로 사용할 수 있다. // 기존의 enum enum Number {ZERO, ONE, TWO} int n = ZERO; // OK // enum class enum class Number {ZERO, ONE, TWO} int n = ZERO; // compile error. ZERO is not exist. Number n = ZERO; // compile error. also. Number n = Number::ZERO; // OK int n = Number::ZERO; // compile error. Number can't be int. int n = static_cast&lt;int&gt;(Number::ZERO); // OK . class 명시까지 해서 좀 길어졌다고 생각할 수도 있지만, enum이 굉장히 많이 쓰이는 큰 프로그램에서는 중복 사용을 피하기 위해 KEY1_KEY2_KEY3_VALUE 와 같이 사용하던 것에 비해 훨씬 안전하고 효율적이어졌다. ",
    "url": "/docs/algorithm/language/cpp/cpp11#enum-class",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#enum-class"
  },"69": {
    "doc": "C++11",
    "title": "템플릿 괄호처리",
    "content": "C++03까지 &gt;&gt;은 항상 shift 연산자로 판단되어 왔지만, C++11은 템플릿에서 &gt;를 잘 판별할 수 있게 되었다. vecotr&lt;pair&lt;int,int&gt; &gt; v; // C++03 &gt;&gt;를 못써서 이렇게 vector&lt;pair&lt;int,int&gt;&gt; v; // C++11 &gt;&gt;사용 가능 . ",
    "url": "/docs/algorithm/language/cpp/cpp11#%ED%85%9C%ED%94%8C%EB%A6%BF-%EA%B4%84%ED%98%B8%EC%B2%98%EB%A6%AC",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#템플릿-괄호처리"
  },"70": {
    "doc": "C++11",
    "title": "Explicit conversion operators",
    "content": "Cpp Docs 참고. 형 변환 연산자(conversion operator)로서 explicit을 사용할 수 있게 되었다. 딱 명시적으로 타입을 말해야만 변환이 된다. ",
    "url": "/docs/algorithm/language/cpp/cpp11#explicit-conversion-operators",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#explicit-conversion-operators"
  },"71": {
    "doc": "C++11",
    "title": "Template aliases",
    "content": "using을 통해 기존의 typedef의 역할을 더 강력하게 지원할 수 있음. typedef는 template과 사용할 수 없었는데, using은 template과 사용할 수 있음. 또 기존에 typedef가 하던 것도 더 이쁘장하게 가능함. typedef void (*FuncionType)(double); // old style using FunctionType = void (*)(double); // new introduce template&lt;typename First, typename Second, int Third&gt; class SomeType; template&lt;typename Second&gt; typedef SomeType&lt;OtherType, Second, 5&gt; TypedefName; // Invalid in typedef using TypedefName = SomeType&lt;OtherType, Second, 5&gt;; // valid in using . ",
    "url": "/docs/algorithm/language/cpp/cpp11#template-aliases",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#template-aliases"
  },"72": {
    "doc": "C++11",
    "title": "Variadic templates",
    "content": "가변인자 함수를 지원하던 것처럼, 가변 템플릿을 지원함. C++03에서는 템플릿에서 가변 인자를 구현하려면 직접 지원하고 싶은 인자 수만큼 템플릿을 정의해주어야 했음. 가변인자 함수와 동일하게 사용할 수 있음. ",
    "url": "/docs/algorithm/language/cpp/cpp11#variadic-templates",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#variadic-templates"
  },"73": {
    "doc": "C++11",
    "title": "New String Literal",
    "content": "이전에는 unicode encoding의 string을 지원하지 않았는데, UTF-8, -16, -32의 인코딩을 지원함. u8\"I'm a UTF-8\"; u\"This is a UTF-16\"; U\"This is a UTF-32\"; . 또한 raw string literal을 위한 아래와 같은 리터럴도 제공함. R\"(The String Data \\ stuff\")\" R\"delimiter(The String Data \\ Stuff\")delimiter\" . ",
    "url": "/docs/algorithm/language/cpp/cpp11#new-string-literal",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#new-string-literal"
  },"74": {
    "doc": "C++11",
    "title": "User-defined Literal",
    "content": "MS Docs 참고. 기존의 float f = 10f와 같이 선언하는 것처럼, 리터럴을 맘대로 추가할 수 있게 되었음. 이를 통해 단위 변환, 환산 가중치 연산도 간단하게 가능해졌음. 예제 참고. ",
    "url": "/docs/algorithm/language/cpp/cpp11#user-defined-literal",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#user-defined-literal"
  },"75": {
    "doc": "C++11",
    "title": "Multithreading memory model",
    "content": "C++11에서 multithread programming을 지원하기 위한 메모리 모델과 라이브러리를 지원. std::thread인데, 초기엔 멀티 플랫폼에서 제대로 동작하지 않는다는 말이 많았으나, 최근에는 잘 지원하는 것으로 보임. ",
    "url": "/docs/algorithm/language/cpp/cpp11#multithreading-memory-model",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#multithreading-memory-model"
  },"76": {
    "doc": "C++11",
    "title": "TLS",
    "content": "Thread Local Storage의 약자. java의 ThreadLocal 처럼, 스레드에 따라 다른 값을 갖도록 하는 변수를 선언. ",
    "url": "/docs/algorithm/language/cpp/cpp11#tls",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#tls"
  },"77": {
    "doc": "C++11",
    "title": "default &amp; delete",
    "content": "default: default construcotr는 컴파일러가 기본적으로 생성하는 생성자인데, 이미 다른 생성자가 생성되어 있다면 컴파일러는 기본 생성자를 생성하지 않는다. 이런 상황에서 생성자 없이 객체를 명시만 하는 경우 오류가 발생하는데 이를 막기 위해 default constructor를 생성해야 하며, 이를 간단하게 해주는 것. 정의와 구현이 나뉘어 있는 경우, 이를 사용하여 구현을 따로 하지 않아도 됨. struct NonDefault{ // NotDefault() = default; NonDefault(int i); } NotDefault n; // default constructor가 없으므로 에러. default관련 stackoverflow 참고. | default를 쓰면 trival과 POD이지만, (){}같이 default를 직접 구현하면 trival도 POD도 아니게 됨. ```cpp struct X{ X() = default; }; struct Y{ Y(){}; }; | . printf(“%d %d\\n”, std::is_trivial::value, std::is_pod::value); printf(\"%d %d\\n\", std::is_trivial::value, std::is_pod::value); . delete: **delete**는 해당 기능을 사용할 수 없게 만든다. ```cpp // copy가 불가능한 클래스 생성 struct NonCopyable { NonCopyable() = default; NonCopyable(const NonCopyable&amp;) = delete; NonCopyable&amp; operator=(const NonCopyable&amp;) = delete; }; // f에서 inst를 매개변수로 받을 수 없도록 struct NoInt { void f(double i); void f(int) = delete; } // f에서 double만 사용할 수 있도록 struct OnlyDouble { void f(double d); template&lt;class T&gt; void f(T) = delete; }; . C++03까지는 이런 코드들을 delete가 아닌 private으로 만들고, 구현부를 정의하지 않음으로써 사용하지 못하도록 했는데, 이젠 delete를 사용할 수 있음. 이전엔 링킹 시점에서 오류를 발견했다면, delete를 사용하면 컴파일 시점에서 오류를 발견할 수 있음. ",
    "url": "/docs/algorithm/language/cpp/cpp11#default--delete",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#default--delete"
  },"78": {
    "doc": "C++11",
    "title": "long long",
    "content": "long long (int), unsigned int, … char16_t 등 새로운 자료형이 도입됐다. 응? 얘네가 C++11에서야 들어온 애들이었구나.. ",
    "url": "/docs/algorithm/language/cpp/cpp11#long-long",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#long-long"
  },"79": {
    "doc": "C++11",
    "title": "static assertion",
    "content": "컴파일 타임에 assertion 테스트를 할 수 있는 static assert가 도입되었다. template 같은 경우의 assertion 테스트가 용이하다. ",
    "url": "/docs/algorithm/language/cpp/cpp11#static-assertion",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#static-assertion"
  },"80": {
    "doc": "C++11",
    "title": "sizeof member",
    "content": "클래스 멤버에 대한 sizeof를 허용한다는 것인데.. 내 리눅스에서는 왜 C++03으로 되는지 의문.. struct SomeType { OtherType member; }; sizeof(SomeType::member); // not work with C++03 . ",
    "url": "/docs/algorithm/language/cpp/cpp11#sizeof-member",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#sizeof-member"
  },"81": {
    "doc": "C++11",
    "title": "alignas &amp; alignof",
    "content": "MS Docs 참고. 메모리 주소를 맞춰주는 역할을 하는 alignas와 그 크기를 찾는 alignof가 새로 추가 됨. 지정한 타입이 메모리의 어느 위치에 배치되는지를 확인하는 것. struct alignas(16) Bar { int i; // 4 bytes int n; // 4 bytes alignas(4) char arr[3]; short s; // 2 bytes }; std::cout &lt;&lt; alignof(Bar) &lt;&lt; std::endl; // output: 16 . ",
    "url": "/docs/algorithm/language/cpp/cpp11#alignas--alignof",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#alignas--alignof"
  },"82": {
    "doc": "C++11",
    "title": "Attributes",
    "content": "attribute가 도입되었는데, #pragma등으로 사용되던 extension들과 유사하게 제공하는 표준. [[ ]]과 같은 형태로 도입되었고, standard attribute로 noreturn과 carries_dependency가 도입되었음. noreturn stackoverflow 참고. [[noreturn]] void f()의 의미는 return 값이 없다는게 아니라, call flow를 caller에게 보내지 않는다는 것이다. | f() 내에서 exit, loop forever, throw exception 같은 상황이 발생할 경우이고, 이럴때 컴파일러에서의 최적화와 경고 출력을 하기 위함. 함부로 쓰기에는 위험. | . carries_dependency는 함수에 데이터 종속성을 지정하여 멀티스레드 동기화 관련해 효율적일 수 있게 함. ",
    "url": "/docs/algorithm/language/cpp/cpp11#attributes",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#attributes"
  },"83": {
    "doc": "C++11",
    "title": "tuple type",
    "content": "구조체의 일반화로 볼 수 있는데, Variadic templates를 활용하여 생성되었음. template &lt;class... Types&gt; class tuple; . default constructor가 있는 클래스들만으로 tuple을 만들면 내부의 다른 정의 없이 사용할 수 있고, 다른 동일한 tuple로 할당하는 것도 가능함. typedef std::tuple&lt;int, double, const char *&gt; test_tuple; test_tuple proof(18, 6.5, \"AAA\"); int i = std::get&lt;0&gt;(proof); . ",
    "url": "/docs/algorithm/language/cpp/cpp11#tuple-type",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#tuple-type"
  },"84": {
    "doc": "C++11",
    "title": "regular expression",
    "content": "#include &lt;regex&gt;; std::regex rgx(\"\\\\n\"); . 과 같이 사용할 수 있으나, 성능이 굉장히 안좋다고 함. 자바의 regular 보다도 훨씬 엄청나게 안좋다고 함. (그럼 왜 만든거…) . ",
    "url": "/docs/algorithm/language/cpp/cpp11#regular-expression",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#regular-expression"
  },"85": {
    "doc": "C++11",
    "title": "smart pointer",
    "content": "C++11에 추가된 unique_ptr, shared_ptr, weak_ptr을 기반으로 한 포인터. 꾸준히 업데이트 되고 있는 걳으로 보이나, 기존의 포인터와 호환하여 사용할 수 없음. unique_ptr&lt;int&gt; p = make_unique&lt;int&gt;(5); // smart pointer printf(\"%d\", *p); // use as normal pointer int a = 1; p = &amp;a; // error . 기존의 단점: . | 딱 보면 포인터인지 모름. | delete 해야하는지의 여부를 모름. | delete 해야하더라도 delete []를 해야하는지 여부를 모름. | 코드 상에서 delete 해주는 함수가 이미 구현되어 있는지 여부도 모름. | 따라서 실수가 많아짐. (가비지 컬렉션 관련된) | . smart pointer: . | pointer를 감싸주는 일종의 wrapper. | pointer와 비슷하게 동작하며 여러 위험을 피할 수 있게 함. | 생? pointer가 할 수 있는 대부분의 일을 하며 알아서 소멸 됨. | 당연히 코드가 줄어듦. | . unique_ptr: 독점적 소유권. 포인터를 이동은 가능하나, 여러 포인터가 가르킬 수 없음. shared_ptr로 변환 가능. shared_ptr: 소유권이 나뉘며 가리키는 포인터가 늘어날 때마다 카운트가 증가하고, 카운트가 0이 될 때 소멸함. weak_ptr: shared에서 서로 가리켜서 삭제되지 않는 경우에 대한 문제를 해결하기 위해 고안 됨. ",
    "url": "/docs/algorithm/language/cpp/cpp11#smart-pointer",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11#smart-pointer"
  },"86": {
    "doc": "C++11",
    "title": "C++11",
    "content": "요새 modern cpp를 공부한다고 cpp11과 cpp14를 공부하고 있다. 뭐가 이렇게 새로운게 많은 것인가.. 싶다. 이런것도 모르고 cpp를 쓰고 있었다니 그런데 한 숨에 이해하기 어려운 것들도 있는데, 나름대로 이해해서 적어 보았다. 많은 C++ 개발자들이 C를 배우기도 했고, 최신 C++의 기능들을 적용하지 못하고 있다는게 이런 코드들이 (우리회사에서도) 잘 사용되지 않는 이유인 듯 했다. C++11 wiki 참고하였다. Table of Contents: . | Lvalue, Rvalue . | &amp;&amp;의 형식 연역 | . | extern template | Uniform Initialization . | Member Initializer List | . | Type Inference | Range-based for loop | std::array | lambda functions | Alternative function syntax | Object construction improvement | overrides &amp; final | null pointer constant | enum class | 템플릿 괄호처리 | Explicit conversion operators | Template aliases | Variadic templates | New String Literal | User-defined Literal | Multithreading memory model | TLS | default &amp; delete | long long | static assertion | sizeof member | alignas &amp; alignof | Attributes | tuple type | regular expression | smart pointer | . ",
    "url": "/docs/algorithm/language/cpp/cpp11",
    
    "relUrl": "/docs/algorithm/language/cpp/cpp11"
  },"87": {
    "doc": "copy in Python",
    "title": "생 복사",
    "content": "생 복사는 할당 연산을 통해 복사되는 것을 말한다. 할당 시 주소까지 가져가기 때문에 아예 동일한 변수가 된다고 보면 된다. 한 쪽에서 수정시 다른 곳에서도 수정된다. a = [1, 2] b = a # b는 a의 주소를 받음. same = a is b # 동일 객체 same = id(a) == id(b) # 동일 주소 b[0] = 0 # b를 수정시 a도 수정 a[0] = 0 # a를 수정시 b도 수정 . ",
    "url": "/docs/algorithm/language/python/python-copy#%EC%83%9D-%EB%B3%B5%EC%82%AC",
    
    "relUrl": "/docs/algorithm/language/python/python-copy#생-복사"
  },"88": {
    "doc": "copy in Python",
    "title": "얕은 복사",
    "content": "shallow copy라고 한다. 얕은 복사는 새로운 객체를 만들고, 원본 객체를 가리키는 참조를 새로운 복합 객체에 삽입한다. 즉, 내부 객체는 참조 객체이다. a = [1, [2, 3]] b = a.copy() same = a is b # False same_val = a == b # True # b의 immutable object의 값이 변경되지 않음. a[0] = 0 # 새로운 객체를 만들었기 때문에 b의 immutable object의 값이 변경되지 않음. a[1][0] = -1 # b의 mutable object의 값은 변경됨. 참조하고 있기 때문 . 얕은 복사의 방식(stackoverflow 참고)은 여러가지가 있음. b = a.copy() b = a[:] # 가독성 문제로 권장하지 않기도 함. b = list(a) import copy b = copy.copy(a) # a의 type을 알아내야 해서 살짝 더 느림. ",
    "url": "/docs/algorithm/language/python/python-copy#%EC%96%95%EC%9D%80-%EB%B3%B5%EC%82%AC",
    
    "relUrl": "/docs/algorithm/language/python/python-copy#얕은-복사"
  },"89": {
    "doc": "copy in Python",
    "title": "깊은 복사",
    "content": "deep copy라고 한다. 깊은 복사는 새로운 객체를 만들고, 재귀적으로 원본 객체의 사본을 새로 만든 복합 객체에 삽입한다. 즉, 완전히 다른 객체를 만드는 것으로 객체 사이에 참조가 없다. 따라서 어떤 수정도 서로 간에 영향을 미치지 않는다. import copy a = [1, [2, 3]] b = copy.deepcopy(a) . 깊은 복사 방식엔 문제(python docs 참고)가 있음. | 재귀 객체가 순한 루프를 만들 수 있음. | memo dictionary를 두어 이미 복사된 것을 저장하여 해결. | . | 깊은 복사는 모든 것을 복사하기 때문에, 복사본 간에 공유해야할 것도 복사할 수 있음. | user-defined class가 복사 연산이나 복사된 구성요소 집합을 override 하도록 함. | . | . ",
    "url": "/docs/algorithm/language/python/python-copy#%EA%B9%8A%EC%9D%80-%EB%B3%B5%EC%82%AC",
    
    "relUrl": "/docs/algorithm/language/python/python-copy#깊은-복사"
  },"90": {
    "doc": "copy in Python",
    "title": "함수 내 반환 시",
    "content": "reference parameter로 전달된 함수에서, parameter 값을 변경시켜서 올려주고 싶다면 아래와 같이 해야한다. def change_param(param: List[int]): new = [1, 2, 3] # calculated value for i in range(new): param[i] = new[i] . 위와 같은 방식을 사용하는 이유는 위에서 배운 생복사, 얕은 복사, 깊은 복사 모두 함수 내부에서 선언된 list의 주소값을 사용하기 때문이다. 우리는 함수 밖에서 온 param의 주소 값을 그대로 가지고 수정해야 하는데 모든 copy는 새로운 list를 할당하여 실제 param을 변경하지 못한다. 위 코드는 아래와 같은 문제가 있다. | index out of range를 피하기 위해 param에 사용하고자 하는 idx가 존재하는지 체크해야 함. | 다 차원 list가 될 경우 더 많은 반복문과 위의 문제가 중첩됨. | . 이런 경우는 빈번히 사용될텐데 reference list의 주소를 그대로 두면서 copy를 진행하는 방법이 존재하나 찾아보았으나 없는 것으로 보인다. 아래와 같은 방법이 최선일 것으로 생각된다. def change_param(param: List[int]): new = [1, 2, 3] param.clear() param.extend(new) . 이렇게 하면 기존의 list의 주소를 두고 값을 변경할 수 있다. ",
    "url": "/docs/algorithm/language/python/python-copy#%ED%95%A8%EC%88%98-%EB%82%B4-%EB%B0%98%ED%99%98-%EC%8B%9C",
    
    "relUrl": "/docs/algorithm/language/python/python-copy#함수-내-반환-시"
  },"91": {
    "doc": "copy in Python",
    "title": "copy in Python",
    "content": "파이썬에서는 세 종류의 복사가 있다고 볼 수 있다. | 생?복사, 얕은복사, 깊은복사 경우에 따라 의도치 않게 참조하거나, 참조가 무시될 수 있으니 알고 구별하여 사용해야 한다. | . ",
    "url": "/docs/algorithm/language/python/python-copy",
    
    "relUrl": "/docs/algorithm/language/python/python-copy"
  },"92": {
    "doc": "Time Complexity in Python data-structure",
    "title": "기본 자료형 time complexity",
    "content": "아래 링크에서 정리된 표를 보면 좋다. | https://wiki.python.org/moin/TimeComplexity | . ",
    "url": "/docs/algorithm/language/python/time-complexity#%EA%B8%B0%EB%B3%B8-%EC%9E%90%EB%A3%8C%ED%98%95-time-complexity",
    
    "relUrl": "/docs/algorithm/language/python/time-complexity#기본-자료형-time-complexity"
  },"93": {
    "doc": "Time Complexity in Python data-structure",
    "title": "libary",
    "content": "heapq . | Operation | Average Big O | . | push | O(log n) | . | pop | O(log n) | . | https://stackoverflow.com/questions/38806202/whats-the-time-complexity-of-functions-in-heapq-library/38833175 | . ",
    "url": "/docs/algorithm/language/python/time-complexity#libary",
    
    "relUrl": "/docs/algorithm/language/python/time-complexity#libary"
  },"94": {
    "doc": "Time Complexity in Python data-structure",
    "title": "reference",
    "content": ". | https://www.ics.uci.edu/~pattis/ICS-33/lectures/complexitypython.txt | https://stackoverflow.com/questions/38806202/whats-the-time-complexity-of-functions-in-heapq-library/38833175 | . ",
    "url": "/docs/algorithm/language/python/time-complexity#reference",
    
    "relUrl": "/docs/algorithm/language/python/time-complexity#reference"
  },"95": {
    "doc": "Time Complexity in Python data-structure",
    "title": "Time Complexity in Python data-structure",
    "content": "당연하게도 자료구조에 따라 python operation들의 time complexity가 달라진다. 같은 operation도 어떤 자료구조를 쓰느냐에 따라 성능이 달라질 수 있다. 고민이 될 때는 아래 링크를 참고해서 각 동작들의 cost를 확인해보는 것도 좋겠다. ",
    "url": "/docs/algorithm/language/python/time-complexity",
    
    "relUrl": "/docs/algorithm/language/python/time-complexity"
  },"96": {
    "doc": "IAM",
    "title": "IAM 항목들",
    "content": "User . 사용자가 누구인지(인증)와 어떤 권한을 가지고 있는지를 설정한다. 제거하기 전까지 영구적인 key 값을 갖는다. 따라서 일반적으로 long term credential에 사용된다. 보안, 권한 관리 등의 목적으로 root 계정보다 IAM user를 등록하는 것을 권장한다. | IAM을 사용하지 않고 root account로 진행해도 되지만 root account는 모든 권한을 가지고 있어 제어를 할 수 없는 문제가 있음. | . Group . 여러 User들을 그룹화하여 권한을 부여한다. Role . Role에 권한을 부여하고 user나 service에 role을 주는 방식으로 권한을 할당한다. user에게 일시적으로 권한을 부여할 수 있기 때문에 short term credential에서 많이 사용된다. (STS와 함께) . ",
    "url": "/docs/aws/iam#iam-%ED%95%AD%EB%AA%A9%EB%93%A4",
    
    "relUrl": "/docs/aws/iam#iam-항목들"
  },"97": {
    "doc": "IAM",
    "title": "IAM Policies",
    "content": "IAM policy는 JSON으로 관리되며 Effects, Action, Resource, Condition, Policy Variables를 가지고 있는다. 예시 . policy 예시: MFA를 사용한 특정 액세스 허용 . { \"Version\": \"2012-10-17\", \"Statement\": { \"Effect\": \"Allow\", \"Action\": [ \"service-prefix-1:*\", \"service-prefix-2:action-name-a\", \"service-prefix-2:action-name-b\" ], \"Resource\": \"*\", \"Condition\": { \"Bool\": {\"aws:MultiFactorAuthPresent\": true}, \"DateGreaterThan\": {\"aws:CurrentTime\": \"2017-07-01T00:00:00Z\"}, \"DateLessThan\": {\"aws:CurrentTime\": \"2017-12-31T23:59:59Z\"} } } } . 정책으로 권한을 부여한다. DENY가 명시되어 있다면 ALLOW 보다 우선 처리된다. Best Practice는 보안을 위해 최소한의 권한만을 부여하는 것이다. AWS managed Policies . AWS에 의해 정의된 policy가 있고 이런 policy들은 서비스가 업그레이드 됨에 따라 변경되기도 한다. specific한 작업들에 관한 policy. 대표적으로 AdministratorAccess, PowerUserAcess가 있다. | AWS에서 관리하는 policy list - link | . AWS manag4ed Policy들을 보면 policy 사용법을 더 이해할 수 있다. AdministratorAccess: *을 사용해서 모든 권한을 허용하는 policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"*\", \"Resource\": \"*\" } ] } . PowerUserAccess: NotAction을 명시하여 대부분의 권한을 허용하지 않는다. \"Effect\":\"Deny\"를 쓰지 않는 것은, deny를 하게되면 이후에 허용하고 싶은 action들이 모두 무시되기 때문이다. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"NotAction\": [ \"iam:*\", \"organizations:*\", \"account:*\" ], \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"iam:CreateServiceLinkedRole\", \"iam:DeleteServiceLinkedRole\", \"iam:ListRoles\", \"organizations:DescribeOrganization\", \"account:ListRegions\" ], \"Resource\": \"*\" } ] } . IAM Policy Conditions . IAM policy condition은 policy의 효력이 발생하는 시점을 지정할 수 있는 요소이다. 이렇게 생겼다. \"Condition\" : { \"{condition-operator}\" : { \"{condition-key}\" : \"{condition-value}\" }} . operator type에 따라 여러가지 연산을 제공한다. | String의 경우, String Equals, StringNotEquals, String Like … | Date의 경우, DateEquals, DateLessThan … | condition list - link | . IAM Policies Variables and Tags . Variable이란 policy에서 사용할 수 있는 aws에서 정의한 변수들이고, Tag란 User나 Resource에 Tag를 하여 Variable처럼 사용할 수 있는 key 값이다. | variable과 tag aws docs - link | . Example: ${aws:username} . | “Resource”: [“arn:aws:s3:::mybucket/${aws:username}/*”] | username으로 시작하는 bucket에 접근할 수 있다. | 모든 유저가 s3에 각자의 bucket을 갖도록 명시할 수 있다. | . AWS specific variables . | aws:CurrentTime, aws:TokenIssueTime, aws:principaltype, aws:SecureTransport … | . Service specific variables . | s3:prefix, s3:max-keys, s3:x-amz-acl, sns:Endpoint, sns:Protocol… | . Tag Based . | iam:ResourceTag/key-name, aws:PrincipalTag/key-name … | . IAM Role vs Resource Based Policies . role(user, application, service)을 assume할 때 original permission을 포기하고 role에 설정된 permission을 갖게 된다. resource-based policy를 사용하면 이런 permission을 포기하지 않을 수 있다. 예시 . A가 dynamoA에 role을 가지고 있다. B가 S3B에 role을 가지고 있다. A가 dynamoA에서 S3B로 data를 dump하고 싶다. | A가 B의 role을 받아가면 A의 permission을 포기해야 하기 때문에 dynamoA의 role을 잃는다. | A가 S3B의 resoure-based policy에 추가되면 dynamoA의 policy를 잃지 않을 수 있다. | . ",
    "url": "/docs/aws/iam#iam-policies",
    
    "relUrl": "/docs/aws/iam#iam-policies"
  },"98": {
    "doc": "IAM",
    "title": "IAM Permission Boundaries",
    "content": "Bouddary는 user나 role에 대한 maximum permission을 설정하는 것이다. Boundary는 user와 role에 대해 지원되고 group은 지원하지 않는다. Boundary를 명시하면 policy가 있더라도 permission을 갖지 못하게 할 수 있다. boundary에서 명시한 permission 중 plicy가 추가된 permission만 효력이 있다. | boundary와 policy들 사이의 effective를 diagram으로 확인 - link | . 예시 . IAM permission boundary . { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"s3:*\", \"cloudwatch:*\", \"ec2:*\" ], \"Resource\": \"*\" } ] } . IAM permission . { \"Version\": \"2012-10-17\", \"Statement\": { \"Effect\": \"Allow\", \"Action\": \"iam:CreateUser\", \"Resource\": \"*\" } } . 위와 같이 boundray와 permission이 있다면 iam action은 boundary에 없으므로 permission이 있더라도 effective하지 않다. refernce . | AWS docs | udemy, Ultimate AWS Certified Solutions Architect Professional 2022 | . ",
    "url": "/docs/aws/iam#iam-permission-boundaries",
    
    "relUrl": "/docs/aws/iam#iam-permission-boundaries"
  },"99": {
    "doc": "IAM",
    "title": "IAM",
    "content": "IAM(Identity and Access Management)은 계정들의 리소스들에 대한 접근 권한을 관리하기 위해 제공하는 AWS의 서비스이다. user와 user에 대한 permission을 부여할 수 있다. IAM은 global service로 모든 리전에서 동일하게 사용할 수 있는 서비스이다. ",
    "url": "/docs/aws/iam",
    
    "relUrl": "/docs/aws/iam"
  },"100": {
    "doc": "기본개념과 용어",
    "title": "클라우드 컴퓨팅",
    "content": "컴퓨팅을 인프라를 하드웨어로 사용하는 것이 아니라 소프트웨어로 사용하는 방식이다. 데이터 센터를 물리적으로 구축하던 것을 인터넷을 통해 온디맨드로 사용하고 사용한 만큼의 비용을 지불하는 것을 말한다. ",
    "url": "/docs/aws/terms#%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85",
    
    "relUrl": "/docs/aws/terms#클라우드-컴퓨팅"
  },"101": {
    "doc": "기본개념과 용어",
    "title": "클라우드 컴퓨팅 모텔",
    "content": "IaaS(Infrastructure as a Service): 기본적인 요소만 갖추어, (네트워킹, 컴퓨팅, 스토리지) 마치 물리적인 장비인 것처럼 사용할 수 있는 것. Paas(Platform as a Service): 윈도우나 DB와 같은 것들을 제공하는 상태의 서비스. 하드웨어나 운영체제를 관리할 필요 없이 실행할 수 있는 상태. SaaS(Software as a Service): 내가 무언가를 준비하지 않아도 사용할 수 있는 상태. ",
    "url": "/docs/aws/terms#%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85-%EB%AA%A8%ED%85%94",
    
    "relUrl": "/docs/aws/terms#클라우드-컴퓨팅-모텔"
  },"102": {
    "doc": "기본개념과 용어",
    "title": "클라우드 컴퓨팅 장점",
    "content": "인프라 구축에 들어가는 자산/시간의 비용을 줄일 수 있다는 장점이다. | 사용한만큼 금액을 지불해 초기 투자 비용이 없음. | 컴퓨터 환경에서 리소스 세팅 시간이 크게 감소. | 인프라 구축과 관리에 시간과 비용 낭비 x. | 필요한 경우 쉽게 추가/축소 가능. | 전 세계의 리전에 쉽게 배포가 가능. | . ",
    "url": "/docs/aws/terms#%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85-%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/aws/terms#클라우드-컴퓨팅-장점"
  },"103": {
    "doc": "기본개념과 용어",
    "title": "AWS(Amazon Web Services)",
    "content": "AWS에는 스토리지, 컴퓨팅, 네트워킹, 데이터베이스, 어플리케이션과 개발 관리 도구 등의 서비스가 있다. AWS의 서비스는 관리형/비관리형의 분리로 나뉜다. 비관리형 서비스: AWS가 관리해주지 않는 서비스. 사용자가 확장, 내결함성 및 가용성을 관리한다. 오류가 발생하거나 리소스를 쓸 수 없을 때 서비스가 어떻게 할지를 사용자가 관리해야한다는 것이다. | ex) EC2의 경우 OS를 올려서 방화벽 등의 관리를 직접 해야 함. | 정교하게 제어할 수 있다는 장점 / 직접 제어해야한다는 단점 | . 관리형 서비스: AWS가 관리해주는 서비스. 일반적으로 확장, 내결함성 및 가용성이 서비스에 내장되어 있다. | ex) S3의 경우 사용자가 관리할 부분이 없음. | . ",
    "url": "/docs/aws/terms#awsamazon-web-services",
    
    "relUrl": "/docs/aws/terms#awsamazon-web-services"
  },"104": {
    "doc": "기본개념과 용어",
    "title": "클라우드 배포 모델",
    "content": "올인 클라우드: 모든 서비스를 클라우드에 올려서 사용하는 것. 하이브리드: 구축되어 있는 인프라와 함께 사용하는 방식. data center를 보유하거나 등의 경우 클라우드와 같이 활용. ",
    "url": "/docs/aws/terms#%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EB%B0%B0%ED%8F%AC-%EB%AA%A8%EB%8D%B8",
    
    "relUrl": "/docs/aws/terms#클라우드-배포-모델"
  },"105": {
    "doc": "기본개념과 용어",
    "title": "마이크로 서비스",
    "content": "모든 프로세스가 결합되어 단일 서비스로 진행되는 방식을 모놀리식 아키텍쳐라고 한다. 모놀리식 아키텍쳐는 단일 서비스이기 때문에 아래와 같은 단점을 갖는다. | 확장이 어려움. 서비스가 커질수록 업데이트 및 유지관리가 어려움. 새로운 기술 도입이 어려움. | . 이러한 방식은 서비스에 적합하지 않아, 서비스 지향 아키텍쳐의 일종으로 나온 것이 마이크로 서비스이다. 마이크로 서비스는 기능별로 별도의 어플리케이션을 가지고 독립적으로 기능을 수행하는 구조이다. 따라서 모놀리식의 단점을 해결하는 아래와 같은 장점을 갖는다. 장점: 각 서비스간에 다른 서비스에 영향을 주지 않아 확장이 쉽고 빠르다. 따라서, 새로운 기술의 도입과 테스트, 반영이 쉽다. 따라서, 서비스 마다 독립적으로 수요를 파악해 가용성을 조정할 수 있다. 따라서, 단일 서비스에서의 문제가 전체 서비스에 끼치는 영향이 줄어든다. 단점: 각 서비스 간 호출에 대한 처리 비용이 더 많이 든다. 테스트가 더 복잡할 수 있다. 구조적으로 너무 많은 서비스를 만들 수도 있다. AWS의 MicroServices 참고. AWS의 각 서비스는 마이크로 서비스 아키텍쳐를 지원하기 좋게 만들어져 있다. ",
    "url": "/docs/aws/terms#%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C-%EC%84%9C%EB%B9%84%EC%8A%A4",
    
    "relUrl": "/docs/aws/terms#마이크로-서비스"
  },"106": {
    "doc": "기본개념과 용어",
    "title": "서버리스",
    "content": "클라우드 컴퓨팅에서 본 클라우드 컴퓨팅의 장점을 넘어서 서버에 대한 고려를 아예 하지 않도록 하는 아키텍쳐. 서버에 대한 관리는 클라우드 사업자가 맡아서 하며, 필요한 기능을 함수로 구현하여 이를 서버에 별도 준비 없이 사용한다. 개발자는 함수 형태로 기능들을 구현하면, 서버리스 컴퓨팅 시 필요에 따라 event driven 방식으로 함수를 호출하여 사용하는 구조이다. 장점: 쉽게 안정적인 대용량 서버를 만들 수 있다. 따라서 개발 기간이 단축되고, 개발자가 서버 운영/관리에서 자유로워져 개발에 집중할 수 있다. 단점: 클라우드 업체를 바꾸기가 어려울 수 있다. 서버 인프라에 문제가 생길 경우 원인을 찾거나 해결하는데 어려움이 있다. AWS에서는 S3, DynamoDB 등이 서버리스 서비스라고 할 수 있고 컴퓨팅 서비스에서는 Lambda가 서버리스를 지원한다. ",
    "url": "/docs/aws/terms#%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4",
    
    "relUrl": "/docs/aws/terms#서버리스"
  },"107": {
    "doc": "기본개념과 용어",
    "title": "AWS Infra",
    "content": "DC (데이터 센터): 단일 데이터 센터에서 수천 개의 서버를 운영한다. 모든 데이터 센터는 온라인으로 연결된다. AZ (가용 영역): AZ는 하나 이상의 DC로 이루어진다. 재해가 발생했을 때 다른 쪽에서 서비스 가능하도록하는 결함 분리 방식으로 설계되어 있다. 고속 프라이빗 링크를 통해 다른 AZ와 상호 연결된다. Region: 두 개 이상의 AZ를 묶어 Region이라고 한다. ",
    "url": "/docs/aws/terms#aws-infra",
    
    "relUrl": "/docs/aws/terms#aws-infra"
  },"108": {
    "doc": "기본개념과 용어",
    "title": "Region 선택",
    "content": "인스턴스를 시작할 때 AZ를 선택하거나 AWS가 AZ를 선택하도록 할 수 있다. 리전을 선택할 때는 아래와 같은 사항들을 고려해서 선택해야 한다. | 법적 요구사항 특정 데이터의 경우 한국에 있어야 한다면 서울 리전만 사용할 수 있음. | 지연시간(근접성) 클라이언트에게 가장 가깝고 빠르게 응답할 수 있는 위치. https://www.cloudping.info/ 에서 현 위치에서의 각 리전별 Latency를 확인할 수 있음. | 사용 가능 서비스 리전 별 사용가능 서비스가 다름. | 비용 리전 별 비용이 다름. | . 서비스는 Region/AZ 기반 서비스로 나뉜다. 가용영역 중심 서비스: 하나의 AZ에서 죽었을 때 다른 곳에서 서비스가 가능하도록 직접 설계해야 한다. 리전 기반 서비스: 기본적으로 다른 AZ에 서비스를 복제하여 AZ에서 죽었을 때에 대한 고려를 하지 않아도 된다. ",
    "url": "/docs/aws/terms#region-%EC%84%A0%ED%83%9D",
    
    "relUrl": "/docs/aws/terms#region-선택"
  },"109": {
    "doc": "기본개념과 용어",
    "title": "기본개념과 용어",
    "content": " ",
    "url": "/docs/aws/terms",
    
    "relUrl": "/docs/aws/terms"
  },"110": {
    "doc": "기본 서비스",
    "title": "EC2(Elastic Compute Cloud)",
    "content": "하드웨어를 가상화하는 서비스. 가장 기본적인 클라우드 컴퓨터. | CPU, mem, storage, net capa를 고려하여 여러 종류의 HW를 선택할 수 있음. (Instance Family Type 참고) 인스턴스를 추가하여 OS를 설치해서 사용. | AMI(Amazon Machine Image)를 사용하여 간단하고 빠르게 설치. 인스턴스를 사용할 때 추가하고 사용하지 않을 때 중지/종료해야 함. (비용 문제) | . 요금제 구성은 아래와 같다. 온디맨드 - 사용한 만큼 낸다. 쓰지 않으면 종료. 예약 인스턴스 - 미리 예약하여 사용. 약정에 따라 할인받을 수 있음. 스팟 인스턴스 - 남는 서버를 싸게 줌. 쓰다가 남는게 없으면 스팟으로 동작하는게 제거될 수 있고 서비스 종료될 수 있음을 고려해야 함. ",
    "url": "/docs/aws/basic-service#ec2elastic-compute-cloud",
    
    "relUrl": "/docs/aws/basic-service#ec2elastic-compute-cloud"
  },"111": {
    "doc": "기본 서비스",
    "title": "ELB(Elastic Load Balancing)",
    "content": "단일 end point로 클라이언트가 들어왔을 때 이를 매핑해주는 역할을 한다. 수신되는 트래픽을 EC2 인스턴스, 컨테이너 등에 자동으로 분산. 애플리케이션 트래픽의 로드를 처리할 수 있음. 인스턴스 상태 확인하는 역할도 한다. | 주기적으로 인스턴스 테스트를 하여 상태를 확인. | 이를통해 정상적인 인스턴스로만 라우팅을 함. | . 고정 세션 기능을 제공한다. | 여러 인스턴스를 사용하면 로드 밸런스 과정에서 다른 인스턴스를 사용할 때 세션이 유지되지 않는 것을 막기 위함. | 고정 세션 기능을 사용하면 사용자 세션을 특정 애플리케이션 인스턴스에 바인딩 할 수 있음. | 그치만, 로드 밸런싱 문제로 세션을 외부의 cache/db로 유지하는 방식이 권장됨. | . ",
    "url": "/docs/aws/basic-service#elbelastic-load-balancing",
    
    "relUrl": "/docs/aws/basic-service#elbelastic-load-balancing"
  },"112": {
    "doc": "기본 서비스",
    "title": "Auto Scaling",
    "content": "적절한 수의 EC2 인스턴스를 유지하도록 자동으로 생성/종료하는 서비스. 사용자 수에 따라 확장/축소할 수 있음. 수동 조정 - 최대/최소 원하는 용량 들을 설정. 예약 조정 - 예측가능한 반복 이벤트에 따라 확장/축소가 발생해야하는 시간을 지정. 동적 조정 - 네트워크 대역폭 등 값을 가지고 더 상세하게 조정. ",
    "url": "/docs/aws/basic-service#auto-scaling",
    
    "relUrl": "/docs/aws/basic-service#auto-scaling"
  },"113": {
    "doc": "기본 서비스",
    "title": "기본 서비스",
    "content": "AWS에서 가장 기본적으로 사용되는 서비스는 EC2와 이와 같이 사용되는 ELB, Auto Scaling이 있다. ",
    "url": "/docs/aws/basic-service",
    
    "relUrl": "/docs/aws/basic-service"
  },"114": {
    "doc": "API Gateway, SQS, SNS",
    "title": "Amazon API Gateway",
    "content": "API Gateway는 API를 생성/게시/유지관리/모니터링/보안 적용할 수 있는 서비스이다. API Gateway를 완전 관리형 서비스로 제공한다. REST API를 제공하여 AWS 서비스를 활용할 수 있도록 한다. Gateway로서 트래픽 관리, 인증과 엑세스 제어, 모니터링, API 버전 관리, 다중 API 호출 처리 등의 작업을 처리한다. 메세지 변환 및 검증 . 메시지 변환 및 검증 기능을 제공한다. 요청/응답 메시지에 대한 스키마를 정의하기 위해 모델을 생성할 수 있다. 요청/응답 페이로드 및 헤더는 모델을 기준으로 적절한 형식인지 검증할 수 있다. 매핑 템플릿을 사용해서 하나의 모델에서 다른 모델로 변환할 수 있다. 백엔드 리소스 노출 . 외부에서 직접적으로 서비스 서버에 접근하지 않고 gateway를 통해서 백엔드를 감출 수 있다. 현관문 역할을 하는 API를 생성할 수 있다. 캐시 . API 응답을 클라이언트에 더 가깝게 가져와서 캐시한다. 캐시를 이용해서 컴퓨팅 리소스를 사용하지 않고 성능을 개선할 수 있음. API 엑세스 제어 . 단일 단말에서의 초당 요청 개수, 일일 요청 개수 등을 조절할 수 있다. 하나의 클라이언트가 백엔드 시스템 용량을 과다하게 차지하는 것을 방지할 수 있다. API 메서드 호출에 보안 적용 . API 엑세스에 보안을 적용할 수 있다. 리소스 정책: 사용자가 API를 호출할 수 있는지 여부를 제어하기 위해 API에 연결하는 Json 정책 문서 IAM 권한 정책: API의 생성과 배포, 메서드 호출의 권한 정책을 생성. VPC: Virtual Private Cloud 클라이언트를 통해서 액세스할 수 있는 API 엔드포인트 생성. Amazon Cognito, Lambda 권한부여자: Lambda 권한부여자나 Cognito와 통합하여 백엔드 리소스에 액세스 하기 전에 클라이언트를 인증. Gateway 활용 . CloudWatch에 로그 메시지 및 상세 지표를 전송하여 API 로깅을 할 수 있음. Lambda 함수를 CRUD 백엔드로 붙여서 해당 데이터를 DynamoDB에 저장할지 S3에 저장할지 구분. ",
    "url": "/docs/aws/gw-sqs-sns#amazon-api-gateway",
    
    "relUrl": "/docs/aws/gw-sqs-sns#amazon-api-gateway"
  },"115": {
    "doc": "API Gateway, SQS, SNS",
    "title": "SNS와 SQS",
    "content": "프로세스는 sync(바로 처리 후 응답) 방식과 async(queue에 넣어 순차 처리) 방식으로 나뉜다. SQS (Simple Queue Service) . async 처리를 하는 완전관리형 서비스이다. 처리를 할 리소스를 기다리는 메시지를 저장하는 Queue의 역할을 한다. 사용자가 메시지 저장/관리에 신경쓰지 않고 메시지를 활용하는 애플리케이션만 집중할 수 있다. EC2 와 결합하여 사용되며 EC2가 죽어도 메시지가 남아 보다 안정적이다. 수신측이 폴링을 통해 메시지를 가져가며 수신과 1대1 관계이다. sendMessageBatch로 최대 10개의 메세지를 한 번에 보낼 수 있다. 표준 대기열과 FIFO 대기열을 지원한다. 표준 대기열: 메시지 순서가 보장되지 않음. 메시지가 중복될 수 있음. 처리량이 비교적 많음. FIFO 대기열: 메시지 순서가 유지됨. 메시지가 중복 없이 한 번만 수신됨. 처리량에 제한. (초당 300개의 트랜잭션) . 메시지는 최대 256KB의 크기이고 제한 시간 초과(기본 30초, 최대 12시간), 메시지 보존 기간(기본 4일, 최소 60초, 최대 14일)를 갖는다. 제한 시간 초과: 하나의 Queue는 생산자/소비자가 가져가는게 규칙인데, 멀티 스레드나 여러 프로그램에서 Queue를 쳐다볼 수 있다는 것이고 이거를 막는것이 제한 시간 초과이다. 예를 들면 여러 EC2 인스턴스가 동시에 처리하는 문제가 생길 수 있음. SQS가 송수신이 1대1이라는 것은 수신이 처리를 하고 메시지를 지워서 혼자만 보기 때문에 1대1이라고 하는 것이고, 보기 전까지 문제가 발생할 수 있는 부분에 대한 내용. 메시지를 수신하면 처리했다는 것을 알리기 위해 메시지를 지워야 한다. SQS 작업 API 참고. SNS (Simple Notification Service) . 메시지가 들어오는 순간 구독자에게 메시지를 알려주는 서비스이다. push 방식으로 알림이 전송되기 때문에 새로운 정보/업데이트를 정기적으로 확인할 필요가 없다. 구독자에는 Lambda, SQS, http, email, SMS, mobile을 등록할 수 있다. 수신측이 푸시를 통해 수동적으로 메시지를 받으며, 1대 다수의 관계이다. 메시지의 순서는 보장되지 않으며 게시된 후에는 삭제할 수 없다.(남한테 보내는거니까) SNS 전송 정책에서 메시지 전송 실패시 재시도를 제어할 수 있다. SNS API 참고. 팬아웃 . 메시지를 SNS로 받아와서 SNS가 여러 대의 SQS로 메시지를 전달하는 것. 각 SQS는 서로 다른 작업을 하는 EC2와 연결될 수 있는 방식이다. 예를들어 팬아웃 방식을 이미지 처리에 사용할 수 있다. SNS로 메세지를 받으면 SNS는 썸네일 생성/모바일용 이미지 생성/웹용 이미지 생성의 각각의 SQS에 메시지를 보내도록 처리할 수 있다. Amazon MQ . Apache ActiveMQ를 위한 관리형 메시지 브로커 서비스. 메시지 브로커를 클라우드에서 쉽게 설정하고 운영할 수 있도록 한다. 기존 애플리케이션의 메시지 기능을 클라우드로 마이그레이션 할 때 사용이 권장된다. ",
    "url": "/docs/aws/gw-sqs-sns#sns%EC%99%80-sqs",
    
    "relUrl": "/docs/aws/gw-sqs-sns#sns와-sqs"
  },"116": {
    "doc": "API Gateway, SQS, SNS",
    "title": "API Gateway, SQS, SNS",
    "content": " ",
    "url": "/docs/aws/gw-sqs-sns",
    
    "relUrl": "/docs/aws/gw-sqs-sns"
  },"117": {
    "doc": "container",
    "title": "도커 컨테이너",
    "content": "도커 컨테이너는 애플리케이션을 실행하는데 필요한 모든 항목(코드, 실행시간, 시스템 도구, 라이브러리 …)를 포함하고 있는 배포의 표준화된 단위이다. 간편하게 서비스 모델링을 할 수 있다. 경량, 이식성, 일관성을 갖는다. 모든 앱 모든 언어에서 사용할 수 있다. 한 번만 작성하여 패키지화 해두면 어디서든 실행할 수 있다. 앱을 마이크로 서비스로 더욱 쉽게 분리할 수 있다. ",
    "url": "/docs/aws/container#%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88",
    
    "relUrl": "/docs/aws/container#도커-컨테이너"
  },"118": {
    "doc": "container",
    "title": "개발 수명 주기",
    "content": "Dockerfile은 컨테이너에 포함되는 구성 요소를 포함하고 있는 파일로, 명령어들로 이루어져 있다. Dockerfile을 통해 컨테이너 이미지를 생성하고 이 이미지를 다운 받아서 사용하도록 한다. ",
    "url": "/docs/aws/container#%EA%B0%9C%EB%B0%9C-%EC%88%98%EB%AA%85-%EC%A3%BC%EA%B8%B0",
    
    "relUrl": "/docs/aws/container#개발-수명-주기"
  },"119": {
    "doc": "container",
    "title": "도커 이미지",
    "content": "도커 이미지는 파일 모음으로 아래와 같은 구조(스택)로 도커 이미지가 구성된다. 커널(bootfs) &gt; 기본 이미지(Debian) &gt; 이미지(emacs 추가) &gt; 이미지(Apache 추가) &gt; 컨테이너(쓰기 가능) . 지침은 Dockerfile에 저장된다. 대부분 동일한 os를 기반하여야 한다. 도커 이미지를 저장하기 위해 amazon ECR/Docker Hub/private repository를 사용할 수 있다. ",
    "url": "/docs/aws/container#%EB%8F%84%EC%BB%A4-%EC%9D%B4%EB%AF%B8%EC%A7%80",
    
    "relUrl": "/docs/aws/container#도커-이미지"
  },"120": {
    "doc": "container",
    "title": "Amazon 컨테이너 서비스",
    "content": "컨테이너가 많아졌을 때는 관리하기가 어려워질 수 있다. AWS에서 컨테이너 관련하여 서비스를 제공한다. 관리 - ECS, EKS (배포/예약/조정 및 관리) 호스팅 - EC2, Fargate (Fargate는 EC2를 관리해줌) 이미지 - ECR (컨테이너 이미지용 리포지토리) . ECS - 컨테이너의 배포 관리를 도와주는 완전 관리형 컨테이너 조정 서비스. EKS - k8s를 쉽게 실행할 수 있도록 하는 관리형 서비스. Fargate - 컨테이너를 실행하기 위해 조정할 필요가 없음. 컨테이너 이미지를 업로드하고 리소스 요구사항을 지정하면 컨테이너를 실행해 준다. ECS와 같이 사용되기도 함. ",
    "url": "/docs/aws/container#amazon-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EC%84%9C%EB%B9%84%EC%8A%A4",
    
    "relUrl": "/docs/aws/container#amazon-컨테이너-서비스"
  },"121": {
    "doc": "container",
    "title": "container",
    "content": "container란 배포를 쉽게할 수 있는 방법으로 사용한다. 개발자가 운영팀의 도움 없이도 배포를 할 수 있다. 개발을 하고 배포하는데 설치/setup 해야하는 작업들이 굉장히 많다. (os/application) . 배포 방식의 변화: . | os/app 들을 차례대로 설치 - 너무 오래 걸림 | os와 platform을 image화 하여 copy/paste로 하여 배포 - os 배포 시간과 부팅 시간이 걸림 | os의 가상화를 이용해 os는 동일하게 사용하고 컨테이너화(app만 독립적으로 동작하도록 쪼개서 파티션화) 함 - app 실행 시간만 걸림 | . 런타임 엔진, 코드, 종속항목 으로 구성된다. 서버 &gt; 호스트 OS &gt; 도커 위에 각 컨테이너(Bins/Libs, app)가 올라간다. ",
    "url": "/docs/aws/container",
    
    "relUrl": "/docs/aws/container"
  },"122": {
    "doc": "ElastiCache",
    "title": "용어",
    "content": "노드 - 가장 작은 블록. 선택에 따라 memcached/Redis 인스턴스를 실행 클러스터 - 하나 이상의 노드로 구성된 논리적 그룹 엔드포인트 - 클러스터에 연결하는 고유한 주소 복제그룹 - Redis 클러스터의 모음 캐시 히트 - 캐시가 요청된 정보를 포함 캐시 미스 - 캐시가 요청된 정보를 포함하지 않음 . ",
    "url": "/docs/aws/elasticache#%EC%9A%A9%EC%96%B4",
    
    "relUrl": "/docs/aws/elasticache#용어"
  },"123": {
    "doc": "ElastiCache",
    "title": "캐싱 전략",
    "content": "레이지 로딩: 캐시 히트/미스에서 레이지 캐싱 전략을 구현한다. 필요할 때만 데이터를 캐시로 로드하는 전략으로 가장 많이 쓰이는 전략이다. 장점: 요청된 데이터만 캐싱 됨. 노드 장애가 치명적인 영향을 주지 않음. 단점: 캐시 미스 패널티가 있음. 애플리케이션이 오래된 데이터를 수신할 수 있음. 연속 쓰기: 데이터베이스가 작성될 때마다 캐시에 데이터를 추가하거나 데이터를 업데이트 한다. 일반적인 DB에서 write: read = 1: 9의 비율이기 때문에 효율이 떨어진다. 장점: 최신 데이터 단점: 쓰기 패널티, 데이터 누락(노드 장애 등으로 새로운 노드 생성시 DB 작성때까지 비어있음), 미사용 데이터, 잦은 캐시 변동. ",
    "url": "/docs/aws/elasticache#%EC%BA%90%EC%8B%B1-%EC%A0%84%EB%9E%B5",
    
    "relUrl": "/docs/aws/elasticache#캐싱-전략"
  },"124": {
    "doc": "ElastiCache",
    "title": "ElastiCache",
    "content": "ElastiCache는 인 메모리 캐시를 쉽게 배포/운영/조정할 수 있게 해주는 서비스. 캐싱의 장점을 가지고 있기 때문에 자주쓰는 데이터를 가져와서 애플리케이션 속도 개선, 지연시간 단축, 쿼리 호출 수를 줄이는 장점이 있다. DB 서버에 대한 트래픽이 증가할 때에 대한 해결책으로 사용할 수 있다. write보다는 read가 많으면서 느리고 비용이 많이 드는 데이터, 정적인 값이면서 자주 사용하는데이터, 기한이 경과된 데이터에서 고려하여 사용한다. Memcached, Redis를 지원한다. Memcached: 멀티스레딩, 유지 관리 용이, 간편한 수평 확장, 단일 AZ Redis: 다양한 데이터 구조 지원, 지속성, 원자조작, 구독 메시지(Pub/Sub), 다중 AZ . | 특성 | Memcached | Redis | . | DB 부하를 줄이는 캐시 | Y | Y | . | 고급 데이터 유형 | N | Y | . | 데이터 세트 정렬/순위 지정 | N | Y | . | Pub/Sub 기능 | N | Y | . | 다중 AZ로 자동 장애 조치 | N | Y | . | 지속성 | N | Y | . ",
    "url": "/docs/aws/elasticache",
    
    "relUrl": "/docs/aws/elasticache"
  },"125": {
    "doc": "Lambda",
    "title": "lambda 사용",
    "content": "간단한 문제를 간단한 솔루션으로 해결하자는게 모토. 간단하게 코드를 작성하고 리소스 모델을 선택하여 유연하게 다른 서비스들과 통합하여 사용한다. CloudWatch로 로그 분석과 X-Ray를 통한 분산 추척을 같이 활용한다. ",
    "url": "/docs/aws/lambda#lambda-%EC%82%AC%EC%9A%A9",
    
    "relUrl": "/docs/aws/lambda#lambda-사용"
  },"126": {
    "doc": "Lambda",
    "title": "lambda 함수의 구조",
    "content": "lambda 함수는 Handler 함수와 이벤트 객체, 컨텍스트 객체로 구성된다. public MyOutput handlerName(MyEvent event, Context context) {} . Handler 함수: Lambda 함수가 호출되면 Handler에서 코드 실행이 시작된다. 코드 방식도 main 보다는 handler와 같이 이루어진다. Handler는 lambda 함수를 생성할 때 지정한다. 이벤트 객체: 서비스에서 만들어져서 전달되는 값이다. event data를 Handler로 전달하는데 사용된다. 함수가 로직을 제어할 때 필요한 모든 데이터와 메타데이터를 포함한다. 컨텍스트 객체: 컨텍스트 객체를 사용해서 함수 코드가 Lambda 실행 환경과 상호작용할 수 있다. 런타임 정보를 제공하는데 AWS RequestId, 함수 제한 시간, 로깅 등을 포함한다. ",
    "url": "/docs/aws/lambda#lambda-%ED%95%A8%EC%88%98%EC%9D%98-%EA%B5%AC%EC%A1%B0",
    
    "relUrl": "/docs/aws/lambda#lambda-함수의-구조"
  },"127": {
    "doc": "Lambda",
    "title": "실행 모델",
    "content": "push event 모델: 이벤트 호출 유형으로 이벤트 소스가 이벤트를 게시할 때 직접 Lambda 함수를 호출한다. S3, SNS Cognito Echo 및 사용자 애플리케이션에 적용되는 방식이다. pull event 모델: Lambda가 이벤트를 감지하면 이벤스 소스를 폴링하고 이벤트 소스가 Lambda를 호출한다. Kinesis 스트림, DynamoDB 스트림 같은 스트리밍 이벤트 소스와 쓰일 때 적용된다. 직접 호출: AWS Lambda가 함수를 동기식으로 실행하고 호출 애플리케이션에 응답을 즉시 반환한다. 사용자 지정 애플리케이션에서 사용할 수 있다. ",
    "url": "/docs/aws/lambda#%EC%8B%A4%ED%96%89-%EB%AA%A8%EB%8D%B8",
    
    "relUrl": "/docs/aws/lambda#실행-모델"
  },"128": {
    "doc": "Lambda",
    "title": "권한",
    "content": "lambda와 관련된 권한은 두 가지 유형이 있다. 실행권한 - Lambda 함수가 다른 AWS 리소스에 액세스하는데 필요한 권한. 호출권한 - 이벤트 소스가 Lambda 함수와 통신하는데 필요한 권한. AWS에서는 서비스 간에도 접근을 위해 권한이 필요하고, lambda에서 꼭 권한을 부여해주어야 한다. ",
    "url": "/docs/aws/lambda#%EA%B6%8C%ED%95%9C",
    
    "relUrl": "/docs/aws/lambda#권한"
  },"129": {
    "doc": "Lambda",
    "title": "실행",
    "content": "설정한 제한시간(기본 3초, 최대 15분)이 넘어가면 종료되어 그 이상가는 프로그램을 사용할 수 없다. 정기적으로 Lambda 함수를 실행하도록 지정할 수 있다. ",
    "url": "/docs/aws/lambda#%EC%8B%A4%ED%96%89",
    
    "relUrl": "/docs/aws/lambda#실행"
  },"130": {
    "doc": "Lambda",
    "title": "제한사항",
    "content": "인바운드 네트워크 연결은 차단된다. TCP/IP 소켓만 지원한다. ptrace(디버깅) 시스템 호출은 제한된다. TCP port 25 트래픽은 스팸 방지로 제한된다. ",
    "url": "/docs/aws/lambda#%EC%A0%9C%ED%95%9C%EC%82%AC%ED%95%AD",
    
    "relUrl": "/docs/aws/lambda#제한사항"
  },"131": {
    "doc": "Lambda",
    "title": "버전 관리 및 별칭",
    "content": "버전은 코드에 구성을 더한 사본으로 변경할 수 없다. 별칭은 버전에 대한 포인터로 변경할 수 있다. 각 버전/별칭에 자체 ARN이 지정된다. ",
    "url": "/docs/aws/lambda#%EB%B2%84%EC%A0%84-%EA%B4%80%EB%A6%AC-%EB%B0%8F-%EB%B3%84%EC%B9%AD",
    
    "relUrl": "/docs/aws/lambda#버전-관리-및-별칭"
  },"132": {
    "doc": "Lambda",
    "title": "요금",
    "content": "아래 항목들로 요금이 청구된다. | 모든 함수에 걸친 총 요청 수. | 코드가 실행되는 시간. | Lambda 함수에 할당하는 메모리 양. | . ",
    "url": "/docs/aws/lambda#%EC%9A%94%EA%B8%88",
    
    "relUrl": "/docs/aws/lambda#요금"
  },"133": {
    "doc": "Lambda",
    "title": "Step Function",
    "content": "AWS Lambda의 경우 제한시간(15분)내에 동작이 완료되어야 한다. 제한시간을 초과할만한 상황(동영상 전송/변환 등)이 있을 수 있고 이를 여러 개의 함수의 수행으로 처리할 수 있다. 여러 함수를 수행하는데 워크플로를 정의하고 단계별로 수행할 수 있도록 정의한다. JSON으로 정의하고 시각화로 확인할 수 있다. 콘솔에서 시각화를 확인하고 모니터링도 가능하다. 사용하는 경우: 실패한 작업을 다시 시도하려는 경우 연속된 작업을 하려는 경우 try/catch/finally를 실행하려는 경우 데이터 기반 작업을 선택하려는 경우 작업을 병렬로 실행하려는 경우 . 장점: 빠르게 애플리케이션을 빌드할 수 있는 생산성을 갖는다. 안정적으로 확장/복구할 수 있다. 단계를 쉽게 편집해서 애플리케이션을 쉽게 수정할 수 있다. 다른 서비스와 연동하여 사용할 수 있다. ",
    "url": "/docs/aws/lambda#step-function",
    
    "relUrl": "/docs/aws/lambda#step-function"
  },"134": {
    "doc": "Lambda",
    "title": "상태 기계",
    "content": "출력을 결정하기 위해 이전 조건에 의존하는 작동 조건을 가진 객체이다. 상태 기계의 입력을 함수로 전달하여 Lambda 함수를 호출한다. Amazon State Language(json)으로 작업을 수행할 수 있는 상태(작업 상태), 전환할 상태를 결정하는 상태(선택 상태), 실행을 중지하는 상태(실패 상태)를 명시해 작업을 수행한다. ",
    "url": "/docs/aws/lambda#%EC%83%81%ED%83%9C-%EA%B8%B0%EA%B3%84",
    
    "relUrl": "/docs/aws/lambda#상태-기계"
  },"135": {
    "doc": "Lambda",
    "title": "Lambda",
    "content": "AWS에서 제공하는 서버리스 컴퓨팅 서비스이다. 코드를 함수로 업로드만 하면 Lambda가 알아서 관리하여 사용될 수 있도록 한다. 이벤트 소스에서 호출을 트리거하면 lambda에서 코드를 가져와서 실행하는 방식이다. ",
    "url": "/docs/aws/lambda",
    
    "relUrl": "/docs/aws/lambda"
  },"136": {
    "doc": "보안, 배포",
    "title": "애플리케이션 보안",
    "content": "통신에 대한 암호화는 Http protocol을 통해 할 수 있다. 암호화에 필요한 키(SSL에서는 인증서)를 가지고 암호화/복호화를 진행한다. AWS Certificates Manager를 통해서 인증서를 쉽게 배포하고 관리할 수 있다. AWS Secrets Manager . Secrets Manager를 통해 수명 주기 전체에서 DB 자격 증명, API키 및 기타 암호를 교체 관리 검색한다. 코드 상에 userid와 pw를 적는 것이 아니라, secrets Manager에 값을 적어두고 Secrets Manager에서 그 값을 가져와서 사용하도록 하는 방식이다. 따라서 암호를 보호하고 유출을 막을 수 있다. STS (Security Token Service) . 어플리케이션에서 임시 키를 생성하는데 사용되는 서비스. IAM을 인증할때는 액세스키/보안키를 사용하지 않고 Security Token Service를 통한 임시 액세스키/보안키를 사용하는 것이 좋다. 임시 키 발급을 요청한 사용자의 IAM 정책을 사용해서 권한을 제어한다. 키를 만들면서 Role을 만들고 Role에 권한을 부여하여 해당 Role로 임시 키를 발급받을 수 있다.(Assume role) 이를 통해 사용자의 권한 전체를 부여하는게 아니라 일부 서비스만 권한을 줄 수 있다. STS 자격 증명 브로커를 사용할 수 있다. | 사용자가 자격 증명 브로커에 엑서스를 요청 | 자격 증명 브로커가 별도의 자격 증명 스토어를 통해 확인(예를 들면 회사 사람인지를 확인) | 자격 증명 브로커가 STS에 키를 요청 | 받은 키로 AWS에 접근 | . Cognito . Amazon Cognito를 통해 다양한 기기에서 사용자 데이터 저장 및 동기화를 허용할 수 있다. 외부 공급자(Google, Amazon, Facebook)로 인증 후 액세스할 수 있다. (이후 Congnito가 STS에 키를 요청) 자체 인증 시스템을 연동해서 사용할 수도 있다. ",
    "url": "/docs/aws/security-deploy#%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EB%B3%B4%EC%95%88",
    
    "relUrl": "/docs/aws/security-deploy#애플리케이션-보안"
  },"137": {
    "doc": "보안, 배포",
    "title": "애플리케이션 배포",
    "content": "최근 데브옵스 문화로 많은 부분이 자동화되고 개발자가 배포도 같이하고 있다. IaC (Infrastructure as Code) . 복잡한 환경에서의 배포를 해결하는 목적 중 하나이다. 말 그대로 코드로 인프라를 갖추는 것이다. 반복 가능하고 자동화된 방식으로 생성될 수 있도록 환경을 정의하고, 코드로 프로덕션 환경을 생성하는 것이다. AWS에서는 이러한 배포 서비스로 CodeStar를 서비스하고 있다. 블루-그린 배포 패턴 . 기존환경(블루)로 라우팅하다가 신규코드(그린)으로 트래픽을 옮기고 이슈가 되면 다시 블루로 롤백하는 배포 방식이다. 그린이 안정적이게 되면 블루가 된다. 문제가 생기면 바로 롤백할 수 있으니 안전한 배포 방식이다. Route53 - Amazon Route53으로 블루 그린 배포패턴을 위한 가중치 기반 트래픽 이동을 쉽게할 수 있다. ELB 활용 - ELB에 블루 인스턴스만 있다가 그린 인스턴스를 추가하고, 블루 인스턴스를 중지 시키는 것.(삭제 아님) . Elastic Beanstalk . AWS Elastic Beanstalk는 EC2, Auto Scaling, ELB 등의 AWS 서비스에 대한 래퍼를 제공하여 배포를 편하게 할 수 있다. ",
    "url": "/docs/aws/security-deploy#%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EB%B0%B0%ED%8F%AC",
    
    "relUrl": "/docs/aws/security-deploy#애플리케이션-배포"
  },"138": {
    "doc": "보안, 배포",
    "title": "보안, 배포",
    "content": " ",
    "url": "/docs/aws/security-deploy",
    
    "relUrl": "/docs/aws/security-deploy"
  },"139": {
    "doc": "성능 좋은 Java/Python의 기본 sorting 알고리즘, Tim Sort 이해하기",
    "title": "TimSort 란?",
    "content": "Tim Sort는 Java, Python을 비롯한 여러 언어와 프레임워크에서 기본 알고리즘으로 사용되는 sorting 알고리즘이다. | python (since v2.3) | java (since SE 7) | android | V8 | Swift | . ",
    "url": "/docs/11.Algorithm/2020-07-13-timsort.html#timsort-%EB%9E%80",
    
    "relUrl": "/docs/11.Algorithm/2020-07-13-timsort.html#timsort-란"
  },"140": {
    "doc": "성능 좋은 Java/Python의 기본 sorting 알고리즘, Tim Sort 이해하기",
    "title": "특징",
    "content": ". | hybrid sorting algorithm (merge + insertion) | highly optimized mergesort | stable and faster mergesort | . ",
    "url": "/docs/11.Algorithm/2020-07-13-timsort.html#%ED%8A%B9%EC%A7%95",
    
    "relUrl": "/docs/11.Algorithm/2020-07-13-timsort.html#특징"
  },"141": {
    "doc": "성능 좋은 Java/Python의 기본 sorting 알고리즘, Tim Sort 이해하기",
    "title": "장점",
    "content": ". | 작은 수의 sort에서 quick이나 merge sort보다 빠른 속도를 보인다. | 큰 수에 있어서도 빠른 속도를 보인다. | real data에서 강하다. | 테스트를 하는 데이터(실험실에서나 보이는)들에서는 whole random data 이기 때문에 기존의 sorting들과 유사한 속도. | real data들은 부분 sorting 되어 있거나 연속적인 값인 경우가 많아 더 효율적. | . | worst case에서도 성능을 유지한다. | quick sort와 대비하여 사용되는 이유가 되기도 함. | . | . ",
    "url": "/docs/11.Algorithm/2020-07-13-timsort.html#%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/11.Algorithm/2020-07-13-timsort.html#장점"
  },"142": {
    "doc": "성능 좋은 Java/Python의 기본 sorting 알고리즘, Tim Sort 이해하기",
    "title": "주요 개념",
    "content": "Tim sort의 기본은 merge sort 이다. 여러가지 기술들로 여러 부분의 단점들을 개선해낸 sorting 알고리즘이다. binary insersion sort . insertion sort의 \\(O(n^2)\\)를 \\(C1 * n^2 + a1\\) 라고 표현한다면 merge sort의 \\(O(nlogn)\\)을 \\(C2 * nlogn + a2\\)라고 표현할 수 있는데, 작은 n에서는 C1과 C2의 크기가 성능에 큰 영향을 미치며 insertion sort가 더 효율적이다. 따라서 성능 개선을 목적으로 tim sort는 작은 단위에서 insertion sort를 사용한다. 효율을 위해 binary search로 넣을 위치를 찾는다. run . run은 각각이 insertion sort로 sorted 된 기본 단위이다. Tim sort는 run이라는 덩어리를 만들어놓고 run들을 merge하는 방식으로 진행된다. minRun을 통해 run의 최소 크기를 정함. | ary의 크기를 N이라하면 minRun = min(N, MIN_MERGE) | MIN_MERGE의 경우 \\(2^5\\) ~ \\(2^6\\) 의 값을 사용. | 이는 통계적으로 insertion sort가 더 빠른 크기. | 전체 크기에서 mergesort가 가장 효율적일 수 있는 minRunLength를 계산하여 사용. | merge sort는 2의 제곱수일 때 가장 효율이 좋음. | . | . merge stack . 각각의 run은 stack에 쌓이고 Tim sort의 merge는 stack에서 run들을 가져와 병합하는 방식으로 이루어진다. 기존의 merge sort에서 중요한 부분들이 run을 도입하여 Tim sort에서 추가적으로 고려해야 되는 부분들이 있다. Tim sort가 여기서 고려한 부분은 다음과 같다. | stack의 갯수를 조절한다. | merge sort는 stack을 사용하지 않음. | run을 무자비하게 쌓으면 stack의 메모리 문제. | . | 길이가 유사한 크기의 run 끼리 병합한다. | merge sort에서는 유사/동일한 크기의 덩어리를 병합하는 것이 기본. | . | 인접한 run을 병합한다. | merge sort에서는 인접한 덩어리를 병합하는 것이 기본. | 안정성과 효율적인 처리를 위해. | . | . 이러한 구현을 위해 stack에 run을 쌓을 때 다음과 같은 조건으로 stack을 쌓는다. | C &gt; A + B | B &gt; A | . run merge . merge를 실제 진행할 때, merge sort의 단점은 추가 메모리를 n 사용한다는 점이었다. Tim sort에서는 두 run의 merge 과정에서 작은 run만 복사하여 merge 값을 채우는 방식으로 진행하여 추가 메모리를 n/2 이하로 줄인다. galloping . 두 run을 merge할 때 한 쪽에서 계속해서 큰 숫자가 보이는 경우 galloping mode를 발동시킨다. galloping mode는 \\(2^k\\) 번씩 점프하며 merge sort의 속도를 증가시킬 수 있도록 한다. ",
    "url": "/docs/11.Algorithm/2020-07-13-timsort.html#%EC%A3%BC%EC%9A%94-%EA%B0%9C%EB%85%90",
    
    "relUrl": "/docs/11.Algorithm/2020-07-13-timsort.html#주요-개념"
  },"143": {
    "doc": "성능 좋은 Java/Python의 기본 sorting 알고리즘, Tim Sort 이해하기",
    "title": "다시보는 장점",
    "content": ". | 작은 수의 sort에서 quick이나 merge sort보다 빠른 속도를 보인다. | insertion sort의 활용 | . | 큰 수에 있어서도 빠른 속도를 보입니다. | 작은 단위에서의 insertion sort의 역할 | 기본적으로 merge sort의 성능 | . | real data에서 강하다. | 테스트를 하는 데이터(실험실에서나 보이는)들에서는 whole random data 이기 때문에 기존의 sorting들과 유사한 속도. | real data들은 부분 sorting 되어 있거나 연속적인 값인 경우가 많아 더 효율적. | insertion sort가 정렬된 데이터에 대해서 보다 효율적으로 동작 | galloping mode로 일부 정렬된 데이터에서 더 빠르게 sort | . | worst case에서도 성능을 유지한다. | quick sort와 대비하여 사용되는 이유가 되기도 함. | 기본적으로 merge sort의 성능 | . | . ",
    "url": "/docs/11.Algorithm/2020-07-13-timsort.html#%EB%8B%A4%EC%8B%9C%EB%B3%B4%EB%8A%94-%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/11.Algorithm/2020-07-13-timsort.html#다시보는-장점"
  },"144": {
    "doc": "성능 좋은 Java/Python의 기본 sorting 알고리즘, Tim Sort 이해하기",
    "title": "코드",
    "content": "jetbrains에서 관리하는 repo인 jdk8를 참고하면 좋다. 이 외에도 여러 곳에서 timsort 소스코드를 확인할 수 있다. ",
    "url": "/docs/11.Algorithm/2020-07-13-timsort.html#%EC%BD%94%EB%93%9C",
    
    "relUrl": "/docs/11.Algorithm/2020-07-13-timsort.html#코드"
  },"145": {
    "doc": "성능 좋은 Java/Python의 기본 sorting 알고리즘, Tim Sort 이해하기",
    "title": "merge sort vs tim sort",
    "content": "merge sort와 tim sort를 비교하는 속도 영상 참고 . ",
    "url": "/docs/11.Algorithm/2020-07-13-timsort.html#merge-sort-vs-tim-sort",
    
    "relUrl": "/docs/11.Algorithm/2020-07-13-timsort.html#merge-sort-vs-tim-sort"
  },"146": {
    "doc": "성능 좋은 Java/Python의 기본 sorting 알고리즘, Tim Sort 이해하기",
    "title": "reference",
    "content": ". | python timsort 원본 | JetBrain에서 사용하는 jdk8의 timsort | Timsort wiki | naver D2에서 정리한 timsort | orchistro님이 정리한 timsort | stackoverflow timsort vs quicksort | stackoverflow timsort vs mergesort | . ",
    "url": "/docs/11.Algorithm/2020-07-13-timsort.html#reference",
    
    "relUrl": "/docs/11.Algorithm/2020-07-13-timsort.html#reference"
  },"147": {
    "doc": "성능 좋은 Java/Python의 기본 sorting 알고리즘, Tim Sort 이해하기",
    "title": "성능 좋은 Java/Python의 기본 sorting 알고리즘, Tim Sort 이해하기",
    "content": " ",
    "url": "/docs/11.Algorithm/2020-07-13-timsort.html",
    
    "relUrl": "/docs/11.Algorithm/2020-07-13-timsort.html"
  },"148": {
    "doc": "서버 개발자, 2020 회고",
    "title": "설계",
    "content": "올해 팀을 옮겨서 배웠던 것 중 가장 크게 배우고 느낀 것은 설계에 대한 부분이다. 이전 팀에서는 유지/보수가 대부분인 업무에 새로 무언가를 개발하는 일은 잘 없기 때문에, 제대로 된 설계 회의를 진행해본 적이 없었다. 팀을 옮기고 새로운 모듈 개발과 이어지는 배치 개발을 위한 반복된 설계가 개인적으로는 배울 점이 많았다. 설계 회의에 참여해서 구조를 생각하고 그려나가고 토론하는 것이 도움이 많이 되었는데, 어떻게 토론을 해나가고 어떤 부분을 짚어나가야 하는지 알 수 있었다. 처음에는 경험이 적다보니 아 그렇구나 하고 넘어가던 설계들이 나중에는 나는 이렇게 생각했는데 팀원들 아이디어가 좋구나 하고 넘어가는 경우도 많았다. 아직은 배워가는게 크지만 내년에는 내가 더 많이 설계에 영향을 미치면 좋겠다는 생각이 든다. 설계는 남기고 싶은 내용들이 있어 따로 정리해본다. 동기화 작업 . 우리는 단말 앱과 연관이 많은 동기화 서버를 개발했다. 처음부터 시작하는 동기화와 현재 어디까지 동기화 되었는지를 구분하기 위한 값을 단말에 제공한다. 이 값은 이렇게 설계된다. | 단말이 이해할 수 없는 값이어야 한다. 따라서 우리만 아는 데이터를 암호화하여 내려준다. | 단말이 이해할 수 있다면, 특정 유저라거나 특정 값의 데이터를 단말이 직접 수정할 수 있으면 우리가 통제할 수 없는 동기화 시나리오가 발생하거나 다른 이슈가 생길 수 있다. | . | 단말이 임의로 수정하면 동기화 에러가 나야한다. | 위와 동일한 이유이다. 동기화 에러가나면 초기 동기화(처음부터 시작하는 동기화)를 할 수 있도록 값을 내려주고 유도한다. | . | . 동기화 서버를 개발하면서 우리한테 쌓인 노하우가 아닌가 싶다. 배치 . 우리가 관리하는 서비스 하나는 배치 서버가 네 대가 있다. 필요해 의해 하나씩 추가되다가 이렇게 되었는데 참 번거롭고 헷갈리기도 하다. 새로 모듈을 만들면서 배치를 설계할 때는 기존의 구조를 따르지 않도록 batch job이 추가가능한 배치 모듈을 설계하려고 노력했다. kafka를 통해 연결된 배치 서버를 개발하고 여러 job task를 수행할 수 있도록 설계하고 필요하다면 task를 추가 설계하는 방식으로 구현했다. 서비스 말고도 배치 서버도 초기 설계가 중요하다는 것을 많이 느꼈다. 그리고 delete는 최대한 안전하고 정확하게 진행되어야 한다는 것도. 언어 . golang을 공부하고 배치에 적용한 것도 기억에 남는다. golang 스터디를 하고 잠깐 잊고 지냈는데 기존 batch의 성능을 개선하는 작업을 하면서 batch를 golang으로 설계했다. language의 중요성을 이번에 느끼게 되었는데 이렇다. | 기존의 python batch가 성능이 굉장이 안좋았다. | 한 눈에 봐도 개선의 여지가 명확했고 일부 로직을 개선한 python batch로 업그레이드?했다. | golang의 go routine(경량 thread)와 빠른 성능이 좋은 효율을 발휘할만한 상황으로 보였다. | language 변경하고 설계하여 다시 개발했다. | 단일 ec2 기준 100배에 가까운 성능 개선이 이뤄졌다. | . 이번 작업을 하면서 느낀 것은 . | 개발 없이 스터디 하는건 오래 남지 않는다. | 코드는 부패하기 마련이고 잊혀진다. | 언어가 중요하다. | golang이 굉장한 효율을 발휘하는 부분들이 있다. | 특히 경량 쓰레드는 굉장하다. | . | . ",
    "url": "/docs/retrospect/2020#%EC%84%A4%EA%B3%84",
    
    "relUrl": "/docs/retrospect/2020#설계"
  },"149": {
    "doc": "서버 개발자, 2020 회고",
    "title": "자동화",
    "content": "작년에 여러 작업들에 걸쳐서 (거창하게 표현하면) 자동화가 많이 진행되었다. 이런 자동화 작업들은 내가 생각하기에 이런 장점들이 있다. | 귀찮은 작업들을 이젠 하지 않아도 된다. | 반복된 업무는 귀찮지만 자동화 툴을 만드는건 재밌는 작업이다. | . 우리 팀은 올해 이런 작업들을 자동화 했다. | WAS나 batch에서 error나 issue에 대해 slack noti 적용 . | 우리가 새로 만든 모듈에서 500 error에 대해 slack noti를 적용하고 이 모듈에서는 우리가 알지 못하는 500 error는 없도록 유지보수를 하고 있다. 모르는 500 error가 나온다면 바로 노티를 받고 수정에 들어간다. (부끄럽지만 다른 모듈은 아마 500 error가 좀 있을 것 같다) | Grafana나 지표는 만들어놔도 손이 잘 안가기 때문에 초기 서버에서 이런 작업을 해놓는게 굉장히 서버 관리에 도움이 되었다. | . | versioning &amp; release note &amp; 문서 작성 . | 우리는 배포 프로세스가 굉장히 귀찮은 편이다. 우선 검증 팀에 변경사항을 문서로 작성해서 보내주어야 하고, 검증이 끝나면 변경사항을 결재를 올려야 한다. 그리고 나서 release note를 작성하는데 이게 참 귀찮아서 날 잡고 자동화를 진행했다. | 문서 작성 프로그램을 python으로 작성했다. git commit과 PR rule을 자동화하기 좋게 convention을 잘 지키면서 convention에 맞는 commit/PR message들을 가지고 major/minor/patch version을 자동으로 계산해서 version을 올리고 수정된 내용들을 정리하는 방식이다. 정리된 내용들과 버전은 검증 문서와 변경사항을 slack으로 보내고, github release에도 자동으로 업데이트 하도록 구현했다. (github / slack api 사용) | python dockerize를 하여 각 모듈에 circleci에 문서 작성 step 추가해서 docker를 수행하도록 했다. | 이 작업으로 정말 귀찮고 어떨땐 빼먹기도 했던 문서 작업들이 정리되었다. | . | . 자동화를 통해 업무에 대한 효율과 서비스 안정성을 확보할 수 있었다는 생각이 든다. 그리고 작업을 진행하면 평소에 관심을 두지 않았던, 진행하지 않았던 일들을 진행하게 되니 공부도 되고 지루하지도 않아 재밌게 개발을 할 수 있게 되었다. 그리고 생각보다 자동화가 어렵지 않다는 것을 느꼈다. 문서 자동화는 항상 불편했다. 자동화가 쉽지 않을 것이라 생각했는데 생각보다 쉽고 빠르게 일을 정리할 수 있었다. ",
    "url": "/docs/retrospect/2020#%EC%9E%90%EB%8F%99%ED%99%94",
    
    "relUrl": "/docs/retrospect/2020#자동화"
  },"150": {
    "doc": "서버 개발자, 2020 회고",
    "title": "테스트",
    "content": "새로운 모듈을 처음부터 개발하면서 우리는 성능 개선이나 요구사항 만족 등을 위해 테스트를 다양하게 진행해왔다. 우리가 진행한 테스트는 아래와 같다. | unit test . | unit 단위의 TDD에 필요한 단위 테스트 | . | api test . | 실제 api를 통해 server 밖에서 호출되는 테스트 | . | scenario test . | api, 기능 단위로 실제 사용자의 호출 flow(시나리오)에 맞게 정상 호출되는지 확인하는 테스트 | . | performance test . | pin point, locust를 통한 성능 테스트 | . | . 켄트 백이 말하는 테스트는 항상 마음을 편안하게 해주고 믿음을 준다라는 말이 참 공감이 된다. 여러 테스트를 통해 출시 전, 후로 우리 서비스에 대한 믿음을 가질 수 있었던 것 같다. 이전 모듈들에서 진행하지 않던 scenario 테스트도 추가했는데 테스트가 중요하고 unit/api 테스트에만 의존하지 않고 여러 종류의 테스트가 필요하다는 것을 배웠다. 돌아볼만한 점은 이렇다. | 중복되는 테스트 . | 위와 같이 여러 테스트가 있다보니 중복되는 테스트들이 있다. 테스트가 많으면 느려지기 쉬우니 test의 layer를 명확하게 하면 좋겠다. | . | 성능 테스트 . | 성능 테스트를 진행할 때 다른 개발을 하느라 성능 테스트 셋업이나 진행에 참여하지 못했는데 아쉽다. | . | 테스트 가독성 . | “테스트니까” 라는 말을 하기도 하고 듣기도 한다. 테스트는 좀 대충 짜도 된다라는 생각인데, 이게 리뷰할 때 굉장히 불편하고 코드 변경이 생길 때 테스트를 이해하는데 시간도 많이쓰게 되었다. | 테스트 안에 분기가 있는건 나는 정말 별로다. 그럴거면 테스트를 나눠야된다고 생각한다. 이게 취향인지, 이걸 하려고하는 팀원도 있긴하다. | . | . 재미있는 한 해였다. 팀 분위기가 중요하다는 것을 많이 느꼈다. pair work이나 code review, 회고 등의 개발 문화에 대해서도 많이 느꼈는데, 우리 팀은 이전 팀보다 자신의 생각과 불편할 수 있는 얘기들을 편하게 할 수 있어 참 좋은 것 같다. ",
    "url": "/docs/retrospect/2020#%ED%85%8C%EC%8A%A4%ED%8A%B8",
    
    "relUrl": "/docs/retrospect/2020#테스트"
  },"151": {
    "doc": "서버 개발자, 2020 회고",
    "title": "서버 개발자, 2020 회고",
    "content": "팀을 옮기고 올해는 새로운 것들을 배워 재미있는 시간들이었다. 팀 내에서 연간 회고를 진행했는데 회사에서의 나의 회고와 회고를 준비하며 느낀 올해에 대해 정리해본다. ",
    "url": "/docs/retrospect/2020",
    
    "relUrl": "/docs/retrospect/2020"
  },"152": {
    "doc": "kotlin in action 정리 #1",
    "title": "chapter 1. Kotlin, What and Why",
    "content": "사용성 . Java 진형의 사용성을 안전하고 간결하고 편리하게 대처하기 위해 나왔다. Intel mutli os engine으로 ios 개발도 가능하다. Javascript로도 컴파일 가능하다. 특성 . 자바와 동일하게 statically typed으로 타입을 컴파일 시점에서 알수 있어야 한다. | Statically typed는 장점이 있다. | performance, reliability, maintainability, tool support | . | . 그치만 자바처럼 모든 타입을 명시할 필요는 없고 알아서 타입을 결정할 수 있다. | 이걸 type inference라고 함. | . 자바의 많은 개념들이 그대로 녹아들어 있다. 추가되는 것들은 nullable type, functional 이 있다. 그래서 object oriented 와 functional을 모두 지원한다. Functional . functional의 주요 컨셉은 아래와 같다. | first-class function, immutability, no side effect functional의 장점은 아래와 같다. | conciseness, safe multithreading, easier testing. | . 철학 . | Pragmatic . | 연구용이 아니라 실제로 사용하기 위해 디자인 되었고 많은 다른 언어들의 개념을 가져와서 사용한다. | . | Concise . | Getter, setter, constructor param 같은 것들을 kotlin에 내장해서 간결하게 하였다. | . | Safe . | NPE를 막을 수 있는 ? 와 ClassCastException을 막기 위한 is 를 제공한다. | . | Interoperable . | Java의 라이브러리들을 그대로 사용할 수 있고  java의 class나 method도 그대로 사용할 수 있다. | Java에서도 kotlin 거를 그대로 사용할 수 있다. | Kotlin은 own collection library를 갖지 않고 java standard library를 사용해서 java와 kotlin간의 어떤 wrapper나 converter가 필요하지 않다. | . | . Compile . Kotlin은 java class로 컴파일되니까 java와 완전 호환된다. 배포시에는 kotlin runtime도 넣어주어야 한다. ",
    "url": "/docs/kotlin/kotlin-in-action/1#chapter-1-kotlin-what-and-why",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/1#chapter-1-kotlin-what-and-why"
  },"153": {
    "doc": "kotlin in action 정리 #1",
    "title": "kotlin in action 정리 #1",
    "content": "Kotlin in Action으로 Kotlin study 하기. ",
    "url": "/docs/kotlin/kotlin-in-action/1",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/1"
  },"154": {
    "doc": "kotlin in action 정리 #2",
    "title": "chapter 2. Kotlin Basics",
    "content": " ",
    "url": "/docs/kotlin/kotlin-in-action/2#chapter-2-kotlin-basics",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/2#chapter-2-kotlin-basics"
  },"155": {
    "doc": "kotlin in action 정리 #2",
    "title": "kotlin function body",
    "content": ". kotlin의 function 구조는 위와 같다. expression . Kotlin은 반복문(for, while)을 제외하고는 expression으로 판단된다. (If, when 등) expression은 value를 갖는다는 점에서 statement와 차이점을 보인다. 반면 java에서는 모든 control structure들이 statement이다. 여기서 value를 갖는다는 것은 expression 자체(expression의 결과)가 value를 갖는 것을 말한다. // 예를 들면 아래 if expression은 value를 갖고 있다. fun max(a: Int, b: Int): Int = if (a &gt; b) a else b . expression body . Block body와 expression body로 function의 body를 구분한다. Block body: {}으로 body가 쌓여진 일반적인 함수. Expression body: {} 없이 구현된 함수. 보통 one line function에서 사용하는 함수. variable . 변수에 타입을 명시하지 않아도 된다. 명시할수도 있는데, 초기 값을 넣어주지 않으면 타입 추론이 안되므로 명시해주어야 한다. val(from value): immutable (final in java) var(from variable): mutable . 기본적으로 val을 사용하고, 수정이 필요한 경우만 var를 사용하도록 한다. var이 change value를 허락해도, type은 fix되서 바뀔 수 없다. $로 local variable에 접근할 수 있고, 이건 $(expression) 으로도 사용이 가능하다. println(\"Hello, $name!\") println(\"Hello, ${if (args.size &gt; 0) args[0] else \"someone\"}!\") . class . kotlin은 public이 default라 public을 생략할 수 있다. property를 선언하면 기본적으로 내부적으로 getter/setter가 같이 선언된 것이라고 보면 된다. 그냥 class의 property를 사용하면 java의 getter를 호출해준다. getter/setter 외의 custom accessors를 만들 수 있다. custom accessors와 function을 만드는것의 차이는 . | 성능 상으로는 차이가 없다 | 가독성에만 차이가 있다 | . package . kotlin에도 package가 있고 java의 package 정책과 유사하다. import로 class와 method를 구분하지 않고 method도 import할 수 있다. 여러 class를 하나의 file에 넣을 수 있다. enum . enum이 java랑 좀 다르다. // 예제가 이해하기 편할 듯 하다. enum class Color( val r: Int, val g: Int, val b: Int ) { RED(255, 0, 0), ORANGE(255, 165, 0), YELLOW(255, 255, 0), GREEN(0, 255, 0), BLUE(0, 0, 255), INDIGO(75, 0, 130), VIOLET(238, 130, 238); fun rgb() = (r * 256 + g) * 256 + b } &gt;&gt;&gt; println(Color.BLUE.rgb()) . when . when과 함께 쓰일 때 enum의 효과가 더 크다. when은 java의 switch와 비슷한데, 더 파워풀하다. | any objects나 들어올 수 있다. (set 등) | . no arg when 을 사용할 때도 있다. | 가독성은 좀 떨어질 수 있다. | 성능상 이점을 얻기 위할 때 사용할 수 있다. | no arg이기 때문에 extra objects를 생성하지 않는다는 장점이 있다. | . is . is는 java의 instanceof와 유사하다. instanceof 체크하고 type casting을 해야하는 java와 달리 is는 compiler가 smart cast를 해준다. (더 강력하고 편리하다) . | smart cast를 위해서 property가 val이어야 하고, custom accessor를 가질 수 없다. 그렇지 않으면 property에 대한 access가 동일한 값을 주는지에 대해 보장할 수 없다. | 명시적 type cast는 as를 이용한다. | . block value . if나 when의 branch에 block을 가질 수 있다. block이 있으면, block의 가장 마지막 expression이 block의 result가 된다. | if나 when은 kotlin에서 expression이고 반환 값을 갖는다는 점을 상기하자. | . fun evalWithLogging(e: Expr): Int = when (e) { is Sum -&gt; { val left = evalWithLogging(e.left) val right = evalWithLogging(e.right) println(\"sum: $left + $right\") left + right // return value } } . loop . java의 for loop과 완전히 매칭되는 for loop은 없다. | while은 java랑 완전히 같음. | . 그래서 range, progression을 사용한다. range는 1..10 처럼 사용될 수 있고, 이런 range를 progression이라고 한다. | range는 char에도 된다. (‘A’..’F’, ‘0’..’9’) | . 또, downTo, step, until을 제공하는데 직관적이다. for (i in 1..10) for (i in 100 downTo 1 step 2) for (i in 0 until size) . exception . exception은 java와 유사하다. try, catch, finally도 java와 유사하다. java와 다른 점은 kotlin의 throw, try도 expression이다. | try는 if와 다르게 {} body를 항상 가져야 한다. val number = try { Integer.parseInt(reader.readLine()) } catch (e: NumberFormatException) { return } . | . 또 다른 점은 kotlin은 함수에 throws를 명시하지 않아도 된다. | java와 다르게 checked exception과 unchecked exception을 구분하지 않는다는 것. | 경험 상 checked exception에서 rethrow나 ignore exception 같은 처리들이 불필요하게 수행되는 경우가 많아 구분을 하지 않는 설계를 했다고 한다. | . ",
    "url": "/docs/kotlin/kotlin-in-action/2#kotlin-function-body",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/2#kotlin-function-body"
  },"156": {
    "doc": "kotlin in action 정리 #2",
    "title": "kotlin in action 정리 #2",
    "content": " ",
    "url": "/docs/kotlin/kotlin-in-action/2",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/2"
  },"157": {
    "doc": "kotlin in action 정리 #3",
    "title": "chapter 3. Defining and Calling Functions",
    "content": "collection . setOf, listOf, mapOf로 collection을생성할 수 있다. kotlin은 java의 collection을 사용한다. | .javaClass로 class를 확인할 수 있다. (getClass()와 동일) | . java의 collection을 쓰지만 더 많은 것을 지원한다. | 예를들면 last, max와 같은 함수로, 얘네는 잠시 뒤에 다룰 extension function으로 제공된다. | . function . parameter에 naming을 할 수 있고, default value도 넣을 수 있다. | 이건 python에서와 유사하다. | . kotlin에서는 함수가 클래스 없이 존재할 수 있기 때문에, java에서 static method를 위해 만들었던 클래스들이 필요가 없다. | 예를 들면 ~utils와 같은 static method를 갖는 클래스들 | 그냥 파일 최상위에 함수가 들어가면 된다. | . jvm은 클래스 안에 있는 코드만 실행이 가능하다. | kotlin 컴파일러가 파일명을 기반으로 클래스를 내부적으로 만들어준다. | 따라서 java에서 kotlin의 함수만 선언된 것을 사용할 때도 이런 네이밍을 맞춰서 쓸 수 있다. | . 변수도 클래스 없이 존재할 수 있다. | static variable을 위한 클래스가 필요가 없어지는 것이지. | val은 getter를, var은 getter/setter를 만드니까 우리가 쓰던 상수처럼 되지 않는다. | const val을 써야 진짜 상수처럼 쓴다. (public static final로 컴파일 됨) | . extension function . 클래스 밖에 선언된 함수를 말한다. 기존의 api를 재작성하지 않고 기능을 사용할 수 있어서, java의 클래스들의 기능을 확장하는 방식으로도 쓰인다. (위에서 보인 last, max 같이) 함수 앞에 클래스 이름을 붙이기만 하면 된다. | 이건 약간 functional language를 위한 기능인 것 같다. golang에서도 함수를 이렇게 쓰니까 | . extension function에서는 클래스 안의 변수나 함수를 모두 자연스럽게 호출할 수 있다. | 그치만 private, protected로 선언된 애들은 호출할 수 없다. | . extension func를 사용하기 위해서는 다른 함수들처름 import를 해줘야 한다. | 자동으로 된다치면 동일한 extension이 여러군데 존재할 수 있기에 문제가 생길 것. | 이걸 응용하면 동일한 extension을 여러 개 두고 필요한 것을 import해서 쓸 수도 있지 않을까? (좋은 구조는 아닐듯) | . Because extension functions are effectively just syntactic sugar over static method calls, you can use a more specific type as a receiver type, not just a class . | 번역으로 의미 전달이 잘 안된다. | 결국 Collection&lt;T&gt;, Collection&lt;String&gt; 이런 애들을 receiver type으로 쓸 수 있다는 거다. | . extension은 override할 수 없다. 부모와 자식이 동일한 extension을 갖는다면 receiver를 first argument로 넘겨준다고 생각하면 된다. fun View.showOff() = println(\"I'm a view!\") fun Button.showOff() = println(\"I'm a button!\") &gt;&gt;&gt; val view: View = Button() &gt;&gt;&gt; view.showOff() I'm a view! . member function과 extension function이 동일하게 존재한다면 우선순위는 member가 더 높다. | 이렇게 기존 라이브러리(여기선 java)를 새로운 언어데서 사용하는 패턴을 Pimp My Library라고 한다. | . extension properties . properties는 이전에 봤던건데 난 사실 되려 더 헷갈리게 되는 것 같아서 쓸지는 모르겠다.. 하여튼 extension으로 property도 만들 수 있다는 것. | 얘는 자기가 갖고있는 field가 없다. (당연히) | 접근할 수 있는 field가 없다면, setter를 만들지 못할 수도 있다. | . varargs . vararg로 가변인자를 받을 수 있다. infix . infix는 .을 생략하는 call을 말한다. 1.to(\"one\") // regular function call 1 to \"one\" // infix call . parameter가 하나 뿐인 함수에 대해 infix call을 사용할 수 있다. | 함수 선언 앞에 infix를 명시해줘야 한다. infix fun Any.to(other: Any) = Pair(this, other) | . destructuring declaration . 두 변수를 초기화할 수 있도록 하는 구현이다. | 설명하긴 어려운데, python/golang에서 값 두 개 반환하는거랑 비슷하게 쓰이는 것 같다. | . 예제로 보는게 좋겠다. val (number, name) = 1 to \"one\" for ((index, element) in collection.withIndex()) { println(\"$index: $element\") } . string . kotlin은 String.split()이 regular expression이 아니다. | 자바는 기본 regular라 헷갈리고 더러워질 때가 있다. | kotlin은 regular를 .toRegex()로 지원한다. | . 여러줄 문자열을 \"\"\" ~ \"\"\"로 지원한다. | 여기서 regular expression이 된다. | . local function . func 안에 func가 있는걸 local function이라고 한다. 외부 함수의 param에 직접 접근이 가능하다. | 이것도 functional language를 지원하기 위한 것 같다. | . ",
    "url": "/docs/kotlin/kotlin-in-action/3#chapter-3-defining-and-calling-functions",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/3#chapter-3-defining-and-calling-functions"
  },"158": {
    "doc": "kotlin in action 정리 #3",
    "title": "kotlin in action 정리 #3",
    "content": " ",
    "url": "/docs/kotlin/kotlin-in-action/3",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/3"
  },"159": {
    "doc": "kotlin in action 정리 #4",
    "title": "chapter 4. Classes, Objects and Interface",
    "content": "interface . interface가 abstract method와 non-abstract method를 모두 가질 수 있다. | java 8과 비슷. abstrat &amp; default method 그치만 어떤 state도 가질 수 없다. | . interface Clickable { fun click() fun showOff() = print(\"I'm clickable!\") // default 명시자가 필요 없음 } class Button: Clickable { override fun click() = println(\"I was clicked\") } . | kotlin에서는 override 사용이 강제된다.(역할은 java의 @Override와 동일. | . java와 유사하게 interface의 implements는 여러 개가 가능하고, class extends는 하나만 가능하다. 동일한 non-abstract method를 갖는 interface 여러 개를 implements 하는 class는 override가 강제로 필요하다. | 특정 interface를 super 하는 방법은 super&lt;Clickable&gt;.showOff() | . modifier . open, final, abstact . java에서는 final을 명시하지 않으면 class 상속이 가능하다. 이런 경우 의도치 않은, 잘 명시되지 않은 class에 대한 상속을 하게 될 수 있다. 상속 이후 parent class가 변경되어 child class가 의도한 동작을 하지 않는 fragile base class 문제가 발생할 수 있다. | 이런 문제가 있었고, 등에서 상속을 의도하지 않는 경우 모두 final로 쓰라는 제안을 한다. | kotlin은 default를 final로 쓰고 상속을 허용하려면 open을 명시해야 한다. | class open 뿐 아니라 open class의 상속받을 method에도 open을 명시해야 한다. | override를 명시한 경우 기본적으로 open 이다. | . abstract class는 open이 없어도 된다. java와 유사하다. abstract class Animated { abstract fun animate() // override 꼭 필요 open fun stopAnimating() {} // override 가능 fun animateTwice() {} // override 불가 } . visibility modifier . | Modifier | Class member | Top-level declaration | . | public (default) | Visible everywhere | Visible everywhere | . | internal | Visible in a module | Visible in a module | . | protected | Visible in subclasses | (can not used) | . | private | Visible in a class | Visible in a file | . | kotlin은 기본적으로 public 이다. | package private이 kotlin에는 없다. | kotlin에게 package는 namespace 관리용 정도. | . | internal이 kotlin엔 존재하는데, 모듈(maven, gradle 등의 프로젝트 모듈) 내에서만 쓰일 수 있게 해서 encapsulation을 지원한다. | module은 java의 package와는 다르다. module은 여러 package가 있을 수 있음. | . | java에서는 같은 package 안에서 protected 멤버에 접근할 수 있지만, kotlin에서는 그렇지 않다. | . inner &amp; nested class . | Class A declared within another class B | In Java | In Kotlin | . | Nested class (doesn’t store a reference to an outer class) | static class A | class A | . | Inner class(stores a reference to an outer class | class A | inner class A | . | kotlin은 default가 nested class. | kotlin inner class에서 outer class에 접근하려면 this@{OuterClassName}을 써야 함. | . sealed class . sealed를 붙이면 클래스 상속을 제한한다. | 제한하는데, 클래스 외부의 상속을 막는 것. | . sealed class Expr { class Num(val value: Int) : Expr() class Sum(val left: Expr, val right: Expr) : Expr() } . | 이렇게 내부에 상속만 가능 | when(classVar)처럼 쓸 때, else가 하위 class에 대한 예외 처리로 default로 들어가야 한다. | sealed를 명시하면 클래스 상속이 제한되니 else가 필요 없다. | 이런 방식은 class가 추가되었을 때에 대한 예외를 까먹지 않을 수 있다는 장점이 있음. | . | . primary constructor . class User constructor(_nickname: String) { val nickname: String init { nickname = _nickname } } class User(_nickname: String) { val nickname = _nickname } class User(val nickname: String) . 위 방식 모두 primary constructor를 만드는 방식이다. class name과 괄호로 싸여진 코드를 primary constructor라고 한다. class 정의 시 constructor를 별도로 생성하지 않으면 컴파일러가 default costructor(class())를 만들어준다. primary constructor에 private을 붙여서 외부에서 instance 생성을 막을수도 있다. | class Secretive private constructor() {} | . secondary constructor . open class View { constructor(ctx: Context) { /* code */ } constructor(ctx: Context, attr: AttributeSet) { /* code */ } } . | 위처럼 View에 ()가 없으니 primary는 선언하지 않았다고 볼 수 있다. | . secondary constructor는 constructor로 시작한다. 필요에 따라 여러 개를 생성해도 된다. properties declared in interfaces . interface User { val nickname: String } class PrivateUser(override val nickname: String) : User class SubscribingUser(val email: String) : User { override val nickname: String get() = email.substringBefore('@') } class FacebookUser(val accountId: Int) : User { override val nickname = getFacebookName(accountId) } . property의 override를 위처럼 할 수 있다. interface User { val email: String val nickname: String get() = email.substringBefore('@') } . 점점 예제 없이 설명이 안된다… property의 getter/setter를 구현할 수도 있으나, field가 없으니 field를 참조할 수 없다. 위와 같은 경우 email은 abstract 하니까 구현이 필요하고, nickname은 안해도 된다. backing field . baeldung의 backing fields를 참고하면 좋다. | Kotlin will use a Java field to store the property values. | These Java fields are known as backing fields in the Kotlin world. | . backing field in getter/setter . var statusCode: Int = 100 set(value) { if (value in 100..599) statusCode = value } var statusCode: Int = 100 set(value) { if (value in 100..599) field = value } . 위 예제에서 statusCode에 할당하면, 계속 statusCode의 setter를 불러서 endless recursion을 만듦. 따라서 kotlin에서는 field라는 애를 사용. setter visibility . class LengthCounter { var counter: Int = 0 private set } . 이렇게 하면 class 밖에서 counter를 set할 수 없음. data class . kdata class Client(val name:String, val postalCode: Int) . toString(), equals(), hashCode() 를 자동으로 구현해주는 class. | kotlin은 ==에 equals()를 사용한다. 주솟값을 비교하려면 ===를 쓰면 된다. | . data class의 property들은 immutable하게 val을 쓰는 것을 권장. | hashMap 등에 넣고 값이 변경되어 문제가 발생할 수도 있고, | multi thread에서 변경될 경우를 고려하지 않아도 되고, | data class가 제공하는 copy()를 써서 데이터 수정보다 유사하게 데이터를 복사하면 된다. | . by . 상속이 불가능한 class인데 상속이 필요하면 Decorator 패턴으로 상속을 흉내낸다. 이러면 구현해야할 양이 많은데, kotlin은 by를 제공해서 구현 양을 줄인다. object for singleton . object Payroll { // ... } Payroll.allEmployees.add(Person()) . object는 consturctor가 필요없이 위처럼 그냥 쓰인다. companion object . companion object는 바깥 class의 private도 호출할 수 있어서 factory pattern 등을 구현하기 좋다. companion에 정의된 property나 method는 companion이 정의된 class 이름으로 접근할 수 있다. | 그러면 왜 굳이 class 안에 안넣고 companion을 쓰느냐..? | companion + extension으로 사용하는 예제가 있음 | companion object에 naming을 붙여서 사용할수도 있음 | companion에서 interface를 구현할 수도 있음 | . anonymous inner class . java에서 흔히 쓰이는 event listener와 같은 코드를 kotlin에서 object를 활용해 anonymous object로 사용할 수 있다. | anonymous object는 외부의 변수를 접근할 수 있음. | . ",
    "url": "/docs/kotlin/kotlin-in-action/4#chapter-4-classes-objects-and-interface",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/4#chapter-4-classes-objects-and-interface"
  },"160": {
    "doc": "kotlin in action 정리 #4",
    "title": "kotlin in action 정리 #4",
    "content": " ",
    "url": "/docs/kotlin/kotlin-in-action/4",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/4"
  },"161": {
    "doc": "kotlin in action 정리 #5",
    "title": "chapter 5. Programming with lambdas",
    "content": "lambdas: 다른 함수에 넘길 수 있는 작은 코드 조각. lambda . event가 발생 했을 때, handler를 통해 event를 처리하도록 하는 행위를 Java에서는 anonymous inner class로 처리했다. 이런 inner class는 verbose syntax 갖게 된다. | listener와 같은 예 들이 있다. (꼴 보기 싫지) | . Java 8 에서는 이런 문제를 lambda로 해결할 수 있도록 했다. Kotlin은 Java 6을 베이스로 했기 때문에 Java와는 다른 lambda를 지원한다. lambda delegates . val people = listOf(Person(\"A\", 29), Person(\"B\", 31)) people.maxBy{it.age} . If a lambda just delegates to a method or property, it can be replaced by a member. | 영작이 어렵다. 값을 주기만 하는 경우, 아래와 같이 수정이 가능하다. | 이건 뭐 Java 8에서도 유사하게 쓰이니까. | . people.maxBy(Person::age) . lambda syntax . kotlin의 lambda는 대괄호 안에 있는 특성이 있다. | 이 부분은 java와 달라서 낯설긴 하다. | . syntax sugar . people.maxBy({p: Person -&gt; p.age}) // 기본 lambda syntax // syntax shortcut이 없어 장황함 people.maxBy() {p: Person -&gt; p.age} // Kotlin에서는 last argument의 lambda를 밖으로 빼낼 수 있음 people.maxBy {p: Person -&gt; p.age} // lambda가 only argument면 괄호를 지울 수 있음 . 위 방식들은 가독성에만 차이가 있을 뿐 모두 같다. lambda의 경우 마지막으로 빼서 저렇게 만드는 것이 가독성에 더 좋다. type inferred sugar . people.maxBy {p -&gt; p.age} // 얘는 type을 명시하지 않은 inferred. people.maxBy {it.age} // autogenerated argument name. type inferred lambda를 쓰기 위해서는, type 추론이 가능해야 하기 때문에 lambda가 variable로 만들어지는 경우에는 사용할 수 없다. ```kotlin val getAge = {p: Person -&gt; p.age} // lambda가 value로 만들어짐 // 따라서 type inferred lambda 사용 불가 people.maxBy(getAge) . accessing variable scope . Java와는 다르게 final value가 아닌 애들한테도 접근 및 수정이 가능하다. 이렇게 lambda에서 access하는 외부 변수들을 captured 되었다고 한다. member reference . function을 value로 변환하는 것. // 함수 변환 val getAge = {person: Person -&gt; person.age} people.maxBy(Person::age) // 생성자 변환 data class Person(val name: String, val age: Int) val createPerson = ::Person val p = createPerson(\"Alice\", 29) . collection library . Kotlin은 Java 보다 collection에 대해 더 많은 library를 제공한다. 대부분 명확한 naming을 갖는다. filter &amp; map . filter는 말 그대로 filtering 하는거다. java 에서와 유사하다. map은 각 value들을 maping 해주는 건데, 이것도 java와 유사하다. 예제를 보면 간단하다. val people = listOf(Person(\"Alice\", 29), Person(\"Bob\", 31)) people.filter { it.age &gt; 30 } val list = listOf(1, 2, 3, 4) list.map { it * it } . 상황에 따라 다르지만, filter와 map을 연달아서 사용한다면 filtering 한 후에 mapping을 하는 것이, mapping 하는 element 수를 줄여 성능에 더 도움이 되는 편이다. all, any . 명확한 function name이다. all과 any의 경우 !all은 any와 같다는 것. !any 역시도 그렇다는 것을 잘 기억하고 가독성이 좋은 방향(!를 제거하는)으로 수정해가는 것이 좋다. count . count의 경우 size와 비교해볼 필요가 있다. size는 collection에 대한 기본 함수니까. count를 써야할 때는 어떤 때일까? . val canBeInClub27 = { p: Person -&gt; p.age &lt;= 27 } people.count(canBeInClub27) people.filter(canBeInClub27).size . 위와 같은 상황에서 명확하다. count의 경우 각각의 element를 추적하며 조건에 맞는 수를 세지만, size를 위해서 filter 조건에 맞는 collection을 생성하고 그 수를 반환한다. 따라서 filtering 이 필요한 경우에서는 count를 쓰는게 맞다. find . find는 만족하는 element가 있다면 첫 번째로 매칭하는 element를 반환하고, 없다면 null을 반환한다. etc . 그 외에도 많은 기본 library들이 있다. 대부분 명확하고 간단하다. groupBy: element 기반으로 list를 map으로 만드는 flatMap: 2겹의 collection을 풀어서 1겹으로 만드는 . lazy operation . kotlin에서 lambda를 사용할 때 제일 중요한 부분이 아닌가 싶다. lambda를 사용하면 매번 작업마다 새로운 temporary collection을 생성해내는데, 이건 비효율 적이다. 그래서 마지막에 한 번에 연산을 마무리하도록 lazy operation을 지원한다. people.map(Person::name).filter { it.startsWith(\"A\") } people.asSequence().map(Person::name).filter { it.startsWith(\"A\") }.toList() // lazy operation . large collection일 경우 lazy operation를 쓰는게 좋다. intermediate operation은 another sequence를 return 하고, terminal operation은 result를 return 한다. 주의사항: If you’re targeting Java 8, streams give you one big feature that isn’t currently implemented for Kotlin collections and sequences: the ability to run a stream operation (such as map() or filter()) on multiple CPUs in parallel. 다음 코드에서는, 첫 번째 find를 하고 이후의 element는 계산도 하지 않는다. 이런 부분도 lazy 의 장점이라고 할 수 있다. println(listOf(1, 2, 3, 4).asSequence().map { it * it }.find { it &gt; 3 }) . with &amp; apply . with는 parameter로 받은 값의 naming을 여러번 반복해서 쓰지 않아도 되게 해주는 역할을 한다. 받은 parameter의 변수/함수들을 내부 호출하듯 사용하는거지. fun alphabet() = with(StringBuilder()) { for (letter in 'A'..'Z') { append(letter) // 여기 StringBuilder()의 함수를 그냥 호출 } append(\"\\nNow I know the alphabet!\") toString() // with()가 반환할 값 } . apply는 with랑 동일한데, 호출한 object(reciever object) 반환한다. fun alphabet() = StringBuilder().apply { for (letter in 'A'..'Z') { append(letter) } append(\"\\nNow I know the alphabet!\") }.toString() . ",
    "url": "/docs/kotlin/kotlin-in-action/5#chapter-5-programming-with-lambdas",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/5#chapter-5-programming-with-lambdas"
  },"162": {
    "doc": "kotlin in action 정리 #5",
    "title": "kotlin in action 정리 #5",
    "content": " ",
    "url": "/docs/kotlin/kotlin-in-action/5",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/5"
  },"163": {
    "doc": "DynamoSizeLimitException 이슈 정리",
    "title": "DynamoSizeLimitException",
    "content": "Dynamo에서는 item에 대한 size 제한을 둔다. 이 size를 넘는 item을 save 요청을 했을 때 Dynamo에서는 DynamoSizeLimitException를 반환한다. 여기에 대해서는 AWS 공식문서를 참고하면 좋다. The maximum item size in DynamoDB is 400 KB, which includes both attribute name binary length (UTF-8 length) and attribute value lengths (again binary length) 그니까 총합 400KB를 넘으면 안된다 이거다 . ",
    "url": "/docs/aws/DynamoSizeLimitException#dynamosizelimitexception",
    
    "relUrl": "/docs/aws/DynamoSizeLimitException#dynamosizelimitexception"
  },"164": {
    "doc": "DynamoSizeLimitException 이슈 정리",
    "title": "예상치 못한 문제 발생",
    "content": "이유를 설명하자면 복잡하지만 있으면 GC에 좋고, 없으면 번거로운 작업이 필요한 일이 있었다. 자주 사용하는 dynamo table에 저장을 하기로 했고, size limit을 피하기 위해 400KB를 넘으면 저장하지 않도록 하는 로직을 구현했다. 그런데 exception이 발생해 alert가 왔다. item을 확인해보니 고작 210KB 정도?? . Document를 읽어도 원인을 알 수 없었고, 한참을 구글링 했다. ",
    "url": "/docs/aws/DynamoSizeLimitException#%EC%98%88%EC%83%81%EC%B9%98-%EB%AA%BB%ED%95%9C-%EB%AC%B8%EC%A0%9C-%EB%B0%9C%EC%83%9D",
    
    "relUrl": "/docs/aws/DynamoSizeLimitException#예상치-못한-문제-발생"
  },"165": {
    "doc": "DynamoSizeLimitException 이슈 정리",
    "title": "LSI에서의 size limit",
    "content": "DynamoDB에서는 Local Secondary Indexes(LSI)를 제공하는데, LSI가 있으면 size limit 계산이 달라진다. LSI는 item을 replica로 사용해서 size를 배로 먹는다는 것. 따라서 LSI가 n개면 n + 1배의 size를 먹는다고 볼 수 있고, item size limit은 그만큼 줄어드는 것이다. 우리는 LSI를 하나 사용하고 있었고, 210KB 짜리가 들어와서 LSI 덕에 400KB가 넘어 이슈가 발생한 것. 이런 내용들이 공식 document에 없다는건 좀 아쉽고, 쉽게 발생하지 않는 이슈여서 자료도 잘 없는 것 같다. aws tech 팀에 contact한 사람의 답변을 통해 알 수 있었다. ",
    "url": "/docs/aws/DynamoSizeLimitException#lsi%EC%97%90%EC%84%9C%EC%9D%98-size-limit",
    
    "relUrl": "/docs/aws/DynamoSizeLimitException#lsi에서의-size-limit"
  },"166": {
    "doc": "DynamoSizeLimitException 이슈 정리",
    "title": "DynamoSizeLimitException 이슈 정리",
    "content": "오늘은 생각지도 못한 DynamoSizeLimitException에 대해 기록한다. DynamoDB는 AWS에서 제공하는 NoSql DB이다. 먼저 DynamoSizeLimitException가 뭔지에 대해 알아볼 필요가 있다. ",
    "url": "/docs/aws/DynamoSizeLimitException",
    
    "relUrl": "/docs/aws/DynamoSizeLimitException"
  },"167": {
    "doc": "kotlin in action 정리 #6",
    "title": "chapter 6. The Kotlin Type System",
    "content": "kotlin에서는 java와 다르게 주의깊게 알아야 하는 부분은 두 가지다. | Nullable Type | Read-Only Collection | . ",
    "url": "/docs/kotlin/kotlin-in-action/6#chapter-6-the-kotlin-type-system",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/6#chapter-6-the-kotlin-type-system"
  },"168": {
    "doc": "kotlin in action 정리 #6",
    "title": "Nullable Type",
    "content": "Java에서는 null이 굉장히 거슬리는 문제가 됐다. 열심히 고려해도 NPE(Null Pointer Exception)는 너무 자주나고, null을 체크하는 코드들은 로직을 어지럽힌다. Optional과 같은 기능들이 추가됐지만 코드가 이뻐지는 것 같지는 않다. Kotlin에서는 이런 것들을 편하게 하기 위한 Type과 장치들을 제공한다. Type? . Nullable Type과 Non-Nullable Type은 간단하다. 예제로 보면 쉽다. val nullable: String? = null // Type에 ?을 붙이면 nullable val nonNullable: String = x // compile 시점에 error 발생 . Type이 정해져있어, compile 시점에 error를 발생시키기 때문에 runtime에 의도하지 않은 NPE가 날 일이 없다. Safe Call Operator ?. Kotlin에서 굉장한 장점이 바로 ?. operator 이다. 아주 간단하고 명료하게, 읽기 쉽게 null 검사와 함수 호출을 가능하게 한다. val allCaps: String? = s?.toUpperCase() // s가 null -&gt; return null // !null -&gt; return s.toUpperCase() val country = company?.address?.country // company나 address가 null이면 return null . 위와 같이 여러 상위 object들의 null check를 할 때 특히 유용하다. | 위 예제를 Java에서 모두 null check 한다고 생각하면… | . Elvis Operator ?: . null 대신 사용할 default value를 지정한다. ?.와 유사한데, default value를 명시해준다. val t: String = s?: \"\" // s가 null -&gt; return \"\" company?.address?: throw IllegalArgumentException(\"No Address\") . 두 번째 예제와 같이 elvis operator의 우항으로 throw를 넣을 수 있다. | Kotlin은 return이나 throw 같은 연산도 식(expression)이기 때문에 elvis operator의 우항으로 넣을 수 있음. | . Safe Casts: as? . 명시적 type case as를 안전하게 할 수 있는 방법이 있다. (2장 참고) . val person = o as? Person ?: return false // type casting이 안될 경우 아예 함수 자체를 return false . Not-null assertion !! . nullable type을 절대 null이 아닐거라고 단정 짓기 위해 !!을 사용한다. !! 사용한 값이 runtime에 실제 null이 올 경우 NPE가 발생한다. null 검사를 이미 했고 다시 하고싶지 않은 경우 사용할 수 있지만, nullable 체크를 하지 않아도 되지만 굉장히 위험하고 추천되지 않는 방식이다. fun ignoreNulls(s: String?) { val sNotNull: String = s!! } . let . let은 null이 아닐 경우 값을 변수에 넣어 작업을 진행하게 한다. if (email != null) sendEmailTo(email) email?.let {email -&gt; sendEmailTo(email)} . 예를 들면 위 코드를 아래와 같이 바꿀 수 있다. lateinit . 일반적으로 kotlin은 constuctor에서 모든 properties를 초기화해야 한다. Junit의 @Before 같은 경우 메소드 안에서 초기화를 하는데, 이런 경우에 Kotlin은 . | nullable type을 쓰고 !!를 쓰거나 | non-nullable로 초기화를 해두거나 | . 그치만 이런 방식은 좋지 않고 kotlin은 lateinit을 제공한다. class MyTest { private lateinit var myService: Myservice // 아직 초기화 안함 @Before fun setUp() { myService = MyService() // 초기화 한다 } } . lateinit property는 항상 var이어야 한다. lateinit property가 초기화되기 이전에 사용되면 lateinit 관련 exception이 발생한다. | 이 exception이 NPE보다 문제의 원인을 확인하기 훨씬 편리하다. | . extensions on nullable types . nullable type에 대한 확장 함수는 safe call ?. 없이 호출할 수 있다. s.isNullOrBlank() // s가 null이어도 true를 반환 . java는 this가 호출된 객체를 가리키므로 항상 null이 아니다. 반면 kotlin에서는 nullable type의 확장 함수에서는 this가 null이 될 수 있다. fun String?.isNullOrBlank(): Boolean = this == null || this.isBlank() . type parameter . type parameter는 기본적으로 nullable하다. fun &lt;T&gt; printHashCode(t: T) { ... } // t가 nullable fun &lt;T: Any&gt; printHashCode(t: T) { ... } // t가 not-nullable . T의 type은 Any?로 추론되기 때문에 nullable하고 not-nullable로 바꾸려면 Any를 명시한다. platform type . platform type은 nullable인지 아닌지 알 수 없는 타입을 말한다. 이 type은 nullable로 처리해도 되고, not-nullable로 처리해도 된다. | 모두 nullable로 하도록 해도 되겠지만 그러면 불필요한 null 체크가 필요할 수 있어 platform type을 만듦 | . 그런데 이 type을 kotlin에서 사용할 수 있도록 허락하지 않는다. Java와 코드가 혼용될 때, Java의 type들이 kotlin에서 platform type으로 표현된다. 이럴 경우 java 처럼 runtime에 대한 handling은 개발자의 몫이다. platform type의 표기는 String!과 같다. | 사용할 수는 없고 error msg에서 확인할 수 있음. | . ",
    "url": "/docs/kotlin/kotlin-in-action/6#nullable-type",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/6#nullable-type"
  },"169": {
    "doc": "kotlin in action 정리 #6",
    "title": "kotlin in action 정리 #6",
    "content": " ",
    "url": "/docs/kotlin/kotlin-in-action/6",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/6"
  },"170": {
    "doc": "kotlin in action 정리 #6-2",
    "title": "chapter 6-2. The Kotlin Type System",
    "content": " ",
    "url": "/docs/kotlin/kotlin-in-action/6-2#chapter-6-2-the-kotlin-type-system",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/6-2#chapter-6-2-the-kotlin-type-system"
  },"171": {
    "doc": "kotlin in action 정리 #6-2",
    "title": "Primitive Types",
    "content": "java는 primitive type(int 등)과 reference type(string 등)을 갖는다. Collection에서는 reference type이 필요하고 이런 상황들에서 primitive type을 쓰는 방법이 wrapper type을 이용하는 것이다. kotlin에서는 wrapper type을 따로 구분하지 않고 사용한다. | 그치만 항상 객체로 표현하는 것은 비효율적이고, 실행 시점에 가장 효율적인 방식으로 표현한다. | kotlin의 Int type은 대부분의 경우 int로 컴파일 되고, Collection 등에 사용될 땐 java의 Integer가 들어간다. | . java type에 맞는 kotlin type . | Integer types - Byte, Short, Int, Long | Floating-point number types - Float, Double | The charater type - Char | The boolean type - Boolean | . kotlin도 마찬가지로 jvm에서 primitive type을 collection에서 받아주지 않으므로 null을 사용하는 Int?와 같은 경우 외에도 collection에서 사용될 땐 Integer로 변환된다. Number conversions . kotlin에서는 number type의 자동 변환을 해주지 않는다. Int를 Long에 넣으려면 명시적 변환을 해줘야한다는 말이다. ",
    "url": "/docs/kotlin/kotlin-in-action/6-2#primitive-types",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/6-2#primitive-types"
  },"172": {
    "doc": "kotlin in action 정리 #6-2",
    "title": "Root type Any, Any?",
    "content": "Java에서는 Object가 최상위 클래스이고, Kotlin에서는 Any가 그렇다. | Java에서 Object를 주면 Kotlin에서는 Any!가 되는거다. | . ",
    "url": "/docs/kotlin/kotlin-in-action/6-2#root-type-any-any",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/6-2#root-type-any-any"
  },"173": {
    "doc": "kotlin in action 정리 #6-2",
    "title": "Unit type",
    "content": "Unit type은 Java에서의 void와 같다. fun f(): { ... } fun f(): Unit { ... } // 위와 같음 . Java의 void와 다른 점은 Unit은 모든 기능을 갖는 일반적인 타입이고, type argument 쓸 수 있다. Unit type에 속한 값은 딱 하나 Unit 뿐이다. generic에서 Unit을 반환할 때 유용하다. (void는 안되니까) . interface Processor&lt;T&gt; { fun process(): T } class NoResultProcessor: Processor&lt;Unit&gt; { override fun process() { /* return이 필요 없음 */ } } . ",
    "url": "/docs/kotlin/kotlin-in-action/6-2#unit-type",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/6-2#unit-type"
  },"174": {
    "doc": "kotlin in action 정리 #6-2",
    "title": "Nothing type",
    "content": "성공적으로 return하는 경우가 없는 경우, 즉 fail 함수와 같이 return 값 자체가 의미 없는 함수. 무한 loop를 도는 함수. 함수가 정상적으로 끝나지 않는다는 사실을 명시하는 것이고, 코드 분석에 유용하단다. Nothing은 return type이나 return type으로 쓰일 type parameter로만 쓸 수 있다. ",
    "url": "/docs/kotlin/kotlin-in-action/6-2#nothing-type",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/6-2#nothing-type"
  },"175": {
    "doc": "kotlin in action 정리 #6-2",
    "title": "Collections",
    "content": "Collections에서도 nullable이 적용된다. List&lt;Int?&gt; // Int가 nullable, List는 not-nullable List&lt;Int&gt;? // Int는 not-nullable, List는 nullable List&lt;Int?&gt;? // Int도 List도 nullable . Read-only &amp; mutable . Kotlin에서는 collection에 대해 수정 가능한지 여부를 제공한다. 즉, 수정 불가능한 collection을 제공한다는 것이다. Java에서는 final로 생성하더라도 collection 자체를 바꿀 수 없을 뿐 내부 entity들을 추가/삭제하는 것은 가능했다. 이런 것을 막기 위해선 Collection.unmodifiableList() 같은 함수로 생성하거나 따로 unmodifiable collection을 구현해야 했다. Kotlin에서는 MutableCollection과 Collection을 가지고 collection의 변경 가능 여부를 구별한다. 이를 통해 어떤 코드에서 collection에 대해 수정을 하는지, 조회만 하는지를 확인할 수 있다. | kotlin은 java.util의 collection 구조를 mutable collection에 그대로 적용함 | Java의 collection들(ArrayList 등)을 Kotlin interface를 상속한 것처럼 취급함 | Java와 kotlin의 코드를 혼용하면, java에서는 모두 수정이 가능 | . collection 생성 함수 . | collection type | read only | mutable | . | List | listOf | mutableListOf, arrayListOf | . | Set | setOf | mutableSetOf, hashSetOf, linkedSetOf, sortedSetOf | . | Map | mapOf | mutableMapOf, hashMapOf, linkedMapOf, sortedMapOf | . ",
    "url": "/docs/kotlin/kotlin-in-action/6-2#collections",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/6-2#collections"
  },"176": {
    "doc": "kotlin in action 정리 #6-2",
    "title": "Array",
    "content": "기본적으로 Array보다는 Collection을 사용해야 한다. Java의 API들이 Array를 사용하는 경우가 있어 써야할 수 있다. | 사실 java에서도 array를 잘 안쓰는 것 같은데.. | . arrayOf, arrayOfNulls로 생성할 수 있다. toTypedArray로 collection을 Array로 바꿀 수 있다. IntArray, ByteArray, CharArray, BooleanArray 등의 클래스들은 int[], byte[] 등으로 컴파일 된다. | 생성자가 size를 받고 default 값으로 초기화 된 배열을 만듦 | . ",
    "url": "/docs/kotlin/kotlin-in-action/6-2#array",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/6-2#array"
  },"177": {
    "doc": "kotlin in action 정리 #6-2",
    "title": "kotlin in action 정리 #6-2",
    "content": " ",
    "url": "/docs/kotlin/kotlin-in-action/6-2",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/6-2"
  },"178": {
    "doc": "config.js",
    "title": "config.js",
    "content": "vue로 github.io에 github page를 로딩하기 위해 build 했다. | vue create {project} 로 project를 생성하고, | npm run build 로 build 한 뒤, | github에 push | . 하면 되야하는데 되지 않는다. github에서는 /docs에 있는 정적 페이지들을 호출할 수 있도록 제공하고 있고 vue의 build 산출물이 docs로 쓰여지게 해야 한다. | default는 /dist 인데 이걸 바꿔주는 것을 config.js에서 할 수 있다. | . module.exports = { outputDir: './docs', publicPath: '/votes/' } . 이렇게 하면 npm run build 시 /docs로 산출물이 생성되고, publicPath는 /votes로 시작하게 된다. ",
    "url": "/docs/vue/config",
    
    "relUrl": "/docs/vue/config"
  },"179": {
    "doc": "linux screen 쓰는 이유, 자주 사용하는 screen 명령어 사용법",
    "title": "session 외부 명령어",
    "content": "| 동작 | 명령어 | 설명 | . | list screen session | screen -listscreen -ls | 현재 열려있는 screen session와 각 screen에 대한 detach/attach 여부, screen 생성 시간, sessionId를 확인할 수 있다. | . | start screen | screen -S {name} | name으로 screen을 생성하고 screen에 진입한다.이미 있는 이름으로 생성하더라도 새로운 session을 만들어주는데, 이는 sessionId가 다르기 때문에 다른 id 이다. | . | enter screen | screen -r {name} or {sessionId} | session에서 나온 이후에 동일한 session에 진입할 때 사용한다.name이나 sessionId로 들어갈 수 있다. 같은 name의 session이 여러 개인 경우 sessionId를 명시해야 한다. | . | enter screen | screen -x {name} or {sessionId} | 혼자서 쓰면 -r 이랑 유사하다.-x option은 screen이 attach 상태(다른 terminal에서 접속한 상태) 여도 들어갈 수 있다.-r option은 attach 상태면 들어갈 수 없다.여러 터미널에서 동시에 진입한 경우 세션이 공유되어 동일한 세션이 터미널에 공유된다. | . | kill screen | creen -X -S {name} kill | 하나의 session 죽이기.session을 exit하지 않고 detach 해서 나오면 screen의 session은 살아있기 때문에 이걸 종료하는데 사용된다. | . | kill all screen | killall screenpkill screen | 모든 session을 종료하기.실수가 남을 수 있어서 조심해야 한다. | . ",
    "url": "/docs/tools/linux-commands/screen#session-%EC%99%B8%EB%B6%80-%EB%AA%85%EB%A0%B9%EC%96%B4",
    
    "relUrl": "/docs/tools/linux-commands/screen#session-외부-명령어"
  },"180": {
    "doc": "linux screen 쓰는 이유, 자주 사용하는 screen 명령어 사용법",
    "title": "session 내부 명령어",
    "content": "| 동작 | 명령어 | 설명 | . | detach screen | ctrl + a d | screen session에서 나오기. detach로 나오면 session은 살아있으면서 나오는 것.가장 빈번하게 사용되는 커맨드 | . | check sessionId | echo $STY | session 내부에서 현재 sessionId를 확인하기 위한 커맨드.현재 터미널이 screen 내부에 있는 것이 맞는지 확인하기 위해 빈번히 사용된다. | . 그 외의 다양한 명령어들이 많으나, 창 분할은 tmux를 사용하는 것이 더 편리하다. ",
    "url": "/docs/tools/linux-commands/screen#session-%EB%82%B4%EB%B6%80-%EB%AA%85%EB%A0%B9%EC%96%B4",
    
    "relUrl": "/docs/tools/linux-commands/screen#session-내부-명령어"
  },"181": {
    "doc": "linux screen 쓰는 이유, 자주 사용하는 screen 명령어 사용법",
    "title": "linux screen 쓰는 이유, 자주 사용하는 screen 명령어 사용법",
    "content": "DDD tactical components . Terminal Shortcut tmux cut jq screen split . screen session에서 작업을 수행하면 terminal session이 끊기더라도 session이 유지되어 작업이 끊기지 않는다. 그래서 screen은 linux server에서 batch 작업이나 장 시간 작업을 수행할 때, background 작업을 수행할 때 많이 사용한다. screen은 창 분할을 위해서도 사용할 수 있지만 이런 경우 나는 주로 tmux를 사용한다. ",
    "url": "/docs/tools/linux-commands/screen",
    
    "relUrl": "/docs/tools/linux-commands/screen"
  },"182": {
    "doc": "대용량 파일 터미널에서 split으로 자르기",
    "title": "문제가 됐던 파일",
    "content": "최근에 내가 확인한 파일은 아래와 같은 파일들이었다. | 하나의 라인에 파일이 수십 GB 쓰여있는 파일. | 수천만 ~ 수억 라인을 갖는 수십 GB 파일. | . ",
    "url": "/docs/dev-tools/linux-commands/split#%EB%AC%B8%EC%A0%9C%EA%B0%80-%EB%90%90%EB%8D%98-%ED%8C%8C%EC%9D%BC",
    
    "relUrl": "/docs/dev-tools/linux-commands/split#문제가-됐던-파일"
  },"183": {
    "doc": "대용량 파일 터미널에서 split으로 자르기",
    "title": "문제",
    "content": "내가 겪은 문제는.. | 큰 파일들은 load하기가 어려워서 vi로 수십 GB의 파일을 load하면 load가 되지 않는 경우가 많다. | 적당히 큰 파일들은 켜지지만 딜레이가 굉장히 컸다. | . | 1번의 한 라인으로 쓰인 파일은 head로 일부를 확인할 수도 없다. | head가 line을 출력하니까.. head시 수십 GB를 print하는 상황 | cut으로 일부 출력이 가능하지만, 포맷을 모르는 한 라인은 무작정 cut을 할수도 없고 시간이 오래걸림 | . | 2번의 여러 라인의 파일은 diff, uniq 같은 커맨드에 대해 process가 kill 되어 버린다. (손을 쓸 수 없다) | . ",
    "url": "/docs/dev-tools/linux-commands/split#%EB%AC%B8%EC%A0%9C",
    
    "relUrl": "/docs/dev-tools/linux-commands/split#문제"
  },"184": {
    "doc": "대용량 파일 터미널에서 split으로 자르기",
    "title": "split 사용 사례",
    "content": "위와 같은 문제를 해결하기 위해 아래와 같이 사용했다. | data를 확인하기 위해 파일을 열어봐야 하는 상황이었다. | file을 split으로 byte 단위로 나누어 열어볼 수 있게 작게 나눴다. | . | data를 diff해야 하는 상황이었다. | 그 외 다른 커맨드나 python 등의 작업에서 로드시 메모리 문제가 없게하기 위해서도 사용할 수 있다. | file을 split으로 line 단위로 나누어 작업하였다. | . | . ",
    "url": "/docs/dev-tools/linux-commands/split#split-%EC%82%AC%EC%9A%A9-%EC%82%AC%EB%A1%80",
    
    "relUrl": "/docs/dev-tools/linux-commands/split#split-사용-사례"
  },"185": {
    "doc": "대용량 파일 터미널에서 split으로 자르기",
    "title": "split 사용 방법",
    "content": "byte 단위로 나누기 . split -b 100MB sourcefile . 이렇게하면 100MB 단위로 파일을 나눌 수 있다. 개인적으로 100MB 정도면.. 파일을 편하게 열어볼 수 있겠더라. | instance의 cpu, mem 사양마다 다를 것. | diff등의 작업에서는 더 크게 1~10GB로 작업했다. | . 위 1번 문제처럼 파일이 라인 단위가 아닐 때 byte 단위로 나누면 좋지 싶다. line 단위로 나누기 . split -l 1000000 sourcefile . 이렇게하면 1000000 라인 단위로 파일을 나눌 수 있다. target file 적용하기 . split -b 100MB sourcefile targetfile . 위 예제에서 targetfile이 없을 경우, targetfile의 name은 xaa, xab … 같은 식이다. targetfile을 명시해주면, targetfileaa, targetfileab … 같은 식이 된다. targetfile suffix . split -d -l 100 sourcefile . -d option을 적용하면 alphabet suffix가 numeric으로 바뀐다. before: targetfile의 name은 xaa, xab … after: targetfile의 name은 x01, x02 … . ",
    "url": "/docs/dev-tools/linux-commands/split#split-%EC%82%AC%EC%9A%A9-%EB%B0%A9%EB%B2%95",
    
    "relUrl": "/docs/dev-tools/linux-commands/split#split-사용-방법"
  },"186": {
    "doc": "대용량 파일 터미널에서 split으로 자르기",
    "title": "reference",
    "content": ". | https://kb.iu.edu/d/afar | . ",
    "url": "/docs/dev-tools/linux-commands/split#reference",
    
    "relUrl": "/docs/dev-tools/linux-commands/split#reference"
  },"187": {
    "doc": "대용량 파일 터미널에서 split으로 자르기",
    "title": "대용량 파일 터미널에서 split으로 자르기",
    "content": "DDD tactical components . Terminal Shortcut tmux cut jq screen split . linux에서 big file을 handling 할 때 사용하는 방법. 최근 split을 사용할 일들이 더 많아져서, 정리하고자 올린다. linux에서 서버를 관리하다보면, 생각보다 큰 파일들을 관리해야할 일들이 많다. 내가 편리하게? 어쩌면 split 없이는 해결할 수 없는 문제들을 해결하기 위해 사용하는 커맨드를 정리한다. ",
    "url": "/docs/dev-tools/linux-commands/split",
    
    "relUrl": "/docs/dev-tools/linux-commands/split"
  },"188": {
    "doc": "cut 사용법 이해하기. 대용량 파일 터미널에서 cut으로 파싱하기",
    "title": "사용성",
    "content": ". | 간단한 파일을 일부만 보고 싶을 때 sed나 awk를 사용해도 되지만, 가장 좋은 성능을 내는 것이 cut이다. | 1GB 이상의 큰 파일로 확인을 해보면 확연한 성능 차이를 볼 수 있다. | . | 큰 파일들을 확인하고 싶을 때 vi는 여는데 한참 걸리지만, cut은 금방 볼 수 있다. | 하나의 라인이 무지막지하게 크다면(예를들면 10GB), vi 등으로 열 수 없는 경우가 있다. 당연히 하나의 라인이라 head로도 확인할 수 없고.. 이럴 때 어떤 데이터인지 cut으로 확인할 수 있다. | 물론 이럴때 split을 사용하는 것도 좋다. | . | python 같은 스크립트를 사용할 때도 데이터를 전처리하면 성능이 크게 올라간다. | . 이런 데이터 전처리는 파일 사이즈가 크나, 단순하고 동일한 포맷일 때 사용하기 굉장히 좋다. | batch 작업을 위한 userdata를 추출해 놓았을 때 | 많은 양의 단순한 비규격 로그의 파싱이 필요할 때 | . ",
    "url": "/docs/dev-tools/linux-commands/cut#%EC%82%AC%EC%9A%A9%EC%84%B1",
    
    "relUrl": "/docs/dev-tools/linux-commands/cut#사용성"
  },"189": {
    "doc": "cut 사용법 이해하기. 대용량 파일 터미널에서 cut으로 파싱하기",
    "title": "사용법",
    "content": "몇가지 사용법을 적지만 사실 맨 처음의 cut -d -f의 사용률이 가장 높다. 일부 char를 잘라내야 하는 경우에서도 유용하게 사용된다. cut의 단점은 char로만 자를 수 있다는 것이지만 생각보다 이렇게 사용할 데이터들이 굉장히 많고, 성능은 그만큼 훌륭하다. db dump, csv, json과 같이 포맷이 일정한 데이터를 파싱할 때 함께 사용할 수 있다. 파일의 파싱이나 데이터 추출, command pipe에서 자주 사용한다. 예시 . delimiter 단위로 자르기 . cut -d 'DELIMITER' -f INDEX FILE . -d: . | 어떤 char로 자를지에 대한 옵션. | char만 올 수 있기 때문에, string을 넣을 수 없음. | . -f: . | 자르고 나서 몇 번째의 값을 가지고 올 것인지 설정. | N, N-M, N,M-L과 같이 설정 가능. | . delimiter가 없는 라인 무시하기 . cut -d 'DELIMITER' -f INDEX -s FILE . -s: . | delimiter가 없는 라인은 아예 출력도 하지 않도록 하는 옵션. | . delimiter를 변경하기 . cut -d 'DELIMITER' -f INDEX --output-delimiter=\"OUTPUT DELEMETER\" FILE . –output-delimiter: . | delimiter로 자른 라인의 구분자를 바꿔줄 문자열. | . character 단위로 잘라내기 . cut -c INDEX . -c: . | character 단위로 잘라낼 수 있다. | 동일하게 N, N-M, N,M-L과 같이 설정 가능. | . ",
    "url": "/docs/dev-tools/linux-commands/cut#%EC%82%AC%EC%9A%A9%EB%B2%95",
    
    "relUrl": "/docs/dev-tools/linux-commands/cut#사용법"
  },"190": {
    "doc": "cut 사용법 이해하기. 대용량 파일 터미널에서 cut으로 파싱하기",
    "title": "cut 사용법 이해하기. 대용량 파일 터미널에서 cut으로 파싱하기",
    "content": "DDD tactical components . Terminal Shortcut tmux cut jq screen split . file data를 파싱할 때 사용하는 커맨드 중 하나이다. 데이터를 파싱하고, 전처리하는 과정에서 효율이 굉장히 좋은 커맨드. ",
    "url": "/docs/dev-tools/linux-commands/cut",
    
    "relUrl": "/docs/dev-tools/linux-commands/cut"
  },"191": {
    "doc": "java coverage test 개념 및 jacoco 사용법",
    "title": "jacoco란?",
    "content": "먼저 jacoco가 뭔지 알아야겠다. jacoco는 line coverage report를 만들어주는 툴이다. jacoco가 직접 test를 한다고 생각하기 쉬운데 실제로 그렇지 않다. jacoco는 surefire의 test coverage information을 가져다가 보고서를 작성하는 녀석이다. ",
    "url": "/docs/test/jacoco#jacoco%EB%9E%80",
    
    "relUrl": "/docs/test/jacoco#jacoco란"
  },"192": {
    "doc": "java coverage test 개념 및 jacoco 사용법",
    "title": "jacoco goal",
    "content": "사실 jacoco를 쓸 때 알아야 할 것들이 많은 건 아니다. 내가 쓰면서 의문이 있었던 부분은 pom.xml에 추가되는 goal들이 무슨 의미였는지였다. 기본으로 추가하는 pom.xml plugin. &lt;plugin&gt; &lt;groupId&gt;org.jacoco&lt;/groupId&gt; &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.8.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;prepare-agent&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;report&lt;/id&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;report&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; . prepare-agent . agent는 collect coverage information when maven-surefire-plugin runs the tests을 한다. 위에서 말했듯이 surefire의 결과를 가져오는 역할이다. 별도의 destFile이 set되어있지 않다면 target/jacoco.exec에 가져온다. report . report는 creates code coverage reports for tests in HTML, XML, CSV formats을 한다. agent에서 가져온 data로 coverage report를 작성하는 역할이다. 별도의 outputDirectory가 set되어있지 않다면 target/site/jacoco에 파일들을 생성한다. check . check는 validates the coverage rules를 한다. coverage가 통과 되었는지 등을 확인할 수 있는 goal인데, 필수적으로 필요한 건 아니다. 여기서 goal을 설정하면 build하다가 fail을 만들 수 있다. check와 같이 사용되는 goal들이 더 있는데, document를 확인하면 될 것 같다. ",
    "url": "/docs/test/jacoco#jacoco-goal",
    
    "relUrl": "/docs/test/jacoco#jacoco-goal"
  },"193": {
    "doc": "java coverage test 개념 및 jacoco 사용법",
    "title": "jacoco command",
    "content": "이제 jacoco command를 확인해보자. intellij에서 run configuration을 jacoco로 하고 line coverage test를 돌리면 intellij test가 돌더라.. | 이 문제는 내 pc에서만 그럴지도 모르겠다. | . 그래서 jacoco 결과를 받지 못했고, command로 돌려서 결과를 확인하는 방법을 찾았다. The command mvn clean test runs unit tests and creates the code coverage report for unit tests to the directory target/site/jacoco-ut. The command mvn clean verify -P integration-test runs integration tests and creates the code coverage report for integration tests to the directory target/site/jacoco-it. The command mvn clean verify -P all-tests runs unit and integration tests and creates code coverage reports for unit and integration tests. 기본적으로 unit test에 대한 coverage를 측정하니까 mvn clean test를 통해 coverage report를 확인할 수 있다. 주의사항 pom.xml에서 surefire.skipTests를 true로 설정했다면 surefire가 돌지 않고, surefire가 돌지 않는다면 jacoco는 test report를 만들 수 없다. ",
    "url": "/docs/test/jacoco#jacoco-command",
    
    "relUrl": "/docs/test/jacoco#jacoco-command"
  },"194": {
    "doc": "java coverage test 개념 및 jacoco 사용법",
    "title": "jacoco.exec",
    "content": "위 agent에서 확인한 jacoco.exec 파일은 열어서 확인할 수 없었다. jacoco.exec는 eclipse나 intellij에서 확인할 수 있었다. intellij 기준 . | Run &gt; Show Code Coverage Data | jacoco.exec 찾아서 선택 | . ",
    "url": "/docs/test/jacoco#jacocoexec",
    
    "relUrl": "/docs/test/jacoco#jacocoexec"
  },"195": {
    "doc": "java coverage test 개념 및 jacoco 사용법",
    "title": "jacoco exclude",
    "content": "jacoco exclude가 이번 글의 목적이었다. exclude를 확인하는데 굉장히 오랜 삽질을 했는데, 위에 적어둔 개념들이 부족했기 때문이다.. jacoco.exec가 jacoco report인 줄 알았고, intellij에서 이거만 주구장창 보면서 exclude를 확인했으니.. 절대 확인할 수 없었다. | 위를 다시 봐보자. jacoco.exec는 surefire의 coverage information이다. | . 그래서 결국 jacoco exclude를 확인하려면 report 결과물의 index.html 이나 jacoco.xml을 확인해야 한다. jacoco exclude . jacoco plugin에서 exclude를 하면 test report에서 exclude를 시키는 것이다. exclude rule은 굉장히 쉽다. 공식 docu를 보면 **, ?, * 등을 활용할 수 있음을 명시하고 있다. &lt;configuration&gt; &lt;excludes&gt; &lt;exclude&gt;**/protobuf/*&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; . surefire exclude . surefire를 계속 얘기하는건.. 삽질을 많이 했다는거다. 그만큼 명확하게 정리된 글이 없었기도 한 것 같다. surefire에서도 exclude를 할 수 있는데, surefire에서 exclude하면 test를 아예 돌려버리지 않는 것이다. 즉 jacoco는 exclude로 coverage 대상에서 제외시켜 coverage를 올리지만, surefire에서 exclude하면 작성된 test를 제외시켜 coverage가 되려 떨어질 수 있다. ",
    "url": "/docs/test/jacoco#jacoco-exclude",
    
    "relUrl": "/docs/test/jacoco#jacoco-exclude"
  },"196": {
    "doc": "java coverage test 개념 및 jacoco 사용법",
    "title": "reference",
    "content": ". | jacoco 개념 참고 | jacoco 공식 document | check goal 설정 관련 예제 | jacoco command line 확인 | jacoco.exec 확인 | . ",
    "url": "/docs/test/jacoco#reference",
    
    "relUrl": "/docs/test/jacoco#reference"
  },"197": {
    "doc": "java coverage test 개념 및 jacoco 사용법",
    "title": "java coverage test 개념 및 jacoco 사용법",
    "content": "최근 회사에서 jacoco로 line coverage exclude를 할 일이 생겼다. protobuf로 java file을 만들었는데, protobuf 생성 파일이 라인 수가 꽤 되서 line coverage를 떨어뜨리고 있었다. exclude를 적용하는 방법에 애를 먹어 정리한다. ",
    "url": "/docs/test/jacoco",
    
    "relUrl": "/docs/test/jacoco"
  },"198": {
    "doc": "kotlin in action 정리 #7",
    "title": "chapter 7. Operator overloading and other conventions",
    "content": " ",
    "url": "/docs/kotlin/kotlin-in-action/7#chapter-7-operator-overloading-and-other-conventions",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/7#chapter-7-operator-overloading-and-other-conventions"
  },"199": {
    "doc": "kotlin in action 정리 #7",
    "title": "why convensions?",
    "content": "Java에서는 Iterable을 구현하면 for loop를 사용할 수 있고, AutoCloseable을 구현하면 try-with-resources를 사용할 수 있다. | Java는 이처럼 어떤 type인지가 중요함. | . Kotlin에서도 Kotlin은 plus 라는 함수를 정의하면 + 연산자로 사용할 수 있는 등의 방식으로 유사한 특성을 제공한다. | Kotlin 에서는 함수의 이름과 연관이 있다. | Kotlin이 이런 방식을 사용하는 건 기존의 Java class를 kotlin에 적용하기 위해서. | 새로운 class를 만들 수는 없지만 새로운 함수는 추가할 수 있으니까. | . | . ",
    "url": "/docs/kotlin/kotlin-in-action/7#why-convensions",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/7#why-convensions"
  },"200": {
    "doc": "kotlin in action 정리 #7",
    "title": "Overloading arithmetic operators",
    "content": "BigInteger class나 Point class에서 plus 함수를 호출하는 대신 +로 사용하는 것이 이해하기에도 가독성 면에서도 좋다. 예제를 보자. data class Point(val x: Int, val y: Int) { operator fun plus(other: Point): Point { return Point(x + other.x, y + other.y) } } . val p1 = Point(10, 20) val p2 = Point(30, 40) println(p1 + p2) Point(x=40, y=60) . plus 함수 앞에는 operator가 꼭 붙어야 한다. | 모든 operator를 정의할 때 필요함. | 이게 없이 operator 함수 명들을 사용하면 operator modifier is required라는 에러가 발생. | a + b는 내부적으로 a.plus(b)를 호출함. | . arithmetic operators . | expression | Function name | . | a * b | times | . | a / b | div | . | a % b | rem | . | a + b | plus | . | a - b | minus | . operator overloading을 하더라도 연산자 우선순위가 적용된다. | a + b * c에서 b * c가 먼저 수행됨. | . different operand types . operator fun Point.times(scale: Double): Point { return Point((x * scale).toInt(), (y * scale).toInt()) } . val p = Point(10, 20) println(p * 1.5) Point(x=15, y=30) . parameter의 type이 같지 않아도 된다. | 여기서도 역시나 a * b는 내부적으로 a.times(b)로 치환된다. | 중요한 것은 교환 법칙을 지원하지 않는다는 것. | 즉, b * a는 다른 식이고 위의 method에 적용될 수 없음. | 필요하다면 operator fun Double.times(p: Point) method를 정의해야 함 | . | . | . different result type . operator fun Char.times(count: Int): String { return toString().repeat(count) } . println(‘a’ * 3) . aaa . 유사하게 parameter들과 result의 type이 달라도 된다. bit operator . kotlin은 standard number type에 대한 bit operator를 제공하지 않는다. bit 연산이 필요한 경우 아래 함수들을 사용한다. | java bit operator | kotlin method | . | « | shl | . | » | shr | . | »&gt; | ushr | . | &amp; | and | . | | or | . | ^ | xor | . | ~ | inv | . assign operator . +=, -= 등의 함수들을 따로 정의할 수 있다. | plusAssign, minusAssign과 같은 함수 | . += operator는 plus(a = a.plus(b)) 와 plusAssign(a.plusAssign(b)) 양쪽으로 컴파일될 수 있다. | 어떤 class가 이 두 함수를 모두 정의하고 둘 다 +=에 사용 가능한 경우 컴파일 에러가 발생. | class과 일관성있게 설계하는 것이 좋다. | plus와 plusAssign을 동시에 정의하는 것은 피하자. | . | . plus의 경우 새로운 값을 반환하는 것이고, plusAssign의 경우 현재 값을 변경하는 것이다. | Point처럼 변경 불가능한 class라면 plus만 있는 것이 맞다. | builder같이 변경 가능한 class를 설계한다면 plusAssign만 있는 것이 맞다. | . kotlin collection은 +와 +=를 모두 제공한다. val list = arrayListOf(1, 2) list += 3 val newList = list + listOf(4, 5) println(list) [1, 2, 3] println(newList) [1, 2, 3, 4, 5] . unary operator . | expression | function name | . | +a | unaryPlus | . | -a | unaryMinus | . | !a | not | . | ++a, a++ | inc | . | –a, a– | dec | . 동일하게 unary operator에서도 overloading을 할 수 있다. ",
    "url": "/docs/kotlin/kotlin-in-action/7#overloading-arithmetic-operators",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/7#overloading-arithmetic-operators"
  },"201": {
    "doc": "kotlin in action 정리 #7",
    "title": "comparison operators",
    "content": "equals . class에 대해 배울 때 kotlin은 ==로 equals를 호출한다는 것을 배웠다. !=도 동일하게 equals를 호출한다. kotlin은 ==에 대해서 null check를 하기 때문에 nullable 값에도 적용할 수 있다. | java처럼 귀찮은 null 체크를 직접하거나 equals 내부에서 구현하지 않아도 됨. | a == b가 a?.equals(b) ?: (b == null)로 컴파일 되기 때문. | . class Point(val x: Int, val y: Int) { override fun equals(obj: Any?): Boolean { if (obj === this) return true if (obj !is Point) return false return obj.x == x &amp;&amp; obj.y == y } } . Point의 equals를 구현하면 위와 같다. equals는 Any에 정의된 equals를 override 하는 것이다. Any에는 equals를 operator를 붙이지만 여기서는 정의된 함수를 override하는 것이라서 operator를 붙이지 않아도 상위 class(Any)의 operator 지정이 적용된다. compareTo . Java에서는 Comparable interface를 구현해서 sort 등의 작업을 한다. | e1.compareTo(e2) 와 같이 명시 Kotlin에서도 똑같은 Comparable interface를 지원하고, compareTo 함수를 호출하는 convention을 제공한다. | &lt;, &gt;, &lt;=, &gt;=이 compareTo로 컴파일 됨. | a &gt;= b는 a.compareTo(b) &gt;= 0 | a &lt; b는 a.compareTo(b) &lt; 0 | . class Person(val firstName: String, val lastName: String): Comparable&lt;Person&gt; { override fun compareTo(other: Person): Int { return compareValuesBy(this, other, Person::lastName, Person::firstName) } } . val p1 = Person(“Alice”, “Smith”) val p2 = Person(“Bob”, “Johnson”) println(p1 &lt; p2) . equals와 마찬가지로, compareTo가 Comparable에 정의되어 있으므로 override를 한다. Comparable을 구현하지 않고 operator를 붙일 수도 있다. compareValuesBy는 param으로 받은 함수의 결과를 0이 아닌 값이 나올 때까지 비교한다. 0이 아닌 값이 나오면 값을 반환하고, 끝까지 나오지 않으면 0을 반환한다. ",
    "url": "/docs/kotlin/kotlin-in-action/7#comparison-operators",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/7#comparison-operators"
  },"202": {
    "doc": "kotlin in action 정리 #7",
    "title": "conventions for collection &amp; ranges",
    "content": "index as get, set . get, set을 구현하면 index로 접근이 가능하다. | print(x[a])는 print(x.get(a)) | print(x[a, b])는 print(x.get(a, b)) | x[a] = b는 x.set(a, b) | x[a, b] = c는 x.set(a, b, c) | . Map MutableMap에는 get, set이 이미 있다. operator fun Point.get(index: Int): Int { return when(index) { 0 -&gt; x 1 -&gt; y else -&gt; throw IndexOutOfBoundsException(\"Invalid coordinate $index\") } } . val p = Point(10, 20) println(p[1]) 20 . get의 param으로 Int가 아닌 type도 사용할 수 있다. 필요하다면 다른 type에 대해 overloading한 get 함수를 여러 개 정의할 수 있다. data class MutablePoint(var x: Int, var y: Int) operator fun MutablePoint.set(index: Int, value: Int) { when(index) { 0 -&gt; x = value 1 -&gt; y = vaule else -&gt; throw IndexOutOfBoundsException(\"Invalid coordinate $index\") } } . val p = MutablePoint(10, 20) p[1] = 42 println(p) MutablePoint(x=10, y=42) . in . contains를 구현하면 in으로 접근이 가능하다. | a in c는 c.contains(a) | . data class Rectangle(val upperLeft: Point, val lowerRight: Point) operator fun Rectangle.contains(p: Point): Boolean { return p.x in upperLeft.x until lowerRight.x &amp;&amp; p.y in upperLeft.y until lowerRight.y } . val rect = Rectangle(Point(10, 20), Point(50, 50)) println(Point(20, 30) in rect) . true . println(Point(5, 5) in rect) . false . 10..20은 10 &lt;= x &lt;= 20 의 범위를 확인하고, 10 until 20은 10 &lt;= x &lt; 20 의 범위를 확인한다. rangeTo . rangeTo를 구현하면 범위를 만들 때 사용하는 ..로 접근이 가능하다. | a..b는 a.rangeTo(b) | Comparable interface를 구현하면 rangeTo를 정의할 필요가 없음. | kotlin standard library가 모든 Comparable에 적용가능한 rangeTo를 함수를 가지고 있음. | operator fun &lt;T: Comparable&lt;T&gt;&gt; T.rangeTo(that: T) ClosedRange&lt;T&gt; | kotlin.ranges.ComparableRange class를 보면 rangeTo 정의를 확인할 수 있음. | . | ClosedRange는 범위를 가지고 있고 contains를 정의해서 a in b..c가 가능한 것. | a in b..c = a in closedRange의 구현(b=start, c=end) = closedRange의 구현(b=start, c=end).contains(a) | . | . rangeTo는 다른 연산자보다 우선순위가 낮으나 괄호를 써주는게 이해하기 좋다. | 0..n + 1는 0..(n + 1)과 같음 | 0..n.forEach{}는 우선순위 문제로 compile할 수 없음. | (0..n).forEach{ print(it) } | . | . iterator, for loop . for loop에서 사용하는 for (x in list) { ... }도 in을 사용하지만 contains와는 다르다. list.iterator()를 호출해서 java와 마찬가지로 hasNext와 next 호출을 반복하는 식으로 변환된다. Kotlin에서는 이 또한 convention으로 iterator 함수를 정의할 수 있다. | String의 상위 class CharSequence는 iterator 확장 함수를 정의한다. | operator fun CharSequence.iterator(): CharIterator | 따라서 for (c in \"abc\") {} 이 가능하다. | . operator fun ClosedRange&lt;LocalDate&gt;.iterator(): Iterator&lt;LocalDate&gt; = object : Iterator&lt;LocalDate&gt; { var current = start override fun hasNext() = current &lt;= endInclusive // compareTo 사용 override fun next() = current.apply{ current = plusDays(1) } } . val newYear = LocalDate.ofYearDay(2017, 1) val daysOff = newYear.minusDays(1)..newYear for (dayOff in daysOff) { println(dayOff) } . 2016-12-31 2017-01-01 . ",
    "url": "/docs/kotlin/kotlin-in-action/7#conventions-for-collection--ranges",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/7#conventions-for-collection--ranges"
  },"203": {
    "doc": "kotlin in action 정리 #7",
    "title": "kotlin in action 정리 #7",
    "content": " ",
    "url": "/docs/kotlin/kotlin-in-action/7",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/7"
  },"204": {
    "doc": "kotlin in action 정리 #7-2",
    "title": "chapter 7-2. Operator overloading and other conventions",
    "content": " ",
    "url": "/docs/kotlin/kotlin-in-action/7-2#chapter-7-2-operator-overloading-and-other-conventions",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/7-2#chapter-7-2-operator-overloading-and-other-conventions"
  },"205": {
    "doc": "kotlin in action 정리 #7-2",
    "title": "Destructuring declarations",
    "content": "Destructuring declaration(구조 분해 선언)을 사용하는 방법을 보자. val p = Point(10, 20) val (x, y) = p . 이렇게 여러 변수의 초기화가 가능한 방식이다. | python도 여러 변수의 초기화를 하지만 kotlin과는 다르다. | . destructuring은 다음과 같은 convention을 사용한다. | 초기화 할 좌변의 변수들을 괄호로 묶어야 한다. | destructuring declaration은 초기화를 위해 componentN 함수를 호출한다. 여기서 N은 destructuring declaration의 변수 위치에 따라 붙는 번호다. | data class는 생성자에 있는 property에 대해 자동으로 componentN 함수를 만들어준다. | kotlin standard libary에서는 맨 앞의 다섯 property에 대해서만 componentN을 제공한다. | collection에 대해서도 destructuring이 가능하다. | . data class가 아닌 경우의 구현 . class Point(val x: Int, val y: Int) { operator fun component1() = x operator fun component2() = y } . Destructuring in loop . 변수 선언이 들어갈 수 이쓴ㄴ 장소라면 어디든 구조 분해 선언을 사용할 수 있다. | for 안에서도 사용할 수 있다. | . 특히 map에서 유용하게 사용할 수 있다. fun printEntries(map: Map&lt;String, String&gt;) { for ((key, value) in map) { println(\"$key -&gt; $value\") } } . ",
    "url": "/docs/kotlin/kotlin-in-action/7-2#destructuring-declarations",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/7-2#destructuring-declarations"
  },"206": {
    "doc": "kotlin in action 정리 #7-2",
    "title": "delegated property",
    "content": "field에 단순 저장하는 것보다 더 복잡하게 작동하는 property를 쉽게 구현할 수 있다. | delegate를 활용해서 값을 field가 아니라 db table이나 browers session, map 등에도 저장할 수 있다. | . // delegate의 일반적인 문법 class Foo { var p: Type by Delegate() } // compiler에서 해석해서 생기는 코드 class Foo { private val delegate = Delegate() var p: Type set(value: Type) = delegate.setValue(..., value) get() = delegate.getValue(...) } . 위에서 예시로 사용한 Delegate class 처럼 사용하려면 getValue와 setValue 함수를 가지고 있어야 된다. lazy initialization . lazy initialization는 객체의 일부를 초기화하지 않고 남겨뒀다가 필요할 경우 초기화할 때 쓰는 패턴이다. 아래는 email을 실제 사용할 때 한 번만 초기화하도록 구현한 class 이다. class Person(val name: String) { private var _emails: List&lt;Email&gt;? = null // 이런걸 backing property라고 함. val emails: List&lt;Email&gt; get() { if (_emails == null) { _emails = loadEmails(this) } return _emails!! } } . email은 not nullable하기 때문에 _email을 사용해서 활용해야 한다. class Person(val name: String) { val emails by lazy { loadEmails(this) } } . lazy는 getValue 함수가 있는 객체를 반환한다. lazy가 by와 함께 사용되면 delegate property를 만들 수 있다. lazy 함수는 기본적으로 thread safe 하다. | 필요에 따라 동기화에 사용할 락을 lazy 함수에 전달할 수 있다. | multi thread에서 사용하지 않을 property를 위해 lazy 함수가 동기화하지 못하게 막을 수도 있다. | . implement delegate property . class ObservableProperty(var propValue: Int, val changeSupport: PropertyChangeSupport) { operator fun getValue(p: Person, prop: KProperty&lt;*&gt;): Int = propValue operator fun setValue(p: Person, prop: KProperty&lt;*&gt;, newValue: Int) { // KProp은 나중에 다룸. name을 가져올 수 있다는 것만 알자. val oldValue = propValue propValue = newValue changeSupport.firePropertyChange(prop.name, oldValue, newValue) // noti하기 위한 따로 구현된 함수라고만 생각하자 } } class Person(val name: String, age: Int, salary: Int): PropertyChangeAware() { var age: Int by ObservableProperty(age, changeSupport) var salary: Int by ObservableProperty(salary, changeSupport) } . by 오른쪽에 오는 객체를 delegate 객체라고 한다. 진짜 객체의 property를 읽거나 쓸 때마다 delegate 객체의 getValue와 setValue를 호출한다. getValue와 setValue에도 operator가 붙는다. 위 코드를 kotlin standard에 있는 Delegates를 이용해서 아래와 같이 바꿀 수 있다. class Person(val name: String, age: Int, salary: Int): PropertyChangeAware() { private val observer = { prop: KProperty&lt;*&gt;, oldValue: Int, newValue: Int -&gt; changeSupport.firePropertyChange(prop.name, oldValue, newValue) } var age: Int by Delegates.observable(age, observer) var salary: Int by Delegates.observable(salary, observer) } . by의 우항에는 꼭 새로운 instance가 생성되어야 하는 것은 아니다. getValue와 setValue를 포함하는 객체를 반환하는 함수 호출이나 다른 property, 다른 expression이 올 수 있다. delegate property rule . delegate가 어떻게 동작하는지 정리해본다. class C { var prop: Type By MyDelegate() } . compiler는 MyDelegate class의 instance를 hidden property에 저장한다. | 이걸 &lt;delegate&gt;라고 부른다. compiler는 KProperty type의 object를 property를 표현하기 위해 사용한다. | 이걸 &lt;property&gt;라고 부른다. | . class C { private val &lt;delegate&gt; = MyDelegate() var prop: Type get() = &lt;delegate&gt;.getValue(this, &lt;property&gt;) set(value: Type) = &lt;delegate&gt;.setValue(this, &lt;property&gt;, value) } . 이렇게 compiler가 property의 접근자에 대해 get/setValue 호출 코드를 생성해준다. framework에서 delegate 활용 . object Users : IdTable() { // db table val name = varchar(\"name\", length = 50).index() // property = column val age = integer(\"age\") } class User(id: EntityID) : Entity(id) { // 각 User instance는 table에 들어있는 구체적인 entity에 해당 var name: String by Users.name var age: Int by Users.age } . Users는 db 전체에 단 하나만 있는 table을 표현하므로 singleton으로 선언됨. 위 같은 코드에서는 User에 접근할 때 entity에 정의된 db에서 값을 가져오므로 편리하다. F/W는 Column class 안에 get/setValue를 정의한다. get/setValue는 kotlin delegate conventions의 요구사항을 만족한다. operator fun &lt;T&gt; Column&lt;T&gt;.getValue(o: Entity, desc: KProperty&lt;*&gt;): T { // retrieve the value from the database } operator fun &lt;T&gt; Column&lt;T&gt;.setValue(o: Entity, desc: KProperty&lt;*&gt;, value: T) { // update the value in the database } . ",
    "url": "/docs/kotlin/kotlin-in-action/7-2#delegated-property",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/7-2#delegated-property"
  },"207": {
    "doc": "kotlin in action 정리 #7-2",
    "title": "kotlin in action 정리 #7-2",
    "content": " ",
    "url": "/docs/kotlin/kotlin-in-action/7-2",
    
    "relUrl": "/docs/kotlin/kotlin-in-action/7-2"
  },"208": {
    "doc": "[OmitStackTraceInFastThrow] java stacktrace 안남는 문제 해결",
    "title": "테스트",
    "content": "테스트 코드를 보고 돌려보면 이해가 잘된다. // test.java public class test { public static void main(String[] args) { String nullStr = null; int i = 0; while (i &lt;= 13000) { i++; try { makeException(nullStr); } catch (Exception e) { e.printStackTrace(); } } } private static void makeException(String obj) { obj.split(\"a\"); } } . stackTrace가 안남는 것 확인하기 . | javac test.java | java test | print 결과를 보면 trace가 쭉 남다가 어느 순간부터 안남는 것 확인 | . stackTrace가 남도록 option 설정 . | javac test.java | java -XX:-OmitStackTraceInFastThrow test | 위와 다르게 끝까지 stackTrace가 남는 것 확인 | . ",
    "url": "/docs/java/issue/stacktrace#%ED%85%8C%EC%8A%A4%ED%8A%B8",
    
    "relUrl": "/docs/java/issue/stacktrace#테스트"
  },"209": {
    "doc": "[OmitStackTraceInFastThrow] java stacktrace 안남는 문제 해결",
    "title": "reference",
    "content": ". | https://stackoverflow.com/questions/2411487/nullpointerexception-in-java-with-no-stacktrace | https://www.oracle.com/java/technologies/javase/release-notes-introduction.html#hotspot | . ",
    "url": "/docs/java/issue/stacktrace#reference",
    
    "relUrl": "/docs/java/issue/stacktrace#reference"
  },"210": {
    "doc": "[OmitStackTraceInFastThrow] java stacktrace 안남는 문제 해결",
    "title": "[OmitStackTraceInFastThrow] java stacktrace 안남는 문제 해결",
    "content": "java에서 NullPointException(NPE) 발생 시 stackTrace가 남지 않는 문제가 발생했다. 흥미로운건 local test에서는 stackTrace가 남고, 실제 서버에서는 남지 않는다는 점이었다. 이는 JVM의 최적화 옵션 때문인데, JVM에서는 최적화와 log 관리를 위해 stack trace를 관리한다. exception이 발생하면 full stack trace를 출력하고 이걸 저장했다가 같은 stack trace가 여러번 반복될 때 출력하지 않도록 한다. 처음만 출력하는 것은 아니고, 충분히 반복된 이후부터 stack trace 출력을 멈춘다. 그렇기 때문에 local에서 띄운 경우 stack이 남고, 실제 서버에서는 이미 충분히 stack trace가 찍힌 후 이후의 exception이 남지 않고 있던 것. 이런 문제를 해결하기 위해 java 실행 시 -XX:-OmitStackTraceInFastThrow 옵션을 넣어주면 모든 경우에 대해 최적화 없이 stackTrace를 남길 수 있도록 한다. 최적화를 푸는게 맞을까하는 생각이 들 수 있지만 잘 준비된 서비스라면 처음 stackTrace의 에러가 발생했을 때 alert를 받고 바로 수정이 될 수 있는 구조여야 한다. ",
    "url": "/docs/java/issue/stacktrace",
    
    "relUrl": "/docs/java/issue/stacktrace"
  },"211": {
    "doc": "[kotlin error] cannot be invoked as a function. The function 'invoke()' is not found",
    "title": "에러 메세지",
    "content": "cannot be invoked as a function. The function 'invoke()' is not found . ",
    "url": "/docs/error-bug/kotlin/cannot-be-invoked-as-a-function#%EC%97%90%EB%9F%AC-%EB%A9%94%EC%84%B8%EC%A7%80",
    
    "relUrl": "/docs/error-bug/kotlin/cannot-be-invoked-as-a-function#에러-메세지"
  },"212": {
    "doc": "[kotlin error] cannot be invoked as a function. The function 'invoke()' is not found",
    "title": "코드",
    "content": "class ListNode(var `val`: Int) { var next: ListNode? = null } val base = ListNode(0) base.next(ListNode(1)) var next = base.next() . 이런 코드에서 문제가 났다. 역시 책으로 공부하는거랑 써보는거랑 다르다.. property의 경우엔 저렇게 쓰는게 아니었다. ",
    "url": "/docs/error-bug/kotlin/cannot-be-invoked-as-a-function#%EC%BD%94%EB%93%9C",
    
    "relUrl": "/docs/error-bug/kotlin/cannot-be-invoked-as-a-function#코드"
  },"213": {
    "doc": "[kotlin error] cannot be invoked as a function. The function 'invoke()' is not found",
    "title": "해결",
    "content": "val base = ListNode(0) base.next = ListNode(1) var next = base.next() . ",
    "url": "/docs/error-bug/kotlin/cannot-be-invoked-as-a-function#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/error-bug/kotlin/cannot-be-invoked-as-a-function#해결"
  },"214": {
    "doc": "[kotlin error] cannot be invoked as a function. The function 'invoke()' is not found",
    "title": "[kotlin error] cannot be invoked as a function. The function 'invoke()' is not found",
    "content": " ",
    "url": "/docs/error-bug/kotlin/cannot-be-invoked-as-a-function",
    
    "relUrl": "/docs/error-bug/kotlin/cannot-be-invoked-as-a-function"
  },"215": {
    "doc": "vue 3.0 global component",
    "title": "예제",
    "content": "객체처럼 사용할 Child.vue . &lt;template&gt; &lt;div&gt; ... &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: 'Child' } &lt;/script&gt; &lt;style&gt; ... &lt;/style&gt; . local component로 사용하는 vue 구현 . local component를 사용할 vue 파일에서 component를 import하고 사용한다. &lt;template&gt; &lt;div&gt; &lt;Child /&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; import child from './Child' // 상대주소로 기입 export default { name: 'HelloWorld', components: { 'Child': child // 앞의 naming이 사용할 name, 뒤에는 import한 name }, } &lt;/script&gt; &lt;style&gt; ... &lt;/style&gt; . global component로 사용하는 app 구현 . global component를 사용할 프로젝트의 main.js 파일에서 component를 import한다. 그러면 위 local component에서 사용하는 것처럼 각 vue에서 component를 쓸 수 있다. import { createApp } from 'vue' import App from './App.vue' import child from './components/Child' const app = createApp(App) app.component('Child', child) app.mount('#app') . 사용하는 쪽 vue에선 script에서 import 없이 바로 template에서 사용할 수 있다. &lt;Child /&gt; . ",
    "url": "/docs/vue/component#%EC%98%88%EC%A0%9C",
    
    "relUrl": "/docs/vue/component#예제"
  },"216": {
    "doc": "vue 3.0 global component",
    "title": "참고",
    "content": "vue guide . | 현재는 3.x guide는 없음 | . ",
    "url": "/docs/vue/component#%EC%B0%B8%EA%B3%A0",
    
    "relUrl": "/docs/vue/component#참고"
  },"217": {
    "doc": "vue 3.0 global component",
    "title": "vue 3.0 global component",
    "content": "vue.js 3.x에서 global component를 사용하기. guide에 나온 내용은 vue.js 2.x 내용이어서 3.x에서는 조금 다른 부분이 있었다. java의 객체를 만들어서 클래스들에서 사용하는 것처럼, vue에서도 .vue 파일을 생성하고 다른 곳에서 활용하고 싶었다. vue에서는 이런걸 component라고 하고 등록하고 사용하고 있었다. component에는 두 가지 종류가 있는데, local과 global이 있다. local component: 쓸 때마다 각 vue에서 등록해서 사용하는 지역변수 같은 느낌 . global component: 한 번 등록하고 각 vue에서 사용하는 전역변수 같은 느낌 . 몰라서 그렇지 한 번만 예제를 확인하면 적용하기는 쉽다. ",
    "url": "/docs/vue/component",
    
    "relUrl": "/docs/vue/component"
  },"218": {
    "doc": "vue 3.0 component props 전달하기",
    "title": "예제",
    "content": "예제 코드는 component 적용의 내용을 참고하자. component 구성이 완료되었다고 생각하고 코드를 일부만 작성하겠다. 객체처럼 사용할 Child.vue . &lt;template&gt; &lt;div&gt; &lt;p&gt;&lt;/p&gt; // prop 사용 &lt;img v-bind:src=\"require(`@/assets/${image}`)\" alt=\"test image\"&gt; // prop 사용 - image, require가 필수이다. &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: 'Child', props: { msg: String, image: String } } &lt;/script&gt; . component를 사용하는 vue . component에서는 prop들을 넣어준다 . &lt;template&gt; &lt;div&gt; &lt;Child msg=\"child test msg\" image=\"1.png\"/&gt; // 여기서 1.png는 src/assets/1.png 에 있다. &lt;/div&gt; &lt;/template&gt; &lt;script&gt; import child from './Child' // 상대주소로 기입 export default { name: 'HelloWorld', components: { 'Child': child // 앞의 naming이 사용할 name, 뒤에는 import한 name }, } &lt;/script&gt; . ",
    "url": "/docs/vue/passing-props#%EC%98%88%EC%A0%9C",
    
    "relUrl": "/docs/vue/passing-props#예제"
  },"219": {
    "doc": "vue 3.0 component props 전달하기",
    "title": "참고",
    "content": "vue guide, props 전달하기 stackoverflow, image 보이기 . ",
    "url": "/docs/vue/passing-props#%EC%B0%B8%EA%B3%A0",
    
    "relUrl": "/docs/vue/passing-props#참고"
  },"220": {
    "doc": "vue 3.0 component props 전달하기",
    "title": "vue 3.0 component props 전달하기",
    "content": "component 적용을 한 뒤에 component의 props를 전달하는 방법이다. component에는 data가 있고 prop이 있는데, prop은 component를 생성하는 쪽에서 각기 다른 값을 넣어줄 수 있는 것이다. | 내가 이해하기엔 java에서 생성자에 넣어주는 값 정도? | . component를 사용할 수 있게 적용하고 난 뒤 할 작업은 prop을 통해 각 component들을 구성하고 view를 꾸며주는 일이다. 이 또한 예제를 보면 간단한데, 문제를 찾는데 시간이 걸렸다. ",
    "url": "/docs/vue/passing-props",
    
    "relUrl": "/docs/vue/passing-props"
  },"221": {
    "doc": "vue emit으로 상위 컴포넌트로 click event 전달하기",
    "title": "예제",
    "content": "예제 코드는 component 적용의 내용을 참고하자. component 구성이 완료되었다고 생각하고 코드를 일부만 작성하겠다. 객체처럼 사용할 Child.vue . &lt;template&gt; &lt;div&gt; &lt;p&gt;&lt;/p&gt; // prop 사용 &lt;img v-bind:src=\"require(`@/assets/${image}`)\" alt=\"test image\"&gt; // prop 사용 - image, require가 필수이다. &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: 'Child', props: { msg: String, image: String } } &lt;/script&gt; . component를 사용하는 vue . component에서는 prop들을 넣어준다 . &lt;template&gt; &lt;div&gt; &lt;Child msg=\"child test msg\" image=\"1.png\"/&gt; // 여기서 1.png는 src/assets/1.png 에 있다. &lt;/div&gt; &lt;/template&gt; &lt;script&gt; import child from './Child' // 상대주소로 기입 export default { name: 'HelloWorld', components: { 'Child': child // 앞의 naming이 사용할 name, 뒤에는 import한 name }, } &lt;/script&gt; . ",
    "url": "/docs/vue/emit-click#%EC%98%88%EC%A0%9C",
    
    "relUrl": "/docs/vue/emit-click#예제"
  },"222": {
    "doc": "vue emit으로 상위 컴포넌트로 click event 전달하기",
    "title": "참고",
    "content": "vue guide, props 전달하기 stackoverflow, image 보이기 . ",
    "url": "/docs/vue/emit-click#%EC%B0%B8%EA%B3%A0",
    
    "relUrl": "/docs/vue/emit-click#참고"
  },"223": {
    "doc": "vue emit으로 상위 컴포넌트로 click event 전달하기",
    "title": "vue emit으로 상위 컴포넌트로 click event 전달하기",
    "content": "vue 하위 컴포넌트에서 클릭한 이벤트를 전달해줄때, . ",
    "url": "/docs/vue/emit-click",
    
    "relUrl": "/docs/vue/emit-click"
  },"224": {
    "doc": "[spring error] java.lang.NoClassDefFoundError: graphql/execution/batched/Batched",
    "title": "에러 메세지",
    "content": "Caused by: java.lang.NoClassDefFoundError: graphql/execution/batched/Batched at com.coxautodev.graphql.tools.MethodFieldResolver$Companion.isBatched(MethodFieldResolver.kt:24) ~[graphql-java-tools-5.2.4.jar:na] at com.coxautodev.graphql.tools.MethodFieldResolver.scanForMatches(MethodFieldResolver.kt:103) ~[graphql-java-tools-5.2.4.jar:na] at com.coxautodev.graphql.tools.SchemaClassScanner.scanResolverInfoForPotentialMatches(SchemaClassScanner.kt:230) ~[graphql-java-tools-5.2.4.jar:na] at com.coxautodev.graphql.tools.SchemaClassScanner.handleRootType(SchemaClassScanner.kt:122) ~[graphql-java-tools-5.2.4.jar:na] at com.coxautodev.graphql.tools.SchemaClassScanner.scanForClasses(SchemaClassScanner.kt:80) ~[graphql-java-tools-5.2.4.jar:na] at com.coxautodev.graphql.tools.SchemaParserBuilder.scan(SchemaParserBuilder.kt:151) ~[graphql-java-tools-5.2.4.jar:na] at com.coxautodev.graphql.tools.SchemaParserBuilder.build(SchemaParserBuilder.kt:157) ~[graphql-java-tools-5.2.4.jar:na] at com.oembedler.moon.graphql.boot.GraphQLJavaToolsAutoConfiguration.schemaParser(GraphQLJavaToolsAutoConfiguration.java:57) ~[graphql-spring-boot-autoconfigure-5.0.2.jar:na] at com.oembedler.moon.graphql.boot.GraphQLJavaToolsAutoConfiguration$$EnhancerBySpringCGLIB$$e208bf0b.CGLIB$schemaParser$2(&lt;generated&gt;) ~[graphql-spring-boot-autoconfigure-5.0.2.jar:na] at com.oembedler.moon.graphql.boot.GraphQLJavaToolsAutoConfiguration$$EnhancerBySpringCGLIB$$e208bf0b$$FastClassBySpringCGLIB$$fdb89603.invoke(&lt;generated&gt;) ~[graphql-spring-boot-autoconfigure-5.0.2.jar:na] at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244) ~[spring-core-5.3.20.jar:5.3.20] at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:331) ~[spring-context-5.3.20.jar:5.3.20] at com.oembedler.moon.graphql.boot.GraphQLJavaToolsAutoConfiguration$$EnhancerBySpringCGLIB$$e208bf0b.schemaParser(&lt;generated&gt;) ~[graphql-spring-boot-autoconfigure-5.0.2.jar:na] at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na] at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na] at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na] at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na] at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ~[spring-beans-5.3.20.jar:5.3.20] ... 124 common frames omitted Caused by: java.lang.ClassNotFoundException: graphql.execution.batched.Batched at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:582) ~[na:na] at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178) ~[na:na] at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521) ~[na:na] ... 142 common frames omitted . ",
    "url": "/docs/error-bug/spring/graphql_execution_batched_Batched#%EC%97%90%EB%9F%AC-%EB%A9%94%EC%84%B8%EC%A7%80",
    
    "relUrl": "/docs/error-bug/spring/graphql_execution_batched_Batched#에러-메세지"
  },"225": {
    "doc": "[spring error] java.lang.NoClassDefFoundError: graphql/execution/batched/Batched",
    "title": "코드",
    "content": "문제의 pom.xml은 이렇다. &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; ... &lt;version&gt;2.7.0&lt;/version&gt; &lt;/parent&gt; ... &lt;dependencies&gt; ... &lt;dependency&gt; &lt;groupId&gt;com.graphql-java&lt;/groupId&gt; &lt;artifactId&gt;graphql-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;5.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.graphql-java&lt;/groupId&gt; &lt;artifactId&gt;graphql-java-tools&lt;/artifactId&gt; &lt;version&gt;5.2.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; . ",
    "url": "/docs/error-bug/spring/graphql_execution_batched_Batched#%EC%BD%94%EB%93%9C",
    
    "relUrl": "/docs/error-bug/spring/graphql_execution_batched_Batched#코드"
  },"226": {
    "doc": "[spring error] java.lang.NoClassDefFoundError: graphql/execution/batched/Batched",
    "title": "해결",
    "content": "위 pom.xml에서 문제는 springboot version 이었다. com.graphql-java의 현재 최신 버전인 각각 5.0.2와 5.2.4가 springboot 2.7.0과 호환이 되지 않는 것이 문제였고, springboot version을 2.6.7로 낮추면서 문제는 해결됐다. reference . 참고한 graphql 코드 . | https://www.baeldung.com/spring-graphql | . 해결 방법 stackoverflow . | https://stackoverflow.com/questions/71039670/spring-boot-graphqlqueryresolver-wont-run-runs-on-test-project | . ",
    "url": "/docs/error-bug/spring/graphql_execution_batched_Batched#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/error-bug/spring/graphql_execution_batched_Batched#해결"
  },"227": {
    "doc": "[spring error] java.lang.NoClassDefFoundError: graphql/execution/batched/Batched",
    "title": "[spring error] java.lang.NoClassDefFoundError: graphql/execution/batched/Batched",
    "content": "graphql을 spring에서 사용하려고 하던 중 에러가 났다. 뭐가 잘못됐는지 시간을 한참 썼는데 원인은 허무하다. 뭐 이런 일들이 항상 그렇지.. ",
    "url": "/docs/error-bug/spring/graphql_execution_batched_Batched",
    
    "relUrl": "/docs/error-bug/spring/graphql_execution_batched_Batched"
  },"228": {
    "doc": "java와 비교한 kotlin 장단점",
    "title": ":heavy_check_mark: 장점",
    "content": ". | java와의 호환 | 안전한 코드 | 간결하고 명확한 코드 | 확장 함수 | 구글 공식 언어 | . ",
    "url": "/docs/kotlin/kotlin-vs-java#heavy_check_mark-%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/kotlin/kotlin-vs-java#heavy_check_mark-장점"
  },"229": {
    "doc": "java와 비교한 kotlin 장단점",
    "title": "java와의 호환",
    "content": "java와 유사하여 java 개발자가 쉽게 kotlin을 사용할 수 있다. 즉 러닝커브가 낮다는 것. 또한 컴파일하여 java와 완벽히 호환이 가능하다. java와 kotlin 코드를 하나의 프로젝트에서 같이 사용할 수도 있다. ",
    "url": "/docs/kotlin/kotlin-vs-java#java%EC%99%80%EC%9D%98-%ED%98%B8%ED%99%98",
    
    "relUrl": "/docs/kotlin/kotlin-vs-java#java와의-호환"
  },"230": {
    "doc": "java와 비교한 kotlin 장단점",
    "title": "안전한 코드",
    "content": "kotlin에서 가장 대표적인 특징 중 하나는 nullable type의 지원이다. kotlin은 nullable type과 not nullable type을 구분한다. not nullable type은 compile 시점에서 NPE를 발생시키기 때문에 runtime에 의도치 않은 NPE가 날 확률이 줄어든다. type을 그냥쓰면 not nullable type이고, type에 ?를 붙여서 nullable type을 사용할 수 있다. 예시 . 아래처럼 not nullable type에 null을 넣으면 Kotlin: Null can not be a value of a non-null type과 같은 compile error가 발생한다. var nullable: String? = null var notNullable: String = null . ",
    "url": "/docs/kotlin/kotlin-vs-java#%EC%95%88%EC%A0%84%ED%95%9C-%EC%BD%94%EB%93%9C",
    
    "relUrl": "/docs/kotlin/kotlin-vs-java#안전한-코드"
  },"231": {
    "doc": "java와 비교한 kotlin 장단점",
    "title": "간결하고 명확한 코드",
    "content": "kotlin은 java에서 불편하고 가독성이 떨어지는 코드들을 많이 개선했다. 그 중 가장 대표적인 것이 nullable type operator와 type cast operator이다. 실제로 kotlin 코드 적용 이후 코드가 줄어든 통계1가 있다. 보일러 플레이팅 . kotlin의 class는 type에 따라 class를 제공하여 보일러 플레이팅 코드가 굉장히 줄어든다. kotlin은 class 생성 시 Getter/Setter와 AllArgsConstructor를 기본으로 제공한다. data class를 사용하면 @lombok.Data 처럼 equals(), hashCode(), toString()을 제공한다. 예시 . class Car(val model: String, var number: String) . 위 코드에서 Car은 아래와 같은 기능이 제공된다. | AllArgsConstructor | model에 대한 getter | number에 대한 getter/setter | . safe call operator . ?.으로 간단하고 명료하게 null 검사와 함수 호출을 가능하게 한다. 예시 . class Address(val country: String?) class Company(val address: Address?) class Person(val company: Company?) { fun getCountry(): String? { return company?.address?.country; } } fun getCountry(): String? { return company?.address?.country } . 위 kotlin 코드는 아래 java 코드와 같다. void getCountry() { if (company == null) { return null; } if (company.getAddress() == null) { return null; } return company.getAddress().getCountry(); } . elvis operator . ?.와 유사한데, default value를 명시해준다. 예시 . fun getCountry(): String { return company?.address?.country?:\"kr\" } . 위 kotlin 코드는 아래 java 코드와 같다. void getCountry() { if (company == null) { return \"kr\"; } if (company.getAddress() == null) { return \"kr\"; } if (company.getAddress().getCountry() == null) { return \"kr\"; } return company.getAddress().getCountry(); } . smart cast . kotlin은 type cast에 is와 as를 제공한다. 이 중에 is는 instanceof와 유사한데, compiler가 smart cast를 해줘서 더 편리하다. 예시 . java 코드로 작성할 경우 instanceof 이후에 명시적으로 type cast를 해주어야 하는 코드를 kotlin에서는 is를 통해 처리할 수 있다. interface Expr class Num(val value: Int): Expr class Sum(val left: Expr, val right: Expr): Expr fun eval(e: Expr): Int { if (e is Num) { return e.value } if (e is Sum) { return eval(e.left) + eval(e.right) } } . ",
    "url": "/docs/kotlin/kotlin-vs-java#%EA%B0%84%EA%B2%B0%ED%95%98%EA%B3%A0-%EB%AA%85%ED%99%95%ED%95%9C-%EC%BD%94%EB%93%9C",
    
    "relUrl": "/docs/kotlin/kotlin-vs-java#간결하고-명확한-코드"
  },"232": {
    "doc": "java와 비교한 kotlin 장단점",
    "title": "확장 함수",
    "content": "확장 함수는 클래스 밖에 선언된 함수를 말한다. 기존의 api들을 재작성하지 않고 기능을 사용할 수 있어서, kotlin에서 java의 클래스들을 그대로 사용하면서 기능을 추가하기 위한 목적으로도 사용된다. 확장 함수에서는 private, protected로 선언되지 않은 변수나 함수를 모두 자연스럽게 (내것 마냥) 호출할 수 있다. 예시 . fun String?.isNullOrBlank(): Boolean = this == null || this.isBlank() . 위 코드처럼 기본 타입에 대해서도 확장 함수를 작성할 수 있다. 실제로 위와 유사한 코드가 코틀린에 이미 정의되어 있고 이를 통해 kotlin은 다양한 기능을 제공한다. 확장 함수로 kotlin은 OO와 FP 모두 사용할 수 있다. ",
    "url": "/docs/kotlin/kotlin-vs-java#%ED%99%95%EC%9E%A5-%ED%95%A8%EC%88%98",
    
    "relUrl": "/docs/kotlin/kotlin-vs-java#확장-함수"
  },"233": {
    "doc": "java와 비교한 kotlin 장단점",
    "title": "구글 공식 언어",
    "content": "무료 오픈소스 언어이자, 구글 공식 언어로의 채택. ",
    "url": "/docs/kotlin/kotlin-vs-java#%EA%B5%AC%EA%B8%80-%EA%B3%B5%EC%8B%9D-%EC%96%B8%EC%96%B4",
    
    "relUrl": "/docs/kotlin/kotlin-vs-java#구글-공식-언어"
  },"234": {
    "doc": "java와 비교한 kotlin 장단점",
    "title": ":x: 단점",
    "content": ". | 빌드 시간 &amp; 크기 | 자바가 아니다 | 학습 리소스의 제한 | . ",
    "url": "/docs/kotlin/kotlin-vs-java#x-%EB%8B%A8%EC%A0%90",
    
    "relUrl": "/docs/kotlin/kotlin-vs-java#x-단점"
  },"235": {
    "doc": "java와 비교한 kotlin 장단점",
    "title": "빌드 시간 &amp; 크기",
    "content": "clean build의 경우 java보다 시간이 더 오래걸린다. kotlin은 증분 컴파일(incremental build)을 제공해서 partial build가 가능한 경우 java보다 더 빠르다. | java는 컴파일 회피만을 제공 | . 컴파일 회피: 모듈 단위의 dirty 체크 증분 컴파일: 파일 단위의 dirty 체크 . kotlin runtime이 package에 들어가야 해서 배포 시 파일 사이즈가 더 커진다. ",
    "url": "/docs/kotlin/kotlin-vs-java#%EB%B9%8C%EB%93%9C-%EC%8B%9C%EA%B0%84--%ED%81%AC%EA%B8%B0",
    
    "relUrl": "/docs/kotlin/kotlin-vs-java#빌드-시간--크기"
  },"236": {
    "doc": "java와 비교한 kotlin 장단점",
    "title": "자바가 아니다",
    "content": "java와 유사하지만 자바가 아니다. 분명히 세세한 사용들에 공부와 검색이 필요할 것이다. java 6을 베이스로 코틀린이 만들어졌다. java 6이후의 버전들과 다른 개념들이 존재한다. ",
    "url": "/docs/kotlin/kotlin-vs-java#%EC%9E%90%EB%B0%94%EA%B0%80-%EC%95%84%EB%8B%88%EB%8B%A4",
    
    "relUrl": "/docs/kotlin/kotlin-vs-java#자바가-아니다"
  },"237": {
    "doc": "java와 비교한 kotlin 장단점",
    "title": "학습 리소스의 제한",
    "content": "아무래도 java 보다는 자료들이 부족하다. 검색하는데 더 많은 시간이 필요할 것이다. | kotlinlang에서는 rough하게 40% 정도의 라인 수가 줄어드는 것을 확인. google home 팀은 코드 size 33% 줄어듦. &#8617; . | . ",
    "url": "/docs/kotlin/kotlin-vs-java#%ED%95%99%EC%8A%B5-%EB%A6%AC%EC%86%8C%EC%8A%A4%EC%9D%98-%EC%A0%9C%ED%95%9C",
    
    "relUrl": "/docs/kotlin/kotlin-vs-java#학습-리소스의-제한"
  },"238": {
    "doc": "java와 비교한 kotlin 장단점",
    "title": "java와 비교한 kotlin 장단점",
    "content": "kotlin을 공부하면서 확인한 장단점을 정리해보았다. kotlin은 java의 많은 것들을 녹여내면서, 최대한 편리하고 간결하게 사용할 수 있다는 특징이 있다. ",
    "url": "/docs/kotlin/kotlin-vs-java",
    
    "relUrl": "/docs/kotlin/kotlin-vs-java"
  },"239": {
    "doc": "[spring error] javax.websocket.server.ServerContainer not available",
    "title": "에러 메세지",
    "content": "java.lang.IllegalStateException: Failed to load ApplicationContext at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:132) at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:124) at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:248) at org.springframework.test.context.junit.jupiter.SpringExtension.postProcessTestInstance(SpringExtension.java:138) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeTestInstancePostProcessors$8(ClassBasedTestDescriptor.java:363) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.executeAndMaskThrowable(ClassBasedTestDescriptor.java:368) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeTestInstancePostProcessors$9(ClassBasedTestDescriptor.java:363) at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654) at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) at java.base/java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312) at java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:735) at java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734) at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeTestInstancePostProcessors(ClassBasedTestDescriptor.java:362) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$instantiateAndPostProcessTestInstance$6(ClassBasedTestDescriptor.java:283) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateAndPostProcessTestInstance(ClassBasedTestDescriptor.java:282) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$4(ClassBasedTestDescriptor.java:272) at java.base/java.util.Optional.orElseGet(Optional.java:369) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$5(ClassBasedTestDescriptor.java:271) at org.junit.jupiter.engine.execution.TestInstancesProvider.getTestInstances(TestInstancesProvider.java:31) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$prepare$0(TestMethodTestDescriptor.java:102) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:101) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:66) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:90) at java.base/java.util.ArrayList.forEach(ArrayList.java:1540) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) at java.base/java.util.ArrayList.forEach(ArrayList.java:1540) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35) at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86) at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86) at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53) at com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:71) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:220) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:53) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'serverEndpointExporter' defined in class path resource [com/oembedler/moon/graphql/boot/GraphQLWebAutoConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: javax.websocket.server.ServerContainer not available at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:953) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:740) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:415) at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:144) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124) ... 69 more Caused by: java.lang.IllegalStateException: javax.websocket.server.ServerContainer not available at org.springframework.util.Assert.state(Assert.java:76) at org.springframework.web.socket.server.standard.ServerEndpointExporter.afterPropertiesSet(ServerEndpointExporter.java:107) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800) ... 84 more Process finished with exit code -1 . ",
    "url": "/docs/error-bug/spring/javax-websocket-server-ServerContainer-not-available#%EC%97%90%EB%9F%AC-%EB%A9%94%EC%84%B8%EC%A7%80",
    
    "relUrl": "/docs/error-bug/spring/javax-websocket-server-ServerContainer-not-available#에러-메세지"
  },"240": {
    "doc": "[spring error] javax.websocket.server.ServerContainer not available",
    "title": "해결",
    "content": "에러 코드 . @SpringBootTest @AutoConfigureMockMvc public class ApiTest { } . RandomPort environment 추가해서 해결 . @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) @AutoConfigureMockMvc public class ApiTest { } . RANDOM_PORT? . SpringBootTest.WebEnvironment webEnvironment() default SpringBootTest.WebEnvironment.MOCK; public static enum WebEnvironment { MOCK(false), RANDOM_PORT(true), DEFINED_PORT(true), NONE(false); private final boolean embedded; ... } . SpringBootTest 코드를 보면 기본적으로 embedded tomcat을 사용하는 것이 false이다. RANDOM_PORT를 사용해서 embedded tomcat을 random port로 사용하도록 하는 것. ",
    "url": "/docs/error-bug/spring/javax-websocket-server-ServerContainer-not-available#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/error-bug/spring/javax-websocket-server-ServerContainer-not-available#해결"
  },"241": {
    "doc": "[spring error] javax.websocket.server.ServerContainer not available",
    "title": "[spring error] javax.websocket.server.ServerContainer not available",
    "content": " ",
    "url": "/docs/error-bug/spring/javax-websocket-server-ServerContainer-not-available",
    
    "relUrl": "/docs/error-bug/spring/javax-websocket-server-ServerContainer-not-available"
  },"242": {
    "doc": "static method class와 spring bean",
    "title": "static method class vs spring bean",
    "content": "구글링해보니, 생각보다 이런 토론이 많이 있었다. 토론의 결과를 참고하여 내가 내린 결론은 이렇다. | static은 종속성이 없을 때, 객체 생성이 필요 없을 때 사용해야 한다. | 조금이라도 의존성이 외부에 있거나, 내부에서 외부에 접근하는 경우(property)엔 static을 사용하면 안된다. | 어떤 이유로든 input에 따른 output이 동일하지 않은 경우 static을 사용하면 안된다. | . 이렇게 static을 사용할 수 있는 경우를 확인하고 사용할 수 있다. 위와 같이 static을 사용할 수 있을 때는 최대한 static을 사용하는 것이 좋을 듯 하다. ",
    "url": "/docs/spring/static-method-vs-bean#static-method-class-vs-spring-bean",
    
    "relUrl": "/docs/spring/static-method-vs-bean#static-method-class-vs-spring-bean"
  },"243": {
    "doc": "static method class와 spring bean",
    "title": "토론 주제",
    "content": "사실 너무 당연한 이야기들이다. 평소에 잠시 잊었을 뿐이지. 명확한 기준에도 토론의 주제가 되는 것들이 있었다. 1. dependency가 생길 수 있으니 bean으로 해야 한다. 이 경우는 static method를 사용하다가 dependency가 생겨서 bean을 사용해야하는 경우가 있을 수 있다는 것이다. 이런 경우 변경을 위한 코드 작업이 너무 번거롭다는 주장. 실제로 나는 이런 케이스를 겪었던 적이 있다. static method class가 아니어야 할 class가 static method class로 되어있어 bean으로 변경한 적이 있는데, 코드 작업이 확실히 번거로웠다. 대부분의 케이스는 이렇지 않기 때문에 예측해서 bean을 사용하는 것은 좋지 않고, 이런 케이스는 처음부터 bean이어야 할 클래스를 잘못 사용했을 가능성이 높다. 그렇지만 나는 나중에 변경될 것이라고 하는 미래의 변화를 예측하려고 하는건 잘못 이라는 의견에 동의한다. YAGNI 원칙에 따라 당연히 static method class 방향이 맞다고 생각한다. 2. 변경 될만한 로직을 정적 메소드로 구현하는게 맞나? . 위와 동일한 답변으로 정리할 수 있다. 설계 단계에서부터 이미 bean으로 설계하는게 적절한 상황이라면 bean으로 가는게 맞지만 나중에 변경될 것을 예측하여 YAGNI 원칙을 어겨선 안된다. 3. bean이면 mock으로 쉽게 할 수 있는 테스트들이 static은 어렵다. 실제로 자주 겪게 되는 문제이다. 실제로 테스트를 위해 bean으로 바꾸고 싶다는 생각도 했다. base64Utils 를 사용하는 함수에 대한 테스트를 작성할 때, 인코딩/디코딩 된 값들을 준비해놔야 테스트가 가능한 경우가 있었다. 하지만 이런 테스트는 실제로 필요한 데이터의 테스트가 맞다. 되려 무작위로 mock을 사용해서 테스트 되어야할 부분을 감추게 될 수 있다. ",
    "url": "/docs/spring/static-method-vs-bean#%ED%86%A0%EB%A1%A0-%EC%A3%BC%EC%A0%9C",
    
    "relUrl": "/docs/spring/static-method-vs-bean#토론-주제"
  },"244": {
    "doc": "static method class와 spring bean",
    "title": "bean과 static method의 목적",
    "content": "실제로 bean과 static method의 목적을 보면 더 명확하게 사용할 수 있지 싶다. bean: 의존성 역전을 위해 사용 static method: 종속성이 없을 때, 객체 생성이 필요 없을 때 사용 . ",
    "url": "/docs/spring/static-method-vs-bean#bean%EA%B3%BC-static-method%EC%9D%98-%EB%AA%A9%EC%A0%81",
    
    "relUrl": "/docs/spring/static-method-vs-bean#bean과-static-method의-목적"
  },"245": {
    "doc": "static method class와 spring bean",
    "title": "reference",
    "content": ". | http://kwon37xi.egloos.com/4844149 | https://softwareengineering.stackexchange.com/questions/360525/dependency-injection-vs-static-methods | https://www.baeldung.com/spring-bean | https://stackoverflow.com/questions/2671496/when-to-use-static-methods | . ",
    "url": "/docs/spring/static-method-vs-bean#reference",
    
    "relUrl": "/docs/spring/static-method-vs-bean#reference"
  },"246": {
    "doc": "static method class와 spring bean",
    "title": "static method class와 spring bean",
    "content": "며칠 전 리팩토링을 위해 코드를 보던 중 이상한 걸 발견했다. ~validator라고 명시된 두 개의 클래스가 같은 패키지에 있었는데, 하나는 static method로 구성된 class였고 다른 하나는 bean으로 사용되고 있었다. 어떤게 옳을까라는 판단은 금방내릴 수 있었다. 정확하게 어떤 근거로 이런 판단을 내린걸까? 에 대해선 선뜻 대답이 되지 않았다. 대부분의 개발자들이 감각적으로 내리는 이런 결정들은 옳은 것 같다. 실제로 DDD를 공부하면서 배운 개발 방법들을 우리 팀에선 이미 해오고 있던 방식이 있던 것처럼 경험이 쌓인 개발자일수록 더더욱 그렇다. ",
    "url": "/docs/spring/static-method-vs-bean",
    
    "relUrl": "/docs/spring/static-method-vs-bean"
  },"247": {
    "doc": "Uncaught SyntaxError: Unexpected token '<' 에러",
    "title": "Uncaught SyntaxError: Unexpected token '<' 에러",
    "content": "vue에서 Uncaught SyntaxError: Unexpected token '&lt;'에러를 받을 때, srcipt의 src를 잘못 명시한 경우이다. index.html의 header에 script를 넣고 싶은 경우에는, public path 밑에 .js, css 파일들을 두어야 한다. | favicon.ico가 있는 그 위치 | . ",
    "url": "/docs/vue/unexpected-token",
    
    "relUrl": "/docs/vue/unexpected-token"
  },"248": {
    "doc": "jq로 가장 빠르게 터미널에서 json 파싱하기",
    "title": "설치",
    "content": "sudo apt install jq . ",
    "url": "/docs/dev-tools/linux-commands/jq#%EC%84%A4%EC%B9%98",
    
    "relUrl": "/docs/dev-tools/linux-commands/jq#설치"
  },"249": {
    "doc": "jq로 가장 빠르게 터미널에서 json 파싱하기",
    "title": "사용성",
    "content": "jq는 이름 값을 한다. json format의 data processing을 해주는 녀석이다. log 등의 데이터에서 jq가 없다면 awk나 cut, sed 등으로 데이터 파싱을 해야하는데 굉장히 귀찮고 커맨드가 길어지기 쉽다. jq는 json data에 대해 lightweight, flexible한 command를 제공한다. 실제로 pipe를 같이 쓰면 이렇게 훌륭한게 없다. 단점은 기본 command도 아니고, json을 파싱해서 그런지, 대용량 파일을 파싱하면 아무래도 느려지기 쉽다. 그치만 이 느려진다는건 비교 대상이 cut 이런 녀석들이지 python으로 json parsing 하는 거보단 훨씬 빠르다. ",
    "url": "/docs/dev-tools/linux-commands/jq#%EC%82%AC%EC%9A%A9%EC%84%B1",
    
    "relUrl": "/docs/dev-tools/linux-commands/jq#사용성"
  },"250": {
    "doc": "jq로 가장 빠르게 터미널에서 json 파싱하기",
    "title": "사용법",
    "content": "jq는 사용법이 많다. 다 배우면 엄청 많고 복잡할 것 같은데, 자주 쓰는 것만 예시와 함께 정리한다. ",
    "url": "/docs/dev-tools/linux-commands/jq#%EC%82%AC%EC%9A%A9%EB%B2%95",
    
    "relUrl": "/docs/dev-tools/linux-commands/jq#사용법"
  },"251": {
    "doc": "jq로 가장 빠르게 터미널에서 json 파싱하기",
    "title": "예시",
    "content": "cat info . {“date”: “2021-08-11T15:12:18.195Z”, “site”: “meansoup.github.io”, “owner”: “meansoup”, “detail”: {“type”: “markdown”, “length”:623}} . jq .date info . “2021-08-11T15:12:18.195Z” . json data의 key를 이용해서 value를 쉽게 가져올 수 있다. jq .detail.length info . 623 . depth가 있어도 쉽게 가져온다. jq . info . { \"date\": \"2021-08-11T15:12:18.195Z\", \"site\": \"meansoup.github.io\", \"owner\": \"meansoup\", \"detail\": { \"type\": \"markdown\", \"length\": 623 } } . beautify 처럼 사용할 수도 있다. 한 라인으로 된 json을 라인을 분리해서 beautiful하게 꾸며준 것. jq '{site: .site, detailType: .detail.type}' info . { \"site\": \"meansoup.github.io\", \"detailType\": \"markdown\" } . 이렇게 새로운 json 형식을 만들어 주거나 필요한 값만 꺼내올 수도 있다. jq -c '{site: .site, detailType: .detail.type}' info . {\"site\": \"meansoup.github.io\", \"detailType\": \"markdown\"} . 위와 동일한 command에서 -c 옵션을 주면 단일 라인으로 출력을 해준다. 실제 사용할 땐 이렇게 단일 라인으로 하는 경우가 많다. (pipeline에 여러 json을 태우고 다시 한 줄로 뽑아내도록) . 몇 가지 써본건 더 있지만 최근엔 익숙해진 이후에 이 정도만 사용하는 것 같다. json이 표준처럼 사용되고 있는 요즘엔 jq는 기본 command 만큼이나 필수적인 것 같다. ",
    "url": "/docs/dev-tools/linux-commands/jq#%EC%98%88%EC%8B%9C",
    
    "relUrl": "/docs/dev-tools/linux-commands/jq#예시"
  },"252": {
    "doc": "jq로 가장 빠르게 터미널에서 json 파싱하기",
    "title": "jq로 가장 빠르게 터미널에서 json 파싱하기",
    "content": "DDD tactical components . Terminal Shortcut tmux cut jq screen split . jq는 linux 기본 command가 아니지만 내가 정말 편하게 사용하는 command 중 하나다. 여러 서비스를 하면서 인스턴스마다 jq가 깔려있지 않은 서비스가 간혹있는데, 그럼 정말 굉장한 불편함을 느낀다. jq는 그렇게 편하다. ",
    "url": "/docs/dev-tools/linux-commands/jq",
    
    "relUrl": "/docs/dev-tools/linux-commands/jq"
  },"253": {
    "doc": "DNS는 무엇이고 어떻게 동작하는가?",
    "title": "DNS의 목적",
    "content": "DNS 서버는 ip 주소를 기억하기 어려우니까. domain이나 hostname을 기억하고 사용하기 위해 사용된다. ",
    "url": "/docs/internet/dns#dns%EC%9D%98-%EB%AA%A9%EC%A0%81",
    
    "relUrl": "/docs/internet/dns#dns의-목적"
  },"254": {
    "doc": "DNS는 무엇이고 어떻게 동작하는가?",
    "title": "DNS flow",
    "content": ". ",
    "url": "/docs/internet/dns#dns-flow",
    
    "relUrl": "/docs/internet/dns#dns-flow"
  },"255": {
    "doc": "DNS는 무엇이고 어떻게 동작하는가?",
    "title": "DNS 서버들",
    "content": "Recursive Resolver: 브라우저나 앱을 통해 query를 받는 서버. Authoritative nameserver에 도달할 때까지 request들을 만들어서 수행한다. Root nameserver: DNS root nameserver는 전 세계에 13개만 존재한다. 그렇지만 각 서버가 대규모 클러스터로 구성되어 안정적이게 서비스한다. TLD nameserver: top-level-domain server로 com, net 과 같은 hostname의 마지막 부분을 호스팅한다. Authoritative nameserver: final nameserver로서 요청한 hostname에 대해 ip주소를 가지고 있다면 반환한다. 실제로 DNS resource record를 가지고 있는 서버. ",
    "url": "/docs/internet/dns#dns-%EC%84%9C%EB%B2%84%EB%93%A4",
    
    "relUrl": "/docs/internet/dns#dns-서버들"
  },"256": {
    "doc": "DNS는 무엇이고 어떻게 동작하는가?",
    "title": "캐싱 (caching)",
    "content": "캐싱의 목적은 분명히 시간과 비용을 줄이기 위함. Browser DNS caching: 브라우저에서 정해진 시간동안 DNS record를 캐싱하도록 설계되어있다. OS level DNS caching: OS 내부에 query를 핸들링하는 stub resolver (혹은 DNS client 라고 불리는)가 cache에 record가 있는지 확인한다. 또, recursive resolver도 caching 해놓은 record가 있는지 확인한다. | Authoritative nameserver의 주소를 갖는 NS record가 있으면 바로 저기로 간다. | 없으면 TLD의 cache가 있으면 TLD로 간다. | . ",
    "url": "/docs/internet/dns#%EC%BA%90%EC%8B%B1-caching",
    
    "relUrl": "/docs/internet/dns#캐싱-caching"
  },"257": {
    "doc": "DNS는 무엇이고 어떻게 동작하는가?",
    "title": "통신 (communication)",
    "content": "DNS는 기본적으로 UDP를 사용한다. TCP handshake 등의 오버헤드를 줄이기 위해서 UDP로 고안되었다. 그래서 512 bytes를 약속처럼 사용하고 있는데, 이는 ipv4 표준에서 576 bytes 이상이면 여러 개의 ip packet으로 fragmented 되는 것과 관련이 있다. | 단일 packet일 경우 하나만 유실되면 전체 유실 등으로 핸들링이 편하기 때문. | . 최근에는 512 bytes를 넘어가기도 하는데 그럴땐 tcp를 사용한다. ",
    "url": "/docs/internet/dns#%ED%86%B5%EC%8B%A0-communication",
    
    "relUrl": "/docs/internet/dns#통신-communication"
  },"258": {
    "doc": "DNS는 무엇이고 어떻게 동작하는가?",
    "title": "reference",
    "content": "https://www.cloudflare.com/learning/dns/what-is-dns https://www.lifewire.com/what-is-a-dns-server-2625854 https://www.lifewire.com/dns-root-name-servers-3971336 https://serverfault.com/questions/587625/why-dns-through-udp-has-a-512-bytes-limit . ",
    "url": "/docs/internet/dns#reference",
    
    "relUrl": "/docs/internet/dns#reference"
  },"259": {
    "doc": "DNS는 무엇이고 어떻게 동작하는가?",
    "title": "DNS는 무엇이고 어떻게 동작하는가?",
    "content": " ",
    "url": "/docs/internet/dns",
    
    "relUrl": "/docs/internet/dns"
  },"260": {
    "doc": "easyRandom - Java에서 테스트 객체 만들기",
    "title": "장점",
    "content": "ObjectMother 패턴을 설명하는 페이지에도 적혀 있지만 이 간단한 패턴으로 얻은 명확한 장점들이 있다. | 이곳저곳 산개되었던 객체 생성 로직을 하나로 묶을 수 있었다. | test Class/Method마다 객체를 만들던 로직이 있었는데, ItemMother와 같이 mother 패턴을 적용하면서 이런 로직이 사라졌다. | Item의 테스트 객체를 만들기 전에 ItemMother가 있는지를 보고 없으면 만들고 있으면 사용하는 방식. | . | 위와 같은 이유로 테스트 객체 생성에 드는 시간과 비용이 줄어들었고, 이는 테스트를 짜는 시간에 영향을 미쳤다. | 위와 같은 장점으로 완성도 높은 테스트 객체 생성 로직을 갖게 되었다. | 원래는 귀찮아서 대충 생성하던 것도 같은 생성 코드를 사용하기 때문에 점진적으로 완성도가 올라간다. | . | 객체 생성 로직이 숨겨지면서 가독성이 올라갔다. | . 우리 코드가 어떻게 되었고, 어떻게 바뀌었는지를 예를 들어서 설명해보겠다. 예를 들면서 EasyRandom의 사용 방법도 설명한다. ",
    "url": "/docs/java/library/easyrandom#%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/java/library/easyrandom#장점"
  },"261": {
    "doc": "easyRandom - Java에서 테스트 객체 만들기",
    "title": "java에서 테스트 객체 만들기",
    "content": "우리가 테스트에서 만들었던 item 생성 코드들을 보자. 코드 sample 1 . ItemDTO ItemDTO = new ItemDTO(); ItemDTO.setCreatetime(0L); ItemDTO.setItemId(\"testItemId\"); ItemDTO.setOwner(\"testOwner\"); . | 테스트에서 이런 코드 반복이 많다. 언제까지 이런 코드를 반복할 것인가? | 테스트의 value들이 random data가 아니다. 테스트가 특정 케이스만 커버할 수 있을지도 모른다. 모든 테스트가 random data로 이뤄져야 하는 건 아니지만 필요한 상황에 모르고 놓치는 경우보다 귀찮아서 안하는 경우일 때가 많다. | . 코드 sample 2 . 오래된 프로젝트의 테스트 코드에서 심심찮게 보이는 반복 호출을 위한 테스트 함수. public static ItemDTO createItemDTO() { ItemDTO dto = new ItemDTO(); dto.setItemId(\"testItemId\"); dto.setCreatetime(0L); dto.setOwner(\"testOwner\"); return dto; } . | 이전 코드보다 조금 낫다고 할 수 있지만 이런 코드틑 프로젝트 테스트의 곳곳에 있다. | 누가 만들었는지, 있는지 없는지 조차 알지 못한다. 심한 경우는 test class 마다 존재한다. | 여전히 random value는 아니다. | . 코드 sample 3 . private static ItemDTO initTestValue() { ItemDTO itemDTO = new ItemDTO(); itemDTO.setCtime(RandomUtils.nextLong(100L, System.currentTimeMillis())); itemDTO.setItemId(RandomStringUtils.randomAlphanumeric(10)); itemDTO.setOwner(RandomStringUtils.randomAlphanumeric(10)); return itemDTO; } . | 이 정도면 일종의 objectMother라고 할 수 있을 것 같다. | 그렇지만 언제까지 random data를 한땀 한땀 넣어줄건지. | 생성로직이 산개되어 있고 네이밍이 명확하지 않다는 문제는 여전하다. 즉 다른 사람이 동일한 코드를 다시 만들 것이다. | . Object Mother . ObjectMother는 테스트 객체의 생성에 대한 패턴을 제공하며 이는 눈에 띄는 확연한 약속으로 테스트 데이터 생성 로직의 산개를 막는다. 테스트 코드 중복과 관리에 대한 문제를 ObjectMother 패턴으로 풀어낼 수 있다. ",
    "url": "/docs/java/library/easyrandom#java%EC%97%90%EC%84%9C-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EA%B0%9D%EC%B2%B4-%EB%A7%8C%EB%93%A4%EA%B8%B0",
    
    "relUrl": "/docs/java/library/easyrandom#java에서-테스트-객체-만들기"
  },"262": {
    "doc": "easyRandom - Java에서 테스트 객체 만들기",
    "title": "EasyRandom",
    "content": "ObjectMother를 효율적으로 사용하기 위한 테스트 데이터를 생성하는 프로젝트들이 찾아보았다. Naver에서 관리하고 있는 FixtureMonkey 도 있었고, 약간은 올드한 네이밍의 PODAM, 조금 궤가 다르지만 param test에 random하게 값을 채워주는 AutoParams 들을 사용해봤다. 가장 쓰기 편하고 효율적인 프로젝트는 EasyRandom이었다. EasyRandom은 github star 수도 가장 많았고, 이름 값 하는 프로젝트다. EasyRandom은 굉장히 강력한데 다음과 같은 특징들이 있다. | setter가 없어도 된다. | contructor가 없어도 된다. (private contructor only인 경우) | 자동으로 sub class들의 값도 random하게 채워준다. | test object list 생성이 간단하다. | . setter와 constructor가 없어도 된다는 점이 굉장히 좋았다. | 가독성++ | . 특정 entity의 경우 private consturctor만 갖고 factory에서 생성을 하는데, factory는 또 dto를 받는 번거로운 구조를 갖는 경우가 있었다. 이런 경우 항상 테스트에서 dto 생성 후 entity를 만드는 test 이해도를 떨어뜨리는 작업을 했어야 했다. EasyRandom은 이런 단점들을 보완해준다. ",
    "url": "/docs/java/library/easyrandom#easyrandom",
    
    "relUrl": "/docs/java/library/easyrandom#easyrandom"
  },"263": {
    "doc": "easyRandom - Java에서 테스트 객체 만들기",
    "title": "사용법",
    "content": "우선 dependency를 추가한다. &lt;dependency&gt; &lt;groupId&gt;org.jeasy&lt;/groupId&gt; &lt;artifactId&gt;easy-random-core&lt;/artifactId&gt; &lt;version&gt;4.0.0&lt;/version&gt; &lt;/dependency&gt; . 기본 사용 . EasyRandom generator = new EasyRandom(); Person person = generator.nextObject(Person.class); List&lt;Person&gt; persons = generator.objects(Person.class, 5).collect(Collectors.toList()); . 간단하게 사용할 수 있고 List나 다른 Collection을 만들기도 쉽다. parameter와 함께 사용 . EasyRandomParameters parameters = new EasyRandomParameters(); parameters.stringLengthRange(3, 3); parameters.collectionSizeRange(5, 5); EasyRandom generator = new EasyRandom(parameters); Person person = generator.nextObject(Person.class); . 아주 간단하게 특정 param이나 value에 조건을 더할 수도 있다. 적용된 코드 예시 . public class ItemDTOMother { private static ItemDTO generate() { EasyRandom easyRandom = new EasyRandom(); return easyRandom.nextObject(ItemDTO.class); } private static ItemDTO generateDeleted() { ItemDTO item = generate(); item.setStatus(\"DELETED\"); return item; } } . 이렇게 되면 모두 동일한 생성 로직(XXMother)를 보게 되고 완성도 높고 재사용률 높은 테스트 코드가 완성된다. ",
    "url": "/docs/java/library/easyrandom#%EC%82%AC%EC%9A%A9%EB%B2%95",
    
    "relUrl": "/docs/java/library/easyrandom#사용법"
  },"264": {
    "doc": "easyRandom - Java에서 테스트 객체 만들기",
    "title": "reference",
    "content": ". | Quick Guide to EasyRandom, https://www.baeldung.com/java-easy-random | EasyRandom github, https://github.com/j-easy/easy-random | . ",
    "url": "/docs/java/library/easyrandom#reference",
    
    "relUrl": "/docs/java/library/easyrandom#reference"
  },"265": {
    "doc": "easyRandom - Java에서 테스트 객체 만들기",
    "title": "easyRandom - Java에서 테스트 객체 만들기",
    "content": "테스트 객체를 관리하는 패턴 중 ObjectMother 패턴이 있다. java에서는 이 패턴을 구현하기 위한 방식으로 EasyRandom을 사용하면 효율적이다. ObjectMother와 EasyRandom을 우리 팀 서비스 코드에 적용해 보았는데 적용 후 테스트 작성에 대한 효율이 눈에 띄기 좋아졌다. 지금은 팀 내에서 ObjectMother 패턴이 자연스럽게 사용된다. ",
    "url": "/docs/java/library/easyrandom",
    
    "relUrl": "/docs/java/library/easyrandom"
  },"266": {
    "doc": "Object Mother, 테스트에 가장 중요한 패턴",
    "title": "Object Mother 란?",
    "content": "테스트에 사용되는 여러 example objects를 생성하는데 도움을 주는 클래스이다. 테스트를 작성할 때 많은 예제 데이터가 필요하고, 이런 data set을 test fixture라고 부른다. 여러 테스트 클래스에서 유사한 data가 필요한 경우가 많다. 테스트 시점에서 standard fixtures를 만들 수 있는 factory object를 만드는 것이 합리적이다. Object Mother는 이런 factory를 말한다. 이렇게 만들어진 object는 일부 test case에서는 적절하지 않을 수 있다. 그렇지만 Folwer는 이런 경우에서 조차도 새로운 object 생성보다 Object Mother로 생성한 객체를 수정하는 방향이 더 이해하기 쉽다고 말한다. | 참고로 Object Mother라는 단어는 Thoughtworks 프로젝트에서 처음 쓰였다. | . ",
    "url": "/docs/pattern/object-mother#object-mother-%EB%9E%80",
    
    "relUrl": "/docs/pattern/object-mother#object-mother-란"
  },"267": {
    "doc": "Object Mother, 테스트에 가장 중요한 패턴",
    "title": "Object Mother 장 단점",
    "content": "장 단점은 오역의 여지가 없도록 ThoughWorks 논문1의 내용을 그대로 발췌했다. 장점 . | Simplified and standardized test object creation | Ease of maintenance, because test object creation is entrusted to a specific class or group of classes. | test object clean-up. | the pattern recovers even greater amounts of time that would otherwise be spent writing and maintaining unit tests. | by removing a significant hurdle from the test-writing process, ObjectMother encourages developers to write more tests. | . 단점 . | added time spent building the pattern | . 주의 사항 . ObjectMother 패턴의 힘은 강력하다. 프로젝트에 도입한 뒤 팀원들은 자발적으로 ObjectMother에 테스트 객체를 추가하기 시작했다. 그러나 ObjectMother를 온전히 이해하지 못하고 작성하는 Mother 패턴들은 ObjectMother의 본질을 흐리게 한다. ObjectMother는 standard fixtures를 만드는 것이다. 개념을 온전히 이해하지 못하고 사용하는 경우엔 standard fixture를 만드는 것이 아니라 모든 fixture를 Object Mother에 추가하는 경우가 많다. standard fixture가 아니라 아무 fixture나 추가된 ObjectMother는 사용되지 않는 것보다는 낫지만 Mother 패턴의 가독성과 신뢰성, 확장성을 많이 떨어뜨린다. Java에서 objectMother 적용하기 . ObjectMother를 공부하면서 Java에서 ObjectMother 패턴 적용하기 위해 도움이 되는 라이브러리들을 찾아보았고, 실제 우리 팀 코드에 적용을 해 보았다. 굉장히 간단한데 실제 패턴을 적용해서 얻는 이점이 많았다. java에서 적용하며 얻은 이점들은 위 페이지에 정리한다. | Thoughtworks 논문 ObjectMother, Easing Test Object Creation in XP 참고 &#8617; . | . ",
    "url": "/docs/pattern/object-mother#object-mother-%EC%9E%A5-%EB%8B%A8%EC%A0%90",
    
    "relUrl": "/docs/pattern/object-mother#object-mother-장-단점"
  },"268": {
    "doc": "Object Mother, 테스트에 가장 중요한 패턴",
    "title": "Object Mother, 테스트에 가장 중요한 패턴",
    "content": "이번엔 ObjectMother라는 패턴에 대해서 정리한다. ObjectMother는 우리가 코드를 개발하면서 한 번쯤은 생각해봤고, 또 편의를 위해 조금씩은 작성해봤을 내용의 패턴이다. 사실 패턴이란게 다 그렇지 않나 싶다. 간단히 표현하자면 test object를 만들어주는 class라고 할 수 있을 것이다. 패턴을 잘 정의하는 Martin Fowler의 글을 참고해서 정리해본다. ",
    "url": "/docs/pattern/object-mother",
    
    "relUrl": "/docs/pattern/object-mother"
  },"269": {
    "doc": "서버 개발자, 2021 회고",
    "title": "배치 작업",
    "content": "서버 개발자에게 batch 작업이란 필수적인 것 같다. 올해는 우리 서비스 운영의 변경 사항들도 많았고, 효율적인 관리를 위해 정말 많은 batch를 설계하고 개발했다. 어떤 특별한 기술을 사용한 것보다 설계를 개선해 나가는 점이 올해 많이 배운게 아닌가 싶다. batch를 계속하면서 내가 배운점들은 이렇다. 1. 배포는 가능하면 쪼개서 나가자 . 우리 회사는 배포가 살짝 불편한 편이다. 모듈마다 다르지만 검증/결재를 기다리는 일들로 배포에는 항상 피로감이 쌓이고 재미가 없다. 이런 이유로 여러 작업의 배포가 필요할 때 한 번에 나갔다가 어디서 이슈가 생겼는지 확인하기가 어려웠다. (근데 이건 배포 방식을 바꿔야 해결이 될 것 같다.) . 2. migration batch는 rollback이 가능한 구조인지 파악하자 . 많은 batch와 migration을 수행하면서 간단한 migration에는 자신감이 충만해질 때가 있다. 그래서 rollback에 대한 생각을 접어둘 때가 있는데, 배포 이후에 rollback이 불가능한 경우를 생각하면 아찔하다. migration은 사용자의 data를 손대는 batch니까 작업 수행 전후로 확인해야할 내용들을 명확히 정리하고 수행해야 한다. 3. 확장성을 보장하자 . 우리가 관리하는 배치들은 대부분 정해진 기간이 있다. 기간을 맞추기 위해, 혹은 낭비되는 cpu를 채우거나 인스턴스 숫자를 조절하기 위해서 보통 batch의 worker(instance 혹은 thread)가 확장 가능한 구조가 굉장히 중요하다. instance를 더 붙이고 싶은데 불가능하거나 그 때마다 재시작해야해서는 안되니까. | 기간을 맞추기 위해 TPS(Transaction Per Second)나 batch 예상 시간을 조회할 수 있는 지표를 남기면 유용하다. | . 4. 위와 유사하게 중단/재시작과 멱등성을 고려하자 . 배치는 여러 이유로 중단/재시작이 필요한 경우가 많다. 인스턴스가 내려갔다거나, memory 부족 등의 이슈로 instance type을 변경한다거나, db throttling 이슈로 input data를 shuffling 해서 재수행하기도 하고 등등.. 이럴 때마다 수행된 user(혹은 특정 item 등의 batch 단위)가 batch에 다시 들어가더라도 문제가 없도록 멱등성이 고려되어야 한다. 이걸 고려하지 않으면 배치 돌릴 때마다 피곤하다. | 여기서 말하는 멱등성은 다시 돌아도 문제가 없는 것도 있지만, 돌아간 user에 대해서 다시 돌리지 않을 수 있는 일종의 flag가 있어야 batch에도 문제가 없고 재수행했을 때 수행 시간에도 문제가 없다. | . 5. data flow를 확인하자 . 우리는 지금 global 5개 region에서 서비스를 하고 있다. file이 오가는 batch의 경우 binary data가 region을 넘어가는 경우가 발생하기도 하는데, 최대한 효율적으로 binary flow를 잡아갈 수 있도록 설계가 필요하다. 한 번은 설계를 잘 해놓고, binary flow를 놓쳐서 성능이 현저하게 떨어져서 다시 개발한 적이 있었다. 6. life cycle을 같이 도는 batch에서 소스 코드를 분리하지 말자 . 중복을 최소화하는 것은 개발자의 숙명이기도 하다. one time job으로 설계된 batch가 아니라 life cycle을 같이하는 batch들에서 소스 코드를 따로 쓰는 경우 문제가 생기기 정말 쉽다. 올 해 우리는 WAS에서 새로운 기능을 내보내고, batch에서는 해당 코드가 추가되지 않아 사용자 데이터를 날려먹을 뻔한 적이 있었다. ",
    "url": "/docs/retrospect/2021#%EB%B0%B0%EC%B9%98-%EC%9E%91%EC%97%85",
    
    "relUrl": "/docs/retrospect/2021#배치-작업"
  },"270": {
    "doc": "서버 개발자, 2021 회고",
    "title": "설계",
    "content": "위에서도 말했듯 올해는 설계를 하며 배운점이 많다. 설계에서는 어떤 어떤 점들을 배웠다보다는 DDD 스터디와 적용을 함께 하면서 설계하는 능력이 성장하는 것을 느꼈다. 1. DDD는 배우면 배울수록 쉽지 않다. 이전에 DDD에 따라 설계했다고 생각한 모듈들이 조금 더 공부하고 보니 불편한 것들이 많았다. 하면서 느는 것 같긴한데, 아직도 명확하지 않는게 느껴진다. 2. 통계도 설계에 함께 포함되어야 한다. 요구사항을 뽑아서 설계를 진행할 때, 통계가 요구사항에 들어가지 않았다. 서비스가 진행되고 통계를 뽑으려면 이미 늦고, 불편한 작업들(우리는 로그를 까보거나 batch를 통해) 필요할 때마다 통계를 요청하게되어 굉장히 불편했다. | 서비스하는 입장이라면 통계를 빠르고 쉽게 전달해줄 수 있는 구조가 되야하는 것 같다. | . 3. first class object를 쓰자. 우리가 가진 모듈 중에 개발된지 오래되고 우리팀 멤버들이 개발에 참여하지 않은 모듈이 있다. 이게 굉장히 가독성이 떨어지는데 hashmap&lt;stirng, object&gt; 이렇게 hashmap을 굉장히 많이 사용한다. 끔찍한건 저기 object에 hashmap이 다시 들어가기도 한다는 것. 정말 최악이다. 그리고 id를 string이 아닌 ID라는 wrapper class를 만들어서 써봤는데 명확하고 실수가 줄어들어 좋았다. ",
    "url": "/docs/retrospect/2021#%EC%84%A4%EA%B3%84",
    
    "relUrl": "/docs/retrospect/2021#설계"
  },"271": {
    "doc": "서버 개발자, 2021 회고",
    "title": "db",
    "content": "올해는 유독 database 관련 작업들이 많았다. 1. db 통합 . 한 모듈은 특정 entity를 두 db에 저장하고 있었다. 여러 database를 사용할 수 있고 db를 옮기거나 추가하기 좋은 확장성을 갖는 interface 구조를 설계하는게 굉장히 중요하다는 것에는 동의하나, 의미 없이 db를 두 벌 사용하는 경우는 피하는게 좋다. 예를 들면, blog에 page db는 cassandra를 쓰고 comment는 dynamodb를 쓴다면 뭐 그러려니 하겠지만, 우리는 page의 db를 cassandra와 dynamodb를 같이 쓰고 있었다. (히스토리가 있는 윗분들의 예전 결정) 두 db를 쓰는건 interface가 잘 나뉘어 있어도 개발(특히 db와 연관된 batch)에 굉장한 부담이 되었다. db 통합은 간단하진 않지만 이걸로 오는 개발/코드리뷰/테스트작성의 효율은 굉장히 컸다. 2. dynamo db table 통합 . nosql인 dynamodb를 mysql처럼 테이블을 종류별로 나눠 사용하던 것을 통합했다. 예를들면 page main table과 page meta table이 있던걸 합치는 작업인데, 이 또한 개발/코드리뷰/테스트작성에 굉장한 효율을 가져왔다. 특히 table 통합 이후에 elpased time이 절반으로 줄었다. 서비스 응답 시간에서 가장 중요한건 DB라는 말이 생각난다. 3. dynamodb의 blob limit 문제 . dynamodb에 대해 좀 더 이해하는 시간이 되었다. LSI를 만들 때는 조심해야 한다. 이 내용은 지난번에 정리한 DynamoSizeLimitException를 참고하면 좋겠다. 4. dynamo db query . 우리 팀에 db query에 탁월한 능력을 가진 분이 있다. nosql을 major로 써서 query에 약했는데, 통계 작업을 하면서 query의 힘을 다시 깨닫는다. 공부가 필요할 것 같다. 2021년에는 2020년보다는 재미있는 작업들을 많이 해보지 못한 것 같아서 아쉽다. 일을 많이 한 것 같은데, 아직도 짐처럼 남아있는 작업들이 있기도 하다. 22년에도 설계를 더 잘하고, 기술적으로는 새로운 기술들도 더 배우고 익숙해지는 한 해가 되었으면 좋겠다. ",
    "url": "/docs/retrospect/2021#db",
    
    "relUrl": "/docs/retrospect/2021#db"
  },"272": {
    "doc": "서버 개발자, 2021 회고",
    "title": "서버 개발자, 2021 회고",
    "content": "21년도 정신 없이 시간이 지났다. 올 해 기억에 남는 것들을 세 가지로 추려서 정리해보았다. ",
    "url": "/docs/retrospect/2021",
    
    "relUrl": "/docs/retrospect/2021"
  },"273": {
    "doc": "[jekyll] Dependency Error, Jekyll::Errors::MissingDependencyException",
    "title": "빌드 에러 메세지",
    "content": "Dependency Error: Yikes! It looks like you don't have jekyll-sitemap or one of its dependencies installed. In order to use Jekyll as currently configured, you'll need to install this gem. If you've run Jekyll with `bundle exec`, ensure that you have included the jekyll-sitemap gem in your Gemfile as well. The full error message from Ruby is: 'cannot load such file -- jekyll-sitemap' If you run into trouble, you can find helpful resources at https://jekyllrb.com/help/! ------------------------------------------------ Jekyll 4.2.1 Please append `--trace` to the `serve` command for any additional information or backtrace. ------------------------------------------------ Traceback (most recent call last): 21: from C:/Ruby27-x64/bin/jekyll:23:in `&lt;main&gt;' 20: from C:/Ruby27-x64/bin/jekyll:23:in `load' 19: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/exe/jekyll:15:in `&lt;top (required)&gt;' 18: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/mercenary-0.4.0/lib/mercenary.rb:21:in `program' 17: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/mercenary-0.4.0/lib/mercenary/program.rb:44:in `go' 16: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `execute' 15: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `each' 14: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `block in execute' 13: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/commands/serve.rb:86:in `block (2 levels) in init_with_program' 12: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/command.rb:91:in `process_with_graceful_fail' 11: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/command.rb:91:in `each' 10: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/command.rb:91:in `block in process_with_graceful_fail' 9: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/commands/build.rb:30:in `process' 8: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/commands/build.rb:30:in `new' 7: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/site.rb:36:in `initialize' 6: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/site.rb:131:in `setup' 5: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/plugin_manager.rb:22:in `conscientious_require' 4: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/plugin_manager.rb:30:in `require_gems' 3: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/external.rb:57:in `require_with_graceful_fail' 2: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/external.rb:57:in `each' 1: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/external.rb:60:in `block in require_with_graceful_fail' C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/external.rb:60:in `require': cannot load such file -- jekyll-sitemap (LoadError) 21: from C:/Ruby27-x64/bin/jekyll:23:in `&lt;main&gt;' 20: from C:/Ruby27-x64/bin/jekyll:23:in `load' 19: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/exe/jekyll:15:in `&lt;top (required)&gt;' 18: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/mercenary-0.4.0/lib/mercenary.rb:21:in `program' 17: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/mercenary-0.4.0/lib/mercenary/program.rb:44:in `go' 16: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `execute' 15: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `each' 14: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/mercenary-0.4.0/lib/mercenary/command.rb:221:in `block in execute' 13: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/commands/serve.rb:86:in `block (2 levels) in init_with_program' 12: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/command.rb:91:in `process_with_graceful_fail' 11: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/command.rb:91:in `each' 10: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/command.rb:91:in `block in process_with_graceful_fail' 9: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/commands/build.rb:30:in `process' 8: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/commands/build.rb:30:in `new' 7: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/site.rb:36:in `initialize' 6: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/site.rb:131:in `setup' 5: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/plugin_manager.rb:22:in `conscientious_require' 4: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/plugin_manager.rb:30:in `require_gems' 3: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/external.rb:57:in `require_with_graceful_fail' 2: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/external.rb:57:in `each' 1: from C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/external.rb:58:in `block in require_with_graceful_fail' C:/Ruby27-x64/lib/ruby/gems/2.7.0/gems/jekyll-4.2.1/lib/jekyll/external.rb:73:in `rescue in block in require_with_graceful_fail': jekyll-sitemap (Jekyll::Errors::MissingDependencyException) . ",
    "url": "/docs/error-bug/kotlin/jekyll-cannot-load-such-file#%EB%B9%8C%EB%93%9C-%EC%97%90%EB%9F%AC-%EB%A9%94%EC%84%B8%EC%A7%80",
    
    "relUrl": "/docs/error-bug/kotlin/jekyll-cannot-load-such-file#빌드-에러-메세지"
  },"274": {
    "doc": "[jekyll] Dependency Error, Jekyll::Errors::MissingDependencyException",
    "title": "원인",
    "content": "해결이 좀 어처구니가 없다. sitemap dependency는 이미 추가해놓았었는데 새로운 dependency 추가 후 local build로 테스트하려다가 실패했다. sitemap은 이미 gh-pages에서 정상동작 하고 있었고.. 원인을 보자면, . | sitemap은 gemfile에 add 되어있지 않았는데 gh-pages에서 동작함. (gh-pages에서 기본적으로 가지고 있나보다) | 새로운 dependency를 gemfile과 _config.yml에 추가 후 빌드. | sitemap이 gemfile에 없어서 애러 발생. | . ",
    "url": "/docs/error-bug/kotlin/jekyll-cannot-load-such-file#%EC%9B%90%EC%9D%B8",
    
    "relUrl": "/docs/error-bug/kotlin/jekyll-cannot-load-such-file#원인"
  },"275": {
    "doc": "[jekyll] Dependency Error, Jekyll::Errors::MissingDependencyException",
    "title": "해결",
    "content": ". | GemFile에 아래 코드 추가 gem 'jekyll-sitemap' . | bundle update | jekyll serve | 문제 해결 | . ",
    "url": "/docs/error-bug/kotlin/jekyll-cannot-load-such-file#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/error-bug/kotlin/jekyll-cannot-load-such-file#해결"
  },"276": {
    "doc": "[jekyll] Dependency Error, Jekyll::Errors::MissingDependencyException",
    "title": "[jekyll] Dependency Error, Jekyll::Errors::MissingDependencyException",
    "content": "Dependency 추가 후 jekyll local build 중 에러가 발생했다. ",
    "url": "/docs/error-bug/kotlin/jekyll-cannot-load-such-file",
    
    "relUrl": "/docs/error-bug/kotlin/jekyll-cannot-load-such-file"
  },"277": {
    "doc": "query를 쉽게하기, ORMs",
    "title": "ORM(Object Relational Mapping) 이란?",
    "content": "SQL Database를 사용하게 되면 아래와 같이 SQL query를 사용할 일들이 많아진다. SELECT * FROM users WHERE email = 'backencbrew@test.com'; . ORM은 이런 복잡하고 번거로운 query들을 Object-Oriented 개념을 사용해서 data를 query/manipulate하는 기술을 말한다. 즉, SQL이 아니라 우리가 사용하는 언어로 database를 사용하는 기술이다. 예를 들면 Java의 ORMs의 표준 스펙인 JPA가 있다. ORMs를 생각할 때 JPA를 떠올리면 ORMs가 더 명확하게 그려진다. ",
    "url": "/docs/db/concept/orms#ormobject-relational-mapping-%EC%9D%B4%EB%9E%80",
    
    "relUrl": "/docs/db/concept/orms#ormobject-relational-mapping-이란"
  },"278": {
    "doc": "query를 쉽게하기, ORMs",
    "title": "flow",
    "content": ". ORM은 query를 작성해주는 소프트웨어라고 했다. 위와 같이 코드로 작성된 object들이 ORM을 통해 database에 query로 변환된다. 예시 . SELECT * FROM users WHERE email = 'backencbrew@test.com'; . 위의 query가 아래 java 코드처럼 접근이 가능하다. 물론 간단한 setup이 필요하다. User findByEmail(String email); . ",
    "url": "/docs/db/concept/orms#flow",
    
    "relUrl": "/docs/db/concept/orms#flow"
  },"279": {
    "doc": "query를 쉽게하기, ORMs",
    "title": "ORM 장점",
    "content": "원래 사용하던 언어를 사용할 수 있다. | SQL은 powerful 하지만 훌륭하게 활용하지 못하는 경우가 많다. | 그치만 원래 사용하던 언어들(Java ..)은 SQL보다 더 훌륭하게 활용할 수 있다. | 함수를 호출하는 것 만큼 쉽다. (원래 db는 사용자 친화적이진 않으니까) | 그래서 결국 가독성이 굉장히 올라간다. | . 시간을 절약할 수 있다. | ORM에서 제공하는 많은 feature들(transaction, connection pooling, streams)을 out of the box로 사용할 수 있다. | 많은 기본적인 query들이 직접 query를 작성하는 것보다 효율적으로 동작한다. | DRY로 데이터를 한 곳에서만 작성해서 유지 관리와 재사용이 쉽다. | 번거로운 SQL을 직접 작성하지 않아도 된다. | . 유연하다. | database를 추상화할 수 있어 종속성이 줄어들고 database의 변경이 비교적 편하다. | 코드를 작성하는 방식과 자연스럽게 연결된다. | . ",
    "url": "/docs/db/concept/orms#orm-%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/db/concept/orms#orm-장점"
  },"280": {
    "doc": "query를 쉽게하기, ORMs",
    "title": "ORM 단점",
    "content": ". | SQL을 훌륭하게 잘 쓴다면 더 좋은 성능의 query를 짤 수 있는 경우가 있다. | ORM에서 수행할 수 없는 query도 존재한다. | ORM을 배우기 위한 overhead가 있다. | initial confiugration을 위한 작업들이 필요하다. | ORM이 많은 것을 해주기 때문에 무슨 작업들이 ORM과 DB에서 벌어지는지에 대한 이해도가 떨어질 수 있다. | . ",
    "url": "/docs/db/concept/orms#orm-%EB%8B%A8%EC%A0%90",
    
    "relUrl": "/docs/db/concept/orms#orm-단점"
  },"281": {
    "doc": "query를 쉽게하기, ORMs",
    "title": "정리",
    "content": "JPA를 자주 사용하는 나한테 ORM의 개념은 굉장히 친숙하고 당연하다. ORM을 쓰면서도 일부 지원하지 않는 기능을 위한 native query를 작성하여 사용하고 있는데, 이런 방식이 가장 적절하지 않나 싶다. 결국 ORM은 굉장히 유용하고 꼭 쓰여야 한다고 본다. 위에서 말한 단점처럼 DB query에 대한 이해도가 많이 줄어드는건 문제이긴 하다. ",
    "url": "/docs/db/concept/orms#%EC%A0%95%EB%A6%AC",
    
    "relUrl": "/docs/db/concept/orms#정리"
  },"282": {
    "doc": "query를 쉽게하기, ORMs",
    "title": "reference",
    "content": ". | https://stackoverflow.com/questions/1279613/what-is-an-orm-how-does-it-work-and-how-should-i-use-one | https://blog.bitsrc.io/what-is-an-orm-and-why-you-should-use-it-b2b6f75f5e2a | https://openclassrooms.com/en/courses/5671811-implement-a-relational-database-with-asp-net-core/6588450-identify-object-relational-mapping-orm-tools-for-net | https://en.wikipedia.org/wiki/List_of_object%E2%80%93relational_mapping_software#Java | . ",
    "url": "/docs/db/concept/orms#reference",
    
    "relUrl": "/docs/db/concept/orms#reference"
  },"283": {
    "doc": "query를 쉽게하기, ORMs",
    "title": "query를 쉽게하기, ORMs",
    "content": " ",
    "url": "/docs/db/concept/orms",
    
    "relUrl": "/docs/db/concept/orms"
  },"284": {
    "doc": "multi terminal tmux 효율적으로 사용하기",
    "title": "tmux; terminal multiplexer",
    "content": "man page의 설명을 참고하면, man tmux . DESCRIPTION tmux is a terminal multiplexer: it enables a number of terminals to be created, accessed, and controlled from a single screen. tmux may be detached from a screen and continue running in the background, then later reattached. ",
    "url": "/docs/dev-tools/linux-commands/tmux#tmux-terminal-multiplexer",
    
    "relUrl": "/docs/dev-tools/linux-commands/tmux#tmux-terminal-multiplexer"
  },"285": {
    "doc": "multi terminal tmux 효율적으로 사용하기",
    "title": "장점",
    "content": ". | terminal windows가 여러 개가 되지 않도록 관리할 수 있다. | window 하나에 pane들을 여러 개 나누기가 쉽다. | 나누어진 pane들에 동시에 입력하기가 편하다. | shell program이기 때문에 remote server에서도 동작한다. 즉, terminal windows를 새로 따기 위해 다시 접속하지 않아도 된다. | terminal을 project 단위로 organize 할 수 있다. | session이 만료되지 않고 in-state 상태로 저장된다. | session을 공유할 수 있어서 다른 사람이 들어오면 typing 하는 것을 실시간으로 볼 수 있다. | script를 작성해두면 여러 pane이 설정된 tmux session을 바로 생성할 수 있다. | . ",
    "url": "/docs/dev-tools/linux-commands/tmux#%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/dev-tools/linux-commands/tmux#장점"
  },"286": {
    "doc": "multi terminal tmux 효율적으로 사용하기",
    "title": "개념",
    "content": ". Sessions . 완전히 분리된 tmux의 최상위 hierarchy. user는 여러 개의 session 을 만들고, attach, detach 할 수 있다. 프로젝트를 관리하는 단위로 session을 할당하는 편이다. Windows . 각 session은 여러 window를 가질 수 있다. 브라우저의 tab이랑 비슷하다. 프로젝트의 특정 task 들을 관리하는 단위로 쓰이는 편이다. Panes . 각 window는 여러 pane으로 화면이 나뉠 수 있다. 동시에 여러 pane을 보게되는 것이고, 현재 작업에 맞게 화면 배열을 할 수 있다. ",
    "url": "/docs/dev-tools/linux-commands/tmux#%EA%B0%9C%EB%85%90",
    
    "relUrl": "/docs/dev-tools/linux-commands/tmux#개념"
  },"287": {
    "doc": "multi terminal tmux 효율적으로 사용하기",
    "title": "자주 사용하는 명령어들",
    "content": "세션 명령어 . | 동작 | 명령어 | 설명 | . | 새로운 세션 생성 | tmux new -s | session을 생성하고 들어가기 | . | 세션 목록 | tmux ls |   | . | 세션 attach | tmux attach -t |   | . | 세션 detach | (ctrl + b) d | 세션을 종료하지 않고 나가기 | . | 세션 kill | tmux kill-session -t | 세션을 종료하기 | . 윈도우 명령어 . | 동작 | 명령어 | 설명 | . | 새로운 윈도우 생성 | (ctrl + b) + c | 윈도우를 새로 추가하기 | . | 윈도우 리스트 확인 | (ctrl + b) + w | 세션에서 생성된 윈도우를 리스트업 | . pane 명령어 . | 동작 | 명령어 | 설명 | . | pane 나누기 | (ctrl + b) % | Pane을 좌우로 나누기 | . |   | (ctrl + b) “ | Pane을 상하로 나누기 | . | pane 커서 이동 | (ctrl + b) 방향키 | 현재 작업하는 커서의 Pane을 이동 | . | pane 사이즈 조정 | (ctrl + b) 누르고 방향키 | 현재 커서가 있는 Pane의 사이즈를 변경 | . | pane 지우기 | (ctrl + b) x | 현재 커서의 pane을 지움 exit으로 나가서 지울 수도 있음 현재 pane이 jumphost를 반복해서 들어간다면 exit을 여러번 해야하는데 이걸 사용하면 좋음 | . |   |   |   | . | pane에서 스크롤 사용하기 | (ctrl + b) [ | tmux는 기본이 스크롤이 안되는데 이걸로 스크롤 사용 설정 그치만 여기서 스크롤을 써도 편한 스크롤은 아님 | . |   |   |   | . | 모든 pane에 입력하기 | 1. (ctrl + b) : 2. 하단 command에 setw synchronize-panes on 3. 입력 | tmux를 사용하는 가장 편리하게 사용하는 방법 중 하나 이렇게 쓰면 지금 열려 있는 모든 pane에 커서가 공유되고 동일한 입력이 가능 나는 여러 region/instance에 동일한 배치 작업을 수행할 때 주로 사용함 | . | 모든 pane에 입력끄기 | 1. (ctrl + b) : 2. 하단 command에 setw synchronize-panes off | 쓰고나서 필요할 땐 끄자 | . | 모든 pane의 크기 맞추기 | (ctrl + b) , (Alt + 2) | vertical 하게 모든 pace이 동일한 크기를 갖도록 맞추기 | . |   | (ctrl + b) , (Alt + 1) | horizontal 하게 모든 pace이 동일한 크기를 갖도록 맞추기 | . | pane 뷰 형상 변경하기 | (ctrl + b) , space | 위의 horizontal, vertical 등의 뷰 형상을 변경해줌 | . | pane 전체화면으로 변경하기 | (ctrl + b) + z | 현재 pane을 전체화면으로 변경. 한번 더 수행하면 다시 여러 pane 뷰로 변경 | . | 현재 pane을 별도 window로 분리 | (ctrl + b) + ! | pane이 여러개인 window에서 현재 pane만 새로운 window를 만들어 분리아래 스크립트와 효율이 좋다 | . ",
    "url": "/docs/dev-tools/linux-commands/tmux#%EC%9E%90%EC%A3%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94-%EB%AA%85%EB%A0%B9%EC%96%B4%EB%93%A4",
    
    "relUrl": "/docs/dev-tools/linux-commands/tmux#자주-사용하는-명령어들"
  },"288": {
    "doc": "multi terminal tmux 효율적으로 사용하기",
    "title": "자주 사용하지 않는데 한 번은 쓴 명령어",
    "content": "현재 세션 이름 알기 . tmux display-message -p ‘#S’ . 현재 window 이름 알기 . tmux display-message -p ‘#I’ . ",
    "url": "/docs/dev-tools/linux-commands/tmux#%EC%9E%90%EC%A3%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EC%A7%80-%EC%95%8A%EB%8A%94%EB%8D%B0-%ED%95%9C-%EB%B2%88%EC%9D%80-%EC%93%B4-%EB%AA%85%EB%A0%B9%EC%96%B4",
    
    "relUrl": "/docs/dev-tools/linux-commands/tmux#자주-사용하지-않는데-한-번은-쓴-명령어"
  },"289": {
    "doc": "multi terminal tmux 효율적으로 사용하기",
    "title": "tmux script",
    "content": "내가 만들어서 사용하는 script. echo라고 입력한 부분에 ssh command를 넣는다. 나는 주로 batch instance를 접속할 수 있도록 command를 꾸려놓고, 위에서 언급한 pane 크기를 맞추고 필요한 경우 동시 입력으로 사용하는 편이다. #!/bin/bash #session을 항상 새롭게 만들고 싶다면 date를 사용할 수 있다. #DATE=`date +%s` #SESSIONNAME=\"meansoup_${DATE}\" SESSIONNAME=\"meansoup\" tmux has-session -t $SESSIONNAME &amp;&gt; /dev/null if [ $? != 0 ] then tmux new-session -d -s $SESSIONNAME \\; split-window -v \\; split-window -v \\; select-pane -t 0 \\; split-window -v\\; split-window -v \\; tmux send-keys -t $SESSIONNAME:0.0 C-z 'echo kr' Enter tmux send-keys -t $SESSIONNAME:0.1 C-z 'echo uw' Enter tmux send-keys -t $SESSIONNAME:0.2 C-z 'echo ew' Enter tmux send-keys -t $SESSIONNAME:0.3 C-z 'echo sg' Enter tmux send-keys -t $SESSIONNAME:0.4 C-z 'echo cn' Enter fi tmux attach -t $SESSIONNAME:0 . ",
    "url": "/docs/dev-tools/linux-commands/tmux#tmux-script",
    
    "relUrl": "/docs/dev-tools/linux-commands/tmux#tmux-script"
  },"290": {
    "doc": "multi terminal tmux 효율적으로 사용하기",
    "title": "reference",
    "content": "https://unix.stackexchange.com/questions/32986/how-do-i-equally-balance-tmux1-split-panes https://github-wiki-see.page/m/dkoes/docs/wiki/Using-tmux https://protechnotes.com/comprehensive-tmux-tutorial-for-beginners-with-a-cheat-sheet/ https://snipcademy.com/linux-command-line-tmux#pane-management-ex-commands . ",
    "url": "/docs/dev-tools/linux-commands/tmux#reference",
    
    "relUrl": "/docs/dev-tools/linux-commands/tmux#reference"
  },"291": {
    "doc": "multi terminal tmux 효율적으로 사용하기",
    "title": "multi terminal tmux 효율적으로 사용하기",
    "content": "DDD tactical components . Terminal Shortcut tmux cut jq screen split . tmux는 원격에서 background에서 작업을 수행할 때 사용하는 command 이다. 이전에 정리했던 linux screen와 유사하다. 나는 요새 screen 보다는 tmux를 사용하려고 한다. 지금 나는 5개 region에서 운영하는 서비스들을 개발하고 있는데, tmux는 여러 batch instance로 들어가서 작업하기가 screen 보다 편리했다. ",
    "url": "/docs/dev-tools/linux-commands/tmux",
    
    "relUrl": "/docs/dev-tools/linux-commands/tmux"
  },"292": {
    "doc": "database transaction model, ACID",
    "title": "database transaction",
    "content": "database system에서 상호작용의 단위를 말한다. data의 추가, 수정, 삭제의 단계들을 하나로 단일 실행 단위의 작업 집합을 말한다. 예시 . A가 B에게 100원을 이체하는 작업에 대해서 아래의 SQL이 모여 하나의 transaction이 된다. BEGIN TRANSACTION UPDATE accounts SET balance = balance - 100 WHERE name = 'A'; UPDATE accounts SET balance = balance + 100 WHERE name = 'B'; COMMIT TRANSACTION . 이론적으로 database system은 각각의 transaction에 대해 ACID를 보장한다. 실제로는 성능 향상을 위해 각 특성들이 종종 완화 되기도 한다. 이런 transaction을 지원하는 database를 transactional database라고 부른다. 대부분의 RDB(Relational DB)는 transactional database이다. ",
    "url": "/docs/db/concept/acid#database-transaction",
    
    "relUrl": "/docs/db/concept/acid#database-transaction"
  },"293": {
    "doc": "database transaction model, ACID",
    "title": "ACID 이란?",
    "content": "database transaction이 안전하게 수행된다는 것을 보장하기 위한 성질이다. 아래의 네 가지 속성을 따서 ACID라고 부른다. Atomicity (원자성) . data의 변경 operation이 single operation으로 수행되었는지를 보장하는 속성이다. single operation이라는 것은 부분적인 성공이 없이 하나의 operation이라는 것을 말한다. 즉, 모든 변경이 수행되거나 아무 변경도 수행되지 않는 것을 말한다. 예시 . A가 B에게 100원을 이체할 때 Transaction T는 두 작업을 갖게 된다. | A := A - 100 | B := B + 100 | . A에서 출금은 성공하고, B에 입금이 실패한다면 A에서는 돈이 빠졌지만 B에는 이체되지 않는 문제가 발생한다. 원자성은 이런 문제를 해결해준다. Consistency (일관성) . transaction이 성공적으로 완료되면 database가 항상 일관성있는 상태로 유지된다는 속성이다. 일관성이라는건 data의 손상이나 오류 등으로 인해 database의 rule을 깨지 않는 것을 말한다. 나는 일관성이 이해하기가 가장 어려웠는데, 쉽게 말하자면 invalid 한 data를 갖는 transaction 을 받아들이지 않는다는 것이다. 즉, valid data가 database에 쓰일 수 있다는 것이다. 예시 . A가 B에게 100원을 이체할 때, A 가지고 있지 않다면 A는 -10원을 갖게 된다. 계좌 table의 rule이 - 값을 가질 수 없다면 이 transaction은 실패하는 것이다. 여기서 일관성을 말하자면 계좌는 항상 0 이상의 값을 갖는다 라는 일관된 규칙이 유지되는 것. Isolation (고립성) . transaction이 다른 transaction과 별개로 동작하는 것을 보장하는 속성이다. 동일한 table에서 여러 transaction이 발생하더라도 서로 간섭하거나 영향을 끼치지 않도록 한다. 구체적으로는 하나의 tranascation의 수정이 반영되기 이전까지 다른 transaction에서 변경 사항을 확인할 수 없는 것을 말한다. 예시 . A가 B에게 100원을 출금하는 작업과, A와 B의 계좌를 조회하는 작업이 동시에 발생한다고 가정하자. | T1 - A := A - 100 | T2 - Read(A) | T2 - Read(B) | T1 - B := B + 100 | . T1에서 A에서 이체하는 작업만 수행된 사이에 A와 B의 계좌를 읽는 작업이 수행되는 경우. tranaction이 종료되지 않은 상황에서 서로 변경사항을 확인할 수 있다면, 순간적으로 A에서는 돈이 빠졌지만 B에는 이체되지 않은 문제가 발생한다. 고립성은 이런 문제를 해결해준다. Durability (지속성) . transaction이 성공적으로 수행된 경우 영구적으로 반영되고 시스템 오류가 발생하더라도 변경사항이 유지되고 취소되지 않는다. 예시 . 계좌 이체가 성공하면 이후에 오류가 발생해도 이체된 data는 변경되지 않는다. ",
    "url": "/docs/db/concept/acid#acid-%EC%9D%B4%EB%9E%80",
    
    "relUrl": "/docs/db/concept/acid#acid-이란"
  },"294": {
    "doc": "database transaction model, ACID",
    "title": "reference",
    "content": "http://www.jidum.com/jidums/view.do?jidumId=906 https://www.ibm.com/docs/ko/cics-ts/5.4?topic=processing-acid-properties-transactions https://ko.wikipedia.org/wiki/데이터베이스_트랜잭션 https://www.geeksforgeeks.org/acid-properties-in-dbms/ https://mariadb.com/resources/blog/acid-compliance-what-it-means-and-why-you-should-care/ https://www.geeksforgeeks.org/sql-transactions/ . ",
    "url": "/docs/db/concept/acid#reference",
    
    "relUrl": "/docs/db/concept/acid#reference"
  },"295": {
    "doc": "database transaction model, ACID",
    "title": "database transaction model, ACID",
    "content": " ",
    "url": "/docs/db/concept/acid",
    
    "relUrl": "/docs/db/concept/acid"
  },"296": {
    "doc": "Curl to Code (Python/Java ..)",
    "title": "사용법",
    "content": "curlconverter.com 에 접속해서 사용한다. 예시 . ",
    "url": "/docs/dev-tools/site/curl-to-code#%EC%82%AC%EC%9A%A9%EB%B2%95",
    
    "relUrl": "/docs/dev-tools/site/curl-to-code#사용법"
  },"297": {
    "doc": "Curl to Code (Python/Java ..)",
    "title": "reference",
    "content": "https://stackoverflow.com/questions/42604586/converting-a-curl-to-python-requests https://curlconverter.com/ . ",
    "url": "/docs/dev-tools/site/curl-to-code#reference",
    
    "relUrl": "/docs/dev-tools/site/curl-to-code#reference"
  },"298": {
    "doc": "Curl to Code (Python/Java ..)",
    "title": "Curl to Code (Python/Java ..)",
    "content": "api 테스트나 여러 서버의 작업을 위해 request를 curl로 짜는 일이 많다. 이렇게 작성한 curl로 python 코드를 짜려고 할 때 번거롭거나 귀찮은 경우가 많다. 나 같은 경우는 간단한 스크립트를 작성하려고 curl을 짜다가, 생각보다 귀찮아지면 python으로 옮기는 경우가 있는데 이럴 때 참고하는 편이다. opensource 프로젝트인 curlconverter를 소개한다. curl을 입력하면 code를 작성해주는 프로젝트. 내가 주로 쓰는 python, java, go를 모두 지원한다. ",
    "url": "/docs/dev-tools/site/curl-to-code",
    
    "relUrl": "/docs/dev-tools/site/curl-to-code"
  },"299": {
    "doc": "GraphQL이란?",
    "title": "graphQL 이란?",
    "content": "graphQL은 API용 query 언어이자 data를 가져오기 위한 query를 수행하는 runtime을 말한다. 이름에서 느껴지듯 Graph Query Language의 약자이자 SQL과 마찬가지로 query 언어이다. 예시 . 여기선 graphQL이 어떻게 생겼는지 맛만 보자. graphQL에서의 query는 다음과 같다. sql의 query 처럼 필요한 값들을 query해 올 수 있다. { hero { name height mass } } . 그렇다면, 응답은 . { \"hero\": { \"name\": \"Luke Skywalker\", \"height\": 1.72, \"mass\": 77 } } . mass 값이 필요하지 않은 경우 . { hero { name height } } . 그렇다면, 응답은 . { \"hero\": { \"name\": \"Luke Skywalker\", \"height\": 1.72 } } . ",
    "url": "/docs/apis/graphql/what_is_graphql#graphql-%EC%9D%B4%EB%9E%80",
    
    "relUrl": "/docs/apis/graphql/what_is_graphql#graphql-이란"
  },"300": {
    "doc": "GraphQL이란?",
    "title": "graphQL의 탄생",
    "content": "facebook에서는 RESTful 서버를 사용하고 있었는데 당시 성능도 별로였고 앱에서의 충돌도 잦았다. 이 때 개발자들이 데이터 전송 방식을 개선해야 한다는 것을 깨닫고 데이터를 다른 시각을 바라보기 시작하면서 탄생한 것이 facebook의 client 및 server의 data model 요구사항과 기능을 정립하기 위한 query 언어였다. 2015년 graphQL의 초기 명세가 나왔고, 현재 facebook은 내부의 data fetch는 대부분 graphQL로 이루어지고 있다고 한다. 이렇게 탄생한 것이 여러 다발의 데이터 전송을 graph로 묶어 request 수를 줄이고 효율성을 확보하여 문제를 해결하는 목적을 가진 graphQL이다. 예시 . REST는 각각의 container에 대해 call을 요청한다. | posts, comments, authors | . GraphGL은 graph를 만들어서 필요한 모든 값들을 한 번에 요청한다. REST의 단점 . 현재의 데이터 전송 방식은 RPC, SOAP를 거쳐 REST를 정석처럼 사용하는 분위기다. | 내가 서비스하는 서버도 REST를 사용하고 있기도 하고. | . 당연히 GraphQL이 탄생하는데는 위에서 말했듯 REST의 단점이 보였기 때문이다. REST의 단점을 명확히 짚어보면 graphQL의 장점이 또렷하게 보인다. Over Fetching . Over Fetch는 RESTful API를 디자인하면 전형적으로 만나볼 수 있는 rest의 단점이다. 나는 이게 되게 불필요하고 손해가 있는 작업이라고 생각하면서도 이걸 바꿀 수 있다는 생각을 못했던 것 같다. 예시 . github의 REST api를 호출해보자. | curl https://api.github.com/users/meansoup | . { \"login\": \"meansoup\", \"id\": 24368552, \"node_id\": \"MDQ6VXNlcjI0MzY4NTUy\", \"avatar_url\": \"https://avatars.githubusercontent.com/u/24368552?v=4\", \"gravatar_id\": \"\", \"url\": \"https://api.github.com/users/meansoup\", \"html_url\": \"https://github.com/meansoup\", \"followers_url\": \"https://api.github.com/users/meansoup/followers\", \"following_url\": \"https://api.github.com/users/meansoup/following{/other_user}\", \"gists_url\": \"https://api.github.com/users/meansoup/gists{/gist_id}\", ... } . 문제는, 만약 내가 만들 서비스가 여기서 id와 avatar_url, url 세 가지 값만 필요한 경우에 발생한다. | 내가 구현한 client는 필요없는 전체 데이터를 모두 받아야 한다. | github server도 필요없는 데이터를 내려주기 위해 네트워크를 낭비해야 한다. | . RESTful api server를 운영해본 개발자라면 공감하겠지만, 사실 대부분의 api에서 over fetch는 굉장히 쉽게 자주 발생한다. under fetching . 그렇다면 under fetch는 뭘까? fetching을 하고 추가 데이터를 또 다시 요청해야 하는 상황을 말한다. 예시 . 이번엔 github의 followers api를 호출해보자. | curl https://api.github.com/users/meansoup/followers | . [ { \"login\": \"chanhyeong\", \"id\": 10507662, \"node_id\": \"MDQ6VXNlcjEwNTA3NjYy\", \"avatar_url\": \"https://avatars.githubusercontent.com/u/10507662?v=4\", \"gravatar_id\": \"\", \"url\": \"https://api.github.com/users/chanhyeong\", \"html_url\": \"https://github.com/chanhyeong\", \"followers_url\": \"https://api.github.com/users/chanhyeong/followers\", \"following_url\": \"https://api.github.com/users/chanhyeong/following{/other_user}\", \"gists_url\": \"https://api.github.com/users/chanhyeong/gists{/gist_id}\", ... } ... } . 나는 이번엔 follower들의 정보를 얻어와서 서비스를 만들려고 한다. | followers 요청을 하고 나온 user들을 가지고 다시 user 정보를 요청해야 한다. | curl https://api.github.com/users/follower1 | curl https://api.github.com/users/follower2 | curl https://api.github.com/users/follower3 | curl https://api.github.com/users/follower4 | . | follower가 많아질 경우 내 call은 n 번이나 증가하게 된다. | 증가되는 call 만큼 resource를 사용하고 데이터는 매번 over fetching되며 응답 시간은 늘어진다. | . under fetching도 쉽게 자주 볼 수 있다. folder 안에 있는 item들을 반환하거나, post의 comment에서도 볼 수 있고. under fetching의 주요 문제는 응답 시간을 늘어지게 하는 api call 수의 증가이고, 이는 graphQL에서 굉장히 효과적으로 처리할 수 있다. endpoint 관리 . REST API의 단점은 유연성이 부족하다는 것이다. client에서 변경사항이 생기면 endpoint를 새로 만들어야 하고, 이렇게 되면 endpoint의 수가 몇 배로 늘어나기도 한다. | 우리 서비스는 v1 api, v2 api로 버전업을 하면서 제공하는 편. | . 이렇게 되면 개발 속도가 느려진다. 새로운 endpoint를 만들기 위해 client &amp; server 팀이 협업을 해야하고, 추후 보수 작업에서도 endpoint에 따른 작업이 많아지기 때문이다. | graphQL은 단일 endpoint를 사용하여 이런 문제점에서 자유롭다. | . ",
    "url": "/docs/apis/graphql/what_is_graphql#graphql%EC%9D%98-%ED%83%84%EC%83%9D",
    
    "relUrl": "/docs/apis/graphql/what_is_graphql#graphql의-탄생"
  },"301": {
    "doc": "GraphQL이란?",
    "title": "reference",
    "content": "웹 앱 API 개발을 위한 GraphQL, Eve Porcello / Alex Banks https://graphql.org/ https://tech.kakao.com/2019/08/01/graphql-basic/ https://www.apollographql.com/blog/graphql/basics/graphql-vs-rest/ . ",
    "url": "/docs/apis/graphql/what_is_graphql#reference",
    
    "relUrl": "/docs/apis/graphql/what_is_graphql#reference"
  },"302": {
    "doc": "GraphQL이란?",
    "title": "GraphQL이란?",
    "content": "기술이 발전하면서 인터넷은 곳곳에서 쓰이게 되었다. 와중에 많은 문제가 발생하고 해결되었는데 아직도 해결중인 문제는 데이터 전송 속도를 올리는 일이다. 더 많은 데이터를 손실 없이 빠르게 전송하는 일은 인터넷의 역사와 같이 발전해왔다. 현 시점에서 가장 현대적인 해결책이 바로 graphQL이다. ",
    "url": "/docs/apis/graphql/what_is_graphql",
    
    "relUrl": "/docs/apis/graphql/what_is_graphql"
  },"303": {
    "doc": "jekyll gh page 폰트 설정하기",
    "title": "TL;DR",
    "content": "jekyll theme 마다 font custom이 다를 수 있다. 검색은 참고만 하되 기본적으로는 theme guide 페이지와 github 코드를 보자. ",
    "url": "/docs/blog/font#tldr",
    
    "relUrl": "/docs/blog/font#tldr"
  },"304": {
    "doc": "jekyll gh page 폰트 설정하기",
    "title": "font 적용 안되는 경우",
    "content": "github blog를 다시 관리하기 시작하면서 참 맘에 안드는 부분이 글씨체다. tistory나 국내 서비스 블로그들은 알아서 이쁜 폰트들을 제공하지만 github은 아니니까. 기본 폰트 킹받는다. 페이지에 폰트를 적용하기 위해 부단한 노력을 했다. 역시나 구글에 검색을 많이 했는데 내 검색어는 다음과 같다. | jekyll font | jekyll 폰트 | jekyll 한글 폰트 | jekyll github font | … | . 결론을 말하자면 여기서 나온 해결책들이 나한텐 하나도 적용되지 않았다. 아마 이런 사람들이 많지 않을까? . ",
    "url": "/docs/blog/font#font-%EC%A0%81%EC%9A%A9-%EC%95%88%EB%90%98%EB%8A%94-%EA%B2%BD%EC%9A%B0",
    
    "relUrl": "/docs/blog/font#font-적용-안되는-경우"
  },"305": {
    "doc": "jekyll gh page 폰트 설정하기",
    "title": "font 적용 안되는 이유",
    "content": "jekyll은 테마마다 포맷들이 참 다르다. 이전에 내가 사용하던 유명한 테마인 lanyon이랑 현재 사용하는 just-the-docs 테마랑은 페이지를 꾸며주는 포맷부터 다르니까. 그러니까, css를 custom으로 적용하는 방식도 다른 경우가 제법 된다는 것이다. 그래서 위의 방식들이 나한텐 통하지 않았다. ",
    "url": "/docs/blog/font#font-%EC%A0%81%EC%9A%A9-%EC%95%88%EB%90%98%EB%8A%94-%EC%9D%B4%EC%9C%A0",
    
    "relUrl": "/docs/blog/font#font-적용-안되는-이유"
  },"306": {
    "doc": "jekyll gh page 폰트 설정하기",
    "title": "해결책",
    "content": "나 같은 경우는 해답을 테마 가이드 페이지에서 찾았다. | jekyll custom theme guide page | 아니면 github directory 구조에서도 힌트를 얻는다 (theme gitub code) | . 몇 번이고 봤던 페이지인데도 대충봐서 놓쳤던 것을.. 한참 시간을 버리고서야 다시 보게 되었다. 가이드를 따라서 해결한 나의 코드는 아래와 같다. // path: /_sass/custom/custom.scss @font-face { font-family: 'GowunDodum-Regular'; src: url('https://cdn.jsdelivr.net/gh/projectnoonnu/noonfonts_2108@1.1/GowunDodum-Regular.woff') format('woff'); font-weight: normal; font-style: normal; } p, a, h1, h2, h3, h4, h5, h6 { font-family: \"GowunDodum-Regular\"; } . ",
    "url": "/docs/blog/font#%ED%95%B4%EA%B2%B0%EC%B1%85",
    
    "relUrl": "/docs/blog/font#해결책"
  },"307": {
    "doc": "jekyll gh page 폰트 설정하기",
    "title": "font list 참고",
    "content": "https://noonnu.cc/font_page . ",
    "url": "/docs/blog/font#font-list-%EC%B0%B8%EA%B3%A0",
    
    "relUrl": "/docs/blog/font#font-list-참고"
  },"308": {
    "doc": "jekyll gh page 폰트 설정하기",
    "title": "jekyll gh page 폰트 설정하기",
    "content": " ",
    "url": "/docs/blog/font",
    
    "relUrl": "/docs/blog/font"
  },"309": {
    "doc": "diagram 그리는 가장 쉬운 방법, 코드로 그리는 uml plantuml",
    "title": "기존의 diagram 그리기",
    "content": "기존에 diagram을 그리는 방법은 다들 비슷하다. 나 역시도 그랬고, 우리 파트원들과 그룹원들도 그랬다. 대부분이 draw.io로 그리고 있었고 MS visio를 사용하기도 했다. 예시 . draw.io에서 그린 sequence diagram. MS visio에서 그린 sequence diagram. 내가 두 가지 툴을 쓰면서 느꼈던 점. | 직접 손으로 그려야해서 많은 시간을 필요로 한다 | visio의 경우 프로그램이 무겁고, draw.io는 웹이라 편하지 않다 | 추가/수정의 작업이 어렵다 . | version up으로 코드가 바뀌는 경우, 중간 flow를 바꿀 때 손이 굉장히 많이 간다. | . | 위의 이유들로 굉장히 귀찮고 재미가 없다. | . 그렇다면, 쉽고 빠르게 diagram을 그리고 수정할 방법이 없을까? . ",
    "url": "/docs/design/plantuml#%EA%B8%B0%EC%A1%B4%EC%9D%98-diagram-%EA%B7%B8%EB%A6%AC%EA%B8%B0",
    
    "relUrl": "/docs/design/plantuml#기존의-diagram-그리기"
  },"310": {
    "doc": "diagram 그리는 가장 쉬운 방법, 코드로 그리는 uml plantuml",
    "title": "plantUML",
    "content": "plantUML을 내가 팀 내에 소개할 때 나는 plantUML을 uml 계의 markdwon 이라고 표현했다. 그럼 plantUml을 알아보자. markdown은 왜 쓰는가? . vs MS Word: . | 간단한 구조와 문법을 지원하기 때문에 직관적이다 | 쉽게 작성할 수 있다 | 쉽게 html이나 jpg로 변경이 가능하다 | 프로그램과 파일 모두 가볍다 | Git(version 관리 시스템)에서 변경 이력 관리가 편리하다 | 문서 편집기의 모든 기능을 지원하지는 못한다 | 그치만 문서 편집기의 디테일한 기능들이 우리한테 필요하진 않다 | . plantUML . 그래서 plantUML이 왜 uml 계의 markdown일까? . PlantUML은 사용자가 플레인 텍스트 언어로부터 UML 다이어그램을 만들 수 있게 하는 오픈 소스 도구이다. PlantUML의 언어는 도메인 특화 언어의 한 예이다. -Wiki- PlantUML 은 다이어그램을 빠르게 작성하기 위한 오픈 소스 프로젝트이다. -Home- . 즉, plantUML은 텍스트 언어로 uml을 만든다. 장점 . 장점을 보면 MS word와 비교한 markdown과 굉장히 유사하다. | 간단한 구조와 문법을 지원하기 때문에 직관적이다 | 쉽게 작성할 수 있다 | 쉽게 html이나 jpg로 변경이 가능하다 | 프로그램과 파일 모두 가볍다 | Git(version 관리 시스템)에서 변경 이력 관리가 편리하다 | draw.io나 visio의 모든 기능을 지원하지는 못한다 | 그치만 draw.io나 visio의 모든 기능이 우리한테 필요하진 않다 | plantuml로 아키텍처를 테스트할 수 있다.1 | . 설치 . plantuml은 editor만 있으면 된다. 주로 나는 vscode에서 작성하는데 intellij 에서도 작성할 수 있다. | vscode - extensions &gt; PlantUML | intellij - Settings &gt; Plugins &gt; PlantUML integration | web - web plantuml 에서 테스트 가능. | . 사용법 . plantUML 가이드 참고. vscode 및 intellij 에서 preview, 및 file export. 예시 . 작성한 uml과 그려진 diagram을 보면 쉽게 이해할 수 있다. 나는 보통 sequence diagram을 가장 많이 그리는데 위 가이드를 보면 class diagram이나 다른 diagram들도 참고할 수 있다. 기본 사용법. @startuml client-&gt; server: invalid msg client&lt;--server: &lt;color #red&gt;400&lt;/color&gt; invalid request @enduml . 조건문의 사용은 이렇게. @startuml client-&gt; server: msg alt validate(msg) client&lt;--server: &lt;color #blue&gt;200&lt;/color&gt; result else client&lt;--server: &lt;color #red&gt;400&lt;/color&gt; invalid request end @enduml . activate 상태 표시. @startuml client-&gt; server: msg activate server server-&gt; requestValidator: validate(header) server&lt;--requestValidator: validateResult server-&gt; requestValidator: validate(msg) server&lt;--requestValidator: validateResult deactivate server alt validateResult == True client&lt;--server: &lt;color #blue&gt;200&lt;/color&gt; result else client&lt;--server: &lt;color #red&gt;400&lt;/color&gt; invalid request end @enduml . 넘버링 하는 방법과 indentation에 대한 팁. 그리고 메모를 적는 방법. @startuml autonumber client-&gt; server: msg note right: msg must have valid header &amp; msg activate server server-&gt; requestValidator: validate(header) server&lt;--requestValidator: validateResult server-&gt; requestValidator: validate(msg) server&lt;--requestValidator: validateResult deactivate server alt validateResult == True client&lt;--server: &lt;color #blue&gt;200&lt;/color&gt; result else client&lt;--server: &lt;color #red&gt;400&lt;/color&gt; invalid request end @enduml . 메모에 개행이 필요한 경우 \\n을 쓸 수도 있지만 아래와 같이 하는게 좋다. @startuml autonumber client-&gt; server: msg note left msg must have valid header &amp; msg header: appId, appVersion msg: must have resourceId end note activate server server-&gt; requestValidator: validate(header) server&lt;--requestValidator: validateResult server-&gt; requestValidator: validate(msg) server&lt;--requestValidator: validateResult deactivate server alt validateResult == True client&lt;--server: &lt;color #blue&gt;200&lt;/color&gt; result else client&lt;--server: &lt;color #red&gt;400&lt;/color&gt; invalid request end @enduml . 상태 구분과 지연되는 상황에 대한 표시를 아래와 같이 나눌 수 있다. @startuml autonumber == intialize == [-&gt; server: set properties [-&gt; server: remove requestInfo ... autonumber == request come-in == client-&gt; server: msg note left msg must have valid header &amp; msg header: appId, appVersion msg: must have resourceId end note activate server server-&gt; requestValidator: validate(header) server&lt;--requestValidator: validateResult server-&gt; requestValidator: validate(msg) server&lt;--requestValidator: validateResult deactivate server alt validateResult == True client&lt;--server: &lt;color #blue&gt;200&lt;/color&gt; result else client&lt;--server: &lt;color #red&gt;400&lt;/color&gt; invalid request end @enduml . ",
    "url": "/docs/design/plantuml#plantuml",
    
    "relUrl": "/docs/design/plantuml#plantuml"
  },"311": {
    "doc": "diagram 그리는 가장 쉬운 방법, 코드로 그리는 uml plantuml",
    "title": "reference",
    "content": ". | intellij SequenceDiagram | plantUML Wiki | plantUML 가이드 | . | java에서 plantuml로 architecture를 테스트할 수 있도록 제공하는 archunit 참고. &#8617; . | . ",
    "url": "/docs/design/plantuml#reference",
    
    "relUrl": "/docs/design/plantuml#reference"
  },"312": {
    "doc": "diagram 그리는 가장 쉬운 방법, 코드로 그리는 uml plantuml",
    "title": "diagram 그리는 가장 쉬운 방법, 코드로 그리는 uml plantuml",
    "content": "학교를 다녔을 때보다, 회사에서는 설계를 위해서 코드 분석을 위해서 diagram을 그릴 일들이 많아졌다. ‘왜 학교에서 이런걸 가르쳤나?’를 깨닫기도 하고. 내가 처음 배치받은 부서는 flow가 굉장히 복잡한 부서였다. sequence diagram으로 flow를 그리기 시작했고 편의성을 위해 여러 툴들을 찾았다. 그러다 마지막에 만난 툴이 바로 plantuml. 나는 팀을 옮기고 파트 내 세미나에서 plantuml을 소개했고 반응이 좋아서 그룹에서도 한 차례 더 세미나를 가졌다. 2년이 지난 지금 우리 그룹의 대부분의 diagram은 plantuml로 그려지고 있다. ",
    "url": "/docs/design/plantuml",
    
    "relUrl": "/docs/design/plantuml"
  },"313": {
    "doc": "python slack bot 개발하기",
    "title": "tutorial",
    "content": "이전에는 slack web hook을 사용하는 script를 작성해서 batch와 server에 붙였었다. slack bot을 검색해보니 web hook을 call 하는 것들이 많이 나왔는데, 최신 문서에서는 bolt라는 slack library를 사용하는 것을 제안하고 있었다. bolt는 javascript 등을 지원하는데, 나는 python으로 작성했다. bolt로 python app(bot)을 만드는 tutorial을 따라하면 어렵지 않다. | https://api.slack.com/start/building/bolt-python | . tutorial만 보고 부족한 부분들을 추가로 정리한다. ",
    "url": "/docs/automation/python-bot#tutorial",
    
    "relUrl": "/docs/automation/python-bot#tutorial"
  },"314": {
    "doc": "python slack bot 개발하기",
    "title": "bolt spec",
    "content": "bolt는 이전에 사용하던 web api 호출과 약간 다르다. api가 wrapping 되어 있기도 하고 event 등 설정이 있어서 spec을 조금 보고 bolt를 이해하면 사용하기 더 편하다. python libary로 사용되는 bolt spec. 여기서 bolt가 지원하는 기능들이 무엇이 있는지 보고, 원하는 것을 사용할 수 있다. | https://slack.dev/bolt-python/api-docs/slack_bolt/app/app.html#slack_bolt.app.app.App.event | . bolt의 param 들 . bolt에서 param들로 여러 작업들을 할 수 있는데, 이걸 알면 일이 한참 수월하다. | say나 logger client 등 bolt에서 param들이 뭔지 알아야 잘 쓸 수 있다. | https://github.com/slackapi/bolt-python#making-things-happen | . 예시 . 가장 많이쓰는 say()를 이해하자면 say는 channel에 말을 하는 것이다. say()에 thread_ts를 명시하면 thread에 말할 수 있다. bolt에서 argument로 모든 기능을 지원하지는 않는다. 지원하지 않는 기능들은 webApi를 client를 통해 사용할 수 있다. ",
    "url": "/docs/automation/python-bot#bolt-spec",
    
    "relUrl": "/docs/automation/python-bot#bolt-spec"
  },"315": {
    "doc": "python slack bot 개발하기",
    "title": "api spec",
    "content": "api list를 여기서 확인할 수 있다. bolt가 지원하지 않는 것들을 client에서 사용하려면 api spec을 참고할 필요가 있다. 아래 spec에서 python 탭을 보면 나오는 api들이 client에서 사용할 수 있는 값이다. | https://api.slack.com/methods?filter=chat | . 참고사항 . 예전에 사용하던 custom integration은 이제 사용하지 않는다. | custom integration은 지원하지 않는 기능들이 많다. | https://api.slack.com/legacy/custom-integrations#migrating_to_apps | . ",
    "url": "/docs/automation/python-bot#api-spec",
    
    "relUrl": "/docs/automation/python-bot#api-spec"
  },"316": {
    "doc": "python slack bot 개발하기",
    "title": "설정",
    "content": "설정하는데 시간을 제일 많이 썼다. 당연히 설정을 제대로 하지 않으면 동작하지 않는데, 추가해야 할 것들이 몇 가지 있다. 이 설정들은 모두 slack app page에서 사용할 app에 대해 설정하는 것이다. | tutorial에서 만든 app | . | OAuth &amp; Permissions에서 permisison 추가 . | 여기 필요한 permission들은 api spec에서 확인 | . | event를 사용하는 경우 Event Subscriptions에서 subscripption 추가 . | permission 이야 이전에 간단한 app 작업을 할 때 추가해봤는데, event를 쓰는건 이번이 처음이어서 여기서 시간을 많이 버렸다. | 내가 이번에 사용한 event는 mention listening이 있는데, 이 외에도 여러 event 들이 있다. | event에 대해서는 아래 링크를 보면 좋다 . | https://api.slack.com/apis/connections/events-api#the-events-api__subscribing-to-event-types | . | . | socket mode 설정 . | app에서 Event API와 Interactive component를 사용할 수 있게 해주는 모드 | http url을 endpoint로 사용하지 않고 web socket으로 통신하는 모드 | https://api.slack.com/apis/connections/socket | . | . ",
    "url": "/docs/automation/python-bot#%EC%84%A4%EC%A0%95",
    
    "relUrl": "/docs/automation/python-bot#설정"
  },"317": {
    "doc": "python slack bot 개발하기",
    "title": "slack app bot 개발에 도움을 주는 library",
    "content": "내가 구현한 bot의 구조는 이렇다. 이렇기 때문에, 2 tunnel ssh가 필요해서 알아보다가 발견한 것이 sshtunnel. sshtunnel에 설명된 예제를 보면 쉽게 사용할 수 있다. ",
    "url": "/docs/automation/python-bot#slack-app-bot-%EA%B0%9C%EB%B0%9C%EC%97%90-%EB%8F%84%EC%9B%80%EC%9D%84-%EC%A3%BC%EB%8A%94-library",
    
    "relUrl": "/docs/automation/python-bot#slack-app-bot-개발에-도움을-주는-library"
  },"318": {
    "doc": "python slack bot 개발하기",
    "title": "reference",
    "content": ". | 슬랙 공식 tutorial, https://api.slack.com/start/building/bolt-python | bolt python argument, https://github.com/slackapi/bolt-python#making-things-happen | bolt say, https://github.com/slackapi/bolt-js/issues/559 | bolt web api client, https://slack.dev/bolt-python/concepts#web-api | sshtunnel, https://pypi.org/project/sshtunnel/ | . ",
    "url": "/docs/automation/python-bot#reference",
    
    "relUrl": "/docs/automation/python-bot#reference"
  },"319": {
    "doc": "python slack bot 개발하기",
    "title": "python slack bot 개발하기",
    "content": "서버를 담당하고 있다보면 PM이나 app, front 개발자로부터 요청이 오곤 한다. 주로 VOC를 확인하기 위한 서버 동기화 data 혹은 log 조회에 관한 내용이다. 이게 시간은 많이 걸리지 않지만 반복되서 재미 없고 귀찮은 일이기도 한데 최근에는 이런 요청이 부쩍 많아져서 이번에 slack bot을 개발하게 되었다. ",
    "url": "/docs/automation/python-bot",
    
    "relUrl": "/docs/automation/python-bot"
  },"320": {
    "doc": "CIDR이란? CIDR을 알고 subnet 이해하기",
    "title": "CIDR 이란?",
    "content": "CIDR(Classless Inter-Domain Routing)으로 말 그대로 클래스 없는 도메인 간 라우팅 기법이다. 클래스가 있는 도메인 라우팅은 CIDR 이전 기법이다. CIDR을 이해하려면 CIDR 이전에 ip routing을 어떻게 해왔는지를 같이 공부하면 좋다. ",
    "url": "/docs/internet/cidr#cidr-%EC%9D%B4%EB%9E%80",
    
    "relUrl": "/docs/internet/cidr#cidr-이란"
  },"321": {
    "doc": "CIDR이란? CIDR을 알고 subnet 이해하기",
    "title": "IP address와 network &amp; host",
    "content": "IP address는 32-bit number로 이루어져 있다. | 10 진수 기준 0.0.0.0 부터 255.255.255.255 까지 | . TCP/IP WAN에서 효율적인 네트워크 관리를 위해 router는 host의 exact location을 알지 못한다. router는 host의 network 만을 아는데, 이 network 까지 data packet을 보내면 network가 host의 exact location까지 전달된다. 그래서 IP의 앞 부분 일부를 network field로 나머지 뒷 부분을 host field로 나누어서 사용한다. 이제부턴 IP address의 사용 역사라고 볼 수 있다. ",
    "url": "/docs/internet/cidr#ip-address%EC%99%80-network--host",
    
    "relUrl": "/docs/internet/cidr#ip-address와-network--host"
  },"322": {
    "doc": "CIDR이란? CIDR을 알고 subnet 이해하기",
    "title": "1. Class 도입 이전",
    "content": "class가 도입되기 이전에는 위에서 언급하는 network field로 8-bit를 사용했다. 이 말은, 256(\\(2^8\\))개의 network field만이 존재한다는 뜻이고, 각 network은 \\(2^{24}\\)개의 host를 가질 수 있다는 의미이다. 이 형식은 LAN도 보급되기 이전의 초기 인터넷인 ARPANET(미국국방부에서 만든) 에서 사용되던 방식이었다. 문제점: 250 여개의 network field만 사용할 수 있는 방식은 금방 network 주소가 고갈되었고 새로운 방식이 필요하게 되었다. ",
    "url": "/docs/internet/cidr#1-class-%EB%8F%84%EC%9E%85-%EC%9D%B4%EC%A0%84",
    
    "relUrl": "/docs/internet/cidr#1-class-도입-이전"
  },"323": {
    "doc": "CIDR이란? CIDR을 알고 subnet 이해하기",
    "title": "2. Classful network",
    "content": "그게 바로 Classful network인데, class로 나누어 network field를 관리하는 방식이다. A~E의 5가지 class가 존재한다. 이 중 D, E의 경우 존재하지만 예약 &amp; 연구 목적으로 실제 end user가 사용하는 값은 아니다. | Class | Leading bits | size of network field | size of host field | start address | end address | subnet mask | . | A | 0 | 8 | 24 | 0.0.0.0 | 127.255.255.255 | 255.0.0.0 | . | B | 10 | 16 | 16 | 128.0.0.0 | 191.255.255.255 | 255.255.0.0 | . | C | 110 | 24 | 8 | 192.0.0.0 | 223.255.255.255 | 255.255.255.0 | . 위 표가 Classful network의 내용이다. Class A의 경우 network field로 8-bit를 사용한다. 이 중 첫 bit는 0으로 시작해서 address는 0.0.0.0부터 127.255.255.255까지가 가능하다. 그렇다면 Class A에서 \\(2^7\\)개의 network가 사용될 수 있고 각 network는 \\(2^{24}\\)개의 host를 가질 수 있다는 의미이다. | start address와 end address를 잘보면 class 마다 사용하는 address가 다른 걸 확인할 수 있는데 이 주소만 가지고 class를 판별할 수 있다는 의미이다. | 0.0.0.0 이나 127.0.0.0 등과 같은 특수한 주소들은 예약되어 사용할 수 없다. | . 유사하게 B, C로 갈수록 더 많은 network를 가질 수 있으면서 각 network가 가질 수 있는 host의 개수는 줄어든다. subnet mask . subnet mask는 host가 local subnet에 있는지, remote network에 있는지 확인하기 위해 TCP/IP에서 사용된다. subnet mask를 통해 network field와 host field를 구분할 수 있다. | network IP의 부분은 1로, host IP의 부분은 0으로 표기한다. | . subnet mask는 위 표에서 설명되어 있어서 예를 들면 쉽게 이해할 수 있을 것 같다. 예시 . 192.168.123.132 라는 IP가 있다. network IP가 192.168.123.0 이고, host IP가 0.0.0.132 라면, subnet은 255.255.255.0 이 된다. network IP가 192.168.0.0 이고, host IP가 0.0.123.132 라면, subnet은 255.255.0.0 이 된다. 문제점: Class C의 경우 약 250(\\(2^8\\))개의 host를 가질 수 있는데 대부분의 경우 Class C는 너무 작았다. Class B의 경우 host는 비교적 넉넉하나, network 개수가 약 16000(\\(2^{14}\\))개로 인터넷이 발전하며 network가 부족해지는 문제가 발생했다. ",
    "url": "/docs/internet/cidr#2-classful-network",
    
    "relUrl": "/docs/internet/cidr#2-classful-network"
  },"324": {
    "doc": "CIDR이란? CIDR을 알고 subnet 이해하기",
    "title": "3. CIDR",
    "content": "클래스 없는 도메인 간 라우팅 기법으로 위 문제를 해결하기 위해 1993년 도입되기 시작한 최신의 IP 주소 할당 방법이다. CIDR는 IP의 field를 Classful에 비해 더 유연하게 나눌 수 있게 한다. CIDR block . CIDR은 A.B.C.D/E 와 같은 방식으로 표기한다. | A.B.C.D는 IP 주소이다. | /E는 0~32까지의 숫자이다. | IP의 첫 bit부터 E bit 만큼 일치하면 CIDR block의 일부라고 한다. | . 예시 . 10.10.1.32/27 라고 표기한다면 27-bit까지 일치하는 IP를 포함하는 것이다. 예시 . 208.130.29.33 라는 웹 서버를 호출하는 경우, . | 208.128.0.0/11를 갖는 MCI에 routing 되고, | 208.130.28.0/22를 갖는 sub-network에서 routing 되고, | 208.130.29.0/24에서 routing 되어 | 208.130.29.33/32인 www.freesoft.org로 routing 된다. | . 장점: . | 부족한 IPv4 주소를 효율적으로 사용할 수 있게 한다 | routing table의 크기가 커지는 문제를 해결해서 router의 부담을 줄인다 | . reference . https://ko.wikipedia.org/wiki/사이더_(네트워킹) https://namu.wiki/w/CIDR https://ko.wikipedia.org/wiki/네트워크_클래스 https://docs.microsoft.com/en-us/troubleshoot/windows-client/networking/tcpip-addressing-and-subnetting . ",
    "url": "/docs/internet/cidr#3-cidr",
    
    "relUrl": "/docs/internet/cidr#3-cidr"
  },"325": {
    "doc": "CIDR이란? CIDR을 알고 subnet 이해하기",
    "title": "CIDR이란? CIDR을 알고 subnet 이해하기",
    "content": " ",
    "url": "/docs/internet/cidr",
    
    "relUrl": "/docs/internet/cidr"
  },"326": {
    "doc": "Java GC 기본 개념 잡기",
    "title": "장점",
    "content": ". | memory의 allication/deallocation을 직접 핸들링 하지 않아도 된다. | Dangling Pointer를 걱정하지 않아도 된다. | Dangling Pointer: GC 된 memory를 객체가 참조하는 것x | . | Double free 를 걱정하지 않아도 된다. | Double free: GC 된 memory를 다시 GC 하는 것 | . | memory leak을 알아서 관리해준다. | memory leak: GC 되어야 하는 memory가 GC 되지 않은 것 | . | . ",
    "url": "/docs/java/gc/basic#%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/java/gc/basic#장점"
  },"327": {
    "doc": "Java GC 기본 개념 잡기",
    "title": "단점",
    "content": ". | JVM이 객체 생성을 추적하기 때문에 CPU를 더 사용한다. | 개발자가 GC의 CPU 시간을 조정할 수 없다. | 적절하게 직접 memory를 관리하는 것보다 성능이 떨어질 수 있다. | . 초기 Java에서 GC는 개발자가 핸들링 할 수 없는 등의 이유로 많은 논란이 되었다고 한다. 현재는 논란의 여지가 없이 GC는 Go 등의 최신 언어에서도 채택된다. ",
    "url": "/docs/java/gc/basic#%EB%8B%A8%EC%A0%90",
    
    "relUrl": "/docs/java/gc/basic#단점"
  },"328": {
    "doc": "Java GC 기본 개념 잡기",
    "title": "기본 원칙",
    "content": "모든 언어의 모든 GC는 두 가지 원칙을 기본으로 설계된다. | 모든 garbage를 수집해야 한다. | 살아있는 객체는 절대로 수집해선 안된다. | . ",
    "url": "/docs/java/gc/basic#%EA%B8%B0%EB%B3%B8-%EC%9B%90%EC%B9%99",
    
    "relUrl": "/docs/java/gc/basic#기본-원칙"
  },"329": {
    "doc": "Java GC 기본 개념 잡기",
    "title": "STW (Stop The World)",
    "content": "GC에서 가장 중요한 것은 STW 이다. GC를 실행하기 위해 JVM이 application을 멈추는 것을 stop-the-world라고 하는데, stop-the-world가 발생하면 GC를 실행하는 thread를 제외한 나머지 thread는 모두 작업을 멈춘다. | 즉, GC 완료 시까지 모든 application thread가 중지된다는 말이다. | . 그리고 GC 작업이 완료된 이후에 다시 작업을 시작한다. 어떤 GC를 사용하더라도 STW는 발생할 수 밖에 없는데, STW 시간을 줄이는 것이 GC 선택과 튜닝의 중요한 목표가 된다. ",
    "url": "/docs/java/gc/basic#stw-stop-the-world",
    
    "relUrl": "/docs/java/gc/basic#stw-stop-the-world"
  },"330": {
    "doc": "Java GC 기본 개념 잡기",
    "title": "GC 기본 동작",
    "content": "GC 알고리즘마다 동작의 차이는 있지만 기본적인 GC 동작은 아래와 같다. 기본 GC 동작을 완벽히 이해하면 다른 알고리즘들이 왜 생겼고 어떻게 동작하는지 이해하기 쉽다. 1. Marking . 어떤 memory가 사용중인지 확인하는 과정이다. 2. Normal Deletion . 참조되지 않은 객체를 제거해서 여유 공간 확보한다. 2a. Deletion with Compacting . 성능 향상을 위해 객체를 압축한다. 이렇게 하면 새로운 memory allocation이 쉽고 빨라진다. ",
    "url": "/docs/java/gc/basic#gc-%EA%B8%B0%EB%B3%B8-%EB%8F%99%EC%9E%91",
    
    "relUrl": "/docs/java/gc/basic#gc-기본-동작"
  },"331": {
    "doc": "Java GC 기본 개념 잡기",
    "title": "GC 발생 요인",
    "content": "어떤 요인들이 Java app에서 GC 발생에 영향을 주는지를 알면, GC의 구조를 이해하는데 더 도움이 된다. Java app에서 GC 발생에 영향을 주는 주요 요인은 두 가지이다. | 할당률 | 객체 수명 | . 할당률은 일정 기간(MB/s) 새로 생성된 객체가 사용한 memory 크기이다. | 비교적 쉽게 측정할 수 있고 툴을 사용하면 정확하게 구할 수 있다. | . 객체 수명은 측정하기 어렵다. | 대부분의 객체는 short-lived 객체인 것이 실험적으로 파악되었다. | . ",
    "url": "/docs/java/gc/basic#gc-%EB%B0%9C%EC%83%9D-%EC%9A%94%EC%9D%B8",
    
    "relUrl": "/docs/java/gc/basic#gc-발생-요인"
  },"332": {
    "doc": "Java GC 기본 개념 잡기",
    "title": "Weak Generational Hypothesis",
    "content": "GC에서는 위 요인 중 객체 수명이 굉장히 중요하다. 객체가 얼마나 살아있냐에 따라 GC의 수행 여부와 대상이 정해지기 때문이다. 그래프에서 볼 수 있듯 실험적으로 확인한 결과 대부분의 객체는 short-lived 객체이다. 여기서 하나의 가설이 나오는데 이게 바로 Weak Generational Hypothesis이다. | 대부분의 객체는 아주 짧은 시간 동안 살아있고(short-lived) 나머지 객체는 훨씬 수명이 길다(long-lived)는 가설이다. | . 이 가설의 결론은 short-lived 객체를 쉽게 빠르게 수집할 수 있고, long-lived 객체를 short-lived 객체와 분리해 놓는 설계가 좋다는 결론으로 이어진다. ",
    "url": "/docs/java/gc/basic#weak-generational-hypothesis",
    
    "relUrl": "/docs/java/gc/basic#weak-generational-hypothesis"
  },"333": {
    "doc": "Java GC 기본 개념 잡기",
    "title": "JVM Generations",
    "content": "모든 객체에 대해서 매번 위와 같이 GC 동작을 수행하는건 효율적이지 않다. 그리고 Weak Generational 가설의 결론으로 보다 효율적인 GC 구조를 설계하게 된다. generation으로 heap의 part를 나누는 방식이다. Young Generation . 새로 생성된 대부분의 객체가 할당되는 영역이다. Young Generation을 정리하는 GC를 minor garbage collection라고 한다. | minor garbage collection은 STW event 이다. | . 사용되지 않는 memory는 GC 처리되고, 살아남은 객체는 Old Generation으로 이동한다. Young은 3가지 영역으로 나뉜다. | eden | survivor1 | survivor2 | . Generational Process . Young이 3가지 영역으로 나뉘는 이유가 중요하다. | 새로 생성한 객체는 eden 영역에 위치한다. | eden 영역에서 GC가 발생하면 survivor 영역 중 하나로 이동한다. | eden 영역에서 GC가 발생하면 객체가 이미 존재하는 survivor 영역에 객체가 쌓인다. | 하나의 survivor 영역이 가득차면 살아남은 객체를 다른 survivor 영역으로 이동한다. | 이 로직으로 survivor 영역 중 한 곳은 항상 비어있는 상태를 유지한다. | . | 이런 동작이 반복되는 것을 aging이라 표현한다. | aging을 반복하며 generation이 변한다. 계속 살아남은 객체는 Old Generation으로 이동한다. | . Old Generation . Weak Generational가설과 Generational Process를 잘 봤다면 Old Generation은 명확하다. Young Generation에서 임계값 만큼의 GC가 처리되고 나서 살아남은 객체가 이동하는 곳이다. Old Generation은 보통 Young보다 큰 heap을 할당받고, 따라서 Old Generation의 GC는 느리다. | 여기서 발생하는 GC를 major garbage collection라고 하며 이 또한 STW event 이다. | 따라서 major GC 수행이 최소화 되는 것이 성능에 유리하다. | Weak Generational 가설에 따라 분리되는 것이 성능상 유리하다. | major GC는 GC 알고리즘 종류에 영향을 받는다. | . Permanent Generation . JVM에서 Class와 Method를 사용하기 위해 필요한 metadata들이 있는 곳이다. application에 사용되는 class를 기반으로 runtime에 JVM에 의해서 생성된다. | Java SE library의 Class와 Method도 여기에 위치한다. | . ",
    "url": "/docs/java/gc/basic#jvm-generations",
    
    "relUrl": "/docs/java/gc/basic#jvm-generations"
  },"334": {
    "doc": "Java GC 기본 개념 잡기",
    "title": "TLAB (Thread-Local Allocation Buffer)",
    "content": "multi-thread를 효율적으로 사용하기 위한 방식으로 현재는 GC의 기본적인 기술이다. GC에 memory를 할당할 때 multi-thread인 경우 thread-safe 하도록 memory를 할당하는 것은 비용이 크다. | global lock을 잡는다고 하면 bottlenect이 걸리고 성능이 떨어진다. | . 이를 해결하기 위해 도입된 것이 TLAB이다. JVM은 eden을 여러 buffer로 나누어서 각 thread가 새 객체를 할당하는 구역으로 활용하도록 한다. thread마다 사용하는 buffer가 정해져 있기 때문에 thread-safe를 위한 계산을 하지 않아도 된다. 이와 함께 Bump-The-Pointer가 사용되는데, 이는 할당된 메모리 바로 뒤에 메모리를 할당하고 pointer는 비어있는 memory 주소를 가리키도록 업데이트 하는 방식이다. | TLAB + BTP 를 통해 JVM thread의 memory allocation 복잡도가 O(1)이 된다. | . 이 외에도 여러 기술들이 사용되어 TLAB에서 memory 낭비가 최소화 되었고 평균적으로 eden의 1% 미만이 낭비된다고 한다. (굉장하다..) . 특정 thread의 buffer가 초과되는 경우 일반적으로 더 큰 크기의 TLAB를 할당하는 방식으로 해결한다. ",
    "url": "/docs/java/gc/basic#tlab-thread-local-allocation-buffer",
    
    "relUrl": "/docs/java/gc/basic#tlab-thread-local-allocation-buffer"
  },"335": {
    "doc": "Java GC 기본 개념 잡기",
    "title": "죄짓기",
    "content": "Java에서 아래와 같이 명시적으로 gc를 호출할 수 있다. System.gc() . 하지만 gc는 위에서 말했듯 시스템 성능에 영향을 미치므로 절대로 사용해서는 안된다. ",
    "url": "/docs/java/gc/basic#%EC%A3%84%EC%A7%93%EA%B8%B0",
    
    "relUrl": "/docs/java/gc/basic#죄짓기"
  },"336": {
    "doc": "Java GC 기본 개념 잡기",
    "title": "reference",
    "content": ". | https://www.baeldung.com/jvm-garbage-collectors | https://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html | https://d2.naver.com/helloworld/1329 | Optimizing Java, chapter6 | https://www.oracle.com/technetwork/java/javase/memorymanagement-whitepaper-150215.pdf | https://dzone.com/articles/thread-local-allocation-buffers#:~:text=TLAB%20stands%20for%20Thread%20Local,new%20objects%20in%20this%20area. | . ",
    "url": "/docs/java/gc/basic#reference",
    
    "relUrl": "/docs/java/gc/basic#reference"
  },"337": {
    "doc": "Java GC 기본 개념 잡기",
    "title": "Java GC 기본 개념 잡기",
    "content": "GC(Garbage Collection)는 memory의 garbage를 찾고 지우는 역할을 한다. 현재까지 Java의 GC는 발전을 거듭해 여러 종류가 있다. 그치만 그 종류를 알기 전에, GC의 기본 개념과 용어들 GC가 생긴 이유들을 아는 것이 중요하다. 이번 글에선 그 내용을 정리한다. 우선, GC를 왜 쓸까? . ",
    "url": "/docs/java/gc/basic",
    
    "relUrl": "/docs/java/gc/basic"
  },"338": {
    "doc": "Java GC의 가장 기본이 되는 Serial GC",
    "title": "Serial GC 란?",
    "content": "Serial GC는 기본적으로 single virtual CPU를 사용하여 minor &amp; major GC를 처리하도록 설계되었다. 따라서 GC가 수행될 때 모든 application thread가 멈추지만 단일 CPU로 GC를 진행한다. 그렇기 때문에 많은 CPU core를 가진 환경에서는 적절하지 않다. ",
    "url": "/docs/java/gc/serial_gc#serial-gc-%EB%9E%80",
    
    "relUrl": "/docs/java/gc/serial_gc#serial-gc-란"
  },"339": {
    "doc": "Java GC의 가장 기본이 되는 Serial GC",
    "title": "usage",
    "content": "CPU가 많은 환경에서 적절하지 않으므로 주로 client style 시스템에서 사용되기도 하는데, STW가 긴 편이므로 STW가 상관없는 환경에서 사용된다. | Java SE5, 6에서 client style machine에 대해 default로 사용되었던 GC 이기도 하다. | . 따라서 client에서는 종종 사용할 수 있지만 운영 서버에서는 절대 사용하면 안되는 방식이다. 운영 서버에서 Serial을 사용하면 application 성능이 많이 떨어질 수 밖에 없다. ",
    "url": "/docs/java/gc/serial_gc#usage",
    
    "relUrl": "/docs/java/gc/serial_gc#usage"
  },"340": {
    "doc": "Java GC의 가장 기본이 되는 Serial GC",
    "title": "Young",
    "content": "young 영역에서는 앞서 설명한 Generational Process에 따라 GC를 수행한다. ",
    "url": "/docs/java/gc/serial_gc#young",
    
    "relUrl": "/docs/java/gc/serial_gc#young"
  },"341": {
    "doc": "Java GC의 가장 기본이 되는 Serial GC",
    "title": "Old",
    "content": "old 영역에서는 Mark Sweep Compact라는 알고리즘을 사용한다. | mark - 살아있는 객체 식별 | sweep - 살아있는 것만을 남기는 동작 | compact - heap의 앞 부분부터 채우는 압축 | . ",
    "url": "/docs/java/gc/serial_gc#old",
    
    "relUrl": "/docs/java/gc/serial_gc#old"
  },"342": {
    "doc": "Java GC의 가장 기본이 되는 Serial GC",
    "title": "command",
    "content": "-XX:+UseSerialGC으로 serialGC를 사용할 수 있다. | java -XX:+UseSerialGC -jar demo.jar | . 공통 command . 아래 command는 모든 GC에서 공통으로 사용되는 command 이다. | command | desc | . | -Xms | Sets the initial heap size for when the JVM starts. | . | -Xmx | Sets the maximum heap size. | . | -Xmn | Sets the size of the Young Generation. | . | -XX:PermSize | Sets the starting size of the Permanent Generation. | . | -XX:MaxPermSize | Sets the maximum size of the Permanent Generation | . ",
    "url": "/docs/java/gc/serial_gc#command",
    
    "relUrl": "/docs/java/gc/serial_gc#command"
  },"343": {
    "doc": "Java GC의 가장 기본이 되는 Serial GC",
    "title": "reference",
    "content": ". | https://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html | . ",
    "url": "/docs/java/gc/serial_gc#reference",
    
    "relUrl": "/docs/java/gc/serial_gc#reference"
  },"344": {
    "doc": "Java GC의 가장 기본이 되는 Serial GC",
    "title": "Java GC의 가장 기본이 되는 Serial GC",
    "content": "Java GC Type . Serial GC Parallel GC CMS GC G1 GC . Java의 Garbage Collection은 CPU의 발전에 따라 새로운 알고리즘들이 생기고 있다. 그 중 가장 기본이되고 간단한 GC가 Serial Garbage Collector 이다. ",
    "url": "/docs/java/gc/serial_gc",
    
    "relUrl": "/docs/java/gc/serial_gc"
  },"345": {
    "doc": "DDD의 Domain Events란? DDD에서 transaction을 관리하는 방법",
    "title": "domain event란?",
    "content": "말 그대로 domain에서 발생한 event. domain의 변화를 다른 곳에 알리기 위해 event로 만드는 것이다. domain event도 domain model의 일부이다. domain event는 aggregate에 의해 생성된다. 아래와 같은 장점 때문에 사용된다. 장점 . domain의 변경에 대한 side effect를 명시적으로 구현할 수 있다. | 유비쿼터스 언어에 기반한 도메인 규칙을 도메인 이벤트로 명시적으로 표현할 수 있는 것. | . 다른 aggregate에 대한 수정이 필요한 경우 이를 분리할 수 있다. | DDD에서는 하나의 transaction에서 하나의 aggregate만 수정해야 한다. 이 규칙을 지킬 수 있는 방법이면서 꼭 사용해야하는 케이스이다. | . domain event 맞나? . event와 domain event를 헷갈리기 쉽다. 아래와 같은 조건들로 domain event 인지 파악하는데 참고할 수 있다. 맞는 근거 . | stakeholders와 business가 관심이 있나? | 우리 system에서 결정된 event 인가? | . 틀린 근거 . | 기술적인 이슈인가? | bounded context 밖에서 일어났나? | system에 대한 요청인가? . | 이건 command 이지 event가 아니기 때문 | . | . domain event 뽑기 . | … 할 때 | 이런 일이 일어나면 … | … 하면 | . 과 같은 경우 domain event modeling을 해야할 가능성이 크다. modeling 하기 . event를 전달하는 목적이 크기 때문에 event는 보통 immutable이고 모델링이 간단하다. 앞서 말했듯 과거에 발생했다는 것을 이름에 반영하는게 중요하다. 발생한 시점(date)이 들어가는 편이고, 그 외의 event의 의미를 나타내기 위한 속성들이 무엇이 필요한지 생각해봐야 한다. 이벤트 발행 . domain model이 event messaging infra에 노출(coupling)되어선 안된다. publisher . publisher는 domain이 modeling 되지 않는다. 즉, DomainEventPublisher는 모든 domain event를 받아서 처리해줄 수 있지, 특정 domain model과 연결되지 않는다는 것이다. subscriber . domain event의 handling은 application이 해야할 일이다. domain은 domain logic에만 집중하기 때문이다. event handler나 side-effect action들은 domain이 신경쓰지 않는다. diagram . 위 sequence에서 aggregate가 publish() 하지만, DomainEventPublisher가 publish()를 받아서 DomainEventSubscriber에게 전달한다. publisher는 여러 subscriber에게 event를 전달할 수 있다. event를 어떻게 처리하는지는 subscriber(application service)의 몫이다. 그림에 나오진 않지만 마찬가지로 publisher도 aggregate 들의 event를 받을 수 있다. 그래서 domain이 들어가서는 안된다. event 생성과 전달을 분리하기 . transaction을 commit 하기 직전에 event를 handler에 전달하는 방식이 바로 event를 전달하는 것보다 좋다. | event 바로 전달되면 side-effect이 클 수 있고, domain model을 test하기 어렵다. | event 발생과 handler로 보내는 작업을 분리할 수 있다. | 발생과 전달을 분리하면 model 캡슐화에 도움이 된다. | event 전달에 유연성을 준다. | . reference . | https://lostechies.com/jimmybogard/2014/05/13/a-better-domain-events-pattern/ | https://docs.microsoft.com/en-us/dotnet/architecture/microservices/microservice-ddd-cqrs-patterns/domain-events-design-implementation | https://serialized.io/ddd/domain-event/ | Implement Domain Driven Design (chapter8 Domain Events), Vaughn Vernon | . ",
    "url": "/docs/ddd/tactical/domain_events#domain-event%EB%9E%80",
    
    "relUrl": "/docs/ddd/tactical/domain_events#domain-event란"
  },"346": {
    "doc": "DDD의 Domain Events란? DDD에서 transaction을 관리하는 방법",
    "title": "DDD의 Domain Events란? DDD에서 transaction을 관리하는 방법",
    "content": "DDD tactical components . VO Entity Domain Service Domain Events Aggregate . 일단 domain events를 사용하는 법을 알고나면 이에 중독되서 어떻게 domain events 없이 살아왔는지 의아해질 것이다. - Vaughn Vernon . event란? . 우선 event가 뭔지 알아보자. event에는 이런 특성들이 있다. | event란 과거에 발생한 것을 말한다. | 그렇기 때문에 항상 과거형으로 쓰인다. | 요청과 혼동하기 쉽기 때문에 과거형을 지키는 것이 좋다. | . | event는 변경할 수 없다. | 이미 발생했기 때문에 바꿀 수 없다. | . | event는 한 번만 발생할 수 있다. | 다시 발생하더라도 이건 다른 event이다. | . | . ",
    "url": "/docs/ddd/tactical/domain_events",
    
    "relUrl": "/docs/ddd/tactical/domain_events"
  },"347": {
    "doc": "Parallel GC는 무엇이고 언제 쓰기 좋은걸까?",
    "title": "Serial vs Parallel",
    "content": "serial GC STW . | . parallel GC STW . | . serial은 GC를 단일 thread로 하기 때문에 위와 같이 thread의 낭비가 크다. parallel은 thread를 효율적으로 사용하고 더 빠르게 GC를 수행할 수 있다. ",
    "url": "/docs/java/gc/parallel_gc#serial-vs-parallel",
    
    "relUrl": "/docs/java/gc/parallel_gc#serial-vs-parallel"
  },"348": {
    "doc": "Parallel GC는 무엇이고 언제 쓰기 좋은걸까?",
    "title": "Parallel GC 란?",
    "content": "Parallel GC는 Serial GC와 비슷하다. multiple CPU를 사용해서 application throughput을 향상시킬 수 있기 때문에 throughput collector라고도 불린다. Young GC를 수행하는데 multiple thread를 사용하는게 특징이다. default로 N개의 CPU일 때 collection에서 N개의 GC thread를 사용한다. ",
    "url": "/docs/java/gc/parallel_gc#parallel-gc-%EB%9E%80",
    
    "relUrl": "/docs/java/gc/parallel_gc#parallel-gc-란"
  },"349": {
    "doc": "Parallel GC는 무엇이고 언제 쓰기 좋은걸까?",
    "title": "usage",
    "content": "Parallel GC는 GC가 발생하면 모든 thread를 중지하고 multi-thread를 사용하여 GC 작업을 수행한다. 따라서 GC 작업은 중단 없이 효율적으로 수행된다. 일반적으로 application 에 사용되는 시간 대비 GC 시간을 최소화할 수 있는 방법이다. 그러나 이후에 나오는 다른 GC들에 비해 한 번의 STW는 긴 편이다. 위와 같은 이유로 개별의 STW가 길어지는 것은 수용할 수 있으나 전체적인 성능이 중요한 작업을 진행할 때 Parallel GC가 사용되기 적합하다. | 대표적으로 batch process나 대량의 database query가 있다. | . ",
    "url": "/docs/java/gc/parallel_gc#usage",
    
    "relUrl": "/docs/java/gc/parallel_gc#usage"
  },"350": {
    "doc": "Parallel GC는 무엇이고 언제 쓰기 좋은걸까?",
    "title": "command",
    "content": "-XX:+UseParallelGC으로 사용할 수 있다. | java -XX:+UseParallelGC -jar demo.jar | . GC thread의 수를 조절하기 위해 XX:ParallelGCThreads를 사용할 수 있다. | -XX:ParallelGCThreads=N | . Maximum garbage collection pause time을 설정하기 위해 -XX:MaxGCPauseMillis을 사용할 수 있다. | -XX:MaxGCPauseMillis=N | 기본적으로는 maxGcPause time은 설정되어 있지 않다. | 이 값이 설정되면 maxGcPause 시간을 맞추기 위해 heap size 등의 parameter가 조정된다. | 이를 통해 GC의 Throughput이 줄어들 수 있다. | 이 시간이 항상 충족되지는 않을 수 있다. | . GC에 사용되는 시간의 비율을 Throughput이라고 한다. -XX:GCTimeRatio를 통해 ratio를 설정할 수 있다. | -XX:GCTimeRatio=N . | \\(\\frac{1}{1 + N}\\) 으로 세팅되며, default N = 99로, GC에서 전체 시간의 1%를 사용하는 것을 목표로 한다. | . | 이는 \\(\\frac{GC time}{application time}\\) 을 의미한다. | . priorify . Parallel 에서의 우선순위는 아래와 같다. | Maximum garbage collection pause time | Throughput | . Maximum garbage collection pause time이 충족된 이후에만 Throughput을 고려한다. 마찬가지로 Throughput이 충족되어야 max heap size를 고려한다. | GC 공통 command에서 -Xmx를 통해 max heap size를 설정할 수 있다. | . ",
    "url": "/docs/java/gc/parallel_gc#command",
    
    "relUrl": "/docs/java/gc/parallel_gc#command"
  },"351": {
    "doc": "Parallel GC는 무엇이고 언제 쓰기 좋은걸까?",
    "title": "Parallel Old GC 란?",
    "content": "Young GC와 Old GC 모두 multithread를 사용하는 GC이다. 지금은 Parallel GC하면 Parallel Old GC를 언급하는 경우가 많다. command . -XX:+UseParallelOldGC으로 사용할 수 있다. | java -XX:+UseParallelOldGC -jar demo.jar | . ",
    "url": "/docs/java/gc/parallel_gc#parallel-old-gc-%EB%9E%80",
    
    "relUrl": "/docs/java/gc/parallel_gc#parallel-old-gc-란"
  },"352": {
    "doc": "Parallel GC는 무엇이고 언제 쓰기 좋은걸까?",
    "title": "reference",
    "content": ". | https://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html | https://docs.oracle.com/en/java/javase/18/gctuning/parallel-collector1.html | https://www.informit.com/articles/article.aspx?p=2496621&amp;seqNum=2 | . ",
    "url": "/docs/java/gc/parallel_gc#reference",
    
    "relUrl": "/docs/java/gc/parallel_gc#reference"
  },"353": {
    "doc": "Parallel GC는 무엇이고 언제 쓰기 좋은걸까?",
    "title": "Parallel GC는 무엇이고 언제 쓰기 좋은걸까?",
    "content": "Java GC Type . Serial GC Parallel GC CMS GC G1 GC . 앞서 본 Serial Garbage Collection은 단점이 명확하다. Serial은 thraed의 낭비가 크다. multiple CPU 로부터 성능을 뽑아내기 위해 Parallel GC를 사용한다. ",
    "url": "/docs/java/gc/parallel_gc",
    
    "relUrl": "/docs/java/gc/parallel_gc"
  },"354": {
    "doc": "Spring CRUD vs JPA 차이",
    "title": "구조",
    "content": ". 우선 위와 같이 상속 구조를 갖는다. ",
    "url": "/docs/spring/jpa/crud-vs-jpa#%EA%B5%AC%EC%A1%B0",
    
    "relUrl": "/docs/spring/jpa/crud-vs-jpa#구조"
  },"355": {
    "doc": "Spring CRUD vs JPA 차이",
    "title": "CrudRepository",
    "content": "기본적인 CRUD 기능을 제공한다. | Create, Read, Update, Delete | . @NoRepositoryBean public interface CrudRepository&lt;T, ID&gt; extends Repository&lt;T, ID&gt; { &lt;S extends T&gt; S save(S var1); &lt;S extends T&gt; Iterable&lt;S&gt; saveAll(Iterable&lt;S&gt; var1); Optional&lt;T&gt; findById(ID var1); boolean existsById(ID var1); Iterable&lt;T&gt; findAll(); Iterable&lt;T&gt; findAllById(Iterable&lt;ID&gt; var1); long count(); void deleteById(ID var1); void delete(T var1); void deleteAll(Iterable&lt;? extends T&gt; var1); void deleteAll(); } . ",
    "url": "/docs/spring/jpa/crud-vs-jpa#crudrepository",
    
    "relUrl": "/docs/spring/jpa/crud-vs-jpa#crudrepository"
  },"356": {
    "doc": "Spring CRUD vs JPA 차이",
    "title": "PagingAndSortingRepository",
    "content": "pagination과 sorting을 제공한다. | pagination할 때 Pageable은 page size, current page number, sorting을 포함해야 한다. | . @NoRepositoryBean public interface PagingAndSortingRepository&lt;T, ID&gt; extends CrudRepository&lt;T, ID&gt; { Iterable&lt;T&gt; findAll(Sort var1); Page&lt;T&gt; findAll(Pageable var1); } . ",
    "url": "/docs/spring/jpa/crud-vs-jpa#pagingandsortingrepository",
    
    "relUrl": "/docs/spring/jpa/crud-vs-jpa#pagingandsortingrepository"
  },"357": {
    "doc": "Spring CRUD vs JPA 차이",
    "title": "JpaRepository",
    "content": "flushing the persistence context과 delete records in a batch 같은 JPA와 관련된 기능을 제공한다. flush()는 database에 entity의 save 요청을 바로 밀어넣는 것을 의미한다. flush가 없다면 save() 요청은 persistence context에 남아있다가 flush()나 commit()이 들어오면 database에 밀어 넣는다. | JPA에서 성능상 최적화되게 flush를 하기 때문에 일반적으로 flush를 사용하는 일은 없다. | 성능 저하가 올 수 있다. | . deleteBatch는 대량의 삭제를 의미한다. @NoRepositoryBean public interface JpaRepository&lt;T, ID&gt; extends PagingAndSortingRepository&lt;T, ID&gt;, QueryByExampleExecutor&lt;T&gt; { List&lt;T&gt; findAll(); List&lt;T&gt; findAll(Sort sort); List&lt;T&gt; findAllById(Iterable&lt;ID&gt; ids); &lt;S extends T&gt; List&lt;S&gt; saveAll(Iterable&lt;S&gt; entities); void flush(); &lt;S extends T&gt; S saveAndFlush(S entity); &lt;S extends T&gt; List&lt;S&gt; saveAllAndFlush(Iterable&lt;S&gt; entities); void deleteAllInBatch(Iterable&lt;T&gt; entities); void deleteAllByIdInBatch(Iterable&lt;ID&gt; ids); void deleteAllInBatch(); T getById(ID id); &lt;S extends T&gt; List&lt;S&gt; findAll(Example&lt;S&gt; example); &lt;S extends T&gt; List&lt;S&gt; findAll(Example&lt;S&gt; example, Sort sort); } . 당연히 상속 때문에 JpaRepository는 모든 기능을 제공한다. 따라서 기능이 필요하지 않은 경우에만 상위 repository를 사용하면 된다. @NoRepositoryBean . repository 마다 붙어있는 @NoRepositoryBean은 뭘까? . 실제 entity의 repository로 사용하지 않을 interface 역할을 하는 repository들이 instance로 생성되는 것을 제외하기 위한 annotation이다. 예시 . stackoverflow의 답변의 예시를 가져왔다. public interface com.foobar.MyBaseInterface&lt;…,…&gt; extends CrudRepository&lt;…,…&gt; { void foo(); } public interface com.foobar.CustomerRepository extends MyBaseInterface&lt;Customer, Long&gt; { } . 위와 같은 코드에서 @EnableJpaRepositories(basePackages = {\"com.foobar\"})으로 jpa repository를 등록한 것이다. 이렇게 있을 때 @NoRepositoryBean가 명시되지 않는다면 spring은 MyBaseInterface가 실제 사용할 repository 구현체가 아니라는 것을 알 수 없다. 그러면 CustomerRepository을 생성하는데 실패한다. 이런 문제를 해결하기 위해 @NoRepositoryBean를 사용한다. reference . | https://www.baeldung.com/spring-data-repositories | https://stackoverflow.com/questions/14014086/what-is-difference-between-crudrepository-and-jparepository-interfaces-in-spring | https://www.baeldung.com/spring-data-jpa-save-saveandflush . | https://stackoverflow.com/questions/11576831/-understanding-the-spring-data-jpa-norepositorybean-interface | https://docs.spring.io/spring-data/commons/docs/current/api/org/springframework/data/repository/NoRepositoryBean.html | . ",
    "url": "/docs/spring/jpa/crud-vs-jpa#jparepository",
    
    "relUrl": "/docs/spring/jpa/crud-vs-jpa#jparepository"
  },"358": {
    "doc": "Spring CRUD vs JPA 차이",
    "title": "Spring CRUD vs JPA 차이",
    "content": "스프링에서 ORMs 개념을 적용한 표준이 JpaRepository이다. JpaRepository와 CrudRepository의 개념을 명확하게 모르고 사용해왔는데 차이를 정리해본다. ",
    "url": "/docs/spring/jpa/crud-vs-jpa",
    
    "relUrl": "/docs/spring/jpa/crud-vs-jpa"
  },"359": {
    "doc": "Spring Connection Pool 확인하기",
    "title": "default connection pool",
    "content": "Spring Boot에서는 아래와 같은 우선순위로 connection pool을 사용한다. | HikariCP | Tomcat pooling | DBCP2 | Oracle UCP | . HikariCP가 performance &amp; concurrency가 가장 우수해서 default로 사용된다. HikariCP를 사용할 수 없는 경우 Tomcat pooling을 사용하고 차례대로 각 CP를 사용한다. spring-boot-starter-jdbc 혹은 spring-boot-starter-data-jpa을 사용하면 자동으로 HikariCP를 사용한다고 보면된다. ",
    "url": "/docs/spring/jpa/find-connection-pool#default-connection-pool",
    
    "relUrl": "/docs/spring/jpa/find-connection-pool#default-connection-pool"
  },"360": {
    "doc": "Spring Connection Pool 확인하기",
    "title": "connection pool 직접 확인하기",
    "content": "connection pool을 default로 Hikari를 쓰겠지만 서비스를 운영하는 입장에서 확인하지 않고 설정하기엔 찝찝했다. Spring에서 어떤 connection pool을 쓰는지 확인하는 방법을 알고 싶기도 했다. 1. test에서 확인하기 . @SpringBootTest class AnyThingTest { @Autowired DataSource dataSource; @Test void checkCP() { System.out.println(\"DATASOURCE = \" + dataSource); } } . printed: DATASOURCE = HikariDataSource (HikariPool-1) . 2. service에서 확인하기 . test는 환경이 다를까 못 미더워서 추가로 확인해보기 . @Component class AnyThing { @Autowired DataSource dataSource; @PostConstruct void init() { System.out.println(\"DATASOURCE = \" + dataSource); } } . printed: DATASOURCE = HikariDataSource (HikariPool-1) . reference . spring boot의 default connection pool 우선순위 . | https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#data.sql.datasource.connection-pool | . connection pool 확인하기 . | https://mkyong.com/spring-boot/spring-boot-how-to-know-which-connection-pool-is-used/ | . ",
    "url": "/docs/spring/jpa/find-connection-pool#connection-pool-%EC%A7%81%EC%A0%91-%ED%99%95%EC%9D%B8%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/spring/jpa/find-connection-pool#connection-pool-직접-확인하기"
  },"361": {
    "doc": "Spring Connection Pool 확인하기",
    "title": "Spring Connection Pool 확인하기",
    "content": "spring 에서는 몇 가지 connection pool을 제공한다. DB를 사용할 때는 connection pool 설정은 필수인데 어떤 pool을 쓰느냐에 따라 property가 달라지기 때문에 어떤 connection pool을 쓰는지 확인하는 방법을 찾아봤다. ",
    "url": "/docs/spring/jpa/find-connection-pool",
    
    "relUrl": "/docs/spring/jpa/find-connection-pool"
  },"362": {
    "doc": "Spring JPA connection pool 조정하기",
    "title": "connection pool 확인",
    "content": "setting 전에 어떤 connection pool을 사용하고 있는지 확인해야 한다. | default는 Hikari | . ",
    "url": "/docs/spring/jpa/set-connection-pool#connection-pool-%ED%99%95%EC%9D%B8",
    
    "relUrl": "/docs/spring/jpa/set-connection-pool#connection-pool-확인"
  },"363": {
    "doc": "Spring JPA connection pool 조정하기",
    "title": "현재 db의 connection 확인",
    "content": "database 접속 후 아래 명령어로 connection을 확인할 수 있다. show status like \"%connect%\"; . ",
    "url": "/docs/spring/jpa/set-connection-pool#%ED%98%84%EC%9E%AC-db%EC%9D%98-connection-%ED%99%95%EC%9D%B8",
    
    "relUrl": "/docs/spring/jpa/set-connection-pool#현재-db의-connection-확인"
  },"364": {
    "doc": "Spring JPA connection pool 조정하기",
    "title": "JPA property setting",
    "content": "Spring Common Property를 참고한다. spring.datasource로 검색하면 datasource property를 찾을 수 있다. 여기서 어떤 connection pool을 사용하느냐에 따라 세팅해야 하는 property가 다르다. 일반적으로는 hikari이고 max pool size와 minimum idle을 세팅해준다. spring.datasource.hikari.maximum-pool-size=10 # 최대 pool size spring.datasource.hikari.minimum-idle=10 # 최소 pool size . | hikari에서는 minimum과 maximum을 같게 커넥션 수를 고정하여 최적의 성능을 뽑을 수 있다. | . ",
    "url": "/docs/spring/jpa/set-connection-pool#jpa-property-setting",
    
    "relUrl": "/docs/spring/jpa/set-connection-pool#jpa-property-setting"
  },"365": {
    "doc": "Spring JPA connection pool 조정하기",
    "title": "connection pool 주의사항",
    "content": "당연하게도 JPA의 property 세팅은 instance 단위이고 maximum 10이고 instance가 20 대이면 200개의 connection이 생길 수 있다. 이를 고려하여 DB(Mysql 등)의 Max Connection을 넉넉하게 유지해야 한다. reference . spring common property . | https://docs.spring.io/spring-boot/docs/current/reference/html/application-properties.html | . ",
    "url": "/docs/spring/jpa/set-connection-pool#connection-pool-%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD",
    
    "relUrl": "/docs/spring/jpa/set-connection-pool#connection-pool-주의사항"
  },"366": {
    "doc": "Spring JPA connection pool 조정하기",
    "title": "Spring JPA connection pool 조정하기",
    "content": "DB를 사용한다면 connection pool을 설정하는 것은 필수이다. 분명 작년에도 했던 작업인데 이번에 Mysql connection pool을 조정하면서 기억이 나지 않아서 기록한다. ",
    "url": "/docs/spring/jpa/set-connection-pool",
    
    "relUrl": "/docs/spring/jpa/set-connection-pool"
  },"367": {
    "doc": "DDD의 VO란? 쉽지만 어려운 VO 완벽하게 이해하기",
    "title": "ValueObject(VO)",
    "content": "Value Object는 말 그대로 값을 갖는 객체를 말한다. 값을 갖기 때문에 이 값 자체가 변할 수는 없다. 예시 . 계좌에 100원이라는 값이 있다고 치자. 친구가 10원을 이체해줬으면 110원이 된다. 이건 100원이라는 값 자체가 110원이 된게 아니다. 내 계좌가 가지고 있는 값이 100원이라는 값에서 110원이라는 값으로 바뀐 것이다. 즉, 값 자체는 바뀌지 않는다. 값이 대체되는 것 뿐이다. ",
    "url": "/docs/ddd/tactical/vo#valueobjectvo",
    
    "relUrl": "/docs/ddd/tactical/vo#valueobjectvo"
  },"368": {
    "doc": "DDD의 VO란? 쉽지만 어려운 VO 완벽하게 이해하기",
    "title": "VO의 특징",
    "content": "Value Object의 특징은 가볍지 않다. 어떤 글보다 이 책에서 명확하게 설명하고 있는데 이걸 잘 이해해야 개발에서 VO를 잘 녹여낼 수 있지 않을까 싶다. 아래의 특징들은 VO의 특징이기도 하고, 이런 특징들이 없거나 필요하지 않은 모델은 VO가 아닐 수 있다. domain의 어떤 대상을 측정하고 수량화하고 설명한다 . 모든 VO는 model의 특성의 의미를 가지고 있고 이를 측정, 수량화, 설명한다. 이 말은 domain model의 어떤 값이 측정, 수량화, 설명을 한다면 VO일 가능성이 크다는 것이다. 예시 . 나이를 예로 들어보자. 나이는 실제하는 대상은 아니지만 대상이 살아온 햇수를 측정하거나 수량화한다. 이름을 예로 들어보자. 이름도 실제하는 대상은 아니지만 대상을 어떻게 부를지를 설명해준다. immutable하다 . 절대로 변하지 않는 것. 가장 대표적인 VO의 특징이다. 이 특성과 밀접하게 관련있는 중요한 특징들이 있다. | 그냥 변하지 않아야 돼 하는게 아니라, 관련된 특성들을 잘 알고 이해하는게 중요하다. | . aggregate의 Id도 절대 변하면 안되니까 VO를 사용할 수도 있다. 관련 특성을 모은 필수 단위로 개념적 전체(Conceptual Whole)를 모델링한다 . 대상을 나타내기 위해 개별적인 특성이 아닌 하나의 전체 값으로 모델링 되어야 한다는 것을 개념적 전체(Conceptual Whole)라고 한다. 예시 . 금액을 말할 때 100은 의미가 없고 원도 의미가 없다. 100원이 합쳐져야 금액이라고 할 수 있다. 이게 바로 개념적 전체이다. 이 개념이 중요한게 Value Object는 불변하는 값이야 라고 해서 하나의 VO에 때려박는건 개념적 전체를 무시한 DDD의 Value Object가 아닌 그저 Value에 불과한 것이다. 각 VO가 유비쿼터스 언어에 따라 적절하게 이름 붙여진 응집도 높은 개념적 전체를 구성해야 한다. 개념적 전체는 불변성과도 밀접하게 관련이 있다. 위의 예시에서 금액(money) 객체에 100을 넣어두고 나중에 원을 붙이는 건 안된다. 개념적 전체를 위해 constructor에서 한번에 완성된 VO가 나와야 한다. 측정이나 설명이 변경될 땐 완벽히 대체 가능하다 . Entity가 VO를 가지고 있는데 올바른 상태의 VO가 아니라면 새로운 값으로 대체되어야 한다. 예시 . 숫자를 예로 들어보자. int total = 3; 에서 total의 값이 변경되면 total = 4;를 한다. 3 = 4;와 같이 3의 값을 바꾸는게 아니라 total에 새로운 value로 대체하는 것이다. 이름을 예로 들어보자. FullName fullName = new FullName(\"임\", \"꺽정\");에서 이름을 개명해서 임걱정으로 바꾼다고 하면 FullName fullName = new FullName(\"임\", \"걱정\");과 같이 한다. fullName.setFirstName(\"걱정\");과 같이 한다면 VO가 아닌 것이고 하면 안되는 짓이다. 다른 값과 등가성을 사용해 비교할 수 있다 . VO에는 entity처럼 id가 없다. 두 객체의 모든 property가 같다면 같은 객체로 간주한다. collaborator에게 side effect free한 행동을 제공한다 . VO의 함수는 불변성을 침해하면 안되기 때문에 side-effect free한 함수만 제공해야 한다. side-effect free method라는 것은 함수를 수행할 때 어떤 수정도 발생하지 않는 함수를 말한다. | 내 값(함수를 가진 VO)을 바꿔야 한다면 대체를 적용한다. | VO의 함수 내부에서 값을 계산한 새로운 VO를 반환할 수 있다. 그치만 수정은 절대 일어나선 안된다. | . | 중요한건 남의 값(parameter로 들어오는 객체의 property)도 바꿔서는 안된다. | 간과하기 쉬운 부분인데 VO가 Entity를 받아서 entity의 값을 수정한다면 이건 side-effect를 한참 만드는 설계이다. | VO가 Entity를 받아선 안되고 연산이 필요하다면 Entity에서 필요한 Value를 만들어서 받아야 한다. | . | 설령 entity가 수정되지 않는다고 하더라도 코드를 읽는 사람은 entity의 값을 바꾸는지 바꾸지 않는지를 알 수 없기 때문이고 이를 테스트하기도 어려워진다. | 모델의 명확성을 약화시키는 설계이기도 하다. - 그니까 사실은 가능한 VO의 parameter로 mutable한 객체가 들어오면 안된다. | . | . primitive는 VO가 아니다 . Value Object라고 생각하고 primitive나 wrapper type을 VO 대신 사용해선 안된다. primitive는 Domain으로 modeling된 naming을 가지고 있지도 않고 side-effect이 없는 함수를 정의할 수도 없다. 이는 domain 모델을 속이는 것이다. ",
    "url": "/docs/ddd/tactical/vo#vo%EC%9D%98-%ED%8A%B9%EC%A7%95",
    
    "relUrl": "/docs/ddd/tactical/vo#vo의-특징"
  },"369": {
    "doc": "DDD의 VO란? 쉽지만 어려운 VO 완벽하게 이해하기",
    "title": "VO의 이점",
    "content": "VO의 특징들을 이해하고 나면 이점들은 명확하다. | 생성이 쉽다. | 테스트가 쉽다. | 사용이 쉽다. | 최적화가 쉽다. | 유지관리가 쉽다. | . 이건 VO 대신 Entity를 사용해서 생성, 테스트, 사용, 최적화, 유지관리를 해보면 쉽게 느낄 수 있다. ",
    "url": "/docs/ddd/tactical/vo#vo%EC%9D%98-%EC%9D%B4%EC%A0%90",
    
    "relUrl": "/docs/ddd/tactical/vo#vo의-이점"
  },"370": {
    "doc": "DDD의 VO란? 쉽지만 어려운 VO 완벽하게 이해하기",
    "title": "VO 저장하기",
    "content": "VO도 영속성 저장소에 저장할 수 있다. 알다시피 대부분은 부모 entity에 담겨서 저장된다. 그러나 놀랍지만 vo가 반드시 repository의 entity로 저장되어야 할 때가 있다. 나는 이 부분이 굉장히 헷갈렸는데, Repository의 Entity와 Domain의 Entity를 헷갈려선 안된다. VO가 저장이 필요한 경우 repository의 entity로 저장된다고 하더라도 domain에서는 VO인 상태를 유지해야 한다. DB model은 부차적인 것이고 domain model을 위해 DB model을 설계해야 한다. | VO가 repository에서 entity로 저장된다고 domain도 entity로 모델링하는 것은 db의 구조를 따라가는 것이다. | . persistance repository에서는 결국 Id를 가져야 하는데 VO는 Id가 없어야하는 부분이 거슬릴 수 있다. | 그래도 VO는 VO. | protected Id를 갖는 abstract class를 VO가 extends 하는 방식 등으로 id를 VO class에서 숨길 수 있다. | . ",
    "url": "/docs/ddd/tactical/vo#vo-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/ddd/tactical/vo#vo-저장하기"
  },"371": {
    "doc": "DDD의 VO란? 쉽지만 어려운 VO 완벽하게 이해하기",
    "title": "VO 구현하기",
    "content": ". | setter가 있을 수 있지만 private으로 constructor에서만 호출되어야 한다. | 잘못된 값이 세팅될 때 assertion을 여기서 진행할 수 있는데 이걸 guard라고 한다. | 난 무조건 없어야 된다고 생각했는데 guard와 같은 명확한 구분을 위해 private setter는 좋은 것 같다. | . | 아래서 말할 copy constructor | getValue() 보다는 value() 같은 유창하게(fluent) 읽을 수 있는 표현을 사용한다 . | String을 보면 charAt(), compareTo(), contaions() 등 get이 들어가는 경우는 거의 없다. | . | . ",
    "url": "/docs/ddd/tactical/vo#vo-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/ddd/tactical/vo#vo-구현하기"
  },"372": {
    "doc": "DDD의 VO란? 쉽지만 어려운 VO 완벽하게 이해하기",
    "title": "VO 테스트하기",
    "content": "VO의 테스트는 domain 전문가 입장에서 의미가 있어야 한다. VO의 함수는 모든 경우에서 불변성이 보장되어야 한다. 따라서 모든 VO 함수 테스트 전 후에 vo의 값이 변하지 않았는지를 테스트하는게 좋다. | 이건 새롭게 배운건데 되게 중요한 것 같다. | . 예시 . TestVo testVo = new TestVo(...); TestVo copyTestVo = new TestVo(testVo); assertEquals(testVo, copyTestVo); testVo.anyMethod(..); assertEquals(testVo, copyTestVo); . testVo의 anyMethod()를 테스트하는 코드에서 anyMethod에 대한 테스트는 기본적으로 하면서 VO가 바뀌지는 않았는지를 테스트한다. 예시와 같은 이유로 위에서 언급했듯 copy constructor를 구현한다. reference . | Implement Domain Driven Design (chapter6 Domain Events), Vaughn Vernon | . ",
    "url": "/docs/ddd/tactical/vo#vo-%ED%85%8C%EC%8A%A4%ED%8A%B8%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/ddd/tactical/vo#vo-테스트하기"
  },"373": {
    "doc": "DDD의 VO란? 쉽지만 어려운 VO 완벽하게 이해하기",
    "title": "DDD의 VO란? 쉽지만 어려운 VO 완벽하게 이해하기",
    "content": "DDD tactical components . VO Entity Domain Service Domain Events Aggregate . DDD를 꽤나 공부했다고 생각했는데도 개발/설계를 해보면 DDD는 정말 어렵다. 개발 사이트나 블로그, 책을 훑어보듯 보면 VO는 참 쉽다. value를 저장하고 바뀌면 안되는 녀석. 쉬워보이지만 설계할 때 보면 정말 명확하지 않다. 개념을 명확하게 잡아야 설계에서 써먹을 수 있다는 생각이 이번에 들었다. Vaughn Vernon의 Implement Domain Driven Design의 Value Object 챕터를 작년에도 읽고 올해도 읽는데, DDD 설계와 논의를 진행하고 나서 읽으니까 더 와 닿는 것들이 많아 정리해본다. ",
    "url": "/docs/ddd/tactical/vo",
    
    "relUrl": "/docs/ddd/tactical/vo"
  },"374": {
    "doc": "DDD의 Domain Service란? Domain Service를 모른다면 DDD를 할 줄 모르는 것이다",
    "title": "도메인 서비스 (domain service)",
    "content": "domain 내에서 service란 도메인 고유의 작업을 수행하는 stateless operation이다. 당연히 domain service는 유비쿼터스 언어에 맞게 모델링 되어야 한다. domain service는 필요에 따라 어떤 도메인 객체든 사용할 수 있다. 말 그대로 도메인 로직을 가지고 있는 서비스인데, 그렇다면 어떤 로직이 domain service에 들어가고 어떤 로직이 entity/vo에 들어가는지를 알아야 한다. ",
    "url": "/docs/ddd/tactical/domain-service#%EB%8F%84%EB%A9%94%EC%9D%B8-%EC%84%9C%EB%B9%84%EC%8A%A4-domain-service",
    
    "relUrl": "/docs/ddd/tactical/domain-service#도메인-서비스-domain-service"
  },"375": {
    "doc": "DDD의 Domain Service란? Domain Service를 모른다면 DDD를 할 줄 모르는 것이다",
    "title": "도메인 모델에서 서비스가 생성되는 경우",
    "content": "일반적으로 이런 상황에서 사용할 수 있다. | Perform a significant business process | Transform a domain object from one composition to another | Calculate a Value requiring input from more than one domain object | . 아래와 같은 상황에서는 필수로 사용해야 한다. 1. Entity/VO에서 적절하지 않은 함수 . 도메인 내의 함수 중 Entity나 VO의 자연스러운 책임이 아닌 경우 독립된 인터페이스로서 서비스로 선언된 operation model을 선언한다. 그러니까 Aggregate이나 VO에서 수행되어야 하는 operation이 각 Aggregate/VO의 함수로 적절하지 않다고 느껴질 때가 도메인 서비스를 사용할 때이다. 대표적인 경우는 함수로 부적절하다고 느껴질 때 static method를 생성하는 경향이 있다. 이런 경우를 Vaughn Vernon은 냄새나는 코드라고 표현했다. 도메인 서비스를 써야한다는 냄새! . 예시 . 최근에 VO에 추가한 static method가 생각이 났다. public class CountVo { // ... public static CountVo add(CountVo augend, CountVo addend) { return new CountVo(augend.imageCount + addend.imageCount, augend.videoCount + addend.videoCount); } } . 위와 같은 코드가 들어갔는데, CountVo에 대한 로직을 CountVo가 갖도록하기 위함이었다. 나는 반대했던 코드인데 뭔가 이상했기 때문이다. 이 책을 보면서 명확한 것은 이런 이상한 느낌(책에서 말하는 냄새나는?)이 도메인 서비스를 써야한다는 신호인 것 같다. 2. domain 로직이 밖으로 유출되는 경우 . domain 로직은 domain 영역 밖으로는 절대로 유출되서는 안된다. 즉, client로 유출되서는 안된다는 말이다. 심지어 client가 application service라고 할지라도. | client의 책임은 모든 세부사항을 다루는 domain operation을 호출하는 역할 뿐이다. | . 여기서 절대로의 의미는 아주 당연하다고 생각되는 작은 로직도 비즈니스 로직이면 application service에 존재해서는 안된다는 말이다. | 예를 들면 위와 같이 값을 더하는 단순 덧셈 연산 로직일지라도. | application은 이 domain 로직(덧셈 연산)을 요청할 책임이 있는 것. | . ",
    "url": "/docs/ddd/tactical/domain-service#%EB%8F%84%EB%A9%94%EC%9D%B8-%EB%AA%A8%EB%8D%B8%EC%97%90%EC%84%9C-%EC%84%9C%EB%B9%84%EC%8A%A4%EA%B0%80-%EC%83%9D%EC%84%B1%EB%90%98%EB%8A%94-%EA%B2%BD%EC%9A%B0",
    
    "relUrl": "/docs/ddd/tactical/domain-service#도메인-모델에서-서비스가-생성되는-경우"
  },"376": {
    "doc": "DDD의 Domain Service란? Domain Service를 모른다면 DDD를 할 줄 모르는 것이다",
    "title": "도메인 서비스가 아닌 경우",
    "content": "무엇보다 중요한 것은 domain service가 과하면 안된다는 것이다. 적절한 상황에만 service로 domain 로직을 모델링 해야지, 지나치게 되면 domain 로직이 Entity와 VO에 흩어지지 못하고 service에만 몰리게 된다. | 이건 제대로 모델링 된 domain이라고 할 수 없다. | . service라는 단어가 뭔가 거창해보일 수 있다. domain service에서 service라는 단어가 들어있다고해서 대단위이거나 원격 기능이 있는 무거운 트랜잭션 오퍼레이션이라는 의미가 아니다. 아닌 경우: 트랜잭션이나 보안은 애플리케이션 서비스내에서 다뤄질 애플리케이션의 문제이지 도메인 서비스에서 다뤄선 안 된다. 애플리케이션 서비스는 당연히 아니다. 복잡한 비즈니스 시스템과 상호교류 하도록 해주는 단위의 큰 컴포넌트. ",
    "url": "/docs/ddd/tactical/domain-service#%EB%8F%84%EB%A9%94%EC%9D%B8-%EC%84%9C%EB%B9%84%EC%8A%A4%EA%B0%80-%EC%95%84%EB%8B%8C-%EA%B2%BD%EC%9A%B0",
    
    "relUrl": "/docs/ddd/tactical/domain-service#도메인-서비스가-아닌-경우"
  },"377": {
    "doc": "DDD의 Domain Service란? Domain Service를 모른다면 DDD를 할 줄 모르는 것이다",
    "title": "도메인 서비스 분리",
    "content": "서비스에 분리된 인터페이스가 있어야 하는지 판단해야 한다. | 인터페이스 구현체는 domain 영역 밖에 있을 수 있다. | . 분리된 인터페이스는 반드시 필요한 것은 아니다. 단일 클래스를 사용해도 된다. | 여기에 대해선 논란이 많다. | . java 프로젝트에서 interface를 접두사로 하고 -impl을 접미사로 하는 방식이 꽤 보편적이다. 그리고 심지어 같은 package에 위치하기도 한다. 이런 네이밍이라면 인터페이스 분리가 필요가 없다거나 네이밍을 신중하게 생각해야한다는 의미일 수 있다. -impl, Default-는 좋지 않다. 여러 특정한 구현을 제공하고 그 구현에 맞게 분리하게 된다면 그에 맞게 이름을 붙여야 한다. | repository -&gt; mysqlRepository | . 혹은 의존성 분리를 위해 인터페이스를 나눌 수 있다. ",
    "url": "/docs/ddd/tactical/domain-service#%EB%8F%84%EB%A9%94%EC%9D%B8-%EC%84%9C%EB%B9%84%EC%8A%A4-%EB%B6%84%EB%A6%AC",
    
    "relUrl": "/docs/ddd/tactical/domain-service#도메인-서비스-분리"
  },"378": {
    "doc": "DDD의 Domain Service란? Domain Service를 모른다면 DDD를 할 줄 모르는 것이다",
    "title": "예제 코드로 이해하기",
    "content": "책에 있는 코드가 domain service를 더 명확하게 이해하게 도와주는 것 같다. client code . UserDescriptor userDescriptor = DomainRegistry .authenticationService() .authenticate(aTenantId, aUsername, aPassword); . service code . package com.saasovation.identityaccess.infrastructure.services; public class DefaultEncryptionAuthenticationService implements AuthenticationService { @Override public UserDescriptor authenticate(TenantId aTenantId, String aUsername, String aPassword) { if (aTenantId == null) { throw new IllegalArgumentException(\"TenantId must not be null.\"); } if (aUsername == null) { throw new IllegalArgumentException(\"Username must not be null.\"); } if (aPassword == null) { throw new IllegalArgumentException(\"Password must not be null.\"); } UserDescriptor userDescriptor = null; Tenant tenant = DomainRegistry .tenantRepository() .tenantOfId(aTenantId); if (tenant != null &amp;&amp; tenant.isActive()) { String encryptedPassword = DomainRegistry .encryptionService() .encryptedValue(aPassword); User user = DomainRegistry .userRepository() .userFromAuthenticCredentials( aTenantId, aUsername, encryptedPassword); if (user != null &amp;&amp; user.isEnabled()) { userDescriptor = user.userDescriptor(); } } return userDescriptor; } } . 코드에서 배운 점: . | service가 없다면 client가 tenant, user, encrypt domain을 호출해서 어떻게 인증할지를 알아야 한다. | 이건 너무 과하다. | 세부 사항은 모두 domain으로 넣어야 한다. 이를 위해 domain service를 사용한다. | . | domain service가 필요에 따라 구현체는 다른 package(domain 밖)에 존재할 수 있다. | 생각한 것보다 많은 부분이 domain service일 수 있다. | . reference . | Implement Domain Driven Design (chapter7 Domain Events), Vaughn Vernon | . ",
    "url": "/docs/ddd/tactical/domain-service#%EC%98%88%EC%A0%9C-%EC%BD%94%EB%93%9C%EB%A1%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/ddd/tactical/domain-service#예제-코드로-이해하기"
  },"379": {
    "doc": "DDD의 Domain Service란? Domain Service를 모른다면 DDD를 할 줄 모르는 것이다",
    "title": "DDD의 Domain Service란? Domain Service를 모른다면 DDD를 할 줄 모르는 것이다",
    "content": "DDD tactical components . VO Entity Domain Service Domain Events Aggregate . 개념만 보면 domain은 domain 로직이 있는 곳이다. 막상 개발/설계를 해보니 어디까지가 domain service이고 어디까지가 application service 인지의 분간하는게 쉽지가 않다. 어떤 팀원들은 domain service는 모르고 entity나 vo에 domain service의 로직이 들어가거나, domain 로직을 domain 밖에 구현하는 경우도 있다. 설계 할때는 이게 맞다 저게 맞다 토론을 하곤 하는데 항상 돌이켜보면 어딘가는 잘못 설계된 것 같다. DDD의 도메인을 이해하는데 절대 빠질 수 없는 요소는 domain service이다. domain service에 대해 명확하게 이해해야 domain 로직을 지키는 온전한 도메인 개발을 해낼 수 있다. ",
    "url": "/docs/ddd/tactical/domain-service",
    
    "relUrl": "/docs/ddd/tactical/domain-service"
  },"380": {
    "doc": "CMS GC란? CMS GC를 이해하고 차이점 알기",
    "title": "CMS (Concurrent Mark Sweep)",
    "content": "Parallel Garbage Collection은 결과적인 효율(전체 시간 대비 STW 시간)은 좋지만 하나의 STW이 긴 편이다. 이를 해결하기 위해 CMS GC가 도입되었다. CMS GC는 전체적인 성능이 비교적 조금 떨어질 수 있지만 STW로 인해 응답하지 못하는 시간이 길어지지 않도록 하는 것이 목표이다. Java 9부터 deprecated 되었고, Java 14에서 drop 되었다. ",
    "url": "/docs/java/gc/cms_gc#cms-concurrent-mark-sweep",
    
    "relUrl": "/docs/java/gc/cms_gc#cms-concurrent-mark-sweep"
  },"381": {
    "doc": "CMS GC란? CMS GC를 이해하고 차이점 알기",
    "title": "Parallel vs CMS",
    "content": "Minor GC(young)의 경우 Parallel과 유사하다. 모든 thread가 Minor GC 수행 시 중단되고 GC 작업은 multi thread로 수행된다. Major GC(old)의 경우 Parallel과 다르다. CMS의 목적은 STW를 방지하는 것이고 이를 위해 짧은 STW를 제외하고는 GC를 application thread 수행과 동시에 수행된다. | GC로 인한 모든 thread의 STW가 최대한 발생하지 않도록 | . ",
    "url": "/docs/java/gc/cms_gc#parallel-vs-cms",
    
    "relUrl": "/docs/java/gc/cms_gc#parallel-vs-cms"
  },"382": {
    "doc": "CMS GC란? CMS GC를 이해하고 차이점 알기",
    "title": "GC process",
    "content": ". | . Initial-Mark . 여기서는 Old GC가 STW로 initial-mark를 진행한다. Marking/Pre-Cleaning . initial-mark가 끝나면 application thread가 동작하면서 일부 CMS thread에서만 을 진행한다. | 이때부터 STW는 끝난 것이다. | . 이 때 hardware thread가 충분하면 CMS thread의 실행 overhead가 성능에 거의 영향을 미치지 않는다. 그러나 충분하지 않을 경우에는 application thread랑 CPU 경합을 벌이면서 성능에 영향을 미치게 된다. Remark . initial-mark 이후에 marking/pre-cleaning 동안 누락되었을 수 있는 objects를 mark한다. Concurrent Sweeping . 모든 dead object의 memory를 free 한다. ",
    "url": "/docs/java/gc/cms_gc#gc-process",
    
    "relUrl": "/docs/java/gc/cms_gc#gc-process"
  },"383": {
    "doc": "CMS GC란? CMS GC를 이해하고 차이점 알기",
    "title": "CMS GC 특징",
    "content": "짧은 STW를 유지하기 위해 사용하는 concurrent 방식을 위해 parallel GC보다 10~20% 더 많은 heap을 필요로 한다. | heap이 부족해지기 전에 GC 작업이 완료될 수 있도록 tuning 하는 것이 중요하다. | . Major GC가 진행되는 동안 Minor GC가 발생할 수 있다. 이런 경우 Major GC가 중단되고, Minor GC가 완료된 이후에 다시 시작된다. 기본적으로 parallel GC에 비해 application thread가 멈추는 시간이 짧다. | 그렇지만 GC에 소모되는 시간은 더 길다. | GC cycle 동안 application 처리율은 감소한다. | GC가 객체를 추적해야하므로 CPU/memory를 더 많이 쓴다. | . ",
    "url": "/docs/java/gc/cms_gc#cms-gc-%ED%8A%B9%EC%A7%95",
    
    "relUrl": "/docs/java/gc/cms_gc#cms-gc-특징"
  },"384": {
    "doc": "CMS GC란? CMS GC를 이해하고 차이점 알기",
    "title": "CMF (Concurrent Mode Failure)",
    "content": "할당률이 급증하면 young GC 시에 조기 승격(premature promotion)이 발생하고 승격된 객체가 너무 많아 tenured 영역도 부족한 상태가 벌어질 수 있다. 이런 현상을 CMF라고 하고 JVM은 어쩔 수 없이 full STW를 유발하는 Parallel GC로 돌아간다. | 새로 승격된 객체를 old에서 처리하여 memory를 확보 할 시간도 없이 새로운 객체가 생성되는 현상. | . CMS는 compaction을 하지 않기 때문에 비어잇는 공간들(fragmentation)이 새로운 객체를 할당하기 위한 공간보다 작을 수 있고, 이것도 CMF로 가는데 영향을 미칠 수 있다. | fragmentation은 예측 불가능하기 때문에 더 문제 | . Parallel GC로 가면 STW의 시간이 길어지기 때문에 CMS를 쓰는 장점이 사라진다. CMF가 자주 일어나지 않게 하려면 tenured가 차기 전에 CMS GC가 돌아야 한다. CMS GC는 tenured가 default 75%가 차면 도는데 값을 지정할 수 있다. ",
    "url": "/docs/java/gc/cms_gc#cmf-concurrent-mode-failure",
    
    "relUrl": "/docs/java/gc/cms_gc#cmf-concurrent-mode-failure"
  },"385": {
    "doc": "CMS GC란? CMS GC를 이해하고 차이점 알기",
    "title": "command",
    "content": "-XX:+UseConcMarkSweepGC으로 사용할 수 있다. | java -XX:+UseConcMarkSweepGC -jar demo.jar | . ",
    "url": "/docs/java/gc/cms_gc#command",
    
    "relUrl": "/docs/java/gc/cms_gc#command"
  },"386": {
    "doc": "CMS GC란? CMS GC를 이해하고 차이점 알기",
    "title": "reference",
    "content": ". | https://www.baeldung.com/jvm-garbage-collectors | https://www.informit.com/articles/article.aspx?p=2496621&amp;seqNum=4 | https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html | Optimizing Java, chapter7 | . ",
    "url": "/docs/java/gc/cms_gc#reference",
    
    "relUrl": "/docs/java/gc/cms_gc#reference"
  },"387": {
    "doc": "CMS GC란? CMS GC를 이해하고 차이점 알기",
    "title": "CMS GC란? CMS GC를 이해하고 차이점 알기",
    "content": "Java GC Type . Serial GC Parallel GC CMS GC G1 GC . ",
    "url": "/docs/java/gc/cms_gc",
    
    "relUrl": "/docs/java/gc/cms_gc"
  },"388": {
    "doc": "intellij 의미 없는 시간 줄이기 live template 편",
    "title": "intellij 의미 없는 시간 줄이기 live template 편",
    "content": "intellij는 개발 시간을 단축할 수 있는 여러 기능들을 제공한다. 그 중 내가 가장 많이 사용하는 것 중 하나가 live template이다. 이게 뭔지는 중요하지 않다. 써보면 안다. live template 확인하기 . | (ctrl + alt + s) 로 settings 진입 | Editor &gt; Live Templates | 각 언어 확인 | . 여기서 각 언어를 들어가면 intellij에서 기본적으로 제공하는 live template 들을 확인할 수 있다. 몇 개를 써보면 금방 감이 온다. 개발 시간을 단축시킬 수 있는 유용한 template 들이 많아서 template 리스트를 확인하는 것도 의미가 있다. 예시 . sout을 입력하고 enter 혹은 tab을 누르면 java에서는 System.out.println();이 완성된다. 이렇게 자주 쓰이는 template들을 약어로 등록하는 것을 live template이라고 한다. live template 설정하기 . 나는 TDD 개발에서 자주 사용하는 given-when-then template을 사용한다. 이게 단순한데 매번 테스트 생성이 번거로워 live template으로 등록하는데 이걸 예로 들어보자. | (ctrl + alt + s) 로 settings 진입 | Editor &gt; Live Templates | 언어 선택 -&gt; kotlin | add | . 아래와 같이 tm, tc에 대해 추가하기 . // Abbreviation: tm // Description: make test method @Test fun $testname$() { // given // when // then } . // Abbreviation: tc // Description: make test class @Nested class $classname$ { } . 동작 확인 . 간단하지만 정말 많은 시간을 줄일 수 있는 template. ",
    "url": "/docs/dev-tools/intellij/live-template",
    
    "relUrl": "/docs/dev-tools/intellij/live-template"
  },"389": {
    "doc": "Google, MS, Oracle의 Java naming convention & 약어 convention",
    "title": "Google, MS, Oracle의 Java naming convention & 약어 convention",
    "content": "네이밍 규칙은 당연히 class, variable, method를 떠나서 명확하고 단순해야 한다. 팀 내에 네이밍에 대한 룰이 정해져있지 않다면 네이밍에 대한 논란이 생기기 쉽고, 팀원마다 생각이 달라 합의를 보기 어려운 경우가 있다. 최근 우리팀에서는 약어 규칙을 어떻게 할 것인가에 대한 논란이 있었다. 각자 다른 생각을 정리하기 위해 여러 기업들의 naming convention을 같이 정리해보았다. 결국 우리 팀은 정리된 약어 규칙을 기반으로 네이밍 룰을 정의했다. Package . | package에는 소문자와 숫자만 사용한다. (Oracle / Google) ✔️ com.example.deepspace ⚠️ com.example.deepSpace ⚠️ com.example.deep_space | . Class . | class name은 명사거나 명사구여야 한다. (W3 / Oracle / Google) ✔️ SpaceShip ⚠️ launchSpaceship | class name의 첫 글자는 대문자여야 한다. UpperCamelCase (W3 / Oracle / Google) ✔️ SpaceShip ⚠️ spaceship ⚠️ spaceShip | . variable . | variable은 lowerCamelCase1이어야 한다. (W3 / Google / Oracle) ✔️ speed ⚠️ Speed ⚠️ SPEED | variable는 명사거나 명사구여야 한다. (W3 / Google) ✔️ fuelLevel ⚠️ calculateFuel | 임시 변수를 제외하고는 한 문자 변수는 안된다. (Oracle) ✔️ point ⚠️ p | . Method . | method는 동사거나 동사구여야 한다. (Oracle / Google) ✔️ calculateDistance ⚠️ distance | method은 lowerCamelCase1이어야 한다. (Oracle / Google) ✔️ calculateDistance ⚠️ CalculateDistance ⚠️ calculate_distance | . Constant . | _ 로 구분된 단어로 모두 대문자여야 한다. (Oracle / Google) ✔️ MAX_SPEED ⚠️ MaxSpeed ⚠️ max_speed | . Test . | test class는 Test라는 postfix로 끝난다 (Google) ✔️ CalculatorTest ⚠️ TestCalculator | . 공통 규칙 . | 내부에서 여러 단어가 사용될 때 각 단어의 첫 글자는 대문자여야 한다. (Oracle / Google) ✔️ DeepSpaceMissionControlCenter ⚠️ deepspacemissioncontrolcenter ⚠️ deep_space_mission_control_center . | 의미없는 prefix, postfix를 사용하지 않는다. (Google) ✔️ name ⚠️ name_ ⚠️ mName . | . 약어 규칙 . | 약어가 full name보다 대중적이고 더 잘 이해되는 단어가 아닌 이상 전체 단어를 사용해야 한다. (W3 / MS) | 약어를 사용할 때도 동일하게 CamelCase2를 적용해야한다. (MS) . | 예를 들면 UUIDIP라는 변수를 생성할 때, uuidIp가 맞고, 이는 Id 처럼 하나의 약어만 사용할 때도 마찬가지다. | 약어도 camelCase를 적용하는 이유는 대표적으로 . | 가독성이 훨씬 좋다. | 약어를 혼동하지 않을 수 있다. (AB, CDE, ABC, DE 와 같은 약어가 있을 때, ABCDE는 어떤 약어인지 알 수 없다) | . | . ✔️ JSON ⚠️ ID -&gt; ️✔️ Id ⚠️ Win -&gt; ️✔️ Window ⚠️ UUIDIPJSON -&gt; ️✔️ UuidIpJson ⚠️ ABCDE -&gt; ️✔️ AbcDe ⚠️ ABCDE -&gt; ️✔️ AbCde . | . Reference . | https://www.w3.org/2005/rules/wg/wiki/Arch/Naming_Conventions | https://www.oracle.com/java/technologies/javase/codeconventions-namingconventions.html | https://docs.microsoft.com/en-us/previous-versions/dotnet/netframework-1.1/141e06ef(v=vs.71)?redirectedfrom=MSDN | https://google.github.io/styleguide/javaguide.html#s5-naming | . | CamelCase와 달리 lowerCamelCase는 첫 문자는 소문자로 시작한다. 그 이후의 단어의 첫 문자는 대문자가 된다. &#8617; &#8617;2 . | CamelCase는 낙타의 등 모양을 본따서 지어진 이름으로 여러 단어가 합쳐진 경우 각 단어의 첫 글자를 대문자로 표기하는 기법이다. &#8617; . | . ",
    "url": "/docs/java/naming-conventions",
    
    "relUrl": "/docs/java/naming-conventions"
  },"390": {
    "doc": "intellij 의미 없는 시간 줄이기 test file 편",
    "title": "intellij 의미 없는 시간 줄이기 test file 편",
    "content": "intellij는 개발 시간을 단축할 수 있는 여러 기능들을 제공한다. 한 번 설정해두면 짜잘짜잘한 시간들을 아낄 수 있는 방법 중 하나는 test file 생성을 template화 하는 것이다. 이게 뭔지는 중요하지 않다. 써보면 안다. 설정 확인하기 . | (ctrl + alt + s) 로 settings 진입 | Editor &gt; File and Code Templates | JUnit5 Test Class 확인 | . 여기서는 어떤 test를 쓰느냐에 따라 다르다. JUnit5를 기준으로 설명한다. 이해하기 . import org.junit.jupiter.api.Assertions.*; #parse(\"File Header.java\") class ${NAME} { ${BODY} } . 우선 설정을 보면 위와 같이 되어있는 것을 확인할 수 있다. 이건 import org.junit.jupiter.api.Assertions.*;를 자동으로 import하고, class 골격을 만든다는 뜻이다. 기본적으로 source code에서 Ctrl + Shift + T를 누르면 template으로 생성된 test class file을 확인할 수 있다. 오늘 목표는 자주 사용되는 import 들을 미리 추가하는 것. 설정하기 . 위 template을 아래와 같이 바꾼다. 나 같은 경우는 junit5의 기본 Test 등과 mock 설정을 위한 import를 추가했다. import org.junit.jupiter.api.Assertions.*; import org.junit.jupiter.api.Test; import org.junit.jupiter.api.Nested; import org.junit.jupiter.api.extension.ExtendWith; import org.assertj.core.api.Assertions.assertThat; import org.mockito.Mockito.*; import org.mockito.Mock; import org.mockito.InjectMocks; import org.mockito.junit.jupiter.MockitoExtension; #parse(\"File Header.java\") class ${NAME} { ${BODY} } . 이득 . intelij에서는 간단하게 import를 할 수 있지만 테스트 클래스를 자주 생성하는 경우 은근히 도움이 된다. | 그리고 일단 귀찮지 않다. | intelij에서는 Optimize Import를 하면 사용하지 않는 import는 모두 제거해주니까 추가해두는 것이 아무 문제가 되지 않는다. | Junit5를 설정하면 Java, Kotlin 모두 적용된다. | . ",
    "url": "/docs/dev-tools/intellij/test-file-template",
    
    "relUrl": "/docs/dev-tools/intellij/test-file-template"
  },"391": {
    "doc": "SQL vs NoSQL",
    "title": "SQL with Normalization",
    "content": "RDBS에서 가장 중요하게 생각하는 것은 정규화이다. 그렇다면 왜 정규화를 하는가? 이 것이 중요하다. 정규화를 하는 목적은 당연히 데이터의 중복을 제거하는 것이 가장 크다. | 물론 이를 통한 데이터의 일관성을 유지하는 목적도 있다. | . 얼핏 보면 당연하지만 데이터의 중복을 제거하는 것이 왜 중요했는지는 시대적 배경을 보면 이해가 된다. hard drive로 보는 Normalization . 1956년 IBM의 5MB hard drive를 한 달 대여하는 비용이 $3200 이었다. | 2019년 가격으로 환산하면 약 $30000 이다. | . 당시에는 hard disk가 이와 같이 굉장히 비쌌기 때문에 hard disk를 효율적으로 사용하는 것이 가장 중요한 일이 되었다. 따라서 당시에 개발되고 주로 사용되던 RDBS에서는 데이터의 중복을 최소화하는 방향으로 개발 되었다. 사실, 정규화하는 operation은 CPU를 사용하는 것인데 CPU를 더 사용하는 비용을 지불하여 disk 비용을 줄이는 것이라고 볼 수 있다. 그치만 현재에 와서는 hard disk 값은 굉장히 싸졌다. ",
    "url": "/docs/db/why-use-nosql#sql-with-normalization",
    
    "relUrl": "/docs/db/why-use-nosql#sql-with-normalization"
  },"392": {
    "doc": "SQL vs NoSQL",
    "title": "그래서 SQL vs NoSQL",
    "content": "그래서 CPU 비용이 되려 비싼 현재에서는 정규화로 과도한 disk 비용을 줄이는 것보다 CPU 비용을 줄이고 disk 비용을 늘리는 방향의 NoSQL이 틀리지 않다. ",
    "url": "/docs/db/why-use-nosql#%EA%B7%B8%EB%9E%98%EC%84%9C-sql-vs-nosql",
    
    "relUrl": "/docs/db/why-use-nosql#그래서-sql-vs-nosql"
  },"393": {
    "doc": "SQL vs NoSQL",
    "title": "아마존의 dynamodb",
    "content": "NoSQL은 최근에 와서야 개발되기 시작한 기술이다. 다른 NoSQL들도 비슷한 상황에서 개발되었는데 아마존에서는 어떻게 dynamodb를 개발하게 되었는지를 보면 이해가 된다. | 2004년 12월 . | 12월은 아마존 쇼핑에서 트래픽이 가장 큰 달이다. | DB scalability 이슈가 발생했다. | . | 2007년 10월 . | 현재의 dynamodb와는 다르지만 dynamo 논문이 발표되었다. | . | 2012년 1월 . | dynamodb genaral availability | . | . SQL에서는 ACID 때문에 scale을 늘리는 것이 더 쉽지 않고, 최근의 enterprise급 service들은 scale이 굉장히 크기 때문에 NoSQL이 발전하게 되었다. ",
    "url": "/docs/db/why-use-nosql#%EC%95%84%EB%A7%88%EC%A1%B4%EC%9D%98-dynamodb",
    
    "relUrl": "/docs/db/why-use-nosql#아마존의-dynamodb"
  },"394": {
    "doc": "SQL vs NoSQL",
    "title": "Scale up vs Scale out",
    "content": ". 위와 같이 sql은 ACID 지원등을 이유로 scale up(vertical-scaling)을 해야 하는게 기본이다. 반면에 nosql들은 scale out(horizontal scaling)으로 관리할 수 있어 scale 관리가 쉽다. ",
    "url": "/docs/db/why-use-nosql#scale-up-vs-scale-out",
    
    "relUrl": "/docs/db/why-use-nosql#scale-up-vs-scale-out"
  },"395": {
    "doc": "SQL vs NoSQL",
    "title": "결론",
    "content": "규모있는 서비스를 하는 경우는 scalable하게 사용 가능한지를 따져봐야하고 그런 면에서 NoSQL이 용이하다. | scaling이 쉽기 때문 | . 그러나 global 대기업들에서 여전히 SQL을 많이 쓰고 있다. (보통 둘 다 쓴다) 그럴 수 있는 이유는 SQL을 scalable하게 사용할 수 있도록 managing 하는 내부 service들을 이미 가지고 있기 때문이다. nosql을 선택하는데는 여러 기준이 있겠지만 scaling을 고려한다면 enterprise 급인데 SQL을 scalable하게 관리하는 service가 없다면 nosql을 충분히 고려해볼만 하다. | 우리 회사도 그렇다. | . 현재는 SQL이 NoSQL의 장점을, NoSQL이 SQL의 장점을 따라가고 있어 경계가 모호해지는 부분들도 있다. reference . | AWS immersion day session 강의 | https://proftomcrick.com/2011/12/26/in-1956-5mb-was-big-enough-for-anyone/ | https://softwareengineering.stackexchange.com/questions/194340/why-are-nosql-databases-more-scalable-than-sql | https://www.iunera.com/kraken/uncategorized/what-is-a-nosql-database/ | . ",
    "url": "/docs/db/why-use-nosql#%EA%B2%B0%EB%A1%A0",
    
    "relUrl": "/docs/db/why-use-nosql#결론"
  },"396": {
    "doc": "SQL vs NoSQL",
    "title": "SQL vs NoSQL",
    "content": "AWS에서 진행하는 dynamodb immersion day 세션에 참여할 수 있는 기회가 생겼다. 강사님께서 왜 nosql을 사용하게 되었고 쓰는지에 대한 배경을 설명해주신 것이 인상적어서 정리해본다. ",
    "url": "/docs/db/why-use-nosql",
    
    "relUrl": "/docs/db/why-use-nosql"
  },"397": {
    "doc": "Instagram, Facebook에서 배우는 유저 제한 정책, 서비스 정책의 중요성",
    "title": "인스타그램 사례",
    "content": "limits (제약 사항)에 대해 잘 적용된 서비스는 인스타그램만한 예시가 없을 것 같다. 이해하기도 쉽고. instagram의 Inauthentic Activity과 spam 정책1에서 instagram은 Inauthentic Activity이 결국 사용자와 서비스를 위한 것이라고 말한다. 이런 허위 활동이 결국 서비스의 질을 떨어트리고 커뮤니티를 망가뜨린다는 것이다. 실제로 초기 페이스북에서 spam이 굉장히 많아 사용자가 이탈한 사건들이 있으니 이런 것들을 만들게 된 것이라고 예상해본다. 허위 활동이라는 것은 서비스 관리도 어렵지만 서비스 질도 떨어뜨린다는 것이 페이스북도 주목한 문제인 것 같다. 인스타그램은 사용자와 api에 대해 적절하게 제한을 두고 있다. 사용자에 대한 제한 . | 제한 대상 | 제한 | . | follow 숫자 제한 | 7500명 | . | likes 제한 | 시간 당 120개 하루에 300-500개 | . | comments 제한 | 하루에 200개 | . | people tag 제한 | post 하나에 20명 | . | DM 제한 | 하루에 50-70명 | . 신뢰성이 높은 유저(가입한지 6개월이 지난 유저 등)인지에 따라 제한이 다르지만, 전체 제한 및 시간/일 별 제한 정책을 가지고 있다. 여기서 follow 숫자를 제외한 다른 정책들은 instagram에서 공식적으로 open한 내용은 아니다. 다만 관련된 많은 글들을 통해 정책을 확인할 수 있다. 예상하건데 시간당 제한은 abusing 유저나 사용할 수 있을만한 숫자이기 때문에 공식적으로 발표하지 않은 것으로 생각한다. Api에 대한 제한 . developer에게 open한 api에서는 24시간에 25개의 post만 생성할 수 있도록 제한한다. ",
    "url": "/docs/service-management/user-limits#%EC%9D%B8%EC%8A%A4%ED%83%80%EA%B7%B8%EB%9E%A8-%EC%82%AC%EB%A1%80",
    
    "relUrl": "/docs/service-management/user-limits#인스타그램-사례"
  },"398": {
    "doc": "Instagram, Facebook에서 배우는 유저 제한 정책, 서비스 정책의 중요성",
    "title": "facebook 사례",
    "content": "흥미로운 점은 facebook은 abusing, spam, sexual post 등에 대해 지표2를 관리하고 공개하고 있다. 우리 서비스는 더 완성도 높아지고 있다는걸 보여주기 위함인 것 같다. 잘못 abusing으로 체크한 경우까지 open하고 있는데 공개하지 못하더라도 배워야할 부분인 것은 분명하다. ",
    "url": "/docs/service-management/user-limits#facebook-%EC%82%AC%EB%A1%80",
    
    "relUrl": "/docs/service-management/user-limits#facebook-사례"
  },"399": {
    "doc": "Instagram, Facebook에서 배우는 유저 제한 정책, 서비스 정책의 중요성",
    "title": "limits에 대해 생각 정리하기",
    "content": "허위 활동을 막기 위해 인스타그램에서는 여러가지 limit을 두고 있다. limit의 숫자들을 어떻게 잡았는지는 모르지만 이걸 정책으로 잡았다는 점이 중요하다. 계산이야 서비스마다 다르겠지만, abusing이 아닌 경우 사용할 수 없는 양을 계산하고 제한하는 것. 서비스를 하기 이전에는 “설마 이런 유저가 있겠어?” 라는 생각을 하지만 그치만 대규모 서비스를 한다면 진짜 무조건 있다. 그런 사람들. 꼭 여럿이 있다. 혹은 봇일 수도 있다. “없겠지”가 아니라 “있을 수 없어”라고 만드는 것이 정책이다. 그리고 이러한 정책은 반드시 서비스에 반영되어야 한다. 이로 인한 장점들은 잠깐만 생각해도 명확하다. ",
    "url": "/docs/service-management/user-limits#limits%EC%97%90-%EB%8C%80%ED%95%B4-%EC%83%9D%EA%B0%81-%EC%A0%95%EB%A6%AC%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/service-management/user-limits#limits에-대해-생각-정리하기"
  },"400": {
    "doc": "Instagram, Facebook에서 배우는 유저 제한 정책, 서비스 정책의 중요성",
    "title": "limit으로 인한 장점들",
    "content": "간단하게 운영 관점과 서비스 관점에서 이슈들을 볼 수 있다. 운영 이슈 . 인스타그램 기준으로 정책이 없다면 follow 하는 수가 100만, 10억 명이 되었을 때 구조를 다시 잡아야 할 것이다. (여기서 follow는 내가 follow하는 수) 내가 팔로우 하는 사람이 100만 명인 것은 말이 안된다. 100만 명을 팔로우 하는건 애초에 정상적이지 않으며, 이게 가능하다면 매일 업로드 되는 피드와 스토리를 감당할 수도 없다. 여기서도 “당연히 100만 명을 팔로우하지 않을거야” 가 아니라, 당연한 것을 불가능하게 만드는 정책의 반영이 중요하다. 정책으로 제한하는 것은 쉽지만, 100만 명을 만든 계정이 생겼을 때 후처리하는 것은 법적인 문제와 더불어 굉장한 골칫덩어리다. 어뷰징을 위한 별도의 아키텍처 설계가 필요할 수도 있다. 서비스 이슈 . 서비스 이슈가 생긴다는 것은 결국 품질 하락을 의미한다. 품질 하락은 서비스 경쟁력을 떨어트리며 소비자 이탈과 결국 서비스의 성패와도 이어진다. 인스타그램의 사례를 다시 가져오면 follow를 마구 할 수 있어 follow count를 어지럽히는 abusing 사용자가 늘어난다면. 현재도 있는 follow를 늘려주는 abusing service들이 더 날뛰게 될 것이며 그로 인해 bot들이 만드는 post와 의미없는 광고의 비율이 늘어날 것이다. 이는 결국 떨어진 품질로 인한 서비스 품질 하락으로 이어진다. ",
    "url": "/docs/service-management/user-limits#limit%EC%9C%BC%EB%A1%9C-%EC%9D%B8%ED%95%9C-%EC%9E%A5%EC%A0%90%EB%93%A4",
    
    "relUrl": "/docs/service-management/user-limits#limit으로-인한-장점들"
  },"401": {
    "doc": "Instagram, Facebook에서 배우는 유저 제한 정책, 서비스 정책의 중요성",
    "title": "limit 정하기",
    "content": "limit은 빨리 정해야 한다. 나중가면 limit을 넣기 힘들기 때문에 개발자라고 할지라도 서비스를 오픈하는 단계라면 먼저 제안할 수 있어야 한다. 현재 내가 맡은 서비스는 abusing 때문에 서비스 이슈가 나는 경우는 잘 없지만 운영 이슈가 너무 명확하고 비용을 크게 잡아 먹고 있다. 아쉬운 점은 이런 정책들을 서버 개발자가 정하기는 어렵다는 것. 특히 서비스 중간에 정책을 반영하기란 쉽지 않다. PM님 설득좀 되세요! :scream: . reference . | 전체 follow 수 제한 . | https://help.instagram.com/408167069251249?locale=ko_KR | . | 공식적으로 open하지 않은 제한 . | https://goinstagram.com/instagram-follow-unfollow-limit/ | . | api 제한 . | https://developers.facebook.com/docs/instagram-api/guides/content-publishing | . | . | 허위 활동에 대한 instagram의 글을 통해 Inauthentic Activity를 대하는 instagram의 태도를 알 수 있다. &#8617; . | facebook 지표를 통해 페이스북은 스팸 block을 고지한다. &#8617; . | . ",
    "url": "/docs/service-management/user-limits#limit-%EC%A0%95%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/service-management/user-limits#limit-정하기"
  },"402": {
    "doc": "Instagram, Facebook에서 배우는 유저 제한 정책, 서비스 정책의 중요성",
    "title": "Instagram, Facebook에서 배우는 유저 제한 정책, 서비스 정책의 중요성",
    "content": "규모 있는 서비스를 관리하다보면 unnormal case에 대한 처리가 batch 작업마다 꼭 생기곤 한다. 이런 이슈 중 상당 수는 user limit에 대한 제한이 없기 때문이 아닌가 싶다. 최근 회사에서 abusing user 이슈를 겪었다. 내가 관리하는 서비스 중 일정을 동기화 하는 서비스가 있는데, batch 작업 중 사용자 한 명이 100만 개 이상의 일정을 가지고 있는 케이스를 발견했다. 반복 일정(매주 화요일 10시 회의) 같은건 하나의 일정으로 치는 것을 감안했을 때 일반 사용자가 만들어낸 일정이라고 볼 수 없었다. | 심지어 10분 만에 1000개의 일정을 만들기도 했다. | . 덕분에 batch 로직의 변경과 instance type 변경 등의 별도 작업과 시간을 써야했다. 전부터 우리 회사 서비스에서 아쉬웠던 것은 이런 정책적인 제한이 (거의) 없다는 것이다. 최근 인스타그램과 페이스북의 api를 보면서 우리 문제를 돌아보게 되었다. ",
    "url": "/docs/service-management/user-limits",
    
    "relUrl": "/docs/service-management/user-limits"
  },"403": {
    "doc": "dynamo 내부구조 이해하기",
    "title": "partitioning",
    "content": "mysql에서는 sharding을 하지만 비슷한 목적으로 dynamodb는 partitioning을 한다. 즉 data를 partition 단위로 나눈다는 것이다. 이 partition 하나는 10GB를 저장할 수 있고, WCU는 1KB, RCU는 3KB까지 수용할 수 있다. 따라서 저장공간이 10GB가 넘거나 WCU/RCU가 넘치는 경우 partition을 다시 나누도록 한다. ",
    "url": "/docs/aws/dynamo/structure#partitioning",
    
    "relUrl": "/docs/aws/dynamo/structure#partitioning"
  },"404": {
    "doc": "dynamo 내부구조 이해하기",
    "title": "dynamodb 내부구조",
    "content": "dynamo의 내부 architecture에 대해서 배우면 partition에 대한 제약들을 더 잘 이해할 수 있다. 위 그림처럼 . | dynamodb로 request가 들어오면 requestRouter 중에 한 곳으로 할당된다. | requestRouter에서 storageNode로 routing을 한다. | . 여기서 중요한 점은 storage node는 3개의 node로 이루어져 있다는 것인데, leaderNode와 2개의 followerNode이다. | db write가 발생하면 leaderNode가 업데이트되고 leaderNode가 followerNode에 data를 복제한다. | 3개 중 2개의 node가 업데이트가 되면 node에서 ack를 보낸다. | . ",
    "url": "/docs/aws/dynamo/structure#dynamodb-%EB%82%B4%EB%B6%80%EA%B5%AC%EC%A1%B0",
    
    "relUrl": "/docs/aws/dynamo/structure#dynamodb-내부구조"
  },"405": {
    "doc": "dynamo 내부구조 이해하기",
    "title": "내부구조 보고 제약사항 이해하기",
    "content": "위 개념을 이해하면 제약들을 이해하기 쉽다. 하나의 node는 1KB의 CU만을 갖는다. | read는 3개의 node에서 이뤄질 수 있으므로 RCU는 \\(1KB * 3 = 3KB\\). | write는 leaderNode에서만 이뤄지므로 WCU는 1KB. | . 각 node는 10GB의 저장공간을 가지므로 하나의 partition의 max size는 10GB. eventually consistancy에서 read를 할 경우 . | read 요청이 \\(1/3\\) 확률로 각 node로 가게 된다. | 위에서 말했듯 3개 중 2개의 node가 업데이트 되면 ack를 보내기 때문에 나머지 하나는 업데이트 되지 않았을 수 있다. | \\(1/3\\) 확률 &amp; 1/3의 노드가 아직 업데이트 되기 이전에, read 요청이 들어온 경우 old data를 가져갈 수 있다. | 물론 대부분의 case는 그 전에 업데이트 되는 편이다. | . strong consistance는 read를 할 경우 항상 leader node로 간다. ",
    "url": "/docs/aws/dynamo/structure#%EB%82%B4%EB%B6%80%EA%B5%AC%EC%A1%B0-%EB%B3%B4%EA%B3%A0-%EC%A0%9C%EC%95%BD%EC%82%AC%ED%95%AD-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/aws/dynamo/structure#내부구조-보고-제약사항-이해하기"
  },"406": {
    "doc": "dynamo 내부구조 이해하기",
    "title": "partitioning 참고사항",
    "content": "10GB가 되지 않는 경우 하나의 partition은 여러 개의 partition key를 가질 수 있다. 여러 개의 partition key를 가진 data set(partition)이 커질 경우 partition key를 기반으로 두 개의 partition으로 분리된다. 하나의 partition key에 대한 data set이 커지는 경우에도 역시 partition key를 기반으로 partition이 분리된다. dynamodb가 내부적으로 hash된 값을 key로 사용하기 때문에 동일한 partition key에 대해 데이터가 커지는 경우도 커버할 수 있다. reference . | AWS immersion day session 강의 | . ",
    "url": "/docs/aws/dynamo/structure#partitioning-%EC%B0%B8%EA%B3%A0%EC%82%AC%ED%95%AD",
    
    "relUrl": "/docs/aws/dynamo/structure#partitioning-참고사항"
  },"407": {
    "doc": "dynamo 내부구조 이해하기",
    "title": "dynamo 내부구조 이해하기",
    "content": "dynamo를 사용하기 위해서 꼭 알고있어야 하는 값들이 있다. WCU, RCU, partition의 max size. AWS immersion day session 강의를 들으면서 원래는 외우고 있었던 것들을 이해할 수 있는 시간이 되었다. 왜 nosql?의 내용도 도움이 된다. ",
    "url": "/docs/aws/dynamo/structure",
    
    "relUrl": "/docs/aws/dynamo/structure"
  },"408": {
    "doc": "[kotlin error] ClassNotFoundException: kotlin.jvm.JvmInline",
    "title": "에러 메세지",
    "content": "Caused by: java.lang.ClassNotFoundException: kotlin.jvm.JvmInline at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:582) at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178) at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521) ... 80 more . ",
    "url": "/docs/error-bug/kotlin/ClassNotFoundException_kotlin_jvm_JvmInline#%EC%97%90%EB%9F%AC-%EB%A9%94%EC%84%B8%EC%A7%80",
    
    "relUrl": "/docs/error-bug/kotlin/ClassNotFoundException_kotlin_jvm_JvmInline#에러-메세지"
  },"409": {
    "doc": "[kotlin error] ClassNotFoundException: kotlin.jvm.JvmInline",
    "title": "코드",
    "content": "&lt;!-- pom.xml --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.module&lt;/groupId&gt; &lt;artifactId&gt;jackson-module-kotlin&lt;/artifactId&gt; &lt;version&gt;2.13.3&lt;/version&gt; &lt;/dependency&gt; . ",
    "url": "/docs/error-bug/kotlin/ClassNotFoundException_kotlin_jvm_JvmInline#%EC%BD%94%EB%93%9C",
    
    "relUrl": "/docs/error-bug/kotlin/ClassNotFoundException_kotlin_jvm_JvmInline#코드"
  },"410": {
    "doc": "[kotlin error] ClassNotFoundException: kotlin.jvm.JvmInline",
    "title": "해결",
    "content": "&lt;!-- pom.xml --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.module&lt;/groupId&gt; &lt;artifactId&gt;jackson-module-kotlin&lt;/artifactId&gt; &lt;version&gt;2.12.7&lt;/version&gt; &lt;/dependency&gt; . ",
    "url": "/docs/error-bug/kotlin/ClassNotFoundException_kotlin_jvm_JvmInline#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/error-bug/kotlin/ClassNotFoundException_kotlin_jvm_JvmInline#해결"
  },"411": {
    "doc": "[kotlin error] ClassNotFoundException: kotlin.jvm.JvmInline",
    "title": "원인",
    "content": "jackson-module-kotlin에서 2.13 version 부터 kotlin 1.5를 사용하기 시작했다. | 참고로 JvmInline이 kotlin 1.5에서 나왔음. | . dependency version을 내리거나, kotlin verison을 올리면 된다. ",
    "url": "/docs/error-bug/kotlin/ClassNotFoundException_kotlin_jvm_JvmInline#%EC%9B%90%EC%9D%B8",
    
    "relUrl": "/docs/error-bug/kotlin/ClassNotFoundException_kotlin_jvm_JvmInline#원인"
  },"412": {
    "doc": "[kotlin error] ClassNotFoundException: kotlin.jvm.JvmInline",
    "title": "reference",
    "content": "https://github.com/FasterXML/jackson-module-kotlin/issues/523 . ",
    "url": "/docs/error-bug/kotlin/ClassNotFoundException_kotlin_jvm_JvmInline#reference",
    
    "relUrl": "/docs/error-bug/kotlin/ClassNotFoundException_kotlin_jvm_JvmInline#reference"
  },"413": {
    "doc": "[kotlin error] ClassNotFoundException: kotlin.jvm.JvmInline",
    "title": "[kotlin error] ClassNotFoundException: kotlin.jvm.JvmInline",
    "content": "kotlin에서 jackson-module-kotlin를 사용할 때 에러. ",
    "url": "/docs/error-bug/kotlin/ClassNotFoundException_kotlin_jvm_JvmInline",
    
    "relUrl": "/docs/error-bug/kotlin/ClassNotFoundException_kotlin_jvm_JvmInline"
  },"414": {
    "doc": "[spring error] Unable to find a @SpringBootConfiguration",
    "title": "에러 메세지",
    "content": "java.lang.IllegalStateException: Unable to find a @SpringBootConfiguration, you need to use @ContextConfiguration or @SpringBootTest(classes=...) with your test at org.springframework.util.Assert.state(Assert.java:76) at org.springframework.boot.test.context.SpringBootTestContextBootstrapper.getOrFindConfigurationClasses(SpringBootTestContextBootstrapper.java:236) at org.springframework.boot.test.context.SpringBootTestContextBootstrapper.processMergedContextConfiguration(SpringBootTestContextBootstrapper.java:152) at org.springframework.test.context.support.AbstractTestContextBootstrapper.buildMergedContextConfiguration(AbstractTestContextBootstrapper.java:392) at org.springframework.test.context.support.AbstractTestContextBootstrapper.buildDefaultMergedContextConfiguration(AbstractTestContextBootstrapper.java:309) at org.springframework.test.context.support.AbstractTestContextBootstrapper.buildMergedContextConfiguration(AbstractTestContextBootstrapper.java:262) at org.springframework.test.context.support.AbstractTestContextBootstrapper.buildTestContext(AbstractTestContextBootstrapper.java:107) at org.springframework.boot.test.context.SpringBootTestContextBootstrapper.buildTestContext(SpringBootTestContextBootstrapper.java:102) at org.springframework.test.context.TestContextManager.&lt;init&gt;(TestContextManager.java:137) at org.springframework.test.context.TestContextManager.&lt;init&gt;(TestContextManager.java:122) at org.junit.jupiter.engine.execution.ExtensionValuesStore.lambda$getOrComputeIfAbsent$4(ExtensionValuesStore.java:86) at org.junit.jupiter.engine.execution.ExtensionValuesStore$MemoizingSupplier.computeValue(ExtensionValuesStore.java:223) at org.junit.jupiter.engine.execution.ExtensionValuesStore$MemoizingSupplier.get(ExtensionValuesStore.java:211) at org.junit.jupiter.engine.execution.ExtensionValuesStore$StoredValue.evaluate(ExtensionValuesStore.java:191) at org.junit.jupiter.engine.execution.ExtensionValuesStore$StoredValue.access$100(ExtensionValuesStore.java:171) at org.junit.jupiter.engine.execution.ExtensionValuesStore.getOrComputeIfAbsent(ExtensionValuesStore.java:89) at org.junit.jupiter.engine.execution.ExtensionValuesStore.getOrComputeIfAbsent(ExtensionValuesStore.java:93) at org.junit.jupiter.engine.execution.NamespaceAwareStore.getOrComputeIfAbsent(NamespaceAwareStore.java:61) at org.springframework.test.context.junit.jupiter.SpringExtension.getTestContextManager(SpringExtension.java:294) at org.springframework.test.context.junit.jupiter.SpringExtension.beforeAll(SpringExtension.java:113) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeBeforeAllCallbacks$10(ClassBasedTestDescriptor.java:381) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeBeforeAllCallbacks(ClassBasedTestDescriptor.java:381) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:205) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:80) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:148) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) at java.base/java.util.ArrayList.forEach(ArrayList.java:1540) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35) at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86) at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86) at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53) at com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:71) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:220) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:53) . ",
    "url": "/docs/error-bug/spring/Unable_to_find_a_SpringBootConfiguration#%EC%97%90%EB%9F%AC-%EB%A9%94%EC%84%B8%EC%A7%80",
    
    "relUrl": "/docs/error-bug/spring/Unable_to_find_a_SpringBootConfiguration#에러-메세지"
  },"415": {
    "doc": "[spring error] Unable to find a @SpringBootConfiguration",
    "title": "코드",
    "content": "spring에서 multi module 이슈라면 kotlin인지 java인지는 중요하지 않다. @ExtendWith(SpringExtension::class) @SpringBootTest class JpaRepositoryTest { @Autowired lateinit var sut: MysqlJpaRepository ... } . ",
    "url": "/docs/error-bug/spring/Unable_to_find_a_SpringBootConfiguration#%EC%BD%94%EB%93%9C",
    
    "relUrl": "/docs/error-bug/spring/Unable_to_find_a_SpringBootConfiguration#코드"
  },"416": {
    "doc": "[spring error] Unable to find a @SpringBootConfiguration",
    "title": "해결",
    "content": "@ExtendWith(SpringExtension::class) @Import(TestConfig::class) @SpringBootTest class JpaRepositoryTest { @SpringBootConfiguration @ComponentScan(\"com.meansoup\") // 여기는 base package name class TestConfig @Autowired lateinit var sut: MysqlJpaRepository ... } . ",
    "url": "/docs/error-bug/spring/Unable_to_find_a_SpringBootConfiguration#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/error-bug/spring/Unable_to_find_a_SpringBootConfiguration#해결"
  },"417": {
    "doc": "[spring error] Unable to find a @SpringBootConfiguration",
    "title": "원인",
    "content": "library가 되는 모듈에는 @SpringBootApplication이 없다. 따라서 @SpringBootConfiguration도 없는데 그렇기 때문에 bean이 있다는 것을 알지 못한다. 위와 같이 테스트에서 @SpringBootConfiguration를 명시해주므로써 bean을 인지하고 사용할 수 있다. ",
    "url": "/docs/error-bug/spring/Unable_to_find_a_SpringBootConfiguration#%EC%9B%90%EC%9D%B8",
    
    "relUrl": "/docs/error-bug/spring/Unable_to_find_a_SpringBootConfiguration#원인"
  },"418": {
    "doc": "[spring error] Unable to find a @SpringBootConfiguration",
    "title": "reference",
    "content": "https://github.com/spring-guides/gs-multi-module . | 위 프로젝트의 코드를 확인 | . https://www.baeldung.com/springbootconfiguration-annotation . | SpringBootConfiguration에 대해 | . ",
    "url": "/docs/error-bug/spring/Unable_to_find_a_SpringBootConfiguration#reference",
    
    "relUrl": "/docs/error-bug/spring/Unable_to_find_a_SpringBootConfiguration#reference"
  },"419": {
    "doc": "[spring error] Unable to find a @SpringBootConfiguration",
    "title": "[spring error] Unable to find a @SpringBootConfiguration",
    "content": "spring에서 Unable to find a @SpringBootConfiguration가 발생할 때 에러. 나 같은 경우는 multi module project를 구성할 때 에러 메세지가 나왔다. multi module에서 library module과 project module을 나눠서 구성할 때. ",
    "url": "/docs/error-bug/spring/Unable_to_find_a_SpringBootConfiguration",
    
    "relUrl": "/docs/error-bug/spring/Unable_to_find_a_SpringBootConfiguration"
  },"420": {
    "doc": "[spring error] JpaRepository NoSuchBeanDefinitionException",
    "title": "에러 메세지",
    "content": "Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.meansoup.whatisthebetter.application.port.out.like.mysql.MysqlLikeJpaRepository' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1799) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1355) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1309) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.resolveDependency(AbstractAutowireCapableBeanFactory.java:489) at org.springframework.beans.factory.annotation.ParameterResolutionDelegate.resolveDependency(ParameterResolutionDelegate.java:136) at org.springframework.test.context.junit.jupiter.SpringExtension.resolveParameter(SpringExtension.java:270) at org.junit.jupiter.engine.execution.ExecutableInvoker.resolveParameter(ExecutableInvoker.java:216) ... 54 more . ",
    "url": "/docs/error-bug/spring/NoSuchBeanDefinitionException_JpaRepository#%EC%97%90%EB%9F%AC-%EB%A9%94%EC%84%B8%EC%A7%80",
    
    "relUrl": "/docs/error-bug/spring/NoSuchBeanDefinitionException_JpaRepository#에러-메세지"
  },"421": {
    "doc": "[spring error] JpaRepository NoSuchBeanDefinitionException",
    "title": "해결",
    "content": "JpaConfiguration을 위한 class를 생성해준다. @Configuration @EnableJpaAuditing @EnableJpaRepositories(\"com.meansoup.whatisthebetter\") class JpaConfiguration {} . ",
    "url": "/docs/error-bug/spring/NoSuchBeanDefinitionException_JpaRepository#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/error-bug/spring/NoSuchBeanDefinitionException_JpaRepository#해결"
  },"422": {
    "doc": "[spring error] JpaRepository NoSuchBeanDefinitionException",
    "title": "원인",
    "content": "spring에서 jpa repository를 enable 하기 위해서 필요하다. ",
    "url": "/docs/error-bug/spring/NoSuchBeanDefinitionException_JpaRepository#%EC%9B%90%EC%9D%B8",
    
    "relUrl": "/docs/error-bug/spring/NoSuchBeanDefinitionException_JpaRepository#원인"
  },"423": {
    "doc": "[spring error] JpaRepository NoSuchBeanDefinitionException",
    "title": "[spring error] JpaRepository NoSuchBeanDefinitionException",
    "content": "spring에서 Jpa bean이 잘 생성되지 않은 경우 . ",
    "url": "/docs/error-bug/spring/NoSuchBeanDefinitionException_JpaRepository",
    
    "relUrl": "/docs/error-bug/spring/NoSuchBeanDefinitionException_JpaRepository"
  },"424": {
    "doc": "[spring error] kotlin cannot be returned by findById(), findById() should return Optional",
    "title": "에러 메세지",
    "content": "org.mockito.exceptions.misusing.WrongTypeOfReturnValue: MysqlUser cannot be returned by findById() findById() should return Optional *** If you're unsure why you're getting above error read on. Due to the nature of the syntax above problem might occur because: 1. This exception *might* occur in wrongly written multi-threaded tests. Please refer to Mockito FAQ on limitations of concurrency testing. 2. A spy is stubbed using when(spy.foo()).then() syntax. It is safer to stub spies - - with doReturn|Throw() family of methods. More in javadocs for Mockito.spy() method. ",
    "url": "/docs/error-bug/spring/kotlin_cannot_be_Returned_by_findById#%EC%97%90%EB%9F%AC-%EB%A9%94%EC%84%B8%EC%A7%80",
    
    "relUrl": "/docs/error-bug/spring/kotlin_cannot_be_Returned_by_findById#에러-메세지"
  },"425": {
    "doc": "[spring error] kotlin cannot be returned by findById(), findById() should return Optional",
    "title": "해결",
    "content": "해결 방법은 두 가지다. | mockK 적용 | test와 code가 조금 이상하게 적용 | . 나는 mockK를 적용하고 싶지 않아서 기존 mockito로 하는 방법을 설명한다. 원래 코드 . // main code val found = mysqlUserJpaRepository.findByIdOrNull(uid.toString()) // test code doReturn(mysqlUser).`when`(mysqlUserJpaRepository).findByIdOrNull(safeEq(uuid.toString())) . 원래 코드는 이렇다. Optional이 나오면 안되서 findByIdOrNull을 사용하는데, 에러는 findById에 대한 에러를 받는 것. 해결 코드 . // main code val found = mysqlUserJpaRepository.findByIdOrNull(uid.toString()) // test code doReturn(Optional.of(mysqlUser)).`when`(mysqlUserJpaRepository).findById(safeEq(uuid.toString())) . 해결 코드는 main code는 findByIdOrNull을 적용하고, test code에는 findById로 테스트한다. ",
    "url": "/docs/error-bug/spring/kotlin_cannot_be_Returned_by_findById#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/error-bug/spring/kotlin_cannot_be_Returned_by_findById#해결"
  },"426": {
    "doc": "[spring error] kotlin cannot be returned by findById(), findById() should return Optional",
    "title": "원인",
    "content": "findByIdOrNull은 kotlin에서 정의한 extension code이다. mockito는 static method에 대한 mocking(kotlin의 extension code)를 지원할 계획이 없으며, 따라서 findByIdOrNull의 실제 코드인 findById가 mockito에서 잡히는 상황. 테스트에서는 findById를 사용해줘야 한다. 혹은 mockK를 사용하면 해결할 수 있다. ",
    "url": "/docs/error-bug/spring/kotlin_cannot_be_Returned_by_findById#%EC%9B%90%EC%9D%B8",
    
    "relUrl": "/docs/error-bug/spring/kotlin_cannot_be_Returned_by_findById#원인"
  },"427": {
    "doc": "[spring error] kotlin cannot be returned by findById(), findById() should return Optional",
    "title": "reference",
    "content": "https://stackoverflow.com/questions/59562177/mockito-findbyidornull-issue https://github.com/mockito/mockito/issues/1481 . ",
    "url": "/docs/error-bug/spring/kotlin_cannot_be_Returned_by_findById#reference",
    
    "relUrl": "/docs/error-bug/spring/kotlin_cannot_be_Returned_by_findById#reference"
  },"428": {
    "doc": "[spring error] kotlin cannot be returned by findById(), findById() should return Optional",
    "title": "[spring error] kotlin cannot be returned by findById(), findById() should return Optional",
    "content": "kotlin에서 jpa findById 사용하기. kotlin spring에서 java에서 사용하던 것처럼 jpa를 사용하려고 하면 만나는 에러에 대한 해결이다. ",
    "url": "/docs/error-bug/spring/kotlin_cannot_be_Returned_by_findById",
    
    "relUrl": "/docs/error-bug/spring/kotlin_cannot_be_Returned_by_findById"
  },"429": {
    "doc": "intellij 대소문자 변경 단축키",
    "title": "intellij 대소문자 변경 단축키",
    "content": "uppercase to lowercase. 대문자를 소문자로, 소문자를 대문자로 바꾸는 intellij 단축키가 있다. 이게 별 것 아닌 것 같지만 세로 편집과 함께하면 효율성이 극대화 된다. ubuntu에서 옵션을 찾아서 수행하다가 안됐던 것을 해결해서 정리해본다. 내가 대소문자 단축키를 사용하는 방법 . 나는 평소에도 세로 편집을 굉장히 자주 사용한다. getter &amp; setter의 변경, entity와 dto 간의 mapping과 factory 생성 등에서 세로 편집은 굉장한 효율을 낸다. 여기에 대소문자 변경까지 단축키로 더해지면 굉장하다. toggle case shortcut . intellij에서는 대소문자 변경을 toggle case라고 이름 지었다. ctrl + shift + U 를 통해서 대문자를 소문자로, 소문자를 대문자로 바꿀 수 있다. ubuntu 이슈 . windows나 mac에서는 사용할 수 있는데, ubuntu에서는 계속 shortcut이 동작하지 않았다. 이번에 확인했는데, ubuntu에서는 이미 ctrl + shift + U를 emoji 단축키로 사용하고 있다. 이건 거의 사용하지 않는 키니까 변경하거나 삭제하면 된다. ubuntu 이슈 해결 . | 커맨드에 ibus-setup 입력 | Emoji tab으로 이동 | ctrl + shift + U가 세팅되어 있는 unicode code point를 선택 | 삭제 혹은 이동 | . 나 같은 경우는 해당 코드를 삭제했다. reference . https://youtrack.jetbrains.codm/issue/IDEA-112533 . ",
    "url": "/docs/dev-tools/intellij/upper-case",
    
    "relUrl": "/docs/dev-tools/intellij/upper-case"
  },"430": {
    "doc": "G1GC란? G1GC를 이해하고 다른 GC랑 비교하기",
    "title": "G1",
    "content": "G1은 Garbage First 라는 이름으로 지어진 GC이다. 큰 memory를 갖는 multiprocessor machine을 타겟으로 높은 throughput과 작은 pause-time 목표로 만들어져서 현재는 java의 default GC이다. java 6에서 처음 선보이고 7에서 광범위하게 수정됐고 8u40 부터 안정된 GC가 되었다. | workload에 상관없이 8u40 이전 버전에선 G1을 쓰지 않는게 좋다. | . G1 특징 . | CMS 보다 훨씬 튜닝하기 쉽다. | 조기 승격에 덜 취약하다. | 대용량 heap에서 확장성(특히 중단시간)이 우수하다. | full STW GC를 없애거나 확 줄일 수 있다. | Java 9 부터 default GC | 이전의 GC와 다르다. | generation 마다 경계가 명확한 memory가 없다. | . | . G1 heap . G1의 heap은 region으로 구성된다. region은 default 1MB인 memory 공간이고 heap이 커질수록 크기가 커진다. (세팅 가능) region을 이용해서 generation 별로 연속적인 메모리 공간을 갖지 않아도 되고 GC 수행마다 매번 전체 garbage를 collect 하지 않아도 된다. G1 에서는 1, 2, 4, 6, 8, 16, 32, 64MB 크기의 region을 사용할 수 있고, 기본적으로 heap에는 2048~4095 개의 region을 가질 수 있다. 모든 region의 크기는 동일하고 JVM 실행 중에 크기가 변경되지 않는다. | region의 크기는 heap size / 2048에서 허용된 값으로 반올림하여 계산 | region 개수는 heap size / region size | . G1 알고리즘 . young-only . | object를 old generation으로 승격시키는 단계 | old generation의 occupancy가 특정 임계점(Initial Heap Occupancy)을 넘을 때 young only에서 space reclamation 단계로 전환된다. | . initial mark . | young GC와 동시에 marking을 시작한다. | space reclamation 단계를 위해 old generation에서의 live object를 결정한다. | marking이 끝나지 않더라도 young collection은 발생할 수 있다. | marking은 remark와 cleanup으로 완료된다. | . remark . | STW | marking을 끝내는 단계 | global reference를 수행하고 class unloading 함 | remark와 cleanup에서 liveness information을 계산하고 내부 데이터 구조를 업데이트 하기 위해 사용되고 마무리 된다. | . cleanup . | STW | 완전히 비어있는 region을 정리하고 space-reclamation을 수행할지 결정한다. | . space reclamation . | young과 old의 live object를 evacuate 하는 단계 | old region을 더 만힝 비워도 노력할만한 공간이 나오지 않는다고 판단될 때 종료 | . Region Set . G1은 region 별로 GC 작업을 수행하므로 대규모 Java heap에 적합하다. Java heap이 크더라도 GC 작업의 양은 작은 Region set으로 제한되기 때문. G1에는 RSet(Remembered Set)라는 장치가 있음. region 별로 하나씩 외부에서 region 내부 region을 참조하는 레퍼런스를 관리하기 위한 장치. G1에서는 region 내부를 바라보는 레퍼런스를 찾기 위해 전체 heap을 뒤질 필요 없이 RSet만 보면 된다. Humongous Objects . G1은 Region size의 50% 가 넘는 객체에 대해 연속되게 할당할 수 있는 region들을 찾는다. 사용할 수 있는 연속된 region이 충분하지 않는 경우 full GC를 통해 heap을 compaction 한다. humongous object의 region은 old region 중 하나로 간주되고 하나의 object만 포함한다. full GC 중에도 움직이지 않는다. | region을 통채로 쓰니 당연한 것 같다. | . 사용하지 않을 경우 cleanup 단계나 full GC에서 수집될 수 있다. | 예외적으로 java primitive type에 대한 array인 경우 어떤 gc 단계에서도 수집할 수 있다. | . G1에서 humongous는 old gc에서 수집되니까 수명이 짧은 humongous는 참조되지 않는 시점을 훨씬 지나서 회수될 수 있는 문제가 있다. | 경우에 따라 young GC에서 수집하는 방법이 구현됨 | 그러나 G1에선 잦은 houmongous 할당은 좋지 않음 | . 다른 GC와 비교 . | Parallel GC는 전체적으로만 Old Generation의 GC가 가능하다. | 반면 G1은 이 작업을 훨씬 더 짧게 여러번에 걸쳐 수행된다. 이렇게 하면 STW가 크게 줄어든다. | . | CMS와 유사하게 G1은 Old Generation GC의 일부를 동시에 수행합니다. | 그렇지만 CMS는 Old generation heap을 조각 모음할 수 없으므로 결국 긴 Full GC가 필요하다. | . | G1은 다른 수집기보다 높은 오버헤드가 있을 수 있고 동시 특성으로 인해 처리량에 영향이 있다. | G1은 old generation의 비어있는 넓은 영역을 GC 할 수 있고, 이는 불필요한 GC 노력 없이 큰 공간을 확보할 수 있다. | . command . +XX:UseG1GC . G1의 주 목표는 중단 시간의 단축이고 GC 마다 application의 최대 중단 시간을 설정할 수 있다. 그러나 이 값은 목표치이고 실제 이 기준에 맞춘다고 보장하진 못한다. 100ms 이하는 현실성이 너무 떨어져 GC가 지키지 못할 가능성이 크다. -XX:MaxGCPauseMillis=200 // 중단 시간을 200ms로 설정 . 1부터 64까지(MB)의 수로 region size를 변경할수도 있다. -XX:G1HeapRegionSize=&lt;n&gt; . ",
    "url": "/docs/java/gc/g1_gc#g1",
    
    "relUrl": "/docs/java/gc/g1_gc#g1"
  },"431": {
    "doc": "G1GC란? G1GC를 이해하고 다른 GC랑 비교하기",
    "title": "reference",
    "content": ". | https://docs.oracle.com/javase/9/gctuning/garbage-first-garbage-collector.htm#JSGCT-GUID-AC383806-7FA7-4698-8B92-4FD092B9F368 | https://www.informit.com/articles/article.aspx?p=2496621&amp;seqNum=5 | Optimizing Java, chapter7 | . ",
    "url": "/docs/java/gc/g1_gc#reference",
    
    "relUrl": "/docs/java/gc/g1_gc#reference"
  },"432": {
    "doc": "G1GC란? G1GC를 이해하고 다른 GC랑 비교하기",
    "title": "G1GC란? G1GC를 이해하고 다른 GC랑 비교하기",
    "content": "Java GC Type . Serial GC Parallel GC CMS GC G1 GC . ",
    "url": "/docs/java/gc/g1_gc",
    
    "relUrl": "/docs/java/gc/g1_gc"
  },"433": {
    "doc": "slack에서 스마트하게 추정하기",
    "title": "demo",
    "content": ". 공식 사이트에서 제공하는 demo를 그대로 가져왔다. 직접 사용해도 동일하게 편하게 사용할 수 있다. ",
    "url": "/docs/dev-tools/slack/pocker-planner#demo",
    
    "relUrl": "/docs/dev-tools/slack/pocker-planner#demo"
  },"434": {
    "doc": "slack에서 스마트하게 추정하기",
    "title": "slack pocker planner",
    "content": "https://deniz.co/slack-poker-planner/ . 옛날 방식의 앱이긴 하나 굉장히 효율적이었다. 팀 내에서도 좋은 반응을 받았다. ",
    "url": "/docs/dev-tools/slack/pocker-planner#slack-pocker-planner",
    
    "relUrl": "/docs/dev-tools/slack/pocker-planner#slack-pocker-planner"
  },"435": {
    "doc": "slack에서 스마트하게 추정하기",
    "title": "사용법",
    "content": ". | 위 사이트에서 add to slack | add 완료 (권한이 없다면 권한 요청) | install slack app | slack 채널에 pocker planner 추가 | /pp {title}으로 사용 | . reference . | https://deniz.co/slack-poker-planner | . ",
    "url": "/docs/dev-tools/slack/pocker-planner#%EC%82%AC%EC%9A%A9%EB%B2%95",
    
    "relUrl": "/docs/dev-tools/slack/pocker-planner#사용법"
  },"436": {
    "doc": "slack에서 스마트하게 추정하기",
    "title": "slack에서 스마트하게 추정하기",
    "content": "원격 근무가 많아지면서 회의하는 방식에 대한 변화도 당연히 생기기 마련이다. 우리는 agile하게 일을 진행하는데, sprint를 할 때는 story에 대한 추정을 한다. 추정 방식은 핸드폰의scrum pocker 앱을 통해 해왔었는데, 원격 근무를 하게 되면 회의할 때 ‘하나 둘 셋’ 하고 자기가 선택한 포커 숫자를 화면에 공개하고 있었다. 최근 회사 보안 문제로 카메라를 켜지 못하는 상황이 되어 웃긴 상황이 벌어졌다. ‘하나 둘 셋’ 하고 슬랙 쓰레드에 각자 추정하는 값을 입력하는 방식… . 최첨단을 달리고자 하는 개발자들이 하기에 조금 아쉽지 않나 싶다. 더 스마트하게 추정을 할 수 없을까 싶어 찾다가 발견한 슬랙 앱. ",
    "url": "/docs/dev-tools/slack/pocker-planner",
    
    "relUrl": "/docs/dev-tools/slack/pocker-planner"
  },"437": {
    "doc": "[spring error] ConflictingBeanDefinitionException: Annotation-specified bean name",
    "title": "에러 메세지",
    "content": "org.junit.jupiter.api.extension.ParameterResolutionException: Failed to resolve parameter [org.springframework.test.web.reactive.server.WebTestClient webClient] in constructor [public com.meansoup.whatisthebetter.was.rest.post.CreatePostControllerTest(org.springframework.test.web.reactive.server.WebTestClient)]: Failed to load ApplicationContext at org.junit.jupiter.engine.execution.ExecutableInvoker.resolveParameter(ExecutableInvoker.java:239) at org.junit.jupiter.engine.execution.ExecutableInvoker.resolveParameters(ExecutableInvoker.java:183) at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:74) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeTestClassConstructor(ClassBasedTestDescriptor.java:355) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateTestClass(ClassBasedTestDescriptor.java:302) at org.junit.jupiter.engine.descriptor.ClassTestDescriptor.instantiateTestClass(ClassTestDescriptor.java:79) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateAndPostProcessTestInstance(ClassBasedTestDescriptor.java:280) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$4(ClassBasedTestDescriptor.java:272) at java.base/java.util.Optional.orElseGet(Optional.java:369) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$5(ClassBasedTestDescriptor.java:271) at org.junit.jupiter.engine.execution.TestInstancesProvider.getTestInstances(TestInstancesProvider.java:31) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$prepare$0(TestMethodTestDescriptor.java:102) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:101) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:66) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:90) at java.base/java.util.ArrayList.forEach(ArrayList.java:1540) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) at java.base/java.util.ArrayList.forEach(ArrayList.java:1540) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35) at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86) at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86) at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53) at com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:71) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:220) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:53) Caused by: java.lang.IllegalStateException: Failed to load ApplicationContext at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:132) at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:124) at org.springframework.test.context.junit.jupiter.SpringExtension.getApplicationContext(SpringExtension.java:283) at org.springframework.test.context.junit.jupiter.SpringExtension.resolveParameter(SpringExtension.java:269) at org.junit.jupiter.engine.execution.ExecutableInvoker.resolveParameter(ExecutableInvoker.java:216) ... 54 more Caused by: org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [com.meansoup.whatisthebetter.was.WhatisthebetterApplication]; nested exception is org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'createPostController' for bean class [com.meansoup.whatisthebetter.adapter.in.rest.post.CreatePostController] conflicts with existing, non-compatible bean definition of same name and class [com.meansoup.whatisthebetter.was.rest.post.CreatePostController] at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:189) at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:331) at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:247) at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:311) at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:112) at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:746) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:564) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408) at org.springframework.boot.SpringApplication.run(SpringApplication.java:308) at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:132) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124) ... 58 more Caused by: org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'createPostController' for bean class [com.meansoup.whatisthebetter.adapter.in.rest.post.CreatePostController] conflicts with existing, non-compatible bean definition of same name and class [com.meansoup.whatisthebetter.was.rest.post.CreatePostController] at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.checkCandidate(ClassPathBeanDefinitionScanner.java:349) at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.doScan(ClassPathBeanDefinitionScanner.java:287) at org.springframework.context.annotation.ComponentScanAnnotationParser.parse(ComponentScanAnnotationParser.java:128) at org.springframework.context.annotation.ConfigurationClassParser.doProcessConfigurationClass(ConfigurationClassParser.java:296) at org.springframework.context.annotation.ConfigurationClassParser.processConfigurationClass(ConfigurationClassParser.java:250) at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:207) at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:175) ... 71 more . ",
    "url": "/docs/error-bug/spring/ConflictingBeanDefinitionException#%EC%97%90%EB%9F%AC-%EB%A9%94%EC%84%B8%EC%A7%80",
    
    "relUrl": "/docs/error-bug/spring/ConflictingBeanDefinitionException#에러-메세지"
  },"438": {
    "doc": "[spring error] ConflictingBeanDefinitionException: Annotation-specified bean name",
    "title": "해결",
    "content": "exception 이름에서 알 수 있다시피 동일한 이름의 bean이 생성된 문제. 일반적으로 동일한 bean이 존재하는 경우인데, 나 같은 경우는 multi module을 구성하면서 동일한 name의 bean을 양 module에서 생성하면서 문제가 발생했다. 사실 하나는 이전에 모듈에 있다가 지웠는데 빌드된게 남아있었던 듯. | mvn clean . | 대부분의 사람들은 이걸로 해결했다고 한다. | . | target directory 삭제 . | mvn clean이 원활하게 되지 않았고, target directory를 삭제해서 빌드된 파일들을 제거해서 해결했다. | . | . ",
    "url": "/docs/error-bug/spring/ConflictingBeanDefinitionException#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/error-bug/spring/ConflictingBeanDefinitionException#해결"
  },"439": {
    "doc": "[spring error] ConflictingBeanDefinitionException: Annotation-specified bean name",
    "title": "[spring error] ConflictingBeanDefinitionException: Annotation-specified bean name",
    "content": "spring에서 테스트 수행중 발생한 에러. 아마 server를 띄우는 중에도 유사한 에러가 발생하는 것 같다. 나 같은 경우는 multi module project를 구성하는 중 에러가 발생했다. ",
    "url": "/docs/error-bug/spring/ConflictingBeanDefinitionException",
    
    "relUrl": "/docs/error-bug/spring/ConflictingBeanDefinitionException"
  },"440": {
    "doc": "[intellij error] Maven 3.3.1+ requires JDK 1.7+",
    "title": "환경",
    "content": "windows, intellij 2020 and 2022, kotlin spring, multi-module project . ",
    "url": "/docs/error-bug/intellij/maven-jdk-version#%ED%99%98%EA%B2%BD",
    
    "relUrl": "/docs/error-bug/intellij/maven-jdk-version#환경"
  },"441": {
    "doc": "[intellij error] Maven 3.3.1+ requires JDK 1.7+",
    "title": "에러 메세지",
    "content": "왼쪽 하단에 팝업 노티로 아래와 같은 메세지가 출력. Error running 'whatisthebetter-was [package]': Maven 3.3.1+ requires JDK 1.7+. Please set appropriate JDK . ",
    "url": "/docs/error-bug/intellij/maven-jdk-version#%EC%97%90%EB%9F%AC-%EB%A9%94%EC%84%B8%EC%A7%80",
    
    "relUrl": "/docs/error-bug/intellij/maven-jdk-version#에러-메세지"
  },"442": {
    "doc": "[intellij error] Maven 3.3.1+ requires JDK 1.7+",
    "title": "해결",
    "content": ". | Settings(Ctrl + Alt + S) 진입 | Build, Execution, Deployment &gt; Build Tools &gt; maven &gt; importing 진입 | JDK for importer를 내가 가지고 있는 java 버전으로 설정 . | 나 같은 경우는 openjdk 11. | 윈도우 default 인지 모르겠으나, 초기 설정은 Use Project JDK으로 되어있었음. | . | . 이래도 해결되지 않았다면, . | Build, Execution, Deployment &gt; Build Tools &gt; maven &gt; Runner 진입 | 위와 동일하게 내가 가지고 있는 java 버전으로 설정 | . ",
    "url": "/docs/error-bug/intellij/maven-jdk-version#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/error-bug/intellij/maven-jdk-version#해결"
  },"443": {
    "doc": "[intellij error] Maven 3.3.1+ requires JDK 1.7+",
    "title": "[intellij error] Maven 3.3.1+ requires JDK 1.7+",
    "content": "intellij에서 maven build 혹은 package 시 발생한 에러. ",
    "url": "/docs/error-bug/intellij/maven-jdk-version",
    
    "relUrl": "/docs/error-bug/intellij/maven-jdk-version"
  },"444": {
    "doc": "DDD의 Entity란? Entity와 ID를 제대로 이해하기",
    "title": "Why use Entities",
    "content": "우리가 entity를 사용하는 이유. domain 개념에서 다른 모든 객체외 반드시 구분해야 하는 경우, 즉 individuality가 필요할 때 entity로 설계한다. entity는 긴 시간에 걸쳐 계속 변화할 수 있는 model. 처음 모습과 많이 달라질 수 있지만 같은 식별자를 가진다면 같은 객체다. VO와 명확하게 구분되는 개념은 ID와 mutability. | 그치만 대부분의 domain model은 VO로 모델링 되는게 맞다. | Vaughn Vernon은 모든 model이 Entity로 모델링 될 바에는 Vo로 모델링 되는게 맞다고 했다. 그만큼 Vo로 최대한 모델링을 진행하라는 것. | . ",
    "url": "/docs/ddd/tactical/entity#why-use-entities",
    
    "relUrl": "/docs/ddd/tactical/entity#why-use-entities"
  },"445": {
    "doc": "DDD의 Entity란? Entity와 ID를 제대로 이해하기",
    "title": "ID",
    "content": "entity는 반드시 고유하게 식별되고 구분되어야 한다. 따라서 entity를 설계할 때는 같은 타입의 여러 객체 중에 원하는 entity를 찾을 때 필요한 속성이 무엇인지 아는게 중요하다. 그냥 모델링을 해놓고 ID를 붙이면 안된다는 말이다. ID는 안정성 확보를 위해 immutable 해야 한다. 그렇기 때문에 entity의 ID로서 VO가 사용될 수 있다. 그리고 ID는 setter가 open 되지 않게 보호되어야 한다. ID가 탐색이나 매칭에 사용될 수 있지만 그렇지 않을 가능성도 높다. 예시 . 인물 정보에 대한 검색을 예로들면 사람의 이름을 ID로 쓰는 일은 거의 없을 것이다. 당연히 중복된 이름이 존재할 수 있고 이는 entity의 특성에 어긋난다. 따라서 human readable하지 않은 ID가 내부적으로 존재할 수 있다. 위에서 설명한 원하는 entity를 찾을 때 필요한 속성이 여기서는 이름이 될 것이다. ",
    "url": "/docs/ddd/tactical/entity#id",
    
    "relUrl": "/docs/ddd/tactical/entity#id"
  },"446": {
    "doc": "DDD의 Entity란? Entity와 ID를 제대로 이해하기",
    "title": "ID 생성 방법",
    "content": "1. 사용자가 입력한 초기 고유 값을 사용 . ID를 생성하는 일을 사용자에게 의지하겠다는 것. 이런 방식은 사실 양질의 ID를 만들 생각이 없다는 것. ID를 사용자가 바꿔선 안되는데 이런 약속이 지켜져야 한다. 사실 이 방법은 쓰면 안되겠지. 2. application 내부에 고유성이 보장되는 알고리즘을 사용 . library나 framework를 사용할 수도 있다. UUID, GUID를 사용할 수 있다. | 신뢰도가 높고 | 32bytes의 사람이 읽을 수 없는 값 | . 이 방법이 가장 많이 쓰이는 방법일 것이다. 3. DB 같은 영속성 저장소를 사용해 ID 생성 . db는 필요한 범위에 따라 고유 값을 생성해준다. | 도메인 모델이 db에 의존하게 된다. | ID를 얻기 위해 db까지 가야하니 성능상 단점이 될 수 있다. | . 대리 식별자 . hibiernate 같은 경우는 숫자 시퀀스 같은 db primitive type을 식별자로 선호한다. 도메인에서 다른 유형의 식별자가 필요하다면 두 개의 식별자를 사용해야 한다. | 도메인 모델에 맞춰 설계된 식별자 | hibernate를 위한 식별자, 대리 식별자 | . 대리 속성은 도메인 모델의 일부가 아니기 때문에 감추는 편이 바람직하다. 대리 속성을 감추기 위해 abstract Entity class 같은 것을 만들어서 구현하도록 하는 방식으로 감출 수 있다. 4. 다른 바운디드 컨텍스트가 ID 할당 . 다른 바운디드 컨텍스트가 ID를 할당할 때는 ID의 검색과 매칭이 필요하다. 예시 . ID를 찾기위해 계좌번호, 사용자 명, 이메일 주소 등의 속성을 제공해야 하고, 이 속성들과 ID가 1대 1로 매칭되는 것이 가장 이상적이다. 식별자 생성 시점 . 클라이언트가 도메인 이벤트를 구독하는 경우 새로운 entity의 인스턴스화가 완료되면 이벤트가 발생할 수 있다. 도메인 이벤트가 올바르게 초기화 되기 위해선 식별자 생성을 빠르게 완료해야 한다. ",
    "url": "/docs/ddd/tactical/entity#id-%EC%83%9D%EC%84%B1-%EB%B0%A9%EB%B2%95",
    
    "relUrl": "/docs/ddd/tactical/entity#id-생성-방법"
  },"447": {
    "doc": "DDD의 Entity란? Entity와 ID를 제대로 이해하기",
    "title": "entity 설계",
    "content": "entity 설계 초기에는 ID를 중심으로 우선적인 특성과 행동을 비롯해 쿼리에 도움을 주는 요소에 집중한다. | entity를 다른 entity들과 구분할 수 있는 특성에 먼저 집중해서 ID를 확인하는 것. | 비지니스적 속성을 먼저 해결하려고하면 문제가 생길 수 있다. | ID와 엑세스 컨텍스트, entity를 찾기 위한 필수적인 속성을 먼저 고려해야 한다. | . entity가 이름이나 설명과 같은 다른 수단으로도 query가 된다면 그 property들도 contructor에 포함시킨다. | 이렇게 생성이 성공적으로 이뤄지면 이 변수들은 절대 null이 되지 않는다. 이를 constructor와 constructor의 setter가 보장해야 한다. | . 예시 . user 객체는 tenantId, username, password, person 등을 포함해야 한다. person의 정보와 username으로 query가 가능해야 하기 때문에. setter . setter를 설계할 수 있지만 요구사항의 용어를 제대로 표현하는 것이라고 볼 수 없다. 절대적으로 부적절한 것은 아니지만 하나의 요청을 완수하기 위해 여러 setter를 사용할 필요가 없을 때 사용한다. 다수의 setter는 의도를 모호하게 하기 때문이다. 또 이런 setter는 하나의 논리적인 커맨드가 되어야 하는 결과를 의미있는 도메인 이벤트로 게시하기 어렵게 만든다. 예시 . setActive(boolean) -&gt; activate(), deactivate() 로 변경. activate 내부에서 active(boolean) 값의 변경과 updatedTime(time) 값의 변경이 동시에 이뤄질 수 있다. 이런 경우 setActive(), setUpdatedTime()을 호출하는건 안좋은 방향이다. | 위에서 말한 하나의 요청을 완수하기 위해 여러 setter를 사용해서 의도를 모호하게 하는 것. setActive() 내부에서 updatedTime을 수행하는 것도 안좋다. | setActive()라는 함수가 active만 set할 것 같은데 숨겨진 기능이 있는 것과 같음. | . 자가 캡슐화, Self Encapsulation . contructor에서 각 property의 할당을 setter에 위임하는 방식. 각 setter가 property의 validation을 책임지는 방식으로 각 변수에 대한 자가 캡슐을 지원한다. | null이면 안된다. | id인 경우 setter가 두번 호출될 수 없다. (set된 값이 null이 아니면 다시 호출하면 에러) | . 이런 검사를 하는 assertion들이 guard라고 불린다. 복잡한 constructor에 대해 property 별로 명확한 assertion을 제공하는 방향이 될 수 있는 것 같다. ",
    "url": "/docs/ddd/tactical/entity#entity-%EC%84%A4%EA%B3%84",
    
    "relUrl": "/docs/ddd/tactical/entity#entity-설계"
  },"448": {
    "doc": "DDD의 Entity란? Entity와 ID를 제대로 이해하기",
    "title": "유효성 검사",
    "content": "도메인 객체의 모든 특성이 개별적으로 유효하다고 해서 객체 전체가 하나의 대상으로 유효하다는 의미는 아니다. | test에서 mother1를 짜다보면 많이 느끼는 것. | 옳은 데이터끼리 짜집어도 결국 틀리는 부분이 있기 마련. | . 하나 이상의 단계로 이뤄진 유효성 검사를 통해 가능한 모든 문제를 다뤄야 한다. | 객체의 인스턴스 변수를 추상화할 수 있도록 해준다. | 이를 통해 해당 객체를 담고 있는 많은 다른 객체에서 손쉽게 특성/속성을 가져오는 방법을 제공한다. | 유효성 검사의 단순한 형태를 지원한다. | . property 유효성 검사 . 반 버논은 자가 캡슐화를 추천한다. 그치만 이걸 유효성 검사라고 하면 거부감이 든다고 한다. 유효성 검사는 도메인 객체가 아닌 유효성 검사 클래스의 책임이어야 하기 때문이다. 반 버논은 이걸 계약에 의한 설계 접근법 측면에서 assertion이라고 말한다. entity의 단순한 특성도 entity의 일부인 것처럼, 이런 guard(자가 캡슐화된 setter)도 entity의 일부이다. 작은 특성들을 guard하지 않는다면 정신 나간 값이 설정되는 상황을 가드할 수 없다. 빈 문자열에 대한 확인은 동의하지만, 문자열 길이나 숫자의 범위 확인은 동의하지 않는 사람들이 있다. 이런 경우는 db에 확인을 맡기는게 최선이라고 생각하기도 한다. 문자열 길이가 모델과 관련이 없다고 생각하는 것인데, 이런 검사가 무결성 점검이라고 볼 수 있다. 전체 객체의 유효성 검사 . 전체 객체에서 유용한 방법은 마지막으로 확인 가능한 순간까지 확인을 지연시킨다. 유효성 검사에는 엔티티의 전체 상태가 사용 가능해야 하므로 유효성 검사 로직을 엔티티에 직접 넣으려고 할 수도 있다. 그치만 도메인 객체 자체보다 도메인 객체의 유효성 검사가 더 자주 변경된다 (번 바논 의견) 엔티티 내부에 유효성 검사를 넣으면 너무 많은 책임을 갖기도 한다. 이미 엔티티는 자신의 상태를 유지해 도메인 행동을 다뤄야 하는 책임을 갖고 있다. 엔티티는 유효성을 검사하는 방법을 알 필요는 없고 유효한지 결과만 알면된다. 유효성 검사 컴포넌트는 엔티티 상태가 유효한지 결정하는 책임을 갖는다. 자바에서는 엔티티랑 같은 패키지에 위치해서 package private으로 entity의 속성에 접근할 수 있도록 한다. | 유효성 검사를 위해 public이 되어야 하는 방향은 바람직하지 않다. | . 유효성 검사에서 첫 문제가 발생할 때 예외를 던지기 보단 절체 결과를 수집하는 것이 중요하다. 예시 . Vaughn Vernon이 예를 든 validator 코드. public class Warble extends Entity { @Override public void validate(ValidationNotificationHandler aHandler) { (new WarbleValidator(this, aHandler)).validate(); } } class WarbleValidator extends Validator { public Validator (Warble aWarble, ValidationNotificationHandler aHandler) { super(aHandler); this.setWarble(aWarble); } public void validate() { this.checkForWarpedWarbleCondition(); this.checkForWackyWarbleState(); } } . 변화 추적 . 엔티티의 정의에 따라 수명주기에 걸쳐 일어나는 모든 상태 변경을 추적할 필요는 없다. 모델에서 일어나는 중요한 사건에 신경을 써야할 때가 있다. 이럴 때 엔티티에서 일어나는 특정 변경의 추적이 도움이 된다. 정확하고 유용하면서 실용적인 변경 추적은 도메인 이벤트와 이벤트 저장소를 사용하는 것이다. reference . | Implement Domain Driven Design (chapter5 Entity), Vaughn Vernon | . | 테스트 객체를 생성하는 기술, ObjectMother 패턴 참고 &#8617; . | . ",
    "url": "/docs/ddd/tactical/entity#%EC%9C%A0%ED%9A%A8%EC%84%B1-%EA%B2%80%EC%82%AC",
    
    "relUrl": "/docs/ddd/tactical/entity#유효성-검사"
  },"449": {
    "doc": "DDD의 Entity란? Entity와 ID를 제대로 이해하기",
    "title": "DDD의 Entity란? Entity와 ID를 제대로 이해하기",
    "content": "DDD tactical components . VO Entity Domain Service Domain Events Aggregate . DDD에서 가장 중심이 되는 부분이 바로 Vo와 Entity이다. Entity는 Vo와 identity를 기준으로 구분되곤 하는데, 실제 설계를 하다보면 entity의 범위는 어디까지인지 aggregate과 entity와의 관계 등이 나에게는 모호해서 entity를 더 공부하게 됐다. Vaughn Vernon의 Implement Domain Driven Design의 Entity 챕터를 다시 읽게 되었는데 DDD를 적용하는 프로젝트를 몇 건 진행한 후에 다시 보니 보이는 것들이 있었다. Entity의 가장 중요한 부분은 identity를 갖는 것이지만 그게 entity의 전부는 아니다. ID 부터 우선 설계해아한다는 것, constructor에 query에 사용되는 parameter들이 모두 포함되어야 한다는 것 등을 배웠다. DDD를 얕게 아는 대부분의 사람들이 “entity는 id가 있고 vo는 없어” 정도로 이해하고 말곤 하지만 VO와 Entity를 제대로 이해하고 개발하는데는 경험이 많이 필요하다. ",
    "url": "/docs/ddd/tactical/entity",
    
    "relUrl": "/docs/ddd/tactical/entity"
  },"450": {
    "doc": "[spring error] repackage failed: Unable to find main class",
    "title": "환경",
    "content": "windows, intellij 2022, kotlin spring, multi-module project . ",
    "url": "/docs/error-bug/spring/repackage-failed-Unable-to-find-main-class#%ED%99%98%EA%B2%BD",
    
    "relUrl": "/docs/error-bug/spring/repackage-failed-Unable-to-find-main-class#환경"
  },"451": {
    "doc": "[spring error] repackage failed: Unable to find main class",
    "title": "에러 메세지",
    "content": "mvn으로 package를 하려고 하다가 발생했다. 나는 multi-module로 core 모듈과, was 모듈을 가지고 있는데, project 상위 pom으로 build를 시도했다가 에러를 받았다. project packaging 중 core 모듈 packaing에서 에러가 발생한 것. Failed to execute goal org.springframework.boot:spring-boot-maven-plugin:2.7.0:repackage (repackage) on project whatisthebetter-core: Execution repackage of goal org.springframework.boot:spring-boot-maven-plugin:2.7.0:repackage failed: Unable to find main class . ",
    "url": "/docs/error-bug/spring/repackage-failed-Unable-to-find-main-class#%EC%97%90%EB%9F%AC-%EB%A9%94%EC%84%B8%EC%A7%80",
    
    "relUrl": "/docs/error-bug/spring/repackage-failed-Unable-to-find-main-class#에러-메세지"
  },"452": {
    "doc": "[spring error] repackage failed: Unable to find main class",
    "title": "해결",
    "content": "spring-boot-maven-plugin에 대해 알 필요가 있다. spring-boot-maven-plugin은 springboot에서 executable jar &amp; war를 packaging 하는 것을 지원한다. 따라서 multi-module에서 core나 library 같은 module은 해당 dependency를 빼주면 된다. core/library module에서 아래 plugin 제거. &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; . reference . | https://docs.spring.io/spring-boot/docs/current/maven-plugin/reference/htmlsingle/ | https://stackoverflow.com/questions/42937577/unable-to-find-main-class-with-maven-on-spring-boot-project-in-eclipse | . ",
    "url": "/docs/error-bug/spring/repackage-failed-Unable-to-find-main-class#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/error-bug/spring/repackage-failed-Unable-to-find-main-class#해결"
  },"453": {
    "doc": "[spring error] repackage failed: Unable to find main class",
    "title": "[spring error] repackage failed: Unable to find main class",
    "content": "intellij에서 maven package 시 발생한 에러. ",
    "url": "/docs/error-bug/spring/repackage-failed-Unable-to-find-main-class",
    
    "relUrl": "/docs/error-bug/spring/repackage-failed-Unable-to-find-main-class"
  },"454": {
    "doc": "[spring error] log4j2, Class path contains multiple SLF4J bindings",
    "title": "환경",
    "content": "windows, intellij 2022, kotlin spring, log4j2 . ",
    "url": "/docs/error-bug/spring/Class-path-contains-multiple-SLF4J-bindings#%ED%99%98%EA%B2%BD",
    
    "relUrl": "/docs/error-bug/spring/Class-path-contains-multiple-SLF4J-bindings#환경"
  },"455": {
    "doc": "[spring error] log4j2, Class path contains multiple SLF4J bindings",
    "title": "pom.xml",
    "content": "내 pom 파일 일부. gradle로 해도 같은 에러가 났다면 동일하게 해결할 수 있을 것 같다. &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;version&gt;2.7.2&lt;/version&gt; &lt;/dependency&gt; . ",
    "url": "/docs/error-bug/spring/Class-path-contains-multiple-SLF4J-bindings#pomxml",
    
    "relUrl": "/docs/error-bug/spring/Class-path-contains-multiple-SLF4J-bindings#pomxml"
  },"456": {
    "doc": "[spring error] log4j2, Class path contains multiple SLF4J bindings",
    "title": "에러 메세지",
    "content": "mvn으로 package를 하려고 하다가 발생했다. 나는 multi-module로 core 모듈과, was 모듈을 가지고 있는데, project 상위 pom으로 build를 시도했다가 에러를 받았다. project packaging 중 core 모듈 packaing에서 에러가 발생한 것. SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/C:/Users/soup/.m2/repository/ch/qos/logback/logback-classic/1.2.11/logback-classic-1.2.11.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/C:/Users/soup/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.17.2/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. SLF4J: Actual binding is of type [ch.qos.logback.classic.util.ContextSelectorStaticBinder] . ",
    "url": "/docs/error-bug/spring/Class-path-contains-multiple-SLF4J-bindings#%EC%97%90%EB%9F%AC-%EB%A9%94%EC%84%B8%EC%A7%80",
    
    "relUrl": "/docs/error-bug/spring/Class-path-contains-multiple-SLF4J-bindings#에러-메세지"
  },"457": {
    "doc": "[spring error] log4j2, Class path contains multiple SLF4J bindings",
    "title": "해결",
    "content": "에러 메세지 그대로, slf4j에 binding된 dependency가 하나가 아니어서 발생한 에러다. 해결을 위해서는 추가된 slf4j가 의도된 dependency만 추가되도록, 그렇지 않은건 제거해줄 필요가 있다. maven dependency를 확인해보자. 내 maven dependency . 보다시피 내가 추가한 org.springframework.boot:spring-boot-starter-log4j2:2.7.2 외에도, org.springframework.boot:spring-boot-starter:2.7.0 이 가지고 있는 logging이 있다. 여기서 에러가 발생한 것. spring-boot-starter-web에서는 exclude를 해줬는데, spring-boot-starter에서는 누락한 것을 추가해준다. &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;version&gt;2.7.2&lt;/version&gt; &lt;/dependency&gt; . reference . | https://www.baeldung.com/slf4j-classpath-multiple-bindings | . ",
    "url": "/docs/error-bug/spring/Class-path-contains-multiple-SLF4J-bindings#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/error-bug/spring/Class-path-contains-multiple-SLF4J-bindings#해결"
  },"458": {
    "doc": "[spring error] log4j2, Class path contains multiple SLF4J bindings",
    "title": "[spring error] log4j2, Class path contains multiple SLF4J bindings",
    "content": "intellij에서 log를 설정한 뒤 test 실행 혹은 application run 중에 경고 같은 에러 발생. ",
    "url": "/docs/error-bug/spring/Class-path-contains-multiple-SLF4J-bindings",
    
    "relUrl": "/docs/error-bug/spring/Class-path-contains-multiple-SLF4J-bindings"
  },"459": {
    "doc": "[spring error] log4j2.yml, yaml property not work",
    "title": "환경",
    "content": "windows, intellij 2022, kotlin spring, log4j2.yaml . ",
    "url": "/docs/error-bug/spring/yaml-property-not-work#%ED%99%98%EA%B2%BD",
    
    "relUrl": "/docs/error-bug/spring/yaml-property-not-work#환경"
  },"460": {
    "doc": "[spring error] log4j2.yml, yaml property not work",
    "title": "현상",
    "content": "console이 멈췄다. run했다는 메세지만 남고 에러도 없고 시작도 안했다. 혹시나 싶어서 동일한 log4j2를 xml로 작성해보면 제대로 동작하는 것도 확인 가능했다. | 테스트를 위한다면 인터넷에 샘플로 제공된 아무 xml이나 넣고 run해서 console 출력을 확인. | . ",
    "url": "/docs/error-bug/spring/yaml-property-not-work#%ED%98%84%EC%83%81",
    
    "relUrl": "/docs/error-bug/spring/yaml-property-not-work#현상"
  },"461": {
    "doc": "[spring error] log4j2.yml, yaml property not work",
    "title": "해결",
    "content": "아주 기본적인 실수를 셋업할 땐 참 많이도 한다. 회사에선 xml만 쓰는데 log4j2의 경우 yml이 가독성이나 라인 수가 더 효율적일 것 같아서 시도했다가 시간을 많이도 버렸따. yaml를 읽어주는 dependency가 빠졌던 것. &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt; &lt;artifactId&gt;jackson-dataformat-yaml&lt;/artifactId&gt; &lt;version&gt;2.5.0&lt;/version&gt; &lt;/dependency&gt; . reference . | https://stackoverflow.com/questions/28101903/what-is-a-sample-default-config-file-in-yaml-for-log4j2 | . ",
    "url": "/docs/error-bug/spring/yaml-property-not-work#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/error-bug/spring/yaml-property-not-work#해결"
  },"462": {
    "doc": "[spring error] log4j2.yml, yaml property not work",
    "title": "[spring error] log4j2.yml, yaml property not work",
    "content": "spring에서 log4j2.yml, log4j2.yaml를 설정했는데 되지 않는 상황. 아무 에러도 뜨지 않고 console이 그냥 멈춘 상태였다. ",
    "url": "/docs/error-bug/spring/yaml-property-not-work",
    
    "relUrl": "/docs/error-bug/spring/yaml-property-not-work"
  },"463": {
    "doc": "spring multimodule에서 library module의 test class 사용하기",
    "title": "현상",
    "content": "src 코드는 잘 추가되어 사용하지만, test 코드들은 추가되지 않는 상황. 현재 maven pom . &lt;dependency&gt; &lt;groupId&gt;com.meansoup&lt;/groupId&gt; &lt;artifactId&gt;whatisthebetter-core&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; . ",
    "url": "/docs/spring/multimodule-test-dependency#%ED%98%84%EC%83%81",
    
    "relUrl": "/docs/spring/multimodule-test-dependency#현상"
  },"464": {
    "doc": "spring multimodule에서 library module의 test class 사용하기",
    "title": "해결",
    "content": "현재 dependency는 그대로 두고 test dependency를 추가하면 사용할 수 있다. 이렇게 되면 scope이 test여서 compile할 때 빨려들어가지도 않을거라 좋은 방향이다. 수정된 maven pom . &lt;dependency&gt; &lt;groupId&gt;com.meansoup&lt;/groupId&gt; &lt;artifactId&gt;whatisthebetter-core&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.meansoup&lt;/groupId&gt; &lt;artifactId&gt;whatisthebetter-core&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;type&gt;test-jar&lt;/type&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; . ",
    "url": "/docs/spring/multimodule-test-dependency#%ED%95%B4%EA%B2%B0",
    
    "relUrl": "/docs/spring/multimodule-test-dependency#해결"
  },"465": {
    "doc": "spring multimodule에서 library module의 test class 사용하기",
    "title": "dependency의 type",
    "content": "dependency의 artifact’s packaging type을 명시하는 것이다. default는 jar. jar, pom, war, test-jar 등이 있고, test-jar를 통해 test package를 명시하였다. ",
    "url": "/docs/spring/multimodule-test-dependency#dependency%EC%9D%98-type",
    
    "relUrl": "/docs/spring/multimodule-test-dependency#dependency의-type"
  },"466": {
    "doc": "spring multimodule에서 library module의 test class 사용하기",
    "title": "attach test-jar",
    "content": "위처럼하면 test를 돌리는데는 문제 없으나, mvn package / deploy 시에 test-jar가 core에서 생성되지 않아 에러가 발생한다. 아래와 같이 plugin을 추가해서 해결한다. &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;test-jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; . ",
    "url": "/docs/spring/multimodule-test-dependency#attach-test-jar",
    
    "relUrl": "/docs/spring/multimodule-test-dependency#attach-test-jar"
  },"467": {
    "doc": "spring multimodule에서 library module의 test class 사용하기",
    "title": "reference",
    "content": ". | https://stackoverflow.com/questions/174560/sharing-test-code-in-maven | . maven type . | https://zditect.com/blog/54005418.html | https://www.quora.com/What-is-the-purpose-to-use-type-in-a-maven-dependency | . test jar build . | https://maven.apache.org/guides/mini/guide-attached-tests.html | . ",
    "url": "/docs/spring/multimodule-test-dependency#reference",
    
    "relUrl": "/docs/spring/multimodule-test-dependency#reference"
  },"468": {
    "doc": "spring multimodule에서 library module의 test class 사용하기",
    "title": "spring multimodule에서 library module의 test class 사용하기",
    "content": "springboot multimodule을 사용하면서, test class가 dependency에 추가되지 않는 것을 확인했다. 처음에는 그냥 그러려니 하고 조금 번거롭게 테스트 코드를 다시 작성했는데, 테스트를 점점 추가하다보니 mother 패턴을 적용했던 코드들을 재사용하는 것이 맞다고 생각됐다. ",
    "url": "/docs/spring/multimodule-test-dependency",
    
    "relUrl": "/docs/spring/multimodule-test-dependency"
  },"469": {
    "doc": "OKE docker registry github action 적용하기",
    "title": "docker login github action",
    "content": "우선 docker에서 제공하는 github action이 있다. docker/login-action을 사용하면 굉장히 쉽게 container registry에 접근할 수 있다. 그런데 나는 oracle에서 이게 잘 안됐고, 다음엔 안까먹기 위해 정리해본다. 여기서 의미하는 여러 value들에 대한 정의가 나한테는 명확하지 않았고 리소스도 많지 않았다. - name: Login to Oracle Container Registry uses: docker/login-action@v2 with: registry: icn.ocir.io username: $ password: $ . icn.ocir.io: . icn의 자리는 region name이다. region name은 reference에 명시한 url에서 확인할 수 있다. 한국은 icn. OCI_DOCKER_NAME: . 여기서 OCI_DOCKER_NAME은 &lt;tenancy-namespace&gt;/&lt;username&gt; . tenancy-namespace는 oracle에서 관리하는 tenancy의 id를 가리킨다. Profile &gt; Tenancy &gt; Object storage namespace 에서 확인 가능. | 나는 cn********ev (12자리) | . username은 email 형식의 계정이다. | 나는 ~@gmail.com | . 그래서 DOCER_NAME은 . | 나는 cn********ev/~@gmail.com | 혹은 cn********ev/oracleidentitycloudservice/~@gmail.com 이기도 하다는데 난 잘 안됐다. | . OCI_AUTH_TOKEN: . OCI_AUTH_TOKEN은 oracle cloud에서 발급한 토큰을 말한다. Profile &gt; My profile &gt; Auth tokens 에서 발급 가능. | 당연히 발급받은 토큰은 발급 시점에만 key를 확인할 수 있다. | 발급 시에 복사해두고, 그렇지 못했다면 재발급. | 나는 3&amp;****************!8 (특수문자 포함 20자리) | . 확인 추천 . | 우선 아래 reference 처럼 docker login을 cmd에서 해본다. | git action에서 key를 yml에 명시해서 해본다. | key를 secrets로 넣어서 해본다. | . git action에서 그냥 하려다가 몇 번 실패하면 스트레스가 이만 저만이 아니다. reference . | https://docs.oracle.com/en-us/iaas/Content/Functions/Tasks/functionslogintoocir.htm | https://docs.oracle.com/en-us/iaas/Content/Registry/Concepts/registryprerequisites.htm#regional-availability | . ",
    "url": "/docs/oci/docker-login#docker-login-github-action",
    
    "relUrl": "/docs/oci/docker-login#docker-login-github-action"
  },"470": {
    "doc": "OKE docker registry github action 적용하기",
    "title": "OKE docker registry github action 적용하기",
    "content": " ",
    "url": "/docs/oci/docker-login",
    
    "relUrl": "/docs/oci/docker-login"
  },"471": {
    "doc": "map key로 쉽게 remove 하는 trick과 outer.this 하기",
    "title": "remove multiple keys from map efficiently",
    "content": "효율적으로 그리고 깔끔하게 key들로 map을 지워내기. map.keySet().remove(key); map.keySet().removeIf(key -&gt; key.startsWith(prefix)); . keySet은 map과 연결되어 keySet에서만 지워도 map이 지워진다는 것이다. 흥미롭다. 어떻게 이게 가능할까. ",
    "url": "/docs/java/tip/java_map_key_remove_and_outer_this#remove-multiple-keys-from-map-efficiently",
    
    "relUrl": "/docs/java/tip/java_map_key_remove_and_outer_this#remove-multiple-keys-from-map-efficiently"
  },"472": {
    "doc": "map key로 쉽게 remove 하는 trick과 outer.this 하기",
    "title": "HashMap과 HashMap.keySet 코드 분석",
    "content": "public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable { public Set&lt;K&gt; keySet() { Set&lt;K&gt; ks = keySet; if (ks == null) { ks = new KeySet(); keySet = ks; } return ks; } final class KeySet extends AbstractSet&lt;K&gt; { public final int size() { return size; } public final void clear() { HashMap.this.clear(); } public final Iterator&lt;K&gt; iterator() { return new KeyIterator(); } public final boolean contains(Object o) { return containsKey(o); } public final boolean remove(Object key) { return removeNode(hash(key), key, null, false, true) != null; } public final Spliterator&lt;K&gt; spliterator() { return new KeySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); } public final void forEach(Consumer&lt;? super K&gt; action) { Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) { int mc = modCount; for (Node&lt;K,V&gt; e : tab) { for (; e != null; e = e.next) action.accept(e.key); } if (modCount != mc) throw new ConcurrentModificationException(); } } } } . HashMap 코드 내부에 위치한 keySet 코드이다. 흥미로운건 size, iterator, contains 등 모든 반환 값은 HashMap의 함수나 값을 쓰고 있다는 것. 그리고 HashMap.this.clear() 와 같은 코드. 확인할 포인트: . | 우선 keySet은 HashMap과 별개라고 생각했는데 keySet이 생성된 이후에도 HashMap을 자유롭게 접근할 수 있다는 점에서 놀랐다. 이게 static도 아닌데 접근이 되서 놀랐는데 덕분에 java에 대한 이해도가 늘었다. | HashMap.this 코드가 이해가 안됐다. static도 아니고 이렇게 쓴다니. 이거에 대해선 아래에 다룬다. | inner class를 가장 효율적으로 짜는 아주 좋은 예시 코드인 것 같다. 가끔 개발에 쓸 수 있을 것 같다. | . ",
    "url": "/docs/java/tip/java_map_key_remove_and_outer_this#hashmap%EA%B3%BC-hashmapkeyset-%EC%BD%94%EB%93%9C-%EB%B6%84%EC%84%9D",
    
    "relUrl": "/docs/java/tip/java_map_key_remove_and_outer_this#hashmap과-hashmapkeyset-코드-분석"
  },"473": {
    "doc": "map key로 쉽게 remove 하는 trick과 outer.this 하기",
    "title": "java parent.this 하기",
    "content": "HashMap.this에 대해 이해가 되지 않아서 찾아봤다. keySet이 HashMap의 값을 사용할 수 있는 것을 아우르는 중요한 개념이 있다. non static inner class는 outer class에 대한 참조를 갖는다. 그리고 outer class name과 this를 함께 사용하면 이 참조를 얻을 수 있다. 요긴하게 쓰일 수 있는 개념이자 팁. 좀 더 이해하기 쉬운 예시를 첨부한다. public class Outer { class Inner { public Inner inner() { return this; } public Outer outer() { return Outer.this; } } } . ",
    "url": "/docs/java/tip/java_map_key_remove_and_outer_this#java-parentthis-%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/java/tip/java_map_key_remove_and_outer_this#java-parentthis-하기"
  },"474": {
    "doc": "map key로 쉽게 remove 하는 trick과 outer.this 하기",
    "title": "결론",
    "content": "그래서 keySet을 사용해서 하는 모든 remove 연산은 실제 hashMap에 영향을 미친다. 이게 미치는 과정이 흥미롭고 배울점이 많다. reference . multiple keys로 map remove 하기 . | https://stackoverflow.com/questions/17675804/remove-multiple-keys-from-map-in-efficient-way | . hashmap.this에 대한 설명 . | https://stackoverflow.com/questions/16999611/hashmap-this-clear-what-does-this-mean-how-does-this-work | . ",
    "url": "/docs/java/tip/java_map_key_remove_and_outer_this#%EA%B2%B0%EB%A1%A0",
    
    "relUrl": "/docs/java/tip/java_map_key_remove_and_outer_this#결론"
  },"475": {
    "doc": "map key로 쉽게 remove 하는 trick과 outer.this 하기",
    "title": "map key로 쉽게 remove 하는 trick과 outer.this 하기",
    "content": "오늘 일하는데 hashmap에서 key들을 받아서 map의 entry를 지우는 코드가 굉장히 지저분했다. iterator로 entry를 받아서 조건에 맞는다면 remove. 그런데 이런 remove가 지저분하게 여러개. 이 코드를 고치기 위해 방법을 찾다가 재밌는 코드를 발견했다. ",
    "url": "/docs/java/tip/java_map_key_remove_and_outer_this",
    
    "relUrl": "/docs/java/tip/java_map_key_remove_and_outer_this"
  },"476": {
    "doc": "OCI cloud shell에서 kubectl 설정하기",
    "title": "설정하기",
    "content": "oci ce cluster create-kubeconfig을 통해 cloud shell이 kubectl을 통해 접근할 수 있는 config를 setup한다. oci는 낯선데 당연히 aws cli 같은 역할을 하겠지. oci ce cluster create-kubeconfig --cluster-id {clusterId} --file $HOME/.kube/config --region ap-seoul-1 --token-version 2.0.0 . | 이 명령어를 cloud shell에 치면 된다. | clusterId는 oracle console에서 확인 | region은 cluster가 있는 region | . ",
    "url": "/docs/oci/kubectl_shell#%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/oci/kubectl_shell#설정하기"
  },"477": {
    "doc": "OCI cloud shell에서 kubectl 설정하기",
    "title": "수행",
    "content": "userId@cloudshell:~ (ap-seoul-1)$ oci ce cluster create-kubeconfig --cluster-id ocid1.cluster.oc1.ap-seoul-1..... --file $HOME/.kube/config --region ap-seoul-1 --token-version 2.0.0 New config written to the Kubeconfig file /home/userId/.kube/config . 이후에 kubectl이 잘 동작한다. reference . | https://www.oracle.com/webfolder/technetwork/tutorials/obe/oci/oke-cloudshell/index.html | . ",
    "url": "/docs/oci/kubectl_shell#%EC%88%98%ED%96%89",
    
    "relUrl": "/docs/oci/kubectl_shell#수행"
  },"478": {
    "doc": "OCI cloud shell에서 kubectl 설정하기",
    "title": "OCI cloud shell에서 kubectl 설정하기",
    "content": " ",
    "url": "/docs/oci/kubectl_shell",
    
    "relUrl": "/docs/oci/kubectl_shell"
  },"479": {
    "doc": "single table을 사용하는 이유",
    "title": "relational design",
    "content": "기존의 관계형 DB에서는 일반적으로 여러 table을 두고 사용한다. 각 table은 다른 table의 foreign key를 갖고, multiple tables에서 join query로 마치 single-table-view를 생성해서 사용한다. 이런 query는 편리하고 유연하지만, DB 내부에선 굉장히 비싼 operation이고 horiziontal scale out이 어렵다. ",
    "url": "/docs/aws/dynamo/single-table#relational-design",
    
    "relUrl": "/docs/aws/dynamo/single-table#relational-design"
  },"480": {
    "doc": "single table을 사용하는 이유",
    "title": "dynamodb design",
    "content": "RDB에서는 scale의 한계가 있지만 dynamodb에서는 scale의 한계가 없다. 이건 SQL과 NoSQL의 차이1이다. dynamodb의 중요한 goal 중 하나인데, scale이 증가하더라도 예측 가능한 performance를 제공할 수 있도록 디자인 한다는 것. 그래서 dynamodb는 scale 할 수 없는 operation 들을 제공하지 않고 있고, join도 그렇다. ",
    "url": "/docs/aws/dynamo/single-table#dynamodb-design",
    
    "relUrl": "/docs/aws/dynamo/single-table#dynamodb-design"
  },"481": {
    "doc": "single table을 사용하는 이유",
    "title": "single-table",
    "content": "join은 할 수 없으나 join 처럼 하나의 query로 data를 가져오기 위한 방법이 있는데 이게 바로 single-table design이다. single-table design에서는 여러 data type들을 하나의 table에 저장하고 client에서 한 번에 query를 해가는 방식이다. 장/단점과 예시를 보자. ",
    "url": "/docs/aws/dynamo/single-table#single-table",
    
    "relUrl": "/docs/aws/dynamo/single-table#single-table"
  },"482": {
    "doc": "single table을 사용하는 이유",
    "title": "single-table 장점",
    "content": ". | join과 유사하게 하나의 query로 data를 가져온다. | 여러 table을 사용하지 않아서 monitoring/alert 포인트를 줄일 수 있다. | 비용을 절약할 수 있다. | . join과 유사하게 하나의 query로 data를 가져온다. 위에서 말했듯 하나의 query로 data를 가져올 수 있다. query의 개수가 줄어드는 것은 RTT 감소로 인한 성능 개선과 비용 감소로 이어진다. 여러 table을 사용하지 않아서 monitoring/alert 포인트를 줄일 수 있다. aws에서 dynamodb를 소개할 때 DBA가 필요하지 않은 서비스라고 소개했다. 그만큼 dynamodb는 돈만내면 참 편하게 쓸 수 있는 DB이다. db의 throttling이나 RCU/WCU에 대한 관리가 여러 db를 모니터링 하지 않아도 되기 때문에 개발팀 입장에서 일이 많이 줄어든다. 비용을 절약할 수 있다. 2번과 이어지는 내용이다. dynamo의 RCU/WCU에는 두 가지 과금 정책이 있는데 ondemand와 provisioned 이다. | ondemand: 쓰는만큼 돈을 내기 | provisioned: provision을 설정하고 그 만큼 돈을 내기 | . ondemand가 더 싸보이지만 enterprise 급에서는 대부분 provisioned를 사용한다. 대체적으로 두 가지 이유 때문이다. | 급격한 db 요청이 몰릴 때, ondemand에서 RCU/WCU를 늘리더라도 시간이 걸리고 그 사이에 장애가 발생한다. (물론 빨리 늘지만 그래도 시간이 걸린다) | provisioned로 계약하면 ondemand 보다 가격이 저렴하다. | . provision는 당연히 서비스에서 사용되는 수치보다 한참 넉넉하게 설정하는 편이다. 10개의 table에 대해 provision이 여유롭게 설정된 것과, 1개의 table로 합쳐서 여유롭게 설정되는 차이에서 비용 절약이 발생한다. ",
    "url": "/docs/aws/dynamo/single-table#single-table-%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/aws/dynamo/single-table#single-table-장점"
  },"483": {
    "doc": "single table을 사용하는 이유",
    "title": "single-table 단점",
    "content": ". | single-table을 설계하기 위해 학습곡선이 있다. | 새로운 access pattern을 추가하기 어렵다. | data dump가 어렵다. | . single-table을 설계하기 위해 학습곡선이 있다. primaryKey, sortKey에 대한 개념. key 중복이 없도록 data 설계. GSI와 LSI. 등에 대해 알고 배워야 한다. join은 정답같은 query가 있다고 한다면 dynamo table design은 설계하는 사람마다 다 다르기 때문에 더 어렵기도 하다. 근데 단점에 학습곡선을 넣는건 단점이 별로 없다는 얘기가 아닐까 싶다. 배우는건 당연하지. 새로운 access pattern을 추가하기 어렵다. RDB의 table join 같은 경우는 table이 추가되고 새로운 query가 필요할 때 join을 다시 짜면 된다. 그런데 single table에서는 primary key &amp; sort key가 query를 한 번에 해오는데 중요한 요소가 되기 때문에 새로운 pattern이 필요할 때 key 설계가 변경되어야 하는 경우가 있다. 그래서 dynamodb 설계는 application의 access pattern, usecase 들을 정리하는 것부터 시작한다. data dump가 어렵다. 블로그를 예로 들면, 유저와 포스트와 코멘트가 한 테이블에 있는 것이기 때문에 유저 dump가 필요한 경우 쉽지 않다. ",
    "url": "/docs/aws/dynamo/single-table#single-table-%EB%8B%A8%EC%A0%90",
    
    "relUrl": "/docs/aws/dynamo/single-table#single-table-단점"
  },"484": {
    "doc": "single table을 사용하는 이유",
    "title": "single table 예시",
    "content": ". db entity의 구조가 위와 같다고 하자. 전통적으로는 아래와 같은 RDB table들을 설계할 수 있다. single table에서는 아래와 같이 table을 설계한다. 요구사항에 따라 primary key, sort key에 맞게 entity를 구분해서 넣는다. ",
    "url": "/docs/aws/dynamo/single-table#single-table-%EC%98%88%EC%8B%9C",
    
    "relUrl": "/docs/aws/dynamo/single-table#single-table-예시"
  },"485": {
    "doc": "single table을 사용하는 이유",
    "title": "참고사항",
    "content": ". | 모든 데이터를 하나의 테이블에 넣는다. 그게 안되면 가능한 적은 테이블을 사용한다. | PK, SK, GS1PK 같은 key name을 맞춘다. | entity의 type을 파악할 수 있도록 attribute를 추가하면 좋다. | single table 적용 후기 | . reference . | https://aws.amazon.com/blogs/compute/creating-a-single-table-design-with-amazon-dynamodb/ | https://www.alexdebrie.com/posts/dynamodb-single-table/ | https://medium.com/till-engineering/single-table-design-aws-dynamodb-cffd230a371f | . | SQL은 기본적으로 scale up, NoSQL은 scale out으로 확장한다. SQL vs NoSQL 참고 &#8617; . | . ",
    "url": "/docs/aws/dynamo/single-table#%EC%B0%B8%EA%B3%A0%EC%82%AC%ED%95%AD",
    
    "relUrl": "/docs/aws/dynamo/single-table#참고사항"
  },"486": {
    "doc": "single table을 사용하는 이유",
    "title": "single table을 사용하는 이유",
    "content": "dynamodb에서는 RDB를 사용하듯이 table을 많이 사용하는 것을 권장하지 않는다. AWS에서 성능과 비용 개선을 위해 가이드를 자주 하기도 한다. 최근 single table에 대한 이점을 다시 돌아볼 기회가 있어서 정리해본다. ",
    "url": "/docs/aws/dynamo/single-table",
    
    "relUrl": "/docs/aws/dynamo/single-table"
  },"487": {
    "doc": "single table 적용 후기",
    "title": "single table",
    "content": "single table 이란? . ",
    "url": "/docs/aws/dynamo/single-table-result#single-table",
    
    "relUrl": "/docs/aws/dynamo/single-table-result#single-table"
  },"488": {
    "doc": "single table 적용 후기",
    "title": "table design 변경",
    "content": "이후에 개발하는 모듈에선 single table을 완전히 적용하기도 했지만 사실 이번 모듈의 migration은 single table까지는 아니다. table을 합치는 방식으로 10개의 table을 4개의 table로 합쳤다. ",
    "url": "/docs/aws/dynamo/single-table-result#table-design-%EB%B3%80%EA%B2%BD",
    
    "relUrl": "/docs/aws/dynamo/single-table-result#table-design-변경"
  },"489": {
    "doc": "single table 적용 후기",
    "title": "비용 개선",
    "content": "provision WCU가 절반으로 줄었다. | 넉넉하게 세팅하던 값이 줄었기 때문이 아닌가 싶다. | 그리고 scaling을 고려해서 여러 table로 나뉘어 있던 데이터들이 하나의 row에 합쳐지는 것들이 있어서 WCU 개선이 컸던 것으로 생각된다. | . provision RCU가 50% 정도 늘었다. | 이건 원인을 잘 모르겠다. 당시 call 수가 늘었는지.. 지금은 정확하게 기억나지는 않는다. | 개념적으로는 줄어드는게 맞다만. | . ",
    "url": "/docs/aws/dynamo/single-table-result#%EB%B9%84%EC%9A%A9-%EA%B0%9C%EC%84%A0",
    
    "relUrl": "/docs/aws/dynamo/single-table-result#비용-개선"
  },"490": {
    "doc": "single table 적용 후기",
    "title": "성능 개선",
    "content": "이 모듈은 요구사항에 맞게 data를 동기화 해주는게 주 목적이었다. db query가 줄어드니 성능은 크게 개선되었다. 주요 api들의 성능이 40~80% 까지 개선되었다. ",
    "url": "/docs/aws/dynamo/single-table-result#%EC%84%B1%EB%8A%A5-%EA%B0%9C%EC%84%A0",
    
    "relUrl": "/docs/aws/dynamo/single-table-result#성능-개선"
  },"491": {
    "doc": "single table 적용 후기",
    "title": "회고",
    "content": "지금 생각하면 table 수를 더 줄일 수 있었을텐데 싶기도 하고. 이때는 single query load multiple type entity에 대한 생각이 잘 없었어서 그런 방향으로 성능 개선이 다시 가능할 것 같다. 물론 바빠서 못함. ",
    "url": "/docs/aws/dynamo/single-table-result#%ED%9A%8C%EA%B3%A0",
    
    "relUrl": "/docs/aws/dynamo/single-table-result#회고"
  },"492": {
    "doc": "single table 적용 후기",
    "title": "single table 적용 후기",
    "content": "우리 팀은 dynamodb를 많이 쓰고 있다. RDB를 쓰다가 dynamodb로 넘어가서 시행착오가 좀 있었다. dynamodb를 처음 적용한 한 모듈은 RDB처럼 table을 나눠서 사용하고 있었다. 성능 개선을 위한 story를 진행하면서 single table에 대한 얘기가 나왔고 migration을 진행했다. 사실 한지는 좀 됐는데 single table에 대해 다시 생각해볼 시간이 있어 정리해본다. ",
    "url": "/docs/aws/dynamo/single-table-result",
    
    "relUrl": "/docs/aws/dynamo/single-table-result"
  },"493": {
    "doc": "list type casting 하기",
    "title": "stream",
    "content": "가장 먼저 생각난건 stream으로 변환하기. List&lt;B&gt; = items.stream().map(i -&gt; (B) i).collect(Collectors.toList()); . 근데 이거 loop를 한 번 돌게 되는게 억울하다. 그래서 찾아보았다. ",
    "url": "/docs/java/tip/list-type-casting#stream",
    
    "relUrl": "/docs/java/tip/list-type-casting#stream"
  },"494": {
    "doc": "list type casting 하기",
    "title": "generic type casting",
    "content": "결론부터 말하자면 이렇게 해결할 수 있다. List&lt;B&gt; = (List&lt;A&gt;) (List&lt;?&gt;) items; . 이유는 A가 B의 parent 이지만 List는 List의 parent가 아니기 때문에 type casting이 되지 않는다. 그치만 **List, List 모두 List&lt;?&gt;의 child 이기 때문에 type casting이 가능하다.** . reference . | https://stackoverflow.com/questions/933447/how-do-you-cast-a-list-of-supertypes-to-a-list-of-subtypes | https://docs.oracle.com/javase/tutorial/java/generics/subtyping.html | . ",
    "url": "/docs/java/tip/list-type-casting#generic-type-casting",
    
    "relUrl": "/docs/java/tip/list-type-casting#generic-type-casting"
  },"495": {
    "doc": "list type casting 하기",
    "title": "list type casting 하기",
    "content": "이번에 작업하면서 list를 casting 할 일이 있었다. 대충 표현하면 이런 코드. class A { /* ... */ } class B extends A { /* ... */ } List&lt;A&gt; items; List&lt;B&gt; needs; . 나는 B의 list가 필요한데 가져온 list는 A인 상황. ",
    "url": "/docs/java/tip/list-type-casting",
    
    "relUrl": "/docs/java/tip/list-type-casting"
  },"496": {
    "doc": "AWS 비용 효율화",
    "title": "비용들",
    "content": "AWS에서 service 별로 어떻게 비용이 증가하는지 확인할 수 있다. tag를 달아서 운영하는 모듈별로 어떤 비율로 사용하는지. 비용은 크게 네 가지로 나눌 수 있다. | storage | database | instance | network | . ",
    "url": "/docs/aws/cost-efficiency#%EB%B9%84%EC%9A%A9%EB%93%A4",
    
    "relUrl": "/docs/aws/cost-efficiency#비용들"
  },"497": {
    "doc": "AWS 비용 효율화",
    "title": "Storage 비용",
    "content": "storage 비용은 request 비용과 storage 비용으로 나뉜다. request 비용 줄이기 . 크기가 작은 경우 dynamoDb에 밀어 넣을 수 있다. 그렇게 되면 성능도 확보할 수 있고 request 비용도 줄일 수 있다. 그치만 크기가 큰 경우나 사용성에 따라 되려 dynamo 저장 비용이 커질 수 있다. dynamo는 request 비용이 싸고 S3는 storage 비용이 싸다. storage 비용 줄이기 . storage layering을 통해 s3 오래된 데이터를 cold storage로 이동시킨다. S3 Glacier가 분 단위 이상의 검색 시간이 걸려서 사용하지 못했으나 새롭게 나온 S3 Glacier Instant Retrieval 같은 타입에서는 밀리초 단위의 검색 시간 소요하기 때문에 비용을 줄이면서 충분히 사용할 수 있다. 물론 우리 팀에선 아직 안써봤고 신뢰성이 조금 떨어질 수 있다고 판단했다. (dynamo에서 consistency가 늘어졌던 적도 있고..) . ",
    "url": "/docs/aws/cost-efficiency#storage-%EB%B9%84%EC%9A%A9",
    
    "relUrl": "/docs/aws/cost-efficiency#storage-비용"
  },"498": {
    "doc": "AWS 비용 효율화",
    "title": "database 비용",
    "content": "database 비용도 비슷한데 RCU/WCU와 storage 비용으로 나뉜다. dynamo storage 비용 줄이기 . 유사하게 storage layering으로 오래된 data를 s3로 이동시킨다. 호출비용과 저장비용을 잘 계산해서 진행해야 한다. 무작정 s3는 되려 비쌀 수 있다. 잘 사용하지 않는 데이터를 bulk로 s3에 backup하면 비용을 많이 줄일 수 있다. 다만 서비스 로직 변경이 크다. CU 줄이기 . CU는 provision을 줄이는 방향으로도 갈 수 있다. 우리 팀에선 single table로 migration 해서 CU를 크게 줄였다. ",
    "url": "/docs/aws/cost-efficiency#database-%EB%B9%84%EC%9A%A9",
    
    "relUrl": "/docs/aws/cost-efficiency#database-비용"
  },"499": {
    "doc": "AWS 비용 효율화",
    "title": "storage &amp; database 공통 비용 줄이기",
    "content": "storage나 database 모두 data를 저장하는 곳이다. data가 service됨에 따라 data가 쌓이기만 한다면 비용은 계속 증가할 수 밖에 없다. 따라서 data에 대한 핸들링이 필요하다. garbage collection 하기 . 지워야 했던, 지울 수 있는 데이터를 삭제한다. 삭제가 필요했던 탈퇴한 사용자에 대한 데이터 삭제가 되지 않았다거나. 관련된 data가 삭제되었으나 남아있는 찌꺼기가 있다거나. 성능 상의 이슈로 미뤄진 data 삭제 등이 남아있을 수 있다. data life cycle 확인하고 조절하기 . data life cycle이 사실 비용에서 가장 중요하다. data가 10년이 지나도 쌓이기만 한다면 비용은 증가할 수 밖에. 1Y 보관기간의 데이터를 6M으로 줄일 수 있다면 storage 비용을 반으로 줄일 수 있다. data life cycle을 확인하고 그 정도의 life cycle이 필요한지 확인한다. 삭제를 하는 경우를 명확하게 정의하고 ttl 설정 혹은 delay batch로 삭제한다. 사진/동영상의 경우 thumbnail의 lifecycle도 고려가 필요하다. ",
    "url": "/docs/aws/cost-efficiency#storage--database-%EA%B3%B5%ED%86%B5-%EB%B9%84%EC%9A%A9-%EC%A4%84%EC%9D%B4%EA%B8%B0",
    
    "relUrl": "/docs/aws/cost-efficiency#storage--database-공통-비용-줄이기"
  },"500": {
    "doc": "AWS 비용 효율화",
    "title": "instance 비용",
    "content": "서비스 특성에 따라 instance가 CPU / memory / I/O 중 어디에 bound 되는지 확인할 필요가 있다. 어느 정도의 instance type과 크기가 필요한지 테스트 해서 적절한 type을 사용한다. ",
    "url": "/docs/aws/cost-efficiency#instance-%EB%B9%84%EC%9A%A9",
    
    "relUrl": "/docs/aws/cost-efficiency#instance-비용"
  },"501": {
    "doc": "AWS 비용 효율화",
    "title": "network 비용",
    "content": "binary가 비효율적으로 흐르지 않는지 확인한다. client와 통신에 compression(Gzip 등)이 적용되었는지 확인한다. 실제로 서비스가 오픈되었다면 심각한 상황이 아니고서야 비용을 크게 줄일만한 부분이 잘 없다. 우리가 제공하는 서비스 같은 경우는 data가 많이 쌓여서 CPU 비용은 비율이 낮을 정도이다. 결국 data life cycle을 확인하고 data 비용을 줄여나가는 방향. 서비스 초기에 life cycle을 잘 잡아두면 도움이 많이 된다. 내가 생각하기에 어느정도 GC가 진행됐다면 지금 우리팀 같은 상황에선 비용이 새고 있는 곳은 없는 것 같다. (작년/재작년에는 새고있는 돈들을 많이 잡았지만) 결국 이정도 상황에선 storage layering을 어떻게 잘 해나가느냐가 비용을 줄일 수 있는 키가 되지 않을까 싶다. ",
    "url": "/docs/aws/cost-efficiency#network-%EB%B9%84%EC%9A%A9",
    
    "relUrl": "/docs/aws/cost-efficiency#network-비용"
  },"502": {
    "doc": "AWS 비용 효율화",
    "title": "AWS 비용 효율화",
    "content": "연말이 다가오면 회사에선 항상 비용을 줄이라고 한다. 매년 비용을 어떻게 줄였는지 간략하게 정리해본다. ",
    "url": "/docs/aws/cost-efficiency",
    
    "relUrl": "/docs/aws/cost-efficiency"
  },"503": {
    "doc": "서버 개발자, 2022 회고",
    "title": "업무 자동화, 혹은 프로젝트 완성",
    "content": "이슈 대응을 위한 bot을 만들면서 업무 자동화라는 생각을 했다. 우리 파트 리더께서 이건 ‘업무 자동화가 아니라 프로젝트를 제대로 완성하는 것’이라는 말씀을 하셨다. 이슈 대응을 위한 프로세스까지도 프로젝트의 일부인데 우리가 놓쳤다는 것. 맞는 것 같다. 그런데 통계며 이슈 대응까지 생각하며 프로젝트를 설계하고 완성하는게 사실 쉽지 않다. 올해처럼 바쁜 일정에는 더더욱이. 그래도 올해 했던 일들을 정리해본다. 1. 이슈 대응 프로세스 만들기 . 우리가 맡은 한 모듈의 클라이언트는 이슈 대응을 위해 한 달에 약 80건 정도의 요청을 한다. 우리는 여태까지 이걸 받으면 빠르면 한 시간에서, 늦으면 일 주일 내로 스크립트를 돌려서 결과가 나오면 응답해주는 프로세스를 갖고 있었다. 생각보다 오래 걸리지 않지만 컨택스트 스위칭 비용이 컸던 일이다. 하루는 이 작업을 하다가 재미가 없어서 재미있는 일로 바꾸기 위해 slack bot을 만들었다. 일주일 정도 일이 끝나고 시간을 조금씩 써서 작업한 봇으로 클라이언트 이슈 대응을 대처했다. | 슬랙 봇 만들기 링크 - /docs/automation/python-bot | . 봇 제작으로 얻은 효과 . | 이슈 대응에 드는 시간 월 40시간 감소 (30분 * 80건) . | 봇 도입 이후 클라이언트는 대응이 늦어 요청하지 못한 요청을 더 많이 했다. | . | 이슈 대응을 기다리는 클라이언트 대기 시간 월 80일 감소 (평균 1일 * 80건) . | 말 그대로 대기시간이기 때문에 일을 못하는건 아니지만, 필요한 경우 주말에도 바로 응답받을 수 있는 프로세스가 구축되었다. | . | 봇 제작을 한번 해보니 기능 추가는 쉬워서 다른 모듈에서 사용할 기능들도 봇에 추가되었다. | . 2. 서비스 장애를 보고받기 . 우리는 grafana를 통해 서비스를 모니터링하는데, grafana는 자주 보게되지 않는다. 모듈마다 다른 임계 성공률(예를들면 99.0%) 이하로 떨어질 경우 알람을 받게 되는데 신규 모듈에는 ‘우리가 모르는 500에러는 없게하자’는 생각으로 개발을 시작했다. 예측되는 장애 상황에 slack noti를 날리는 aws lambda를 구축해서 500 에러 장애 상황을 바로 확인할 수 있도록 구현했다. 3. 통계 설계하기 . 이미 완성된 모듈에서 통계를 뽑는건 곤혹이다. 일 년에 한 두번 요청하는 통계를 뽑는데 db를 dump하는 작업을 하거나 1년치 로그를 조회하는 경우가 있었다. 신규 모듈에서는 설계 시점부터 통계를 같이 설계하려고 노력하고 통계를 정리하는 배치 모듈을 같이 개발했다. ",
    "url": "/docs/retrospect/2022#%EC%97%85%EB%AC%B4-%EC%9E%90%EB%8F%99%ED%99%94-%ED%98%B9%EC%9D%80-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EC%99%84%EC%84%B1",
    
    "relUrl": "/docs/retrospect/2022#업무-자동화-혹은-프로젝트-완성"
  },"504": {
    "doc": "서버 개발자, 2022 회고",
    "title": "tactical DDD",
    "content": "작년부터 이어지는 DDD를 통한 개발. 우리팀은 작년 말부터 하나의 모듈을 개발했고, 연중에 하나의 모듈을 리팩토링하고, 연말에 하나의 모듈을 새로 개발했다. 총 세 건의 모듈을 DDD로 개발하면서 DDD에 대한 개념을 제대로 익힐 수 있었던 것 같다. 올해 나는 Vaughn Vernon의 Implement Domain Driven Design의 tactical 부분을 읽고 정리했다. | domain events | Value Object | Domain Service | Entity | aggregate | . 사실 개념들을 요약해서만 읽어도 ‘아하 이거구나’ 싶지만 개발할 때 팀원들 간의 DDD에 대한 이해도와 생각은 다 달랐다. 정리한 내용들을 팀 내에 짧게 공유하기도 하고 내용을 기반으로 배운 것들이 많았다. 덕분에 설계 능력도 성장한 것 같다. 1. aggregate . aggregate은 반버논 아저씨도 DDD에서 가장 애매하다고 말한 부분이다. 우리 팀 내에서도 의견이 가장 분분했던 부분이기도 하다. 우리는 한 모듈을 엄청나게 큰 aggregate으로 작성했는데, 사실 이게 코드스멜이 느껴져서 aggregate에 대해 공부를 더 해보게 되었다. 책에서 말하는 큰 aggregate의 단점을 직접 설계한 모듈에서 느낄 수 있어서 더 배울점이 많았던 것 같다. aggregate은 크기도 중요하지만 어떤 기준으로 나누느냐가 굉장히 중요하다는 것을 배웠다. 2. domain events . 사실 우리팀은 domain event를 사용하는 팀이 아닌데, 이 개념을 공부하고 팀 내에 공유하고 나선 domain event를 적용해야 하는 부분들이 꽤 많았다라는 피드백을 받았다. domain model의 commit 시점에 event를 전달하고 이걸 처리하는 프로세스가 우리 프로젝트에 바로 적용하기 애매해서 거의 적용하진 못했다. 그치만 ‘이건 domain event면 좋았겠다’라는 생각을 할 수 있게 되었다. ",
    "url": "/docs/retrospect/2022#tactical-ddd",
    
    "relUrl": "/docs/retrospect/2022#tactical-ddd"
  },"505": {
    "doc": "서버 개발자, 2022 회고",
    "title": "팀",
    "content": "우리 팀은 팀 단위의 협업이 잘되고 효율도 좋다고 생각한다. 올해는 우리 팀의 프로세스 몇 가지가 좋은 방향으로 변경되었다. 1. 스토리 표준화와 명확하게 나누기 . 우리 팀은 작업의 단위를 스토리로 나눈다. 올 해는 개발 스토리를 정리하면서 표준화 하는 작업을 했는데 이 작업을 통해 스토리를 만드는 시간도 줄고, 스토리에서 놓치는 작업없이 마무리할 수 있었다. 표준화된 개발 스토리는 이렇다. | 구현 설계 | acceptance test 작성 | interface 구현 | scenario test 작성 | domain 구현 | usecase 구현 | scenario test pass | acceptance test pass | 회고하기 | . 이런 알찬 구성에서 필요하지 않은 카드는 설계를 하면서 제거한다. 예를 들면 domain의 일부만 수정되어 외부 변경사항이 없다면 test나 interface 카드는 삭제하는 식이다. 스토리를 명확하게 분리하면 팀원들간에 작업 분배가 원활하다. 2. 스토리 포인트 추정 . 우리는 원래 시간 단위의 추정을 해왔다. 스토리 포인트라는 개념이 처음엔 낯설었는데 스토리 포인트로 작업량을 기준으로 추정을 하는 방식으로 추정 방식을 변경하였다. 스토리 포인트 추정과 팀의 MH를 통해 우리가 어느정도의 스토리를 처리할 수 있는지를 정리하고 있다. 재밌는건 리더는 스토리 포인트를 최대한 많이 가져가려고 한다는 것. (우리는 스크럼 리더를 돌아가면서 한다) . 3. 우선순위 기반 일정 관리 . 원래도 스토리들을 backlog에 쌓아두고 일정관리를 했었지만. 올해는 스토리들에 우선순위(high, mid, low)를 두고 우선순위를 조정하면서 스크럼을 진행했다. 가장 급한 우선순위들을 먼저 보고 스프린트 계획을 세우는 방식이다. 한 눈에 우선순위가 들어오고, 우선순위와 우리가 추정했던 스토리 포인트를 기반으로 스프린트의 스토리들을 결정했다. 결국 할 수 없는 수준의 스토리를 스프린트에 가져온다거나 사실 급하지 않은 일을 먼저 처리하는 일들이 줄었다. 중요한 일들을 할 수 있을지를 어느정도 판단해서 스프린트를 세울 수 있었다. 4. 번외. 팀 리더 . 연 말에는 회사에서 교육을 가게 되었는데 교육 마지막엔 일주일짜리 팀 프로젝트가 있었다. 서로 다른 팀에서 온 사람들과 진행하게 되었는데. 이 교육 마지막 날 밤을 세워 프로젝트를 마무리하는 팀들도 많다고 했다. 팀이 첫 회의를 할 때 프로젝트 설계를 제대로 진행하는 분위기가 아닌 것 같아서 내가 리더아닌 리더 역할을 하게 되었다. 설계 회의, 설계 내용 공유, 테스트 작성, 인터페이스 작성과 작업 분배. 우리 팀이 팀 단위의 일과 리더로서의 역할을 잘 해내고 있다는 것을 느낄 수 있었고. 처음으로 다른 팀에서 리더를 해본 경험이라 재미있었다. 올해의 교훈은 같은 일을 같은 방식으로 하면 재미없다. 새로운 일을 하려고 하는데 쉽지 않았다. 내년에는 새로운 일을 아니면 새로운 방식으로 좀 더 재미있게 일할 수 있었으면 좋겠다. ",
    "url": "/docs/retrospect/2022#%ED%8C%80",
    
    "relUrl": "/docs/retrospect/2022#팀"
  },"506": {
    "doc": "서버 개발자, 2022 회고",
    "title": "서버 개발자, 2022 회고",
    "content": "22년은 무슨 일을 했는지 모르겠다. 쏟아지는 일정을 우선순위에 맞게 쳐내다가 한 해가 지나간 것 같다. ASAP으로 위에서 내려오는 요구사항들을 만족시키다보니 여유를 갖고 보수하거나 개발할만한 시간이 부족했던 것 같아 아쉽다. ",
    "url": "/docs/retrospect/2022",
    
    "relUrl": "/docs/retrospect/2022"
  },"507": {
    "doc": "telnet 없을 때 connection 확인하기",
    "title": "telnet 없이 telnet 하기",
    "content": "curl -v telnet://127.0.0.1:22 . 이거하나면 어디든. ",
    "url": "/docs/dev-tools/linux-commands/telnet-by-curl#telnet-%EC%97%86%EC%9D%B4-telnet-%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/dev-tools/linux-commands/telnet-by-curl#telnet-없이-telnet-하기"
  },"508": {
    "doc": "telnet 없을 때 connection 확인하기",
    "title": "reference",
    "content": "https://gist.github.com/Khoulaiz/41b387883a208d6e914b . ",
    "url": "/docs/dev-tools/linux-commands/telnet-by-curl#reference",
    
    "relUrl": "/docs/dev-tools/linux-commands/telnet-by-curl#reference"
  },"509": {
    "doc": "telnet 없을 때 connection 확인하기",
    "title": "telnet 없을 때 connection 확인하기",
    "content": "서버에 연결이 잘 되는지를 확인할 때 telnet이나 ping을 사용하곤 한다. 권한 문제 등으로 연결이 되지 않거나 서버가 떠있지 않은 경우를 확인할 수 있다. 문제는 alpine 이미지로 생성한 docker를 접속할 때를 대표적으로 telnet이나 ping이 없는 경우가 있다는 것. 굉장히 파워풀한 해결책을 가져왔다. ",
    "url": "/docs/dev-tools/linux-commands/telnet-by-curl",
    
    "relUrl": "/docs/dev-tools/linux-commands/telnet-by-curl"
  },"510": {
    "doc": "flutter theme",
    "title": "pub.dev readme",
    "content": "https://pub.dev/packages/flex_color_scheme . ",
    "url": "/docs/flutter/flutter-theme#pubdev-readme",
    
    "relUrl": "/docs/flutter/flutter-theme#pubdev-readme"
  },"511": {
    "doc": "flutter theme",
    "title": "playground",
    "content": "https://rydmike.com/flexcolorscheme/themesplayground-v6/#/ . playground에서 선택을하고 copy만 하면 적용할 수 있다. ",
    "url": "/docs/flutter/flutter-theme#playground",
    
    "relUrl": "/docs/flutter/flutter-theme#playground"
  },"512": {
    "doc": "flutter theme",
    "title": "flutter theme",
    "content": "flutter에서 간단하게 테마를 적용할 수 있는 툴이 있다. 디자이너가 아닌 경우에 색깔을 선택하는데도 도움이되고, 나처럼 front-end 실력이 부족한 경우에 크게 도움이 되는 것 같다. 별건 없으니 나중에 내가 보기 위해 . ",
    "url": "/docs/flutter/flutter-theme",
    
    "relUrl": "/docs/flutter/flutter-theme"
  },"513": {
    "doc": "DDD의 Aggregate란? Aggregate를 적절하게 만들기",
    "title": "aggregate?",
    "content": "에그리게잇이란 단지 공통 부모 아래 긴밀하게 연결된 객체의 그래프를 묶는 방법 중 하나가 아니다. 이런 생각들로 잘못 모델링 된 aggregate들이 생겨난다. | 컴포지션의 편의에 맞춰 설계해서 에그리게잇을 너무 크게 만들어버리는 경우 | 너무 걷어내서 고정자를 보호하지 못하는 에그리게잇을 만드는 경우 | . ",
    "url": "/docs/ddd/tactical/aggregate#aggregate",
    
    "relUrl": "/docs/ddd/tactical/aggregate#aggregate"
  },"514": {
    "doc": "DDD의 Aggregate란? Aggregate를 적절하게 만들기",
    "title": "큰 aggregate",
    "content": "A는 ~를 포함한다. 에 중점을 두고 aggregate을 설계한다면 큰 aggregate을 만들기 쉽다. 옳지 않다. 장점: . | A에 포함된 모델들의 변경에 따라 모든 부분을 보호하기 위해 이런 설계를 할 수 있다. | A를 내부의 객체들을 포함한 아주 큰 aggregate으로 모델링하면 의도치 않은 client가 누락되지 않도록 보호할 수 있다. | . 단점: . | 크기가 큰 에그리게잇은 처음엔 그럴싸해 보였지만 실제로 실용적이진 않다. | 에그리게잇의 단위가 크기 때문에 트랜잭션이 실패하기 쉽다. | . ",
    "url": "/docs/ddd/tactical/aggregate#%ED%81%B0-aggregate",
    
    "relUrl": "/docs/ddd/tactical/aggregate#큰-aggregate"
  },"515": {
    "doc": "DDD의 Aggregate란? Aggregate를 적절하게 만들기",
    "title": "다수의 aggregate",
    "content": "동시성 문제를 해결하기 위해 아래와 같은 구조를 사용하기도 한다. 이런 구조는 aggregate의 invirant를 동시에 발생하는 변경으로부터 보호할 수 있다. 장점: . | 트랜잭션에 이점이 있다. 성공하기 쉽다. | 다른 aggregate 인스턴스들을 동시에 안전하게 생성할 수 있다. | . 단점: . | 클라이언트가 사용하는 관점에서 여러 개의 작은 aggregate은 불편할 수 있다. | . ",
    "url": "/docs/ddd/tactical/aggregate#%EB%8B%A4%EC%88%98%EC%9D%98-aggregate",
    
    "relUrl": "/docs/ddd/tactical/aggregate#다수의-aggregate"
  },"516": {
    "doc": "DDD의 Aggregate란? Aggregate를 적절하게 만들기",
    "title": "큰 aggregate vs 다수 aggregate",
    "content": ". | 큰 에그리게잇은 에그리게잇 내부에서 모두 수행하는 (return void) CQS command로 수행되고 | 다수 에그리게잇은 각 메소드가 새로운 에그리게잇 인스턴스를 반환하는 (return Aggregate) CQS query로 수행된다 | . 다수의 aggregate 모델링에서는 다른 aggregate에 대해서 얼마든지 동시에 생성할 수 있다. | 트랜잭션에 이점이 있다. 큰 aggregate에서 문제가 되는 부분. | 클라이언트가 사용하는 관점에서 여러 개의 작은 에그리게잇은 불편할 수 있다. | . ",
    "url": "/docs/ddd/tactical/aggregate#%ED%81%B0-aggregate-vs-%EB%8B%A4%EC%88%98-aggregate",
    
    "relUrl": "/docs/ddd/tactical/aggregate#큰-aggregate-vs-다수-aggregate"
  },"517": {
    "doc": "DDD의 Aggregate란? Aggregate를 적절하게 만들기",
    "title": "모델링 규칙",
    "content": "invirant . invirant는 aggregate의 모델링 규칙을 설명할 때 가장 중요한 개념으로 :star: 언제나 일관성을 유지해야 한다는 비즈니스 규칙이다. 예시 . | c = a + b | a = 2 | b = 3 | . 같은 조건 이 있을 때 c가 5가 아닌 경우는 시스템의 invirant를 위반하는 것이다. c가 일관성을 갖게 하기 위해 모델의 특성을 둘러싸는 경계를 설계해야 한다. 그렇다면 a, b, c는 하나의 aggregate에 속하게 되는 것. 예시 . | c = a + b | a = 2 | b = 3 | d + e = 5 | . 같은 조건 이 있을 때 c가 5가 아닌 경우는 시스템의 invirant를 위반하는 것이다. c가 일관성을 갖게 하기 위해 모델의 특성을 둘러싸는 경계를 설계해야 한다. 그렇다면 a, b, c는 하나의 aggregate에 속하게 되는 것. 여기에 마지막 조건이 추가된다고 보자. a, b, c는 하나의 aggregate이겠지만, d, e는 관련이 없는 다른 aggregate이 될 것이다. 진짜 invirant를 일관성 경계 안에서 모델링하라 . 가장 먼저 invirant를 소개한 것은 bounded context에서 aggregate을 찾으려면 모델의 진짜 invirant를 이해해야 하기 때문이다. invirant를 알아야 aggregate으로 묶어야 할 객체가 무엇인지 결정할 수 있다. 일관성 경계는 어떤 요청이 수행되든 경계 안의 모든 대상이 invirant에 대한 비즈니스 규칙들을 준수하도록 논리적으로 보장해야 한다. 이 경계 밖의 일관성은 aggregate과 무관하다. 그러므로 aggregate은 트랜잭션의 일관성 경계와 같은 개념이다. 올바르게 설계된 aggregate은 단일 트랜잭션 내에서 완벽한 일관성을 유지하면서 비즈니스 요구사항과 그 invirant에 맞춰 수정되어야 한다. 또 하나의 트랙잭션당 하나의 aggregate만 수정되어야 한다. | 경험적으로 얻어진 aggregate을 사용하는 가장 중요한 이유라고 | . 작은 aggregate으로 설계하라 . 모든 트랜잭션이 성공하는 경우에도 큰 aggregate을 사용하는 것은 성능과 확장성에 문제가 있다. | 데이터가 많이 쌓인 상황에서 데이터를 추가하고 싶을 때도 한 번에 가져오는 데이터의 크기가 너무 많다. | 이를 막기 위해 지연로딩을 하기도 하지만 지연로딩으로도 해결할 수 없는 경우가 있다. | . 다이어그램의 0 ... * 에 속으면 안된다 0이 되는 경우는 거의 없고 대부분은 시간이 지나면 계속 증가한다. 결국 큰 aggregate은 시간이 흐를수록 더 나빠진다. 위 예제를 보면 거짓 invirant와 컴포지션적 편의성이 설계를 주도했기 때문에 시작부터 문제가 있었다. 트랜잭션의 성공적인 종료, 성능, 확장성에 안좋은 영향을 미쳤다. 그럼 얼마나 작아야할까? 당연한 말이지만, 무작정 작지도 않고 너무 크지도 않게 필요한 만큼만 작아야 한다. aggregate은 도메인 전문가가 규칙으로 구체화하지 않더라도 다른 대상과 일관성을 유지해야 한다. 예시 . product가 name과 description을 갖는다면 name과 description이 일관성이 맞지 않는건 상상할 수 없다. 둘 중 하나를 바꾸고 다른 것을 그대로 두는 경우는 철자를 고치거나 description을 name에 맞게 바꾸는 정도일 것. 도메인 전문가가 비즈니스 규칙으로 명시하지 않더라도 여기에 비즈니스 규칙이 녹아있는 것. 예시 . Qi4j를 사용한 한 프로젝트에서 니클라스 헤드만의 팀은 aggregate을 설계할 때 70 퍼센트는 단일 엔티티와 vo의 aggregate으로 설계하고 남은 30 퍼센트는 두 세개의 엔티티가 필요했다고 한다. 대부분 이런 것은 아니지만 높은 비율로 aggregate 루트 엔티티를 하나로 구성할 수 있다. 최대한 나누는 방향을 고려하는데, 고려할 때 invirant를 확인한다. 예시 . BacklogItem«Aggregate root»에 Task«Entity»가 있다 이 둘을 나눠야 하지는 않을지 고민해보고 그 기준으로 invirant가 있는지 확인한다. 크기가 작은 aggregate은 성능과 확장성이 좋고, 커밋을 가로막는 문제가 없어 트랜잭션 성공 가능성도 높다. 따라서 크기를 제한하는 편이 현명하다. 혹시 일관성 규칙이 꼭 필요한 상황에서는 엔티티나 컬렉션을 추가하고 그러면서도 전체 크기는 가능한 작게 유지하자. 유스케이스를 전부 믿지는 말기 . 도메인 전문가가 만든 유스케이스는 설계에 영항을 크게 미친다. 그러나 유스케이스는 개발자와 모델링 관점이 포함되지 않았다는 것을 생각하야 한다. 각 유스케이스와 현재의 모델은 조화를 이뤄야 하고 여기엔 aggregate에 대한 결정도 포함된다. 특정 유스케이스 때문에 여러 aggregate를 수정해야 한다면 유스케이스의 진짜 목적이 여러 트랜잭션에 있는지 하나의 트랜잭션 안에서 이뤄지는지 반드시 확인해야 한다. 여러 aggregate을 수정하는 것이 하나의 트랜잭션에서 필요하다면 잘 작성된 유스케이스라고 해도 진짜 aggregate을 정확히 반영하지 못할 수 있다. | 유스케이스가 무조건 하나의 트랜잭션에서 이뤄져야하는 것은 아니다. 여러 트랜잭션일 수 있다. 단순히 여러 aggregate 인스턴스가 하나의 트랜잭션에서 수정되는 것만 막으면 된다. | . 하나의 트랜잭션에서 일관성을 유지해주길 기대하는 유스케이스가 있다고 해서 반드시 지켜야하는 것은 아니다. 이런 경우 대부분 aggregate 사이의 결과적 일관성을 통해 비즈니스 목표를 달성할 수 있다. 유스케이스를 그대로 따르기만 하면 통제하기 힘든 설계로 이어질 수 있다. 유스케이스를 그냥 따르는 것이 아니라 비판적으로 살펴보고 면밀히 확인해야 한다. 필요에 따라다시 유스케이스를 써야할 수도 있다. ID로 다른 aggregate을 참조하라 . aggregate을 설계하면서 객체 그래프를 깊이 탐색하는 컴포지션 구조를 설계할 수도 있지만 이는 aggregate에 맞지 않는다. aggregate은 다른 aggregate 루트로의 참조를 가질 수 있다. 그렇지만 이는 참조된 aggregate을 참조하고 있는 aggregate의 일관성 경계 안쪽에 위치시킨다는 의미가 아니다. aggregate을 가지고 있는 경우 . public class BacklogItem extends ConcurrencySafeEntity { private Product product; } . 이런 구조는 좋지 않지만 이런 구조를 갖는 경우 고려해야할 것들이 있다. | 참조하는 aggregate과 참조된 aggregate이 하나의 트랜잭션 안에서 수정되면 안된다. | 하나의 트랜잭션에서 여러 인스턴스를 수정하고 있다면 일관성 경계가 잘못되었을 경우가 많다. | 2번과 유사하게 수정이 묶여있는 aggregate에 영향을 미친다면 원자적 일관성 대신 결과적 일관성을 사용해야 한다는 표시일 수 있다. | . 객체 참조가 아닌 ID를 참조함으로서 이런 상황을 완전히 피할 수 있다. 참조(Id)를 가지고 있는 경우 . public class BacklogItem extends ConcurrencySafeEntity { private ProductId productId; } . | 참조를 즉시 가져올 필요가 없기 때문에 작아진다. | 인스턴스를 가져올 때 elapsed가 짧고 메모리가 적게 필요하기 때문에 모델의 성능도 개선된다. | 메모리 할당 비용과 GC에도 긍정적인 영향을 미친다. | 그렇다고 모델을 전혀 탐색할 수 없는건 아니다. | aggregate 내부에서 리파지토리를 사용하거나 aggregate 사용 전에 repository나 domain service를 통해 객체를 조회할 수 있다. | . | . 경계의 밖에서 결과적 일관성(Eventual Consistency)을 사용하라 . 하나의 aggregate 인스턴스에서 커맨드를 수행할 때 하나 이상의 aggregate에서 추가적인 비즈니스 규칙이 수행돼야 한다면 결과적 일관성을 사용하자. 큰 규모의, 트래픽이 많은 엔터프라이즈에서는 aggregate 인스턴스가 절대적이고 완전하게 일관성을 유지할 수 없다는 점을 받아들인다면, 결과적 일관성이 더 적은 인스턴스가 관련된 더 작은 규모에서도 의미있다는 사실을 좀 더 쉽게 이해할 수 있다. 한 인스턴스가 수정되고 관련된 다른 수정이 완료될 때까지 어느정도 시간 지연이 용납될 수 있는지 도메인 전문가에게 물어보자. 개발자들은 원자적 변경의 사고방식에 사로잡혀있기 마련이고 도메인 전문가는 지연된 일관성에 더 관대하다. 결과적 일관성을 지원하는 방법 . | aggregate 함수가 하나 이상의 비동기 구독자에게 제때 전달되는 도메인 이벤트를 발행한다. | 각각의 구독자가 다른 유형의 aggregate 인스턴스를 가져오고 그에 기반해 동작을 수행한다. | 각 구독자는 분리된 트랜잭션 내에서 수행되며 트랜잭션당 하나의 인스턴스만 수정한다는 aggregate 규칙을 따른다. | . public class BacklogItem extends ConcurrencySafeEntity { // ... public void commitTo(Sprint aSprint) { // ... DomainEventPublisher .instance() .publish(new BacklogItemCommitted( this.tenantId(), this.backlogItemId(), this.sprintId())); } } . 이렇게 domain event를 발행해서 다른 트랜잭션에서 다른 aggregate을 수정1하도록 한다. 결과적 일관성 사용 여부 결정하기 . 트랜잭션을 사용할지 결과적 일관성을 사용할지 결정하기 쉽지 않다. 에릭 에반스의 지침을 참고하면 도움이 된다. | 일관성을 보장하는 주체가 유스케이스를 수행하는 사용자의 일이라면 트랜잭션을 통해 일관성을 보장하자. | 일관성을 보장하는 주체가 다른 사용자나 시스템이라면 결과적 일관성을 선택하자. | . 규칙을 어기는 경우 . 충분한 이유가 있을 때만 규칙을 어겨야 한다. 경험에 의지해서 규칙을 지키지 않아야할 변명거리를 찾아선 안된다. 반버논이 얘기하는 규칙을 어길만한 사례들 . 1. 사용자 인터페이스의 편의 . 편의를 위해 사용자가 한 번에 여러 일의 공통 특성을 정의해 배치를 생성할 수 있도록 허용할 때도 있다. 2. 기술적 메커니즘의 부족 . 결과적 일관성을 위해 메시징이나 타이머, 백그라운드 쓰레드와 같은 추가적인 처리 기능이 필요할 수 있다. 이런 메커니즘을 전혀 제공하지 않고 있다면 큰 aggregate을 생성하는 방향으로 가게될 확률이 높고 aggregate을 변경하거나 하나의 트랜잭션에서 둘 이상의 aggregate을 수정해야할 수도 있다. 3. 글로벌 트랜잭션 . two-phase commit transaction을 엄격하게 지켜야하는 경우도 고려가 필요하다. 그치만 꼭 바운디드 컨텍스트 내에서 다수의 aggregate 인스턴스를 한 번에 수정해야하지 않을수도 있다. 4. 쿼리 성능 . 다른 aggregate에 대해 직접 객체 참조를 유지하는 편이 최선일 때가 있다. 리파지토리의 쿼리 성능 문제를 해결하는데 사용될 수도 있다. 구현 . 그래서 어떻게 해야할까. | 고유 ID와 root entity를 생성한다. 하나의 entity를 aggregate root로 모델링한다. | 가능하면 aggregate 내부를 entity보다는 VO로 모델링한다. (entity/vo 참고) | ‘데메테르의 법칙’과 ‘묻지 말고 시켜라’를 사용한다. | 데메테르의 법칙: 서버의 구조를 클라이언트가 완벽하게 알지 못하고 인터페이스만 제공받는다. | 묻지말고 시켜라: 클라이언트가 서버 객체의 일부를 요구해선 안되고 자신이 갖고 있는 상태에 기반해 결정하고 서버에게 무엇을 할지 시켜야 한다. | . | . reference . | Implement Domain Driven Design (chapter5 Entity), Vaughn Vernon | . | domain event를 통해 side effect으로 발생한 aggregate의 transaction을 분리할 수 있다. domain event 참고 &#8617; . | . ",
    "url": "/docs/ddd/tactical/aggregate#%EB%AA%A8%EB%8D%B8%EB%A7%81-%EA%B7%9C%EC%B9%99",
    
    "relUrl": "/docs/ddd/tactical/aggregate#모델링-규칙"
  },"518": {
    "doc": "DDD의 Aggregate란? Aggregate를 적절하게 만들기",
    "title": "DDD의 Aggregate란? Aggregate를 적절하게 만들기",
    "content": "DDD tactical components . VO Entity Domain Service Domain Events Aggregate . 에그리게잇은 모든 DDD의 전술적인 지침 중에서도 무엇보다 정확히 규명되지 않은 패턴 중 하나다. - Vaughn Vernon . ",
    "url": "/docs/ddd/tactical/aggregate",
    
    "relUrl": "/docs/ddd/tactical/aggregate"
  },"519": {
    "doc": "서버 개발 도메인, 동기화에 대해 이해하기",
    "title": "interface 관점에서",
    "content": ". | initial changepoint . | 초기 동기화, 즉 처음부터 받아갈 수 있는 인터페이스를 정의한다. | 우리는 보통 initial changepoint 값을 제공했다. | . | changepoint . | 클라이언트는 해석할 수 없는 changepoint를 내려준다. | 어디까지 받았는지 어떤걸 받아야하는지, 받아 갈 때의 schema와 바뀌진 않았는지 등을 확인할 수 있다. | . | multiple api에 대한 partial error vs full error . | partial은 성능에 좋지만 이슈 파악에 너무 안좋다 | 에러가 그렇게 잦을건가? 아닐거다. 라는게 최근 우리의 결론. | . | . ",
    "url": "/docs/career/domain/sync#interface-%EA%B4%80%EC%A0%90%EC%97%90%EC%84%9C",
    
    "relUrl": "/docs/career/domain/sync#interface-관점에서"
  },"520": {
    "doc": "서버 개발 도메인, 동기화에 대해 이해하기",
    "title": "code 관점에서",
    "content": ". | 누락없는 get의 관리 . | get의 기준점을 확인하자. | modifiedTime이 기준점이라면, 동일한 modifiedTime에 걸친 경우 누락이 생길 수 있는 구조인지 확인한다. | 누락이 없을 수 있도록 주의하기. | 웹과 다르게 한번 누락이 되면 초기 동기화를 하지 않는한 사용자 입장에선 영구 누락과 같게될 수 있다. | . | 여러 모듈 간의 중복 코드는 하나의 코드를 사용하도록 하자 . | 배치에서 was를 보든지 was의 코드와 같이 하나의 repository에서 관리하든지. | . | gdpr . | 사용자의 데이터를 관리하는 eu의 법적인 요구사항. 동기화 서비스를 글로벌하게 한다면 필수적인 요소. | 서비스 로직의 domain을 그대로 사용하지 않으면 추후 서비스 변경에 따라 관리하기 복잡해진다. | hexagonal을 잘 정리한 뒤 도메인 로직은 동일하게 사용한다. | . | . ",
    "url": "/docs/career/domain/sync#code-%EA%B4%80%EC%A0%90%EC%97%90%EC%84%9C",
    
    "relUrl": "/docs/career/domain/sync#code-관점에서"
  },"521": {
    "doc": "서버 개발 도메인, 동기화에 대해 이해하기",
    "title": "data 관점에서",
    "content": ". | 삭제한 데이터도 row가 남아서 삭제 동기화가 되어야 함 (단말엔 이미 받아져 있으므로, 웹과는 다르다) . | 단말이 여러개라거나 하는 이슈로 row를 확실히 지울 수 있는 시점을 장담하기 어렵다. | . | 사용자 탈퇴 등으로 데이터가 보여지지 않아야 하는 경우를 위해 sequence(link)를 사용한다. | sequence를 올려서 데이터는 남아있지만 사용자가 볼 수 없게. 이 데이터는 배치로 삭제. | . | 실제 데이터의 row 삭제가 필요한 경우 마킹하고 배치로 삭제하자 . | 실제 삭제로 인한 딜레이가 크다. | 특히 container에 대한 삭제라면 container 안의 item을 삭제하는 시간까지 굉장하다. | 마치 cassandra mv가 delete 요청시 바로 삭제해서 성능 이슈가 생기는 것처럼 서버도 바로 삭제하지 않고 사용자에게 응답하고 나중에 삭제한다. | . | 삭제는 안전하게 . | 모든 서비스가 그렇겠지만 동기화에서는 더더욱이 사용자 데이터를 삭제할 땐 조심해야 한다. | 삭제 api가 들어온다면 “제 사진이 지워졌어요!” 같은 이슈를 쉽게 대응할 수 있도록 로그를 남겨야 하고. | 배치를 수행한다면 안전하게 지우고 가능하면 딜레이를 주는 것도 좋다. | . | . ",
    "url": "/docs/career/domain/sync#data-%EA%B4%80%EC%A0%90%EC%97%90%EC%84%9C",
    
    "relUrl": "/docs/career/domain/sync#data-관점에서"
  },"522": {
    "doc": "서버 개발 도메인, 동기화에 대해 이해하기",
    "title": "service 관점에서",
    "content": ". | 단말의 로직에 downsync가 주도되기 때문에 단말 구현이 올바른지 파악이 필요함 . | 단말에서 dirty(수정사항) 체크가 잘 되고 있는지. | 단말에서 오구현을 할 경우를 찾기 위한 지표들을 셋업하자. | . | 정책을 결정하기 . | 우리 PM들은 세부 정책들을 결정해주지 않았다. | 사용자가 가질 수 있는 달력 일정의 개수라거나, 하루에 생성할 수 있는 item의 개수/사이즈라거나. | 인스타그램이나 구글 포토 같은 서비스들은 정책이 결정되어 있다. (일하기 좋겠다..) | 정책이 없는 경우, 이로 인한 문제점들을 보게된다. migration 시 비정상적인 item을 갖는 사용자, 기획된 의도와 완전히 다르게 사용하는 어뷰징 유저들. | . | 누구의 동기화인가 . | 누구의 동기화인지도 중요하다. 사용자 혼자 쓰는지. 아니면 누군가와 함께 사용하는지. 아니면 오픈된 동기화인지. | 동기화의 종류에 따라 서버에서 마킹하는 데이터가 달라진다. (생성자와 소유권의 관계, 사용량을 점유하는 사용자에 대한 정책들 등) | . | . ",
    "url": "/docs/career/domain/sync#service-%EA%B4%80%EC%A0%90%EC%97%90%EC%84%9C",
    
    "relUrl": "/docs/career/domain/sync#service-관점에서"
  },"523": {
    "doc": "서버 개발 도메인, 동기화에 대해 이해하기",
    "title": "서버 개발 도메인, 동기화에 대해 이해하기",
    "content": "동기화 서버 개발자로서 구른지 어언 3년. 그 동안 우리 팀은 회사에서 서비스하는 대부분의 동기화 서비스를 담당했다. 수 억 명의 MAU의 요청을 받아내는 동기화 서비스 개발자로서. 나중에 내가 까먹지 않기 위해 동기화 서비스의 도메인과 동기화 서비스를 개발하며 겪었던 노하우들을 적어본다. ",
    "url": "/docs/career/domain/sync",
    
    "relUrl": "/docs/career/domain/sync"
  },"524": {
    "doc": "java serialize 사용할 때 주의사항",
    "title": "serialize 단점",
    "content": ". | java에서 serialize를 한다면 java 외의 다른 언어에서 deserialize할 수 없다. | 언어에 제약이 생기게 된다. batch나 다른 작업에도 java 밖에. | . | java serialize는 serialized된 data의 크기가 크다. | package / class 정보가 포함되기 때문에 다른 serialize 알고리즘 보다 무겁다. | . | 실수하기 쉽다. | 오늘 다루려고하는 부분인데 실수하기 쉽다. | serialize 하는 class에 손을 대는 경우 이미 만들어놓은 serialize 데이터가 deserialize가 불가능할 수 있다. | . | . ",
    "url": "/docs/java/tip/java-serialize#serialize-%EB%8B%A8%EC%A0%90",
    
    "relUrl": "/docs/java/tip/java-serialize#serialize-단점"
  },"525": {
    "doc": "java serialize 사용할 때 주의사항",
    "title": "그럼에도 사용하는 경우",
    "content": "serialize의 장점은 별도의 라이브러리가 필요없는 것 하나 밖에 없다. 아주 형편없는 것. :weary: . 그럼에도 사용하는 경우는 기존 모듈에서 사용하는 경우 하나 뿐인 것 같다. 새로 합류한 팀에서 java serialize를 사용하고 있었고, 덕분에 serialize에 대해 다시 생각해볼 기회가 되었다. 그 전에 serialize가 필요하면 성능(압축률과 시간, cpu 점유)을 비교해서 알고리즘을 선택했었는데, 그 중 java serialize는 없었다. 특정 성능이 아주 중요하고, java serialize가 그걸 만족한다면 사용할 수도 있을 것 같으나 일반적으로 사용하진 않는다. ",
    "url": "/docs/java/tip/java-serialize#%EA%B7%B8%EB%9F%BC%EC%97%90%EB%8F%84-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94-%EA%B2%BD%EC%9A%B0",
    
    "relUrl": "/docs/java/tip/java-serialize#그럼에도-사용하는-경우"
  },"526": {
    "doc": "java serialize 사용할 때 주의사항",
    "title": "serialize의 주의사항",
    "content": "오늘 정리하려고 했던 내용. serialize는 단점이 많지만 일단 사용한다면 별 수 없다. 실수하기 쉽다는 부분을 커버하기 위해. | serialVersionUID를 고정한다. | package 이동에 주의한다. | 테스트를 작성한다. | . serialVersionUID를 고정한다 . property 추가 혹은 제거 등의 이유로 java class가 변하게 되면 serialVersionUID가 변하게 된다. serialVersionUID는 serialize/deserialize에 사용되기 때문에 이 값이 바뀌지 않도록 고정하는 것이 java serialize를 사용할 때 필수이다. // 임의의 값으로 고정 private static final long serialVersionUID = 1234567L; . package 이동에 주의한다 . 내가 이번에 당했던 이슈는 이거다. legacy 프로젝트를 hexagonal과 ddd에 맞춰 리팩토링을 진행하면서 package를 옮겼더니 장애가 발생했다. 다행히 InputStream에서 readClassDescriptor()를 조작함으로써 문제를 해결할 수 있었다. 이게 되게 재미있는 부분이었는데 stream을 쓰지 않다보니 package 이동이 문제가 된다는걸 모르고 있었던 것. 실수가 발생하기 참 좋은 구조인 것 같다. 테스트를 작성한다 . 그래서 이런 문제들을 해결하려면 테스트가 필요하다. 내가 리팩토링하면서 작성했던 테스트들은 변경된 구조에서의 serialize &amp; deserialize. 그런데 java serialize를 사용한다면 현재 알고리즘으로 serialized string을 만들어 놓고 이걸 수정된 로직에서 deserialize 하는 것을 테스트할 수 있어야 한다. 그니까 테스트는 이럴거다. @Test void deserializeTest() { String serialized = \"abcde..............\"; // 현재 개발과 별개로 이전에 serialize 해놓은 데이터 Object deserializedObject = Serializer.deSerialize(serialized); } . 이렇게 테스트를 작성하면 혹여 serialVersionUID가 바뀌었든, package가 바뀌었든 모두 커버할 수 있는 테스트를 갖게된다. ",
    "url": "/docs/java/tip/java-serialize#serialize%EC%9D%98-%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD",
    
    "relUrl": "/docs/java/tip/java-serialize#serialize의-주의사항"
  },"527": {
    "doc": "java serialize 사용할 때 주의사항",
    "title": "오늘의 결론",
    "content": ":x: java serialize 사용하지 마라. reference . | serialVersionUID 관련 . | https://www.baeldung.com/java-serial-version-uid | . | package 이동 관련 . | https://stackoverflow.com/questions/2358886/how-can-i-deserialize-the-object-if-it-was-moved-to-another-package-or-renamed | . | . ",
    "url": "/docs/java/tip/java-serialize#%EC%98%A4%EB%8A%98%EC%9D%98-%EA%B2%B0%EB%A1%A0",
    
    "relUrl": "/docs/java/tip/java-serialize#오늘의-결론"
  },"528": {
    "doc": "java serialize 사용할 때 주의사항",
    "title": "java serialize 사용할 때 주의사항",
    "content": "java에서 serialize를 잘 사용하지 않는 편이다. 그럼에도 사용해야 하는 경우가 있는데, 이번이 그랬다. ",
    "url": "/docs/java/tip/java-serialize",
    
    "relUrl": "/docs/java/tip/java-serialize"
  },"529": {
    "doc": "MSA의 데이터 일관성 유지 기법 Saga 이해하기",
    "title": "saga 패턴이 필요한 이유",
    "content": "분산시스템(MSA)에서는 application을 여러 개의 작은 application으로 나누기 때문에 단일 요청이 여러 요청으로 세분화된다. (여러 개의 트랜잭션) 이런 요청들은 일부는 성공하고 일부는 실패할 수 있다. 이 경우 모든 단계가 완료되거나 모든 단계가 완료되지 않아야 하는 데이터 일관성을 유지하기 어렵다. 여러 트랜잭션의 경우 원자적 일관성을 유지할 수 없고, 궁극적 일관성을 유지하려고 하는데 그 방법 중 하나가 saga 패턴이다. ",
    "url": "/docs/pattern/saga#saga-%ED%8C%A8%ED%84%B4%EC%9D%B4-%ED%95%84%EC%9A%94%ED%95%9C-%EC%9D%B4%EC%9C%A0",
    
    "relUrl": "/docs/pattern/saga#saga-패턴이-필요한-이유"
  },"530": {
    "doc": "MSA의 데이터 일관성 유지 기법 Saga 이해하기",
    "title": "saga 패턴의 해결 방식",
    "content": "트랜잭션의 모든 단계는 보상 트랜잭션(compensating transaction) 즉, 롤백할 수 있다. 그리고 실패가 발생하는 경우 진행된 트랜잭션에 보상 트랜잭션이 실행되어 완료된 작업을 취소할 수 있도록 한다. ",
    "url": "/docs/pattern/saga#saga-%ED%8C%A8%ED%84%B4%EC%9D%98-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EC%8B%9D",
    
    "relUrl": "/docs/pattern/saga#saga-패턴의-해결-방식"
  },"531": {
    "doc": "MSA의 데이터 일관성 유지 기법 Saga 이해하기",
    "title": "saga 패턴",
    "content": "그래서 saga 패턴은 . | MSA에서 장기 트랜잭션 문제를 해결하는 것을 목표로 하는 필수적인 micro service 패턴이다. | 트랜잭션에서 문제가 발생할 경우 롤백을 할 수 있게 설계한 패턴이다. | . ",
    "url": "/docs/pattern/saga#saga-%ED%8C%A8%ED%84%B4",
    
    "relUrl": "/docs/pattern/saga#saga-패턴"
  },"532": {
    "doc": "MSA의 데이터 일관성 유지 기법 Saga 이해하기",
    "title": "saga 패턴 사용 예시",
    "content": "대표적인 saga 패턴 사용 예시는 전자 상거래. 전자 상거래 서비스의 경우 사용자가 상품을 주문했을 때 연속적으로 발생하는 작업들이 있다. 주문, 결재, 배송의 각각의 트랜잭션을 saga 패턴으로 관리할 수 있다. 만약 배송 트랜잭션에서 문제가 발생하면, 결제와 주문 트랜잭션을 롤백한다. ",
    "url": "/docs/pattern/saga#saga-%ED%8C%A8%ED%84%B4-%EC%82%AC%EC%9A%A9-%EC%98%88%EC%8B%9C",
    
    "relUrl": "/docs/pattern/saga#saga-패턴-사용-예시"
  },"533": {
    "doc": "MSA의 데이터 일관성 유지 기법 Saga 이해하기",
    "title": "장점",
    "content": ". | 여러 마이크로 서비스에서 복잡한 트랜잭션을 쉽게 구현할 수 있다. | 오류를 적절하게 처리하고 데이터 일관성을 보장한다. | 시스템 복원력과 견고성을 높인다. | 데이터 불일치 및 업데이트 손실을 방지한다. | 트랜잭션 보상을 위한 명확하게 정의된 프로세스를 제공한다. | . ",
    "url": "/docs/pattern/saga#%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/pattern/saga#장점"
  },"534": {
    "doc": "MSA의 데이터 일관성 유지 기법 Saga 이해하기",
    "title": "단점",
    "content": ". | 구현 및 유지 관리가 어렵고 모니터링 및 디버깅도 어렵다. | saga의 상태를 저장하고 관리하는 오버헤드가 있다. | 여러 마이크로 서비스에서 트랜잭션을 관리해야 하기 때문에 성능 오버헤드가 발생한다. | 애플리케이션은 마이크로 서비스 간에 여러 번 왕복해야 하기 때문에 대기 시간이 증가한다. | 서로 다른 마이크로 서비스에서 sagas를 구현하는 데 표준화가 없다. (java나 spring에도 없다) | . DDD의 aggregate 간의 domain event를 통한 통신, MSA의 모듈간 통신에서 빼놓을 수 없는 패턴이 된 것 같다. ",
    "url": "/docs/pattern/saga#%EB%8B%A8%EC%A0%90",
    
    "relUrl": "/docs/pattern/saga#단점"
  },"535": {
    "doc": "MSA의 데이터 일관성 유지 기법 Saga 이해하기",
    "title": "reference",
    "content": ". | https://medium.com/javarevisited/what-is-saga-pattern-in-microservice-architecture-which-problem-does-it-solve-de45d7d01d2b | https://www.baeldung.com/cs/saga-pattern-microservices | . ",
    "url": "/docs/pattern/saga#reference",
    
    "relUrl": "/docs/pattern/saga#reference"
  },"536": {
    "doc": "MSA의 데이터 일관성 유지 기법 Saga 이해하기",
    "title": "MSA의 데이터 일관성 유지 기법 Saga 이해하기",
    "content": " ",
    "url": "/docs/pattern/saga",
    
    "relUrl": "/docs/pattern/saga"
  },"537": {
    "doc": "S3 처리량 제한",
    "title": "처리량 제한",
    "content": "S3의 처리량 제한은 접두사 별로 존재한다. | 초당 3500개의 PUT (PUT/COPY/POST/DELETE) | 초당 5500개의 GET (GET/HEAD) | . 이 처리량은 접두사별로 존재하기 때문에, 접두사를 분리해주면 병렬화하여 처리량을 늘릴 수 있다. | S3의 접두사는 첫 / 이 등장하기 전까지의 bucket prefix. | 예전엔 접두사의 수가 6-8 자리로 해싱을 권장했으나, 내부적으로 해시를 사용하여 해결됨. (아래 레퍼런스 참조) | . ",
    "url": "/docs/aws/s3/throughput#%EC%B2%98%EB%A6%AC%EB%9F%89-%EC%A0%9C%ED%95%9C",
    
    "relUrl": "/docs/aws/s3/throughput#처리량-제한"
  },"538": {
    "doc": "S3 처리량 제한",
    "title": "S3 처리량에 대해",
    "content": "사실 초당 3500개의 put을 하는건 object storage에서 쉽지 않다. 테스트로 100KB 파일 2만 개를 올리는데 걸린 시간은 16분. prefix만 적절하게 사용한다면 문제가 있기는 어렵다. 그렇지만 엔터프라이즈 급에서 prefix 설계가 잘못된다면 문제가 생길 수 있다. dynamo의 partitionKey 제한도 그렇지만, s3 key도 이미 서비스 중에 prefix를 변경하기 어려우므로 설계 단계에서 잘 고려될 필요가 있겠다. ",
    "url": "/docs/aws/s3/throughput#s3-%EC%B2%98%EB%A6%AC%EB%9F%89%EC%97%90-%EB%8C%80%ED%95%B4",
    
    "relUrl": "/docs/aws/s3/throughput#s3-처리량에-대해"
  },"539": {
    "doc": "S3 처리량 제한",
    "title": "reference",
    "content": ". | 처리량 제한 문서 . | https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/optimizing-performance.html | . | 접두사 수 관련 문서 . | https://aws.amazon.com/ko/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/ | . | . ",
    "url": "/docs/aws/s3/throughput#reference",
    
    "relUrl": "/docs/aws/s3/throughput#reference"
  },"540": {
    "doc": "S3 처리량 제한",
    "title": "S3 처리량 제한",
    "content": "우리는 팀 내에서 storage로 대부분 S3를 사용하고 있다. S3를 굉장히 자주, 잘 씀에도 S3를 잘쓰는 방법에 대한 노하우는 많지 않다. aws s3 cli를 통해 활용하는 노하우 정도. S3에도 dynamo처럼 처리량 제한이 있는데, 이건 잘 모르고 사용하는 편이다. ",
    "url": "/docs/aws/s3/throughput",
    
    "relUrl": "/docs/aws/s3/throughput"
  },"541": {
    "doc": "http 1.0 semantics",
    "title": "multipart form data",
    "content": "http의 단순 전송은 크게 신경쓸게 없다. 보통 http 응답은 한 번에 한 파일씩 반환하므로 경계를 신경쓸 필요가 없다. 그런데 multipart를 이용하는 경우 한 번의 요청에 여러 파일을 전송할 수 있으므로 받는 쪽에서 파일을 나눠야 한다. 예시 . Content-Type: multipart/form-data; boundary=boundary-example --boundary-example Content-Disposition: form-data; name=\"text\" Sample text part. --boundary-example Content-Disposition: form-data; name=\"file\"; filename=\"example.txt\" Content-Type: text/plain This is the content of the file. --boundary-example-- . Content-Type은 multipart/form-data. boundary에는 랜덤하게 생성된 경계 문자열이 들어간다. body는 이 경계 문자열로 블록이 나뉜다. | 경계 문자열에 –이 prefix로 붙는다 | . 각각의 블록 내부도 http와 같이 header 후에 빈 줄 그리고 body로 이루어진다. 그리고 파일의 마지막도 경계 문자열로 끝난다. | 마지막 경계 문자열은 prefix와 postfix 모두 –를 붙여 끝낸다. | . ",
    "url": "/docs/internet/http/http1.0/semantics#multipart-form-data",
    
    "relUrl": "/docs/internet/http/http1.0/semantics#multipart-form-data"
  },"542": {
    "doc": "http 1.0 semantics",
    "title": "content negotiation",
    "content": "통신 방법을 최적화하고자 하나의 요청 안에 서버와 클라이언트가 서로 최고의 설정을 공유하는 시스템을 말한다. 이를 위해 header를 이용한다. | request header | response header | negotiation target | . | Accept | Content-Type | mime type | . | Accept-Language | Content-Language | 표시 언어 | . | Accept-Charset | Content-Type | 문자의 문자셋 | . | Accept-Encoding | Content-Encoding | body 압축 | . 파일 종류 결정 . Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8 . 서버는 요청에서 요구한 형식 중에서 파일을 반환한다. 우선 순위를 해서개 위에서부터 차례로 지원하는 포맷을 찾고 일치하면 그 포맷을 반환한다. 서로 일치하는 요청이 없다면 서버가 406 Not Acceptable 오류를 반환한다. 표시 언어 . Accept-Language: en-US,en;q=0.8,ko;q=0.6 . 동일하게 적혀있는 우선순위로 요청을 보낸다. en-Us, en, ko 순 . 문자셋 . Accept-Charset: windows-949,utf-8;q=0.7,*;q=0.3 . 현대의 어떤 브라우저도 Accept-Charset을 송신하지 않는다. 브라우저가 문자셋 인코더를 내장하고 있어 미리 negotiation 할 필요가 없어졌기 때문으로 여겨진다. 문자셋은 mime type과 함께 Content-Type header에 실려 응답된다. Content-Type: text/html; charset=UTF-8 . 압축 . 압축은 전송속도 향상을 위한 것이다. 통신에 걸리는 시간보다 압축과 해제가 짧은 시간에 이루어짐으로 압축을 함으로써 웹페이지를 표시할 때 걸리는 전체적인 처리 시간을 줄일 수 있다. 통신량이 줄어들기 때문에 시간 뿐만 아니라 통신 비용(사용자 데이터, 서버 데이터, 전력 소비 등)도 줄어든다. Accept-Encoding: deflate, gzip . 이렇게 header를 보내면 전송받은 목록 중 지원하는 방식이 있으면 응답할 때 그 방식으로 압축된 콘텐츠를 반환한다. 서버가 gzip을 지원한다면 헤더는 이렇다. Content-Encoding: gzip . 이제는 서버에서 받아올 때 뿐 아니라 서버로 올릴 때도 압축을 사용한다. 목적은 압축을 통해 얻는 이득을 업로드에도 누리기 위해서. 이런 경우엔 동일하게 Content-Encoding을 클라이언트가 header에 싣어서 보낸다. 쿠키 . 쿠키랑 웹사이트의 정보를 브라우저 쪽에 저장하는 작은 파일이다. 쿠키도 http header를 기반으로 구현되었다. 예를 들면 서버에서 access 시간을 저장하기 위해 이렇게 header를 보낼 수 있다. Set-Cookie: LAST_ACCESS_DATE=Jun/18/2023 Set-Cookie: LAST_ACCESS_TIME=12:04 . 이러면 클라이언트가 이 값을 저장하고 다음에 방문할 때 서버에 이런 형식으로 보낸다. Cookie: LAST_ACCESS_DATE=Jun/18/2023 Cookie: LAST_ACCESS_TIME=12:04 . 이렇게 서버가 상태를 유지하는 stateful처럼 보이게 서비스를 제공할 수 있다. 쿠키를 사용할 때 주의할점 . | 영속성 문제가 있다. 데이터는 사라진다. | 따라서 db 대신 쓸 수 없다. | 용량 문제도 있다. 최대 4KB로 더 보낼 수 없다. | 쿠키는 header로 항상 통신되는데 쿠키가 많아지면 통신량이 늘고 성능이 떨어진다. | 사용자가 자유롭게 접근할 수 있고 수정도할 수 있어 민감정보는 넣으면 안된다. | http의 경우 평문으로 전송되서 유의할 필요가 있다. | . 쿠키는 몇 가지 속성(Expires, Max-Age, Domain, Path, Secure, …)으로 제어하고 제한할 수 있다. 쿠키의 이런 기능 추가 역사는 웹 보안의 역사와도 이어진다고. 캐시 . 콘텐츠가 변경되지 않았을 때 로컬에 저장된 파일을 재사용함으로써 다운로드 횟수를 줄이고 성능을 높이는 매커니즘. GET / HEAD method 이외는 기본적으로 캐시되지 않는다. 캐시의 방식 . | 갱신 일자에 따른 캐시 . | 서버가 데이터 수정 시간을 헤더로 주고, 클라이언트가 다음 요청에 이를 헤더에 넣는다. | 수정이 생겼으면 200에 새로운 데이터를 | 수정이 생기지 않았으면 304 Not Modified를 반환 | . | expries . | 갱신 일자에 따른 캐시는 서버에 콜을 한번 더 넣어야 한다. | expires에 날짜와 시간을 넣어서 지정한 기간 내에선 캐시를 강제로 사용한다. | . | ETag . | 날짜와 시간을 이용한 캐시 비교만으로 해결할 수 없을 때 | 동적으로 바뀌는 요소가 많아져서 캐시 유효성 판단이 어려워질 때 | ETag(Entity Tag)는 순차적 갱신 일시가 아니라 파일의 해시 값으로 비교한다. | 갱신 일자에 따른 캐시처럼 ETag를 받고 다음 요청에 받은 ETag를 넣어 보낸다. | 서버에서 비교해서 같다면 304 Not Modified를 반환 | ETag는 http 1.1의 기능이다. | . | . 캐시는 Cache-Control header로 유연하게 캐시 제어를 지시할 수 있다. | 서버에서 내리는 값들도 있고, 클라이언트에서 요청할 때 사용할 수 있는 값들도 있다. | Cache-Control도 http 1.1의 기능이다. | . ",
    "url": "/docs/internet/http/http1.0/semantics#content-negotiation",
    
    "relUrl": "/docs/internet/http/http1.0/semantics#content-negotiation"
  },"543": {
    "doc": "http 1.0 semantics",
    "title": "reference",
    "content": ". | Real World Http chapter 2 | . ",
    "url": "/docs/internet/http/http1.0/semantics#reference",
    
    "relUrl": "/docs/internet/http/http1.0/semantics#reference"
  },"544": {
    "doc": "http 1.0 semantics",
    "title": "http 1.0 semantics",
    "content": " ",
    "url": "/docs/internet/http/http1.0/semantics",
    
    "relUrl": "/docs/internet/http/http1.0/semantics"
  },"545": {
    "doc": "http 1.0 syntax 이해하기 (vs http 0.9)",
    "title": "http 0.9",
    "content": "HTML 도큐먼트를 요청해서 가져오기만 하는 단순 프로토콜 웹사이트의 페이지를 서버에 요청하고 그 응답으로 웹사이트의 내용을 받아온다. 수신 후에는 서버와의 연결이 끊어진다. 요청에는 host(혹은 ip)과 port 번호를 지정한다. | port는 생략하면 기본 80 | . | 검색을 위해 주소 끝에 ?를 사용하는 것도 0.9에서 사용되었다. | 1.0 사양이 확정되고 1.0 이전이라는 의미에서 0.9로 불리게 됐다. | 0.9는 현행 프로토콜과 하위 호환성이 없다. | . ",
    "url": "/docs/internet/http/http1.0/syntax#http-09",
    
    "relUrl": "/docs/internet/http/http1.0/syntax#http-09"
  },"546": {
    "doc": "http 1.0 syntax 이해하기 (vs http 0.9)",
    "title": "http 1.0",
    "content": "0.9는 매우 단순했고 할 수 없는 일들이 많았다. | 하나의 문서를 전송하는 기능 밖에 없었다. | 통신되는 모든 내용은 html 문서로 가정했으므로 다운로드할 콘텐츠의 형식을 서버가 전달할 수단이 없었다. | 클라이언트 쪽에서 검색 이외의 요청을 보낼 수 없었다. | 새로운 문장을 전송하거나 갱신 또는 삭제할 수 없었다. | 요청이 올바른지, 서버가 올바르게 응답했는지 알 수 없었다. | . 그렇기 때문에 1.0에선 다른 요소들이 추가 되었다. | 요청 시 method가 추가됐다. (GET ..) | 요청 시 http version이 추가됐다. (HTTP/1.0) | header가 추가됐다. (Host, USer-Agent) | . ",
    "url": "/docs/internet/http/http1.0/syntax#http-10",
    
    "relUrl": "/docs/internet/http/http1.0/syntax#http-10"
  },"547": {
    "doc": "http 1.0 syntax 이해하기 (vs http 0.9)",
    "title": "http 1.0의 구성요소",
    "content": "http 1.0은 다른 기술들(전자메일, 뉴스그룹)을 참고해서 스펙이 결정됐다. http의 네 가지 구성 요소. | header | method &amp; url | body | status code | . header . http의 header는 요청과 응답 양쪽에서 사용된다. 이 아이디어는 전자메일에서 가져왔다.1 header의 개념은 RFC에 규정되어 왔다. 예시 . 메일의 원시 정보를 참고하면 http의 header와 유사하다. Delivered-To: yoshiki@shibu.jp (생략) MIME-Version: 1.0 Recieved: by 10.176.69.212 with HTTP; Wed, 6 Apr 2023:06:18 -1200 (KST) From: Yoichi Fujimoto &lt;wozozo@example.com&gt; Date: Wed, 6 Apr 2023:06:18 +1000 Message-ID: &lt;ABCDE....&gt; Subject: hi To: yosiki@shibu.jp Content-Type\" text/plain; charset=UTF-8 hello . header의 특징들 . | header 이름은 대소문자를 구분하지 않는다. | header에는 본문 이외의 모든 정보가 포함돼 있다. | RFC는 같은 header를 여러번 보내는 것도 허용한다. | 수신측에선 결합문자로 다루거나 배열의 개별 요소로 처리하기도 한다. | . | User-Agent, Authorization 같이 클라이언트가 보내는 header, Content-Type, Content-Length와 같이 서버가 보내는 header가 정의되어 있고, X- 로 시작하는 header는 각 서비스에서 자유롭게 사용해도 좋다고 되어 있다. | . 결과적으로 http 1.0은 전자메일이 고속으로 왕복하는 것과 유사하다. method . method는 뉴스그룹으로부터 가져왔다.2 뉴스 그룹의 method들의 사용성과 유사하게 method를 도입했다. | LIST, HEAD, BODY, POST | . http 규정이 생기기 전까지 많은 method의 제안이 있었지만 사라졌다. | LINK, UNLINK (1.0에 들어왔지만 1.1에 삭제) | CHECKOUT, CHECKIN, SHOWMETHOD, SEARCH (1992년 판에 제안됐지만 1.0에서 삭제) | . status code . method와 같이 뉴스그룹으로부터 가져온 statusCode는 세 자리 숫자를 보고 서버의 응답을 한눈에 알 수 있는 값이다. 예시 . 지금 우리가 너무 잘 아는 에러 값이다. | 1XX, 2XX, 3XX, 4XX, 5XX | . 200 OK 404 NOT FOUND 500 INTERNAL SERVER ERROR ... URL . schema://hostName/path 와 같은 구조로 이루어진다. schema 해석은 브라우저의 책임. 브라우저는 schema를 보고 적절한 접속 방법을 선택해야 한다. 실제 통신하는 곳은 hostName으로 지정된 서버. port가 생략되면 schema 별 기본 port를 사용한다. | http: 80 | https: 443 | . URL 구성 문자는 ASCII 문자열(영문자, 숫자, 일부 기호)이었지만 RFC 2718에서 URL을 인코딩함으로써 다국어 문자를 다룰 수 있게 되었다. HTTP 사양상 URL 길이에 제한은 없지만 인터넷 익스플로러에서 2083자까지만 다룰 수 있어 ‘대체로 2000자’가 기준이 되었다. body . header 끝에 빈 줄을 넣으면 그 이후는 모두 body가 된다. 예시 . 아래 코드에서 header 끝에 빈 줄이 들어간 body start! 부터 body가 된다. header1: header1value header2: header2value Content-Length: bytes of body body start! . 속도를 위해 body를 압축하기도 하고 Content-Encoding에서 지정된 압축 알고리즘으로 읽어 온 body의 데이터를 전개할 필요가 있다. 이런 경우에 Content-Length는 압축 후 통신 데이터 크기가 된다. | get에서도 body를 보낼 수 있지만 그렇게 하지 않는 것이 좋다. | . ",
    "url": "/docs/internet/http/http1.0/syntax#http-10%EC%9D%98-%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C",
    
    "relUrl": "/docs/internet/http/http1.0/syntax#http-10의-구성요소"
  },"548": {
    "doc": "http 1.0 syntax 이해하기 (vs http 0.9)",
    "title": "reference",
    "content": ". | Real World Http chapter 1 | . | 전자메일이라고 불리는 메일 시스템은 인터넷이 보급 되기 이전부터 사용되던 기술로 http에 영향을 줬다. &#8617; . | 뉴스라는 이름이지만 매스미디어가 아닌 대규모 전자 게시판으로 인터넷 이전의 주요 미디어였다. &#8617; . | . ",
    "url": "/docs/internet/http/http1.0/syntax#reference",
    
    "relUrl": "/docs/internet/http/http1.0/syntax#reference"
  },"549": {
    "doc": "http 1.0 syntax 이해하기 (vs http 0.9)",
    "title": "http 1.0 syntax 이해하기 (vs http 0.9)",
    "content": "http 1.0을 알기 위해서 http가 어떻게 만들어졌는지 이해하면 좋다. http 0.9는 내용이 너무 간단해서 1.0에서 함께 개념을 정리해본다. 이번에 정리하는 내용은 http 1.0의 syntax. 참고사항 . http는 웹 브라우저와 웹 서버가 통신하는 절차와 형식을 규정한 것이다. 현재는 이런 규정을 넘어서 다양한 서비스의 인터페이스로 사용되면서 인터넷의 기초가 됐다. | 1990년 HTTP/0.9 | 1996년 HTTP/1.0 | 1997년 HTTP/1.1 | 2005년 HTTP/2 | . ",
    "url": "/docs/internet/http/http1.0/syntax",
    
    "relUrl": "/docs/internet/http/http1.0/syntax"
  },"550": {
    "doc": "client call 확인을 위한 webhook site",
    "title": "사용법",
    "content": ". | https://webhook.site/에 접속한다. | 해당 페이지에서 임의로 발급되는 webhook site url을 확인한다. | 예를 들면 https://webhook.site/554e2d76-a7ee-46c3-8f9f-ce6819fbcedf | . | 해당 host로 작성한 test를 날린다. | 분석되는 call을 페이지에서 확인한다. | . ",
    "url": "/docs/dev-tools/site/webhook-site#%EC%82%AC%EC%9A%A9%EB%B2%95",
    
    "relUrl": "/docs/dev-tools/site/webhook-site#사용법"
  },"551": {
    "doc": "client call 확인을 위한 webhook site",
    "title": "reference",
    "content": ". | https://webhook.site/ | . ",
    "url": "/docs/dev-tools/site/webhook-site#reference",
    
    "relUrl": "/docs/dev-tools/site/webhook-site#reference"
  },"552": {
    "doc": "client call 확인을 위한 webhook site",
    "title": "client call 확인을 위한 webhook site",
    "content": "굉장히 좋은 사이트를 알아왔다. 처음 개발을 할 때, 클라이언트에 문제가 있는지 서버에 문제가 있는지. 서버가 잘 떠 있는지 GW 나 권한 문제가 있지는 않은지 애매하게 확인할 부분들이 있다. 서버 개발자 입장에선 acceptance test나 scenario test를 위해 작성하는 test client 들이 server(local 혹은 dev)에 잘 들어오지 않는 경우도 있다. 특히 multi-part의 경우 call을 잘 만들었나 싶은데 이걸 확인하기 아주 좋은 사이트. ",
    "url": "/docs/dev-tools/site/webhook-site",
    
    "relUrl": "/docs/dev-tools/site/webhook-site"
  },"553": {
    "doc": "GC 로그 및 튜닝",
    "title": "GC 로깅",
    "content": "GC 로그는 시스템 다운의 원인을 분석할 때 유용하다. 모든 중요한 애플리케이션에서는 두가지를 설정해야한다. | GC 로그를 생성한다. | 애플리케이션 출력과 별도로 특정 파일에 GC 로그를 보관한다. | . ",
    "url": "/docs/java/gc/log_tuning#gc-%EB%A1%9C%EA%B9%85",
    
    "relUrl": "/docs/java/gc/log_tuning#gc-로깅"
  },"554": {
    "doc": "GC 로그 및 튜닝",
    "title": "GC 로깅 켜기",
    "content": "-Xloggc:gc.log -XX:+PrintGCDetails -XX:+PrintTenuringDistributuion -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps . 필수 flag . | flag | operation | . | -Xloggc:gc.log | GC event 로깅할 파일을 지정 | . | -XX:+PrintGCDetails | GC event 세부 정보를 로깅 | . | -XX:+PrintTenuringDistributuion | 툴링에 필요한 부가적인 GC event 세부 정보를 추가 사람이 확인하기 어려운 데이터지만 memory pressure, premature promotion 등 확인에 필요한 기본 데이터를 제공 | . | -XX:+PrintGCTimeStamps | GC event 발생 시간을 (VM 시작 이후 경과 시간으로) 초단위 출력 GC event와 application event를 연관짓는 용도로 사용 | . | -XX:+PrintGCDateStamps | GC event 발생 시간을 (시간 기준으로) 출력 GC event와 JVM event를 연관짓는 용도로 사용 | . Rotation flag . | flag | operation | . | -XX:+UseGCLogFileRotation | log file rotation 기능을 켜기 | . | -XX:+NumberOfGCLogFiles= | rotation file 개수 설정 | . | -XX:+GCLogFileSize= | rotation file 최대 사이즈 설정 | . ",
    "url": "/docs/java/gc/log_tuning#gc-%EB%A1%9C%EA%B9%85-%EC%BC%9C%EA%B8%B0",
    
    "relUrl": "/docs/java/gc/log_tuning#gc-로깅-켜기"
  },"555": {
    "doc": "GC 로그 및 튜닝",
    "title": "GC 로그 장점",
    "content": "JVM과 GC는 수 많은 component가 조합된 아주 복잡한 구현체. 성능 역시 예측하기가 굉장히 어렵다. 그렇기 때문에 GC를 모든 워크로드들이 특정 값으로 최적화할 수 없다. 이를 모니터링하고 GC 튜닝에 유용하게 사용되는 것이 GC 로그. GC 로깅은 사실상 오버헤드가 거의 없기 때문에 주요 JVM 프로세스는 항상 로깅을 켜놓아야 한다. | JVM 내부에서 non-blocking write. 운영계에선 계속 켜놓는게 맞다. | . ",
    "url": "/docs/java/gc/log_tuning#gc-%EB%A1%9C%EA%B7%B8-%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/java/gc/log_tuning#gc-로그-장점"
  },"556": {
    "doc": "GC 로그 및 튜닝",
    "title": "GC 로그 파싱",
    "content": "GC 로그 메세지는 정해진 포맷이 따로 없다. 로그에 어떤 메세지를 남길지는 hotspot 개발팀 마음이라 minor release에서도 포맷이 다르기도 하다. 단순 로그 파싱은 어렵지 않지만 로그가 많이 복잡하다. GC 설정을 변경하면 로그 포맷이 변경되고 파서가 동작하지 않는 경우도 있다. 따라서 로그를 스스로 파싱하려고하지 말고 반드시 로그 툴을 사용하자. | 센섬 . | 상용 메모리 분석기 (유료) | 파싱, 정보 추출부터 시간 뷰, 전체 클러스터 뷰까지 제공 | 센섬 개발팀이 openJDK code의 logging 소스를 분석해서 반영하기 때문에 철저하고 강력함 | . | GCViewer . | 오픈소스 (무료) | 센섬보다 빈약한 기능 | 로그 파싱, 그래프 출력등의 기본 기능만 있고 분석기능은 없음 | . | . ",
    "url": "/docs/java/gc/log_tuning#gc-%EB%A1%9C%EA%B7%B8-%ED%8C%8C%EC%8B%B1",
    
    "relUrl": "/docs/java/gc/log_tuning#gc-로그-파싱"
  },"557": {
    "doc": "GC 로그 및 튜닝",
    "title": "GC 기본 튜닝",
    "content": "튜닝을 해야하는 이유 . | GC가 성능 문제를 일으키는 원인인지 혹은 영향이 없는지 파악하는 비용은 크지 않다. | GC가 성능 문제를 일으키는지 밝히는건 쉽다. | 맞다면 더 구체적인 원인 파악과 튜닝을, 아니라면 ‘문제없어’를 확신하고 넘어갈 수 있다. | . | testing 단계에서 GC flag를 켜는 것도 비용이 작다. | memory profiler 설정은 비용이 크다. | . heap 크기 조정 flag . | flag | operation | . | -Xms | heap 최소 크기를 결정한다 | . | -Xmx | heap 최대 크기를 결정한다 | . | -XX:MaxMetaspaceSize= | metaspace의 최대 크기를 결정한다 | . 튜닝 시 주의사항 . | GC flag를 추가/변경할 때는 한 flag씩 추가한다. | 각 flag가 무슨 작용을 하는지 알고 사용해야 한다. | 부수 효과를 일으키는 flag 조합이 있을수도 있다. | . 튜닝 주요 인자 . | 할당 | 중단시간 | 처리율 추이 | 객체 수명 | . 1. 할당 . 튜닝 뿐 아니라 성능 판단에 꼭 필요하다. young generation GC event 데이터를 통해 할당된 데이터 양, 단위 수집 시간, 평균 할당률을 계산할 수 있다. | 수작업으로 할당률을 계산하는 것은 시간 낭비. 툴을 사용하자 | . 2. 중단 시간 . 대부분의 application에서 100ms 정도의 중단은 무시할만하다. 중단 시간을 얼마나 허용할 수 있느냐를 기준으로 GC를 선택할 수 있다. | 일반적으로 중단시간이 1초 이상으로 커도 된다면 Parallel이 좋다. | . ",
    "url": "/docs/java/gc/log_tuning#gc-%EA%B8%B0%EB%B3%B8-%ED%8A%9C%EB%8B%9D",
    
    "relUrl": "/docs/java/gc/log_tuning#gc-기본-튜닝"
  },"558": {
    "doc": "GC 로그 및 튜닝",
    "title": "reference",
    "content": ". | Optimizing Java, chapter8 | . ",
    "url": "/docs/java/gc/log_tuning#reference",
    
    "relUrl": "/docs/java/gc/log_tuning#reference"
  },"559": {
    "doc": "GC 로그 및 튜닝",
    "title": "GC 로그 및 튜닝",
    "content": " ",
    "url": "/docs/java/gc/log_tuning",
    
    "relUrl": "/docs/java/gc/log_tuning"
  },"560": {
    "doc": "리팩토링 why? when? what?",
    "title": "리팩토링 하는 이유",
    "content": "소프트웨어 설계가 개선되니까 . 리팩토링 하지 않으면 설계는 노후된다. 단기 목적의 수정은 코드가 산만해지게 하고 리팩토링은 이를 정리한다. 이해하기 쉬워지니까 . 리팩토링 대상은 제대로 실행되지만 구조가 완전하지 못한 코드이고 리팩토링 후에 코드가 본연의 목적에 더 충실해지고 의도한 바를 정확히 전달할 수 있다. 버그 찾기 쉬워지니까 . 리팩토링은 코드를 근본적으로 이해하는 작업이 깨달음이 코드에 즉시 반영된다. 프로그램을 명료하게 만들 수 있는 수준이라면 버그를 놓치기 어렵다. 리팩토링으로 프로그래밍 속도가 빨라진다. 설계가 지저분하면 새 기능을 추가하는 시간, 버그 찾는 시간, 시스템을 이해하고 중복 코드에 적용하는 시간 등으로 코드가 길어지고 시간이 늘어난다. 깔끔한 설계는 개발속도를 적절히 유지할 수 있다. ",
    "url": "/docs/refactoring/basic#%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81-%ED%95%98%EB%8A%94-%EC%9D%B4%EC%9C%A0",
    
    "relUrl": "/docs/refactoring/basic#리팩토링-하는-이유"
  },"561": {
    "doc": "리팩토링 why? when? what?",
    "title": "리팩토링은 언제하는가",
    "content": "시간내서 따로 하는게 아니라 일상적으로 틈틈히 해야한다. 작정해서 하는게 아니라 다른 작업을 하는데 리팩토링을 하면 작업이 쉬워지기 때문에 하는 것. 같은 작업을 세번 할 때 . 처음할 땐 그냘하고 두번째는 망설여져도 그냥하고 세 번째 하게되면 리팩토링하는 기법 . 기능을 추가할 때 . 이때 하는 이유는 코드를 이해하기 쉽게 만들기 위해서이다. 리팩토링 후 코드가 더 이해하기 쉬워진다고 확신한다면 리팩토링한다. 설계가 지저분해서 기능 추가가 어려울 때 ‘이런 설계였으면 좋았겠다’ 싶을 때 설계를 수정한다. 버그를 수정할 때 . 버그 수정시엔 기능을 이해하려고 리팩토링한다. 앞서 말했듯 리팩토링하면 이해가 쉬워진다. 코드를 검수할 때 . 코드를 검수하면 다른 사람이 짠 코드를 보고 새로운 아이디어가 생기기도 하고 리팩토링하여 코드 검수가 더 잘되기도 한다. ",
    "url": "/docs/refactoring/basic#%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81%EC%9D%80-%EC%96%B8%EC%A0%9C%ED%95%98%EB%8A%94%EA%B0%80",
    
    "relUrl": "/docs/refactoring/basic#리팩토링은-언제하는가"
  },"562": {
    "doc": "리팩토링 why? when? what?",
    "title": "리팩토링의 효용성",
    "content": "프로그램이 지닌 가치는 두 종류이다. | 현재의 기능이라는 가치. | 미래의 기능이라는 가치. | . 현재 기능이 프로그램의 일부에 불과하다는 사실을 깨우치지 않으면 개발자로서 오래갈 수 없다. 오늘 일은 할 수 있어도 내일 일을 내일 할 능력을 일게 되기 때문이다. 리팩토링은 과거의 판단이 불합리하다는 것을 발견하고 수정하는 작업으로 가치를 높이는 일이다. ",
    "url": "/docs/refactoring/basic#%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81%EC%9D%98-%ED%9A%A8%EC%9A%A9%EC%84%B1",
    
    "relUrl": "/docs/refactoring/basic#리팩토링의-효용성"
  },"563": {
    "doc": "리팩토링 why? when? what?",
    "title": "리팩토링 문제들",
    "content": "데이터베이스 . 리팩토링으로 데이터베이스 스키마를 수정하면 데이터도 바뀌기 때문에 별도의 계층을 두면 좋다. 인터페이스 . 인터페이스의 변경은 호출하는 부분도 바뀌어야한다. 그렇지만 published interface의 경우엔 이게 어렵다. 사용하는 client들(다른 팀)의 수정까지 interface를 한동안 유지해줘야 한다. | 그러니 published를 필요할 때가 아니면 만들지 말자. | 서버에겐 api와 같다. api는 필요한 것만 만드는 것도 중요하지만 필요하지 않은 param, body가 들어오지 않도록 클라이언트와 명확하게 설계하는게 좋다. | . 리팩토링하면 안되는 상황 . 차라리 완전히 처음부터 새로 작성하는게 나을 때가 있다. 물론 이 판단은 쉽지 않고 기준도 없다. 납기가 임박한 시점에도 리팩토링을 삼가야한다. 리팩토링으로 인한 생상성이 납기 이후에 가시화 될테니. 납기가 임박하지 않다면 시간이 없다는 핑계로 리팩토링을 미뤄선 안된다. 언제나 시간에 쫓긴다면 그건 리팩토링해야하는 신호이다. 켄트 백의 모자 두 개 . 리팩토링이라는 모자와 기능 추가 모자가 있다. 모자는 각각 번갈아가며 쓸 수 있다. 그치만 두 모자를 동시에 쓸 수는 없다. 리팩토링 때는 코드 구조만 개선되고 테스트도 추가될 필요가 없다. 그러나 기능을 추가할 땐 리팩토링을 하지 않는다. ",
    "url": "/docs/refactoring/basic#%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81-%EB%AC%B8%EC%A0%9C%EB%93%A4",
    
    "relUrl": "/docs/refactoring/basic#리팩토링-문제들"
  },"564": {
    "doc": "리팩토링 why? when? what?",
    "title": "리팩토링과 설계",
    "content": "리팩토링은 설계를 보완하는 역할을 한다. 사전 설계를 빡세게 하지 않아도 리팩토링으로 잡을 수 있기 때문에 최상의 솔루션을 찾지 못해도 괜찮다. 단순히 구현하고 나중에 리팩토링하면 비용(시간)이 얼마나 들까를 고려해서 단순한 솔루션을 사용할지 결정할 수 있다. 유연하고 복잡한 설계가 필요하지 않은 경우도 많다. ",
    "url": "/docs/refactoring/basic#%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81%EA%B3%BC-%EC%84%A4%EA%B3%84",
    
    "relUrl": "/docs/refactoring/basic#리팩토링과-설계"
  },"565": {
    "doc": "리팩토링 why? when? what?",
    "title": "리팩토링과 성능",
    "content": "코드를 이해하기 쉽게 만들려면 수정할 일이 많은데 수정으로 프로그램이 느려질수도 있다. 설계의 순수성을 강조하더라도 성능을 무시하는건 이론을 가르치는 교수나 하는 말. 더 좋은 성능을 포기해선 안된다. 성능 개선에서 재밌는 사실은 대부분의 개발자들이 코드를 분석할 때 작은 코드 조각에 얽메여 있다는 것이다. 모든 코드를 최적화한다고 했을 때 그 최적화 중 90%는 실행될 일이 거의 없는 코드를 최적화하는 의미없는 일이다. 성능과 관련해선 프로그램의 시간과 공간을 알수있는 프로파일러 하에 프로그램을 실행해야 한다. 이렇게하면 성능에 영향을 주는 프로그램의 작은 부분을 찾을 수 있고 그 부분에 대해 최적화를 적용한다. 리팩토링으로 작은 부분을 쪼개고나면 성능 분석을 더 정밀하게 할 수 있고 튜닝도 쉬워진다. ",
    "url": "/docs/refactoring/basic#%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81%EA%B3%BC-%EC%84%B1%EB%8A%A5",
    
    "relUrl": "/docs/refactoring/basic#리팩토링과-성능"
  },"566": {
    "doc": "리팩토링 why? when? what?",
    "title": "reference",
    "content": ". | 마틴 파울러, 리팩토링 2장 | . ",
    "url": "/docs/refactoring/basic#reference",
    
    "relUrl": "/docs/refactoring/basic#reference"
  },"567": {
    "doc": "리팩토링 why? when? what?",
    "title": "리팩토링 why? when? what?",
    "content": " ",
    "url": "/docs/refactoring/basic",
    
    "relUrl": "/docs/refactoring/basic"
  },"568": {
    "doc": "복합 리팩토링",
    "title": "복햡 리팩토링은",
    "content": "개발팀 전원의 합의하에 실시해야한다. 수정 방향이 많이 바뀌기 때문에 팀 전원이 복합리팩토링이 진행중임을 알고 움직여야한다. 사공이 많아 배가 산으로 가지 않도록. ",
    "url": "/docs/refactoring/big-refactoring#%EB%B3%B5%ED%96%A1-%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81%EC%9D%80",
    
    "relUrl": "/docs/refactoring/big-refactoring#복햡-리팩토링은"
  },"569": {
    "doc": "복합 리팩토링",
    "title": "복합 리팩토링 필요성",
    "content": "단순 리팩토링은 예측 가능하고 절차가 투명하고 만족을 즉시 얻는다는 장점이 있다. 충분리 이해하지 못한 상태에서 결정된 설계가 쌓이면 막 자란 물풀로 막힌 운하처럼 프로그램이 막힌다. 단편적인 이해로 결정된 설계는 프로그램에 악영향을 전파시킨다. 이런 문제를 해결하고 예방하는게 복합 리팩토링. ",
    "url": "/docs/refactoring/big-refactoring#%EB%B3%B5%ED%95%A9-%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81-%ED%95%84%EC%9A%94%EC%84%B1",
    
    "relUrl": "/docs/refactoring/big-refactoring#복합-리팩토링-필요성"
  },"570": {
    "doc": "복합 리팩토링",
    "title": "대표적인 복합 리팩토링",
    "content": ". | 상속 구조 정리 | . 하나의 상속 계층이 두 작업을 동시에 수행할 땐 상속 계층을 하나 더 만들어서 위임을 통해 다른 계층을 호출하자 . | 절차 코드를 객체로 전환 | . 코드가 절차식으로 작성되어 있을 땐 데이터 레코드를 객체로 바꾸고 기능을 쪼개서 각각의 객체로 옮기자 . | 메인 로직을 표현과 분리 | . 도메인 로직이 들어있은 GUI 클래스가 있을 깬 도메인 로직을 별도의 도메인 클래스로 떼어내자 . | 계층구조 추출 | . 한 클래스에 기능이 너무 많고 일부분에라도 조건문이 많을땐 각 조건에 해당하는 하위 클래스를 작성해서 계층구조를 만들자 . ",
    "url": "/docs/refactoring/big-refactoring#%EB%8C%80%ED%91%9C%EC%A0%81%EC%9D%B8-%EB%B3%B5%ED%95%A9-%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81",
    
    "relUrl": "/docs/refactoring/big-refactoring#대표적인-복합-리팩토링"
  },"571": {
    "doc": "복합 리팩토링",
    "title": "reference",
    "content": ". | 마틴 파울러, 리팩토링 12장 | . ",
    "url": "/docs/refactoring/big-refactoring#reference",
    
    "relUrl": "/docs/refactoring/big-refactoring#reference"
  },"572": {
    "doc": "복합 리팩토링",
    "title": "복합 리팩토링",
    "content": "복합 리팩토링을 할때는 상황이 변화무쌍하다. 가동중인 시스템을 대상으로 하는 리팩토링은 수 개월에서 수 년이 걸리기도 한다. 서비스 중인 시스템을 작업 중단하고 리팩토링하겠다는 말을 받아주는 팀장은 없기 때문에. 리팩토링은 시작했다고 끝을 봐야하는건 아니다. 기능 추가나 버그 수정시에 시작해서 필요한 만큼만 하면 된다. 어느정도 센스와 경력이 있는 개발자들은 리팩토링 냄새를 맡고 수정하는 일을 잘 하고 있다. 실제 개발에서 리팩토링을 얼마나 잘하느냐는 복합 리팩토링을 어떻게 하느냐가 아닐까 싶다. ",
    "url": "/docs/refactoring/big-refactoring",
    
    "relUrl": "/docs/refactoring/big-refactoring"
  },"573": {
    "doc": "리팩토링 마음가짐",
    "title": "습관적으로 목표를 정하자",
    "content": "코드에서 구린내가 풍기면 구린내를 없야겠다는 결의를 다진 후 목표를 향해 나아가자. 리팩토링의 목표는 아름다운 코드가 아니라 이해하기 쉬운 코드, 퇴화하는 프로그램의 통제력을 되찾는 작업이다. , . 이게 생각보다 어려운 사람들이 있다. 어떤 사람이랑 일하면 당연하게 구린내를 제거하는데 어떤 사람들은 구린내에 냄새를 더 더한다. 개발자는 코가 민감해야 한다는 생각을 같이 일하다보면 느끼게 된다. ",
    "url": "/docs/refactoring/putting-together-refactoring#%EC%8A%B5%EA%B4%80%EC%A0%81%EC%9C%BC%EB%A1%9C-%EB%AA%A9%ED%91%9C%EB%A5%BC-%EC%A0%95%ED%95%98%EC%9E%90",
    
    "relUrl": "/docs/refactoring/putting-together-refactoring#습관적으로-목표를-정하자"
  },"574": {
    "doc": "리팩토링 마음가짐",
    "title": "확신이 없으면 중단하자",
    "content": "목표를 향해 전진할 때 현재 작업이 프로그램 로직을 보전하리란 사실을 입증할 수 없는 순간이 닥칠 수 있다. 그렇다면 작업을 중단해야 한다. 중단한 시점에 코드가 개선됐다면 결과물을 반영하고 그렇지 않다면 코드를 버린다. , . 코드를 버리는걸 잘 못하는 사람들이 있다. 한 번은 동료가 리팩토링 방향을 잘못잡고 개발한걸 버리지 못하고 넣어서 되잡는데 시간을 더 오래썼다. ",
    "url": "/docs/refactoring/putting-together-refactoring#%ED%99%95%EC%8B%A0%EC%9D%B4-%EC%97%86%EC%9C%BC%EB%A9%B4-%EC%A4%91%EB%8B%A8%ED%95%98%EC%9E%90",
    
    "relUrl": "/docs/refactoring/putting-together-refactoring#확신이-없으면-중단하자"
  },"575": {
    "doc": "리팩토링 마음가짐",
    "title": "되돌아가자",
    "content": "리팩토링은 방향이 잘못들기 쉽다. 테스트를 돌리지 않고 여러 수정이 반영됐다면, 테스트가 도는 시점으로 되돌아가서 다시 수정사항을 반영하며 테스트 결과를 확인하는 것이 더 합리적이다. 1시간을 개발한 코드를 다시 짜는 것은 10분이면 되는데 이걸 디버깅하려면 2시간이 걸릴수도 있다. , . 이건 확신이 없으면 중단하자의 내용과도 이어지는 것 같다. 여기서 중요한건 리팩토링 하면서 중간중간 테스트를 돌려야 한다는 것. ",
    "url": "/docs/refactoring/putting-together-refactoring#%EB%90%98%EB%8F%8C%EC%95%84%EA%B0%80%EC%9E%90",
    
    "relUrl": "/docs/refactoring/putting-together-refactoring#되돌아가자"
  },"576": {
    "doc": "리팩토링 마음가짐",
    "title": "작업은 둘이서 하자",
    "content": "리팩토링은 조심히 체계적으로 해야한다. 내가 보지 못한 부분을 파트너가 챙겨줄 수 있을 것이고. 둘 중 한명이 이해하지 못한다면 리팩토링을 중단해야할 시점이라는 것도 알 수 있다. 포기하고 싶을 땐 함께 작업을 이어갈 수 있다. , . 완전히 동의되지는 않는 부분이기도 하다. 리팩토링을 페어 프로그래밍 하는것도 되겠지만 복합 리팩토링에서의 설계를 같이 나누거나 리팩토링의 한 부분을 나누는 것도 괜찮은 것 같다. 결국 페어 프로그래밍은 꼼꼼한 리뷰로 커버가 되기도 하니까. ",
    "url": "/docs/refactoring/putting-together-refactoring#%EC%9E%91%EC%97%85%EC%9D%80-%EB%91%98%EC%9D%B4%EC%84%9C-%ED%95%98%EC%9E%90",
    
    "relUrl": "/docs/refactoring/putting-together-refactoring#작업은-둘이서-하자"
  },"577": {
    "doc": "리팩토링 마음가짐",
    "title": "두 개의 모자",
    "content": "리팩토링할 땐 리팩토링 전의 기능을 그대로 유지하는것이 필수다. 구린내가 나더라도 일정상 현재 리팩토링을 진행할 수 없다면 리팩토링을 잠시 보류할 필요도 있다. , . 일부 팀원들한테 많이 했던 얘기중 하나는 리팩토링 코드와 기능 개발 코드를 같이 커밋하지 말라는 얘기였다. 라인을 정리한다거나, 클래스 이동 같은 리팩토링이 기능 개발과 같이 들어가서 리뷰가 어려워지고 히스토리 관리가 안되는 경우가 빈번한 사람들이 있다. 리팩토링은 커밋을 나누거나, PR까지 나눠도 좋을 것 같다. ",
    "url": "/docs/refactoring/putting-together-refactoring#%EB%91%90-%EA%B0%9C%EC%9D%98-%EB%AA%A8%EC%9E%90",
    
    "relUrl": "/docs/refactoring/putting-together-refactoring#두-개의-모자"
  },"578": {
    "doc": "리팩토링 마음가짐",
    "title": "reference",
    "content": ". | 마틴 파울러, 리팩토링 15장 | . ",
    "url": "/docs/refactoring/putting-together-refactoring#reference",
    
    "relUrl": "/docs/refactoring/putting-together-refactoring#reference"
  },"579": {
    "doc": "리팩토링 마음가짐",
    "title": "리팩토링 마음가짐",
    "content": "마틴 파울러의 refactoring 15장의 Putting It All Together를 보고 정리한 내용이다. 가장 마지막장의 내용으로 마틴 파울러가 설명한 리팩토링에 대한 내용들을 정리하는 내용인데, 나는 리팩토링의 마음가짐이라고 정리해본다. 리팩토링을 알고 기법이랑 테스트를 알아도 리팩토링을 완전히 이해했다고 볼수는 없다. 리팩토링은 가벼운 마음으로 해야하는데 리팩토링을 하는데 마틴 파울러의 팁이 있다. 경험이 있는 개발자들에겐 어쩌면 당연한 내용들이면서도 생각하고 작업하면 좋을 내용들이어서 정리해본다. ",
    "url": "/docs/refactoring/putting-together-refactoring",
    
    "relUrl": "/docs/refactoring/putting-together-refactoring"
  },"580": {
    "doc": "마틴 파울러의 리팩토링",
    "title": "챕터별 내용 정리",
    "content": "| chapter | summary | . | 1장 | 맛보기 예제로 리팩토링을 잘 모르는 사람들이 보면 좋겠다 | . | 2장 | 리팩토링의 개념에 대해 다시 생각해볼 수 있다 - 리팩토링 개론 | . | 3장 | 코드의 구린내를 잘 맡느냐 나는 좀 냄새에 예민한 편이다 | . | 4장 | 리팩토링의 필수 전제조건으로 견고한 테스트가 있어야 한다 | . | 5장 | 뒷 장부터 이어지는 기법들에 대한 카탈로그 | . | 6장 | 메서드 단위의 리팩토링 기법 | . | 7장 | 기능이 어디에 위치하는지가 적절한지를 중점으로 객체간 기능 리팩토링 기법 | . | 8장 | 데이터 연동을 간편하게 만들자 | . | 9장 | 조건문을 처리하는 리팩토링 기법 조건문은 복잡해질 가능성이 높아서 리팩토링도 다양한데 대부분이 조건문을 쪼개는 리팩토링이다 | . | 10장 | 함수의 이름과 변수를 이해하기 쉽게하자 | . | 11장 | 상속 계층에서 함수나 필드를 상위나 하위로 옮기는 기법 | . | 12장 | 리팩토링을 얼마나 잘하느냐는 복합 리팩토링을 잘하느냐가 되지 않을까 - 복합 리팩토링 | . | 13장 | 리팩토링에 대한 이야기 책에서 다루는 전반적인 내용이랑 중복도 꽤 있으나 보면 ‘음 그렇지’ 하는 내용들이다 | . | 14장 | rename이나 extract method 같은걸 지원하는 도구에 대한 이야기결국 인텔리제이가 지원하는 다양한 기능들에 대해 필요한 이유와 장점들에 대한 내용이다아무래도 이 책이 처음 나올 당시엔 이런 툴이 부족했어서 적지 않았을까 싶다 | . | 15장 | 리팩토링의 마음가짐에 대해 이야기하는 마지막 장이다 - 리팩토링 마음가짐 | . ",
    "url": "/docs/refactoring/martin-fowler-refactoring#%EC%B1%95%ED%84%B0%EB%B3%84-%EB%82%B4%EC%9A%A9-%EC%A0%95%EB%A6%AC",
    
    "relUrl": "/docs/refactoring/martin-fowler-refactoring#챕터별-내용-정리"
  },"581": {
    "doc": "마틴 파울러의 리팩토링",
    "title": "reference",
    "content": ". | 마틴 파울러, 리팩토링 | . ",
    "url": "/docs/refactoring/martin-fowler-refactoring#reference",
    
    "relUrl": "/docs/refactoring/martin-fowler-refactoring#reference"
  },"582": {
    "doc": "마틴 파울러의 리팩토링",
    "title": "마틴 파울러의 리팩토링",
    "content": "마틴 파울러의 refactoring을 보고 정리한 내용이다. 사실 이미 아는 내용들도 많아서 정리할게 많진 않다. ",
    "url": "/docs/refactoring/martin-fowler-refactoring",
    
    "relUrl": "/docs/refactoring/martin-fowler-refactoring"
  },"583": {
    "doc": "현업에서 진행하는 대규모 리팩토링 프로세스",
    "title": "리팩토링의 분류",
    "content": "리팩토링은 기존의 코드를 재구성하여 코드의 품질을 향상시키는 작업이다. 일반적으로 리팩토링이라하면 변수나 함수를 정리하는 등의 방식으로 코드 품질과 생산성을 높이는 방식을 말한다. 그런데 이렇게 간단하게 진행되는 리팩토링 외에 ‘리디자인’ 정도로 리팩토링이 필요한 경우가 있다. 마틴파울러는 이걸 big refactoring이라고 불렀다. big refactoring을 어떻게 하면 좋을지를 고민해보며 업데이트 하는 나의 리팩토링 방향. ",
    "url": "/docs/refactoring/my-refactoring#%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81%EC%9D%98-%EB%B6%84%EB%A5%98",
    
    "relUrl": "/docs/refactoring/my-refactoring#리팩토링의-분류"
  },"584": {
    "doc": "현업에서 진행하는 대규모 리팩토링 프로세스",
    "title": "사용하지 않는 코드 삭제하기",
    "content": "사용하지 않는 코드는 남아서 refactoring이 경직되게 만들고 코드를 이해하기 어렵게 만든다. 따라서 사용하지 않는 코드는 리팩토링의 모든 스텝마다 가장 먼저 체크되어야 할 부분이다. 특히 legacy module의 경우 어떤 코드(모듈)을 사용하는지 사용하지 않는지 조차 알지 못하는 경우도 많다. api call 지표를 보면서 사용하지 않는 api를 확인하는 것도 좋다. 이런 삭제는 얽혀있는 스파게티가 풀릴 수 있는 하나의 실마리들이 된다. 리팩토링으로 제거할 수 있는 코드들은 이런게 있다. 내가 실제로 10년 된 모듈을 맡게되면서 리팩토링한 것들. | 사용하지 않는 api | 사용하지 않는 policy | 사용하지 않는 code | . 사용하지 않는 api . 내가 맡은 모듈은 전세계에서 하루에 수십 억건의 요청이 들어오는 서비스이다. 10년 된 모듈 답게 legacy version부터 수 십개의 api가 있었는데, 리팩토링을 하며 사용하지 않는 api들을 찾았다. 먼저 지표에서 api 호출이 없는 것을 확인하고, 클라이언트 담당자에게 사용하는 api인지를 확인했다. 이렇게 지운 api만 해도 수 건이지만, 중요한건 이게 지워짐으로 인해 꼼꼼하게 얽혀있는 스파게티 코드에서 스파게티 몇 줄을 뺌으로써 조금 더 느슨한 스파게티를 만들 수 있다는 것이다. 사용하지 않는 policy . api와 마찬가지로 사용하지 않는 policy도 많다. 이 서비스에서 policy는 property의 일종으로 사용되었고 서비스 전반에 영향을 미치는 짬뽕 같은 코드였다. 한 눈에 보이지도 않고 리팩토링을 하려고 하면 계속 냄새를 내뿜는 policy를 손보았다. 오버 프로그래밍으로 만들어뒀지만 사용하지 않는 policy가 정리되기도 하지만, Content 타입 별로 서로 다른 동작을 하도록 넣어뒀던 policy가 사실 모두 같은 값을 갖고 있기도 했다. 이런 policy를 지우면 해당 로직도 지울 수 있고 마찬가지로 느슨한 스파게티를 만드는데 도움이 된다. 사용하지 않는 code . api나 policy는 관심을 갖고 보아야 확인할 수 있지만 사용하지 않는 code를 찾는건 참 쉽다. 상위의 class, method, parameter, property 레벨에서 사용하지 않는 것들을 먼저 정리하면 하위의 필요 없던 로직들이 덩달아 지워지기도 한다. ‘리팩토링을 다 하고 봤더니 실제론 필요 없는 코드’라는 상황이 되지 않도록 사용하지 않는 코드들을 먼저 정리하면 스파게티도 느슨하고 리팩토링도 더 쉽다. ",
    "url": "/docs/refactoring/my-refactoring#%EC%82%AC%EC%9A%A9%ED%95%98%EC%A7%80-%EC%95%8A%EB%8A%94-%EC%BD%94%EB%93%9C-%EC%82%AD%EC%A0%9C%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/refactoring/my-refactoring#사용하지-않는-코드-삭제하기"
  },"585": {
    "doc": "현업에서 진행하는 대규모 리팩토링 프로세스",
    "title": "리팩토링 아키텍쳐 설계하기",
    "content": "이미 운영중인 서비스, 그것도 legacy 서비스를 한 순간 리팩토링하긴 쉽지 않다. 마틴 파울러도 저서 ‘리팩토링’에서 이건 불가능한 일임을 몇 번이고 얘기했다. 작은 리팩토링이라면 서비스 개발 중에 리팩토링을 할 수 있겠지만 big refactoring의 경우 전략적인 접근이 필요하다. 중간에 치고들어오는 다른 작업들로 리팩토링이 생각한 일정대로 진행되지 않을 수도 있다. 리팩토링을 한번에 하지 못하고 끊기더라도 나아갈 방향을 제시하기 위해 아키텍쳐 설계는 꼭 필요하다. 아키텍쳐 설계가 중요한 이유는 리팩토링된 모듈의 구조에 대한 생각이 팀원들 모두 다르기 때문이다. 나 혼자 한다면 설계는 내 머리 속에 있지만 팀원들은 그렇지 않다. 생각보다 설계를 맞추는 과정은 더 디테일해야할 수 있는데, 실제로 아키텍쳐를 공유했는데도 다르게 이해해서 리팩토링이 잘못 진행되기도 했다. 명확한 리팩토링 아키텍쳐는 리팩토링 방향을 명확하게 한다. 리팩토링은 천천히 진행되겠지만 설계는 명확한 방향으로 나와야 한다. 설계가 명확하지 않으면 애써 진행한 리팩토링한 것을 다시 리팩토링 할수도 있다. 그렇지만 전체 아키텍쳐 설계를 다시할 순 없다. 설계가 명확한 방향이어야할 뿐, 전체적인 설계가 완벽하게 나와야한다는 것은 아니다. 리팩토링의 대상이 되는 서비스들의 설계가 명확하면 된다. | 특정 UseCase나 domain에 대해서만 명확하게 설계를 잡을수도 있다. | . ",
    "url": "/docs/refactoring/my-refactoring#%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81-%EC%95%84%ED%82%A4%ED%85%8D%EC%B3%90-%EC%84%A4%EA%B3%84%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/refactoring/my-refactoring#리팩토링-아키텍쳐-설계하기"
  },"586": {
    "doc": "현업에서 진행하는 대규모 리팩토링 프로세스",
    "title": "Acceptance test 확보하기",
    "content": "리팩토링이지만 대규모 작업을 하기 위해선 작업의 안정성을 확보하기 위한 test는 필수다. 마틴 파울러도 리팩토링을 커버할 수 있는 충분한 test가 필요하다고 말한다. 리팩토링이 안전하게 됐는지 검증해줄 수 있는 test가 분명 필요하다. 이 test는 SQE 팀에서 만든 test일수도 있고, 배포 전에 팀 내에서 수행하던 acceptance test일 수도 있다. 혹은 둘 다 일수도 있고. test가 없다면 만들어야한다. 수정하지 않고 리팩토링만 하고 내보내겠다며 test를 수행하지 않는 것은 문제다. 완전히 커버할 수 있는 test를 만들기는 어렵다. 그렇다고 리팩토링하며 모든 모듈의 test를 작성할 여유가 없을 수 있다. 그렇지만 기본적인 시나리오를 커버하는 acceptance test는 있어야 한다. 개인적으로 big refactoring에선 unit test가 큰 효용성을 갖기는 어렵고 acceptance test 같은 상위 수준의 test가 필요하다고 생각한다. ",
    "url": "/docs/refactoring/my-refactoring#acceptance-test-%ED%99%95%EB%B3%B4%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/refactoring/my-refactoring#acceptance-test-확보하기"
  },"587": {
    "doc": "현업에서 진행하는 대규모 리팩토링 프로세스",
    "title": "점진적으로 작업하기",
    "content": "이미 말했듯, 리팩토링을 한번에 하는 것은 쉽지 않다. 그리고 대규모 리팩토링으로 인한 장애가 있을수도 있다. 아키텍쳐 리팩토링에서 가장 중요한 것 중 하나는 점진적으로 작업하는 것이다. legacy 코드들을 보다보면 아키텍쳐 변경 외에도 손대고 싶은 로직들이 많다. ‘신기하게도 지저분한 코드를 만들었네’ 하는 생각과 ‘이걸 어떻게 오류 없이 돌렸을까’ 하는 생각도 들고, 때로는 오류를 발견하기도 한다. 이런 로직에 대한 수정들이 아키텍쳐와 같이 반영되면, 장애가 발생했을 때 아키텍쳐로 인한 것인지, 로직 수정에 의한 것인지 알 수 없다. 로직은 잠시 내려놓고 아키텍쳐에 대한 리팩토링만 반영하고 배포까지 되도록 한다. 점진적인 작업에서 중요한건 잦은 배포다. 잦은 배포로 안정적인 rollback point를 만들어두고 나면 혹시 잘못된 수정이 있더라도 리팩토링된 안전한 코드들을 확보할 수 있다. ",
    "url": "/docs/refactoring/my-refactoring#%EC%A0%90%EC%A7%84%EC%A0%81%EC%9C%BC%EB%A1%9C-%EC%9E%91%EC%97%85%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/refactoring/my-refactoring#점진적으로-작업하기"
  },"588": {
    "doc": "현업에서 진행하는 대규모 리팩토링 프로세스",
    "title": "인터페이스 나누기",
    "content": "어느정도 사용하지 않는 코드도 걷어내고, 리팩토링 아키텍쳐도 설계했고, 신뢰할 수 있는 테스트도 준비됐다면 실제 리팩토링은 어떤 작업부터 하면 좋을까? 모든 개발이 그렇듯 인터페이스를 나누는 것이 가장 먼저가 되야한다. 그렇기 때문에 아키텍쳐를 설계를 먼저하는 것이기도 하고. 리팩토링에서 가장 중요한건 인터페이스를 끊어내고 리디자인된 인터페이스로 옮겨가는 것이다. 한번에 갈 수 없기 때문에 인터페이스를 먼저 작업하고 부분 부분 옮겨가야한다. 도메인 인터페이스를 나누고, UseCase를 나누고, Port 인터페이스를 분리하는 작업들을 한번에 하기보다는 하나의 도메인, 하나의 UseCase, 하나의 Port 씩 인터페이스를 생성하고 옮겨가는 방향이 명확하다. 인터페이스 방향을 잡아놓으면 새로 추가되는 클래스들은 리디자인된 인터페이스 방향에 맞춰 개발할 수 있다. 인터페이스를 나눌 때 패키지의 위치도 중요하다. 여러 인터페이스 레벨에서 이게 adapter의 인터페이스인지, application의 인터페이스인지 . ",
    "url": "/docs/refactoring/my-refactoring#%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4-%EB%82%98%EB%88%84%EA%B8%B0",
    
    "relUrl": "/docs/refactoring/my-refactoring#인터페이스-나누기"
  },"589": {
    "doc": "현업에서 진행하는 대규모 리팩토링 프로세스",
    "title": "도메인 분리하기",
    "content": "Hexagonal + DDD의 리팩토링을 초점에 둔다면, 리팩토링을 통해 얻을 수 있는 것은 도메인을 명확하게 하고 로직을 분리할 수 있다는 것이다. 인터페이스를 나누면 어느정도 정리가 되지만 도메인을 분리하면 장점은 너무 많다. DDD 자체의 장점을 다 가지게 되는 것이나 마찬가지니까. 코드 이해도를 확연하게 높일 수 있고 중복 제거도 된다. 도메인 로직 보호와 도메인 언어로 서비스 코드를 관리할 수도 있다. 그런데, 생각보다 10년 묵은 legacy 코드를 도메인으로 분리하는건 쉽지 않았다. 인터페이스만 나눈다고 될 일도 아니고 도메인 로직이 프로젝트 전반에 걸쳐 사용되고 있었기 때문이다. 도메인 로직을 분리하는 팁이라고 하자면, . | 우선 대상 aggregate을 만든다. | aggregate의 꼴이 새로 DDD를 했을 때와는 다르겠지만 현재 legacy 코드와 호환할 수 있는 aggregate를 만든다. | aggregate와 legacy에서 사용하는 class들 사이의 converter를 만든다. | 이 converter는 리디자인된 aggregate을 사용하는 로직들에서 legacy 코드들과 호환할 때 convert 한 후 사용할 수 있는 도구. | . | . | aggregate에 도메인 로직을 넣는다. | 도메인 개념이 없는 코드에선 도메인 로직이 여기저기 흩어져있다. | 이런 경우엔 중복코드가 여러곳에 있고 코드가 파편화되어 있기도 하다. | 도메인 개념의 로직들을 하나씩 도메인 모델로 밀어넣고 코드를 정리한다. | . | 대상 aggregate의 repository를 만든다. | 서비스에 따라 필요한 CRUD가 다를 수 있으나 보통은 몇 가지 인터페이스의 CRUD가 있기 마련이다. | aggregate의 CRUD 중 가능한 기능부터 repository에 추가하고 분리한다. | repository의 개념은 db의 repository와 다를 수 있고 이를 명확하게 잡는 것이 중요하다. (이건 DDD 개념이 있어야 함) | . | repository를 서비스에 적용한다. | repository의 모든 기능이 만들어질 필요는 없다. read 중 하나의 함수만 완성되었다면 그걸 서비스에 적용한다. | 서비스 로직에서 도메인 개념없이 read를 하고 있었다면 이것만으로도 가독성이 향상되고 지저분한 로직을 제거하고 곳곳에서 호출되던 중복된 repository 로직들을 제거할 수 있다. | . | . 이 정도만 해도 도메인이 어느정도 정리된다. 이 과정이 부분부분 반복되다보면 도메인 서비스로 분리할 것들이 보이기도 한다. 그치만 legacy 코드를 전부 이렇게 만드는 것만 하더라도 오랜 시간이 걸린다. ",
    "url": "/docs/refactoring/my-refactoring#%EB%8F%84%EB%A9%94%EC%9D%B8-%EB%B6%84%EB%A6%AC%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/refactoring/my-refactoring#도메인-분리하기"
  },"590": {
    "doc": "현업에서 진행하는 대규모 리팩토링 프로세스",
    "title": "reference",
    "content": ". | 도메인 주도 설계 첫걸음 13장 | 스트렝글러 패턴 | 리팩토링, 마틴 파울러 | . ",
    "url": "/docs/refactoring/my-refactoring#reference",
    
    "relUrl": "/docs/refactoring/my-refactoring#reference"
  },"591": {
    "doc": "현업에서 진행하는 대규모 리팩토링 프로세스",
    "title": "현업에서 진행하는 대규모 리팩토링 프로세스",
    "content": " ",
    "url": "/docs/refactoring/my-refactoring",
    
    "relUrl": "/docs/refactoring/my-refactoring"
  },"592": {
    "doc": "구글 아이디로 로그인 구현하기",
    "title": "구글 로그인 서비스 생성",
    "content": "아래 링크에서 구글 로그인에 사용할 서비스를 생성한다. | https://console.cloud.google.com/apis/credentials | . 테스트나 소규모 서비스에 대해선 무료에 가깝다. ",
    "url": "/docs/apis/oauth/google-login#%EA%B5%AC%EA%B8%80-%EB%A1%9C%EA%B7%B8%EC%9D%B8-%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%83%9D%EC%84%B1",
    
    "relUrl": "/docs/apis/oauth/google-login#구글-로그인-서비스-생성"
  },"593": {
    "doc": "구글 아이디로 로그인 구현하기",
    "title": "flutter client 구현",
    "content": "import 'package:google_sign_in/google_sign_in.dart'; Future&lt;String&gt; signInGoogle() async { final GoogleSignInAccount? googleUser = await GoogleSignIn( clientId: '{YOUR_CLIENT_ID}.apps.googleusercontent.com' ).signIn(); if (googleUser != null) { print('email = ${googleUser.email}'); var snapshot = await googleUser.authentication; return snapshot.idToken ?? \"\"; } return \"\"; } Future&lt;void&gt; signOutGoogle() async { await GoogleSignIn( clientId: '{YOUR_CLIENT_ID}.apps.googleusercontent.com' ).signOut(); } . 내가 이번에 사용한 frontend는 flutter. flutter의 코드는 위와 같은데, idToken을 받아오는 api이다. 위 코드를 실행하면 우리가 흔히 아는 구글 로그인 팝업이 뜬다. 팝업으로 구글 로그인을 하면 email을 print하고 idToken을 반환하는 코드이다. 여기 client에서 받은 idToken을 server에 전달해서 idToken으로 server에서 google에서 확인된 token이 맞는지를 verify 한다. ",
    "url": "/docs/apis/oauth/google-login#flutter-client-%EA%B5%AC%ED%98%84",
    
    "relUrl": "/docs/apis/oauth/google-login#flutter-client-구현"
  },"594": {
    "doc": "구글 아이디로 로그인 구현하기",
    "title": "spring server 구현",
    "content": "@Service class GoogleSignInService { private lateinit var verifier: GoogleIdTokenVerifier @PostConstruct fun init() { val httpTransport = NetHttpTransport() val jacksonFactory = JacksonFactory() verifier = GoogleIdTokenVerifier.Builder(httpTransport, jacksonFactory).build() } fun getIdToken(idToken: String) { val googleIdToken = verifier.verify(idToken) ?: throw UnAuthenticatedUserException(idToken) } } . 이번에 사용한 backend는 코프링. kotlin/java에서는 GoogleIdTokenVerifier를 사용한다. client에서 받은 idToken을 여기에 넣어주기만 하면 googleIdToken을 받아온다. googleIdToken은 우리가 필요한 여러 데이터들을 갖고 있다. | 응답으로 내려오는 데이터 목록 | . 여기서 내가 필요한건, email, name, picture, locale 정도. ",
    "url": "/docs/apis/oauth/google-login#spring-server-%EA%B5%AC%ED%98%84",
    
    "relUrl": "/docs/apis/oauth/google-login#spring-server-구현"
  },"595": {
    "doc": "구글 아이디로 로그인 구현하기",
    "title": "reference",
    "content": ". | https://cloud.google.com/apigee/docs/api-platform/security/oauth/oauth-introduction?hl=ko | https://developers.google.com/identity/openid-connect/openid-connect#authenticatingtheuser | https://developers.google.com/identity/protocols/oauth2 | . ",
    "url": "/docs/apis/oauth/google-login#reference",
    
    "relUrl": "/docs/apis/oauth/google-login#reference"
  },"596": {
    "doc": "구글 아이디로 로그인 구현하기",
    "title": "구글 아이디로 로그인 구현하기",
    "content": "사이드 프로젝트 개발 중, 로그인 기능을 고려하게 되었다. 처음 로그인을 생각할 땐 회원가입, 로그인, 로그아웃, 회원탈퇴을 생각하면 뭔가 골치가 아팠다. 더불어 사용자 계정과 비밀번호를 관리하는 것까지. 회사에선 써볼일이 없는 OAuth를 적용해보기로 했다. 개념은 정리하지 않고 간단히 하자면 네이버 아이디로 로그인, 구글 아이디로 로그인 같이 다른 소셜 서비스의 아이디로 로그인할 수 있는 약속을 말한다. ",
    "url": "/docs/apis/oauth/google-login",
    
    "relUrl": "/docs/apis/oauth/google-login"
  },"597": {
    "doc": "linux 환경변수 설정하기 - /etc/profile.d",
    "title": "etc/profile.d",
    "content": "/etc/profile.d 폴더는 linux에서 user와 system 전체 환경 변수와 스크립트를 설정하기 위한 폴더이다. 로그인 시에 폴더 안의 파일들이 자동 실행되어 환경 변수 설정 등에 사용된다. ",
    "url": "/docs/dev-tools/linux/etc_profiled#etcprofiled",
    
    "relUrl": "/docs/dev-tools/linux/etc_profiled#etcprofiled"
  },"598": {
    "doc": "linux 환경변수 설정하기 - /etc/profile.d",
    "title": "사용 목적",
    "content": ". | 스크립트 파일로 환경 변수를 export 하면 시스템 전반에 설정되는 환경변수를 세팅할 수 있다. | 스크립트를 사용해 시스템 동작을 변경하거나 환경을 설정할 수 있다. | . ",
    "url": "/docs/dev-tools/linux/etc_profiled#%EC%82%AC%EC%9A%A9-%EB%AA%A9%EC%A0%81",
    
    "relUrl": "/docs/dev-tools/linux/etc_profiled#사용-목적"
  },"599": {
    "doc": "linux 환경변수 설정하기 - /etc/profile.d",
    "title": "주의 사항",
    "content": ". | 일반적으로 .sh로 끝나는 관례를 따른다. | 여러 스크립트가 추가될 수 있기 때문에 명확한 이름을 사용한다. | 스크립트는 알파벳 순서에 맞춰 수행되는 것에 주의한다. | 시스템의 모든 사용자에게 적용된다는 점을 고려한다. | . ",
    "url": "/docs/dev-tools/linux/etc_profiled#%EC%A3%BC%EC%9D%98-%EC%82%AC%ED%95%AD",
    
    "relUrl": "/docs/dev-tools/linux/etc_profiled#주의-사항"
  },"600": {
    "doc": "linux 환경변수 설정하기 - /etc/profile.d",
    "title": "예시",
    "content": "예를 들면 실제로 내가 사용하는 로그인 토큰을 담은 환경변수 스크립트를 작성해본다. 로그인 토큰 같은 경우 사용되는 보안상의 이유로 스크립트를 git에 올리지 못하기 때문에 환경변수로 세팅해놓고 스크립트에서 환경 변수를 조회하도록 하면 좋다. /etc/profile.d/login_token.sh . #!/bin/bash export LOGIN_TOKEN=\"Hello_TOKEN\" . ",
    "url": "/docs/dev-tools/linux/etc_profiled#%EC%98%88%EC%8B%9C",
    
    "relUrl": "/docs/dev-tools/linux/etc_profiled#예시"
  },"601": {
    "doc": "linux 환경변수 설정하기 - /etc/profile.d",
    "title": "reference",
    "content": ". | linuxfromscratch.org/blfs/view/11.0/postlfs/profile.html | . ",
    "url": "/docs/dev-tools/linux/etc_profiled#reference",
    
    "relUrl": "/docs/dev-tools/linux/etc_profiled#reference"
  },"602": {
    "doc": "linux 환경변수 설정하기 - /etc/profile.d",
    "title": "linux 환경변수 설정하기 - /etc/profile.d",
    "content": " ",
    "url": "/docs/dev-tools/linux/etc_profiled",
    
    "relUrl": "/docs/dev-tools/linux/etc_profiled"
  },"603": {
    "doc": "archunit으로 아키텍처 테스트하기",
    "title": "아키텍처를 보호하기 위한 테스트 ArchUnit",
    "content": "개발에 있어서 아키텍처의 중요성은 점점 커져가고 있다. 최근 팀을 옮기고 개발하면서 불편한 점 중 하나는 아키텍처에 대한 이해도가 팀원들마다 다르다는 점이다. DDD와 hexagonal에 맞추어 잡아놓은 아키텍처가 다른 사람들의 작업으로 인해 무너지기도 한다. 리뷰로 잡아야겠지만 휴가 중이거나 리뷰를 놓치는 경우도 있다. 아키텍처가 문서화되고 준수되어야겠지만 이를 확인하고 강제하는 도구도 필요하다. 아키텍처도 테스트로 강제화하는 방법을 소개한다. ",
    "url": "/docs/java/library/archunit#%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EB%A5%BC-%EB%B3%B4%ED%98%B8%ED%95%98%EA%B8%B0-%EC%9C%84%ED%95%9C-%ED%85%8C%EC%8A%A4%ED%8A%B8-archunit",
    
    "relUrl": "/docs/java/library/archunit#아키텍처를-보호하기-위한-테스트-archunit"
  },"604": {
    "doc": "archunit으로 아키텍처 테스트하기",
    "title": "ArchUnit",
    "content": "ArchUnit은 아키텍처를 확인하기 위한 라이브러리. package, class, layer 간의 dependency 확인과 circular dependency 확인 등의 작업을 할 수 있다. ",
    "url": "/docs/java/library/archunit#archunit",
    
    "relUrl": "/docs/java/library/archunit#archunit"
  },"605": {
    "doc": "archunit으로 아키텍처 테스트하기",
    "title": "사용법",
    "content": "archunit의 가이드 참고 . ",
    "url": "/docs/java/library/archunit#%EC%82%AC%EC%9A%A9%EB%B2%95",
    
    "relUrl": "/docs/java/library/archunit#사용법"
  },"606": {
    "doc": "archunit으로 아키텍처 테스트하기",
    "title": "test 코드를 통한 architecture 제한 예시",
    "content": "@AnalyzeClasses(packages = \"com.meansoup\") public class HexagonalArchitectureTest { @Test @DisplayName(\"archunit 적용하기\") void domain() { JavaClasses importedClasses = new ClassFileImporter().importPackages(\"com.meansoup\"); ArchRule archRule = noClasses().that().resideInAPackage(\"..domain..\") .should().dependOnClassesThat().resideInAnyPackage(\"..adapter..\", \"..application..\"); archRule.check(importedClasses); } } . ",
    "url": "/docs/java/library/archunit#test-%EC%BD%94%EB%93%9C%EB%A5%BC-%ED%86%B5%ED%95%9C-architecture-%EC%A0%9C%ED%95%9C-%EC%98%88%EC%8B%9C",
    
    "relUrl": "/docs/java/library/archunit#test-코드를-통한-architecture-제한-예시"
  },"607": {
    "doc": "archunit으로 아키텍처 테스트하기",
    "title": "plantuml을 통한 architecture 제한 예시",
    "content": "plantuml에 component diagram을 그려놓고 archunit을 적용할 수 있다. public class HexagonalArchitectureTest { @Test @DisplayName(\"plantuml로 archunit 적용하기\") void byPlantUml() { JavaClasses importedClasses = new ClassFileImporter() .withImportOption(ImportOption.Predefined.DO_NOT_INCLUDE_TESTS) .importPackages(\"com.meansoup\"); ClassesShouldConjunction shouldConjunction = classes().should( adhereToPlantUmlDiagram(\"docs/01.architecture/component/architecture.puml\", consideringOnlyDependenciesInDiagram()) ); shouldConjunction.check(importedClasses); } } . withImportOption을 적지 않으면 테스트에서도 적용되고, 이게 현재 작성한 fitness 테스트까지 검사해서 테스트가 실패한다. @startuml [application] &lt;&lt;..application..&gt;&gt; [domain] &lt;&lt;..domain..&gt;&gt; [application] --&gt; [domain] @enduml . 위 테스트에서 사용한 예시 component diagram . ",
    "url": "/docs/java/library/archunit#plantuml%EC%9D%84-%ED%86%B5%ED%95%9C-architecture-%EC%A0%9C%ED%95%9C-%EC%98%88%EC%8B%9C",
    
    "relUrl": "/docs/java/library/archunit#plantuml을-통한-architecture-제한-예시"
  },"608": {
    "doc": "archunit으로 아키텍처 테스트하기",
    "title": "실제 사용",
    "content": "초기 모듈을 개발하는 경우 개발 처음부터 설계된 package와 class에 맞춰 archunit 테스트를 작성하면 된다. 개발되는 모든 사항이 테스트를 통과해서 아키텍처에 맞게 반영되는지 확인할 수 있다. 그러나 이미 개발된 모듈이라면 패키지별로 테스트를 작성하고 수정하는 방식이 필요하다. 나 같은 경우는 이미 개발된 모듈의 domain 패키지의 dependency를 제거하는 것을 첫 번째 테스트로 잡았다. reference . | https://www.archunit.org/userguide/html/000_Index.html | https://www.baeldung.com/java-archunit-intro | https://d2.naver.com/helloworld/9222129 | . ",
    "url": "/docs/java/library/archunit#%EC%8B%A4%EC%A0%9C-%EC%82%AC%EC%9A%A9",
    
    "relUrl": "/docs/java/library/archunit#실제-사용"
  },"609": {
    "doc": "archunit으로 아키텍처 테스트하기",
    "title": "archunit으로 아키텍처 테스트하기",
    "content": " ",
    "url": "/docs/java/library/archunit",
    
    "relUrl": "/docs/java/library/archunit"
  },"610": {
    "doc": "일회성 배치에 대한 회고",
    "title": "one time batch",
    "content": "일반적으로 사용하는 배치작업과 일회성 배치는 결이 좀 다른 것 같다. 한번만 수행하면 된다는 특징이 있다. 일회성 배치를 뭐라고 하는지 모르겠지만 one time batch라고 하면 좋을 것 같다. 일회성 배치를 돌리는 상황들을 생각해보면 아래와 같은 케이스들이 있다. 다른 케이스가 더 있을지도 모르지만 내가 batch를 수행했던 이유들은 이렇다. 1. migration . 마이그레이션을 하는 이유 repository의 구조 변경을 하는 경우가 많다. 우리는 마이그레이션을 수 차례 진행했는데 이런 케이스다. | database를 변경하는 케이스 | database 효율화를 위해 table을 통합하거나 스키마를 변경하는 케이스 | storage key를 변경하는 케이스 | . legacy 모듈에는 database 스키마나 storage key가 굉장히 이상하게 작성되어 있는 경우가 종종 있다. 신규 피처를 추가하거나 리팩토링하면서 이런 로직들을 안고 분기처리할 수도 있지만 마이그레이션을 하면 코드 관리가 더 좋았다. 마이그레이션도 처음이 어렵지 여러번 하다보니 괜찮기도 했고. 2. delete . 서비스를 eof 시킬때도 일회성 배치를 활용했다. 서비스가 통채로 사라진다면 일정시간 보관 후 데이터를 전부 날리면 되겠지만 우리는 서비스의 일부 content만 eof되는 케이스가 있었다. 이때도 일회성 배치를 계속 사용했다. 3. check . 서비스에 버그가 있어서 장애를 겪는 사용자가 있는지 파악하기 위해 일회성 배치를 활용하기도 했다. 데이터 저장에 버그가 있는 이슈를 발견했을 때 이런 케이스에 해당하는 유저 데이터가 어느정도 되는지 파악하기 위해 사용하기도 한다. 4. revise . 버그를 찾았다면 수정을 해야할 경우에도 일회성 배치를 사용한다. ",
    "url": "/docs/retrospect/one-time-batch#one-time-batch",
    
    "relUrl": "/docs/retrospect/one-time-batch#one-time-batch"
  },"611": {
    "doc": "일회성 배치에 대한 회고",
    "title": "배치에서 생각할 것",
    "content": "일회성 배치를 수십 차례 수행하면서 느낀 것. 배치에서 필요한 고려사항들. 이 느낀점은 한참 배치를 많이 수행하던 21년도 회고에서 회고한 내용도 포함한다. 확장성 보장하기 . 대부분의 일회성 배치들은 대부분 정해진 기간이 있다. 마이그레이션이라면 기간이, eof를 위한 삭제에도 기간이 있고 이슈 해결을 위한 작업들은 언제나 ASAP. 기간을 맞추기 위해, 혹은 낭비되는 cpu를 채우거나 인스턴스 숫자를 조절하기 위해서 보통 batch의 worker(instance 혹은 thread)가 확장 가능한 구조가 굉장히 중요하다. 우리는 배치를 한번 돌리면 대상이 수천만에서 수억이기 때문에 확장이 많이 필요했다. instance를 더 붙이고 싶은데 불가능하거나, 성능을 높이려면 재시작이 항상 필요하다면 곤란하다. 배치를 돌리다보면 성능을 늘리고 보니 더 늘리게 되는 경우가 태반이니까.= . 멱등성 보장하기 . 재시작이 필요하지 않은 확장성을 보장하더라도, 배치를 돌리다보면 여러 이유로 배치 프로세스를 중단하고 재시작을 하는 경우가 많다. 배치 트리거 인스턴스에서 memory/disk가 부족해서 scale up, ebs 추가를 하기도 했고. db thorttling 이슈로 input data를 정리해서 재수행하기도 했다. 뭐 그렇지 않더라도 인스턴스가 내려간다거나 하는 케이스도 고려되야할 것 같다. 재수행 할 때마다 수행된 타겟이 batch에 다시 들어가더라도 문제가 없도록 멱등성이 고려되어야 한다. 그렇지 않으면 어디까지 돌렸는지를 정확하게 정리하는데 더 많은 시간을 쓰게 된다. 배치 수행이 한번 되든 열번 되든 타겟에는 한번 된 것과 동일한 문제 없는 상태여야한다는 말. 재수행 고려하기 . 멱등성만 보장된다고 문제가 없는 건 아니다. 초기에 돌렸던 일회성 배치중 하나는 멱등성이 완벽하게 보장되었지만 재수행에 대한 고려가 되어있지 않은 케이스가 있었다. 배치가 돌아간 타겟이 다시 시간을 잡아먹으면서 배치가 길어지고, 타겟을 좀 더 추려내기 위해 개발자가 붙어 작업을 하기도 했다. 재수행이 고려되어 있지 않다면 일주일을 배치를 돌리고 다시 돌렸을 때, 동작은 동일하지만 일주일을 꼬박 다시 기다려야한다거나 하는 이슈가 생길 수 있다. 물론 실제로 수행하다보면 일주일이나 돌렸다면 어느정도 타겟을 정리 하겠지만 앞서 말했듯 타겟을 명확하게 정리하는 일은 생각보다 귀찮다. 이미 수행된 타겟이 다시 재수행되는 경우 재수행 시간이 오래걸리지 않도록 고려가 필요하다. migration이라면 rollback 구조를 파악하기 . 많은 배치와 migration을 수행하면서 간단한 migration에는 자신감이 충만해질 때가 있다. 그래서 rollback에 대한 생각을 접어둘 때가 있는데, 배포 이후에 rollback이 불가능한 경우를 생각하면 아찔하다. migration은 사용자의 data를 손대는 배치다보니 작업 수행 전후로 확인해야할 내용들을 명확히 정리하고 수행해야 한다. migration 이후에도 이슈가 리포트되면 이전 상태로 rollback할 수 있는 구조를 가져가는 편이 안전하다. 지표 확보하기 . 배치를 수행하는데 이게 언제 끝날지 감이 잡히지 않는다면 곤란하다. 기간을 맞추기 위해선 tps나 batch의 예상 시간을 조회할 수 있는 지표를 남기면 유용하다. 이대로 배치를 돌리면 1년이 넘게 걸리겠다는 인사이트를 지표를 통해 얻은적이 많다. 지표를 확보하고 필요하다면 배치를 확장한다. 남은 타겟의 수나 예상 시간을 지표화하면 인스턴스에 들어가서 진행 상황을 보지 않더라도 잘 수행되고 있는지, 배치가 완료되었는지를 확인할 수 있어 좋다. data flow 확인하기 . 우리는 지금 global 5개 region에서 서비스를 하고 있다. file이 오가는 batch의 경우 binary data가 region을 넘어가는 경우가 발생하기도 하는데, 최대한 효율적으로 binary flow를 잡아갈 수 있도록 설계가 필요하다. 한 번은 설계를 잘 해놓고, binary flow를 놓쳐서 성능이 현저하게 떨어져서 다시 개발한 적이 있었다. ",
    "url": "/docs/retrospect/one-time-batch#%EB%B0%B0%EC%B9%98%EC%97%90%EC%84%9C-%EC%83%9D%EA%B0%81%ED%95%A0-%EA%B2%83",
    
    "relUrl": "/docs/retrospect/one-time-batch#배치에서-생각할-것"
  },"612": {
    "doc": "일회성 배치에 대한 회고",
    "title": "배치 개발하기",
    "content": "배치에서 필요한 것들을 생각해보면 배치를 어떻게 개발해야할지가 그려진다. 저 요구사항들을 맞추기 위해 우리가 개발했던 방향들. batch api 개발 . 배치는 api를 사용하는 편이 좋다. 예전에는 db를 직접 조작하는 스크립트를 수행하는 적도 있었지만 스크립트 배치는 단점이 너무 크다. | 소스코드가 잘 관리되지 않는다. | 마찬가지로 소스 히스토리가 관리되지 않는다. | 테스트가 넉넉하지 않고 허점이 있을 수 있다. | 위험하다. | . 반면 서비스 코드에 api로 작성하게 되면 히스토리 관리나 테스트, 안전성을 확보할 수 있다. 그리고 서비스 코드의 domain과 usecase들을 활용할 수 있어서 개발이 훨씬 간단하다. 위에서 말했듯 일회성 배치에서는 확장성이 가장 중요하다. 일회성 배치를 위해 배치 인스턴스를 확장 가능하게 가져가고 타겟을 분배하는 아키텍처를 잡는 것은 시간 낭비다. was의 pipeline을 사용하거나 확장해서 사용하면 이걸 고려하지 않아도 된다. batch runner 개발 . batch api를 만들었다면 target 리스트를 보고 api를 호출하는 runner가 있어야 한다. runner는 언어가 무관하지만 경험상으론 golang이 가장 적절하다. 초창기 우리팀의 일회성 배치는 python 스크립트로 타겟들을 읽어서 api를 호출하는 방식으로 구현됐다. 내가 이걸 처음 돌리게 됐을 때 대상 타겟이 수 억개 였고 python process를 늘리더라도 1년 이상의 시간이 걸리는 상황. runner 자체가 오래걸리니 부하 조절을 할수가 없는 상황이었다. 이를 해결하기 위해 golang으로 runner를 개발했다. golang의 경우 kb 단위의 메모리를 사용하는 경량 쓰레드인 go-routine 덕분에 쓰레드 조절에 문제가 없었다. backend가 충분히 받쳐준다면 runner의 문제로 부하를 조절하지 못하는 상황은 없다. | 배치 수행하면서 c5.xlarge로도 3000개의 thread까지 호출했다. | 이건 api의 workload가 중요한데 당시 batch api는 평균 1000ms. | 이 때도 우리 일정상 더 높은 부하가 필요하지 않았을 뿐 c5.xlarge에서 3000개의 go-routine이 부담스럽진 않았다. | . 이렇게 작성한 runner는 배치마다 조금씩 업데이트해서 현재는 모든 배치에서 거의 동일한 runner를 사용할 수 있게 됐다. batch runner 개발시 생각할 것 . runner에서는 배치 로그를 확인할 수 있으면 좋다. 어떤 이유로 실패했는지를 로그를 보고 알 수 있다면 api를 수정하기 쉽다. 이건 api도 어느정도 설계가 잘 되어야 한다. 배치 결과 실패한 타겟들을 별도로 뽑을 수 있어야 한다. 실패한 타겟들을 따로 추출할 필요 없이 배치 수행시 실패한 타겟을 별도로 뽑아서 재수행시 해당 타겟들만 재수행할 수 있는 구조가 되어야 한다. 배치는 한 번에 성공하기는 불가능하고 수정과 배포를 하며 수차례 재수행하는데 수행이 간단해야 한다. | 이런 재수행이 한번의 스크립트로 수행될 수 있어야 재수행에 대한 시간낭비가 적고 귀찮음도 줄 수 있다. | . 동적으로 thread 추가가 가능해야 한다. 우리는 worker라고 불렀는데 property를 통해 thread를 동적으로 늘릴 수 있어야 한다. 지표를 확인하고 부하를 참고한 뒤 재수행 없이 확장 가능하도록 thread를 property 변경으로 늘릴 수 있는 구조를 만들어야 한다. ",
    "url": "/docs/retrospect/one-time-batch#%EB%B0%B0%EC%B9%98-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/retrospect/one-time-batch#배치-개발하기"
  },"613": {
    "doc": "일회성 배치에 대한 회고",
    "title": "문서화",
    "content": "배치를 수행하는 정보를 기록하고 관리해야한다. 한 해에 열 번이 넘는 일회성 배치를 작업하면서 우리는 배치작업을 폴더 이름으로 관리했다. 우리도 이렇게 배치를 많이 돌리게 될줄은 몰랐지. 나중 가서야 우리가 문서화를 제대로 하지 않았다는 것을 확인했다. | migration1, migration2, migration 21, … | . 어떤 배치에서 어떤 작업들을 했는지 보이지가 않았다. 이런 배치들은 이름만 봐도 알 수 있게 분리되고 관리되어야 한다. 시간이 지나고 이 배치들을 돌아봐야 할 때가 있다. 이슈가 생겼다거나, 특정 시점의 데이터가 수상하다거나. 배치에 대한 정보가 명확하게 기록되어 있지 않으면 나중엔 이걸 찾는 것도 일이다. 배치가 열 번이 넘어갈 때쯤 나는 팀 docs 아래 문서 하나를 만들었다. 히스토리를 관리하는 history.md에 배치 시작 시간, 끝나는 시간, 사용한 api, 타겟과 배치 특이사항을 기록하는 표를 작성했다. 배치 수행 기록을 한눈에 볼 수 있게 문서화하는 것이 중요하다. 문서화의 다른 목적은 휴가를 잘 가기 위한 방향이다. 배치는 생각하지 못한 이슈로 길어지기도 한다. 내가 휴가를 가야될 때 다른 팀원이 배치 진행사항을 확인할 수 있도록 문서화 되어야 한다. ",
    "url": "/docs/retrospect/one-time-batch#%EB%AC%B8%EC%84%9C%ED%99%94",
    
    "relUrl": "/docs/retrospect/one-time-batch#문서화"
  },"614": {
    "doc": "일회성 배치에 대한 회고",
    "title": "일회성 배치에 대한 회고",
    "content": "서버 개발을 하다보면 batch를 수행하게 될 일들이 종종있다. 종종이 어떨때는 자주가 되기도 한다. batch application을 개발하는 것과는 별개로 한번만 수행되는 batch 작업을 하게 되는 경우도 많다. 이런 일회성 배치는 생각보다 자주 수행하게 되는데 많을 땐 한 해에 10번을 넘게 돌리기도 했다. 최근 데이터 정리를 위해 오랜만에 일회성 배치를 돌리면서 내 생각들을 정리한다. ",
    "url": "/docs/retrospect/one-time-batch",
    
    "relUrl": "/docs/retrospect/one-time-batch"
  },"615": {
    "doc": "업무 효율 극강화 linux terminal 단축키",
    "title": "창 조절",
    "content": "| 단축키 | 설명 |   | . | windows + up | 터미널을 전체 화면으로 만든다. | 터미널에서만 동작하는 명령어가 아니라 모든 앱에서 동작한다. | . | windows + down | 터미널을 작은 화면으로 만든다. | - | . | windows + left | 터미널을 왼쪽으로 옮긴다. | - | . | windows + right | 터미널을 오른쪽으로 옮긴다. | - | . | ctrl + ‘-‘ | 터미널 크기를 줄인다. | 전체화면에선 터미널의 글자 크기를 줄인다. | . | ctrl + shift + ‘+’ | 터미널 크기를 키운다. | 전체화면에선 터미널의 글자 크기를 키운다. | . ",
    "url": "/docs/dev-tools/linux-commands/terminal#%EC%B0%BD-%EC%A1%B0%EC%A0%88",
    
    "relUrl": "/docs/dev-tools/linux-commands/terminal#창-조절"
  },"616": {
    "doc": "업무 효율 극강화 linux terminal 단축키",
    "title": "프로세스 관련",
    "content": "| 단축키 | 설명 |   | . | Ctrl + C | 현재 실행 중인 명령어를 취소한다. |   | . | Ctrl + D | 현재 터미널 세션을 종료한다. exit과 유사. | exit을 치지 않아도 되서 좋다. 특히 jumphost 안에서나 tmux 같이 exit이 연달아 필요했을 때 편하다. | . ",
    "url": "/docs/dev-tools/linux-commands/terminal#%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EA%B4%80%EB%A0%A8",
    
    "relUrl": "/docs/dev-tools/linux-commands/terminal#프로세스-관련"
  },"617": {
    "doc": "업무 효율 극강화 linux terminal 단축키",
    "title": "터미널 출력 관련",
    "content": "| 단축키 | 설명 |   | . | Ctrl + S | 터미널에 나오는 출력을 잠시 멈춘다. | 로그를 본다거나 너무 많은 출력으로 보고싶은 터미널을 볼 수 없을 때 멈추고 보기 좋다. | . | Ctrl + Q | Ctrl + S랑 쌍으로 멈춘것 풀기. |   | . | Ctrl + L | 터미널 지우기. clear와 유사 | clear를 치지 않아도 되니 좋다. | . ",
    "url": "/docs/dev-tools/linux-commands/terminal#%ED%84%B0%EB%AF%B8%EB%84%90-%EC%B6%9C%EB%A0%A5-%EA%B4%80%EB%A0%A8",
    
    "relUrl": "/docs/dev-tools/linux-commands/terminal#터미널-출력-관련"
  },"618": {
    "doc": "업무 효율 극강화 linux terminal 단축키",
    "title": "터미널 입력 관련",
    "content": "| 단축키 | 설명 |   | . | Ctrl + U | 현재 입력중인 줄을 지운다. |   | . | Ctrl + K | 현재 커서 위치부터 줄 끝까지 지운다. |   | . | Ctrl + W | 현재 커서 위치부터 이전 단어까지 지운다. |   | . ",
    "url": "/docs/dev-tools/linux-commands/terminal#%ED%84%B0%EB%AF%B8%EB%84%90-%EC%9E%85%EB%A0%A5-%EA%B4%80%EB%A0%A8",
    
    "relUrl": "/docs/dev-tools/linux-commands/terminal#터미널-입력-관련"
  },"619": {
    "doc": "업무 효율 극강화 linux terminal 단축키",
    "title": "명령어 관련",
    "content": "| 단축키 | 설명 |   | . | Tab | 자동완성 |   | . | up / down | 이전 명령어 |   | . | Ctrl + R | 이전에 실행했던 명령어들을 검색한다. | 이거 없으면 일 못하지. | . ",
    "url": "/docs/dev-tools/linux-commands/terminal#%EB%AA%85%EB%A0%B9%EC%96%B4-%EA%B4%80%EB%A0%A8",
    
    "relUrl": "/docs/dev-tools/linux-commands/terminal#명령어-관련"
  },"620": {
    "doc": "업무 효율 극강화 linux terminal 단축키",
    "title": "history (!) command",
    "content": "| 단축키 | 설명 |   | . | !! | 가장 최근에 수행한 명령어를 재수행한다. |   | . | !{abc} | abc로 시작하는 가장 최근에 수행한 명령어를 재수행한다. |   | . | !{abc}:p | abc로 시작하는 가장 최근에 수행한 명령어를 수행하지 않고 출력한다. |   | . ",
    "url": "/docs/dev-tools/linux-commands/terminal#history--command",
    
    "relUrl": "/docs/dev-tools/linux-commands/terminal#history--command"
  },"621": {
    "doc": "업무 효율 극강화 linux terminal 단축키",
    "title": "업무 효율 극강화 linux terminal 단축키",
    "content": "DDD tactical components . Terminal Shortcut tmux cut jq screen split . 모든 단축키가 업무 효율을 굉장히 올려준다만 리눅스 터미널 단축키만큼 많이 쓰이고 당연하게 쓰이는건 없는 것 같다. 그만큼 리눅스 단축키를 알면 효율이 급격히 올라간다. ",
    "url": "/docs/dev-tools/linux-commands/terminal",
    
    "relUrl": "/docs/dev-tools/linux-commands/terminal"
  },"622": {
    "doc": "api gateway, envoy란?",
    "title": "Envoy?",
    "content": "Envoy는 대규모 현대 서비스 지향 아키텍처를 위해 설계된 L7 proxy 및 communication bus이다. Lift의 프로젝트로, Cloud Native Computing Foundation(CNCF)의 Graduated Project이다. 이 프로젝트는 아래와 같은 목적으로 탄생했다. 네트워크는 애플리케이션에 투명해야 한다. 네트워크 및 애플리케이션 문제가 발생하면 문제의 원인을 쉽게 파악할 수 있어야 한다. msa의 단일 application과 service를 위해 설계된 high performance C++ distributted proxy으로, yaml로 policy를 작성하면 고성능의 proxy를 사용할 수 있다. ",
    "url": "/docs/apis/envoy/envoy#envoy",
    
    "relUrl": "/docs/apis/envoy/envoy#envoy"
  },"623": {
    "doc": "api gateway, envoy란?",
    "title": "why envoy?",
    "content": "우리가 gateway를 찾을 때 우리의 요구사항은 간단했다. 기본적으로 gateway가 제공하는 인증/인가, end point의 역할을 하는 것. 그리고 http/2와 grpc를 지원하는 것. envoy, kong, zuul, spring cloud gateway 같은 gateway들은 최근에는 모두 http/2, grpc를 지원하고 있다. 그 중에 envoy를 선택한 이유는 learning curve가 비교적 낮기 때문이다. 그리고 오픈소스이며 enterprise도 존재하지 않는다. (kong은 enterpirse 서비스가 존재) . envoy는 정책 기반으로 동작하는 proxy로 yaml 정책을 명시하기만 하면 proxy를 사용할 수 있다. 고성능으로. 필요한 기능은 C++, Lua로 작성한 filter를 추가할 수 있다. 대부분의 필요한 기능들은 이미 필터가 제공되고 있기도 하다. envoy는 태생부터 service mesh를 위해 만들어진 서비스이다. k8s에서 service mesh로 사용하는 istio에서도 envoy를 사용하고 있기 때문에, 검증된 솔루션일 뿐만 아니라 envoy를 사용함으로써 추후에 istio를 더 쉽게 도입할 수 있다. ",
    "url": "/docs/apis/envoy/envoy#why-envoy",
    
    "relUrl": "/docs/apis/envoy/envoy#why-envoy"
  },"624": {
    "doc": "api gateway, envoy란?",
    "title": "기능",
    "content": "기능이야 많지만 대표적인 기능들만 추려보면. Out of process architecture . Envoy proxy는 self contained process로 모든 언어와 application server와 함께 동작할 수 있게 설계되었다. envoy는 application과 투명하게 메세지를 주고 받으며 여러 application과 언어를 사용하는 현대 서비스 방향을 투명하게 만들어준다. 그 자체로 메모리사용량이 적은 고성능의 서버이다. 모든 프로그래밍 언어, 프레임워크와 함께 실행될 수 있다. 즉 다양한 언어와 프레임워크를 사용하는 MSA 구조에 적합하고 유용하다. L3/L4 filter architecture . envoy는 L7 proxy 이지만 L3/L4 proxy에도 핵심 기능이 있다. pluggable filter를 통해 TCP/UDP 관련 처리 등을 할 수 있다. HTTP L7 filter Architecture . Http는 현대 application architecture에서 중요하고 envoy는 이를 지원한다. buffering, rate limiting, routing/forwarding 등을 수행할 수 있다. HTTP L7 routing . path, authority, content type, runtime value 등에 따라 routing이나 redirectiong을 할 수 있는 routing을 지원한다. protocol support . HTTP/2에 대해 투명한 지원을 한다. HTTP/1.1과 HTTP/2를 조합하여 사용할수도 있다. gRPC를 지원한다. 현재 알파버전으로 HTTP/3도 지원하고 있다. Service discovery and dynamic configuration . 계층화된 dynamic configuration APIs를 사용한다. 이 layer는 envoy에 backend cluster, routing 등에 대해 dynmic update를 제공한다. Advanced load balancing . health check, automatic retries, circuit breaking, global rate limiting 등을 제공한다. ",
    "url": "/docs/apis/envoy/envoy#%EA%B8%B0%EB%8A%A5",
    
    "relUrl": "/docs/apis/envoy/envoy#기능"
  },"625": {
    "doc": "api gateway, envoy란?",
    "title": "Network topology",
    "content": "|   |   | . | service mesh | | . | internal load balancer | | . | ingress/egress proxy on the network edge | | . | multi-tier topologies | | . envoy는 service mesh의 sidecar proxy로 시작되었지만 다양한 network topology에서 사용될 수 있다. ",
    "url": "/docs/apis/envoy/envoy#network-topology",
    
    "relUrl": "/docs/apis/envoy/envoy#network-topology"
  },"626": {
    "doc": "api gateway, envoy란?",
    "title": "envoy architecture",
    "content": ". envoy는 listner와 cluster라는 2개의 main part로 이루어져 있다. | listener는 downstream request를 핸들링하고 lifecycle을 관리하는 책임이 있다. | cluster는 endpoint에 대한 upstream connection을 선택하고 구성하는 책임이 있다. | listner와 cluster는 HTTP router filter로 연결되어 있다. | filter는 listener로부터 받은 요청을 filtering, 조작, 인증 등을 거쳐 cluster로 routing 하는 역할을 한다. | . ",
    "url": "/docs/apis/envoy/envoy#envoy-architecture",
    
    "relUrl": "/docs/apis/envoy/envoy#envoy-architecture"
  },"627": {
    "doc": "api gateway, envoy란?",
    "title": "reference",
    "content": ". | https://www.envoyproxy.io/docs/envoy/latest/intro/what_is_envoy | https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request | . ",
    "url": "/docs/apis/envoy/envoy#reference",
    
    "relUrl": "/docs/apis/envoy/envoy#reference"
  },"628": {
    "doc": "api gateway, envoy란?",
    "title": "api gateway, envoy란?",
    "content": " ",
    "url": "/docs/apis/envoy/envoy",
    
    "relUrl": "/docs/apis/envoy/envoy"
  },"629": {
    "doc": "마이크로 서비스(MSA)란? 개념, 장단점과 방향성 이해하기",
    "title": "마이크로 서비스 (MSA, MicroService Architecture)",
    "content": "마이크로 서비스는 한 가지만 아주 잘 처리하자는게 기본 원칙이다. 그렇기 때문에 비즈니스 도메인을 중심으로 모델링된 여러 마이크로 서비스들이 나오게된다. 독립적으로 배포 가능한 서비스들이 네트워크로 서로 통신한다. ",
    "url": "/docs/design/msa#%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C-%EC%84%9C%EB%B9%84%EC%8A%A4-msa-microservice-architecture",
    
    "relUrl": "/docs/design/msa#마이크로-서비스-msa-microservice-architecture"
  },"630": {
    "doc": "마이크로 서비스(MSA)란? 개념, 장단점과 방향성 이해하기",
    "title": "마이크로 서비스의 특징",
    "content": ". | 독립적인 배포 가능성 | 느슨한 결합 | 자유로운 언어 선택 | 각 컴포넌트가 갖는 자체 데이터베이스 | 서비스 안전성과 유지보수성 | . 독립적인 배포 가능성을 위해 느슨한 결합과, 자체 데이터베이스가 요구된다. 독립적인 배포를 통해 언어에 구애받지 않게 되며, 서비스 유지보수에 용이하고 안전성을 얻을 수 있다. ",
    "url": "/docs/design/msa#%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C-%EC%84%9C%EB%B9%84%EC%8A%A4%EC%9D%98-%ED%8A%B9%EC%A7%95",
    
    "relUrl": "/docs/design/msa#마이크로-서비스의-특징"
  },"631": {
    "doc": "마이크로 서비스(MSA)란? 개념, 장단점과 방향성 이해하기",
    "title": "독립적인 배포 가능성 (Independent deployability)",
    "content": "다른 서비스를 활용하지 않고 마이크로서비스에 변경을 가하는 방식으로 서비스 환경에 배포할 수 있다는 개념이다. 서비스가 느슨하게 결합(loosely coupled) 되어 있음을 보증할 필요가 있고, 이를 위해 서비스간에 안정적인 계약이 필요하다. 인터페이스가 안정적이게 느슨하려면 서비스 경계를 찾아야한다. 그래서 도메인 중심의 모델링이 중요하다. 데이터 소유권 문제 . 몇몇 구현의 선택이 느슨한 결합 어렵게 만드는데 가장 자주 보이는 예시는 데이터베이스의 공유이다. 데이터 베이스 공유에 대한 원칙 . | 정말 필요한 경우가 아니라면 DB를 공유하지 말자. | 정말 필요해도 피할 수 있는 방법을 찾자. | . 어떤 이유로 변경될 수 있는 내부 구현 세부사항으로부터 안정적인 공개 계약으로 서비스를 매핑해야한다. 독립적 배포가능성에서는 안정적인 인터페이스가 필수이며 DB 공유는 독립적 배포 가능성을 위해할 수 있는 최악의 선택이다. 데이터를 보유한 서비스에 요청하는게 당연하다. 무엇을 공유하고 숨길지 결정해야하고, 이 인터페이스가 안정적으로 나와야 한다. 인터페이스가 바뀌면 사용하는 서비스들도 변경되어야 한다. 서비스와 데이터 소유권 . MSA는 아니지만 내가 개발하는 모듈에서 배치와 같은 작업으로 멀티 서비스 구조를 갖게 되었을 때 데이터베이스 공유 문제로 이슈가 된적이 있다. 우리는 서비스 서버와 서비스 서버에서 발생한 메시지를 처리하는 배치 서버에서 동일한 데이터베이스를 공유했다. 초기엔 편하게 서비스를 개발하고 유지했는데, 키와 스키마 변경, 데이터 베이스 변경 등의 이슈 때마다 배포 순서를 신경써야 했다. 한번은 서비스 서버의 데이터 반영이 배치 서버에 반영되지 않아 사용자 데이터를 유실할 뻔 하기도 했다. 그 이후로 개발하는 배치에선 데이터베이스 공유를 하지 않는 방향을 기본으로 한다. 데이터의 안정성과 데이터에 대한 책임을 하나의 서비스가 갖는 것이 중요하다. 이건 어떤 편의성이 있더라도 교환해선 안되는 문제이다. ",
    "url": "/docs/design/msa#%EB%8F%85%EB%A6%BD%EC%A0%81%EC%9D%B8-%EB%B0%B0%ED%8F%AC-%EA%B0%80%EB%8A%A5%EC%84%B1-independent-deployability",
    
    "relUrl": "/docs/design/msa#독립적인-배포-가능성-independent-deployability"
  },"632": {
    "doc": "마이크로 서비스(MSA)란? 개념, 장단점과 방향성 이해하기",
    "title": "마이크로 서비스의 장점",
    "content": ". | 독립적인 배포로 시스템 확장과 견고성 개선 . | 독립적인 배포는 각각의 서비스에 대한 자체적인 빌드, 배포, 테스트, 모니터링, 확장, 롤백이 가능하다. | . | 서비스의 병렬 개발(콘웨이의 법칙) | 맡은 부분에만 몰입해서 개발 | 다양한 기술적 선택 | 아키텍처적 유연성 | . 콘웨이의 법칙 . 시스템 구조는 그 시스템을 설계하는 조직의 통신 구조를 그대로 따라갈 수밖에 없다. - 콘웨이 . ‘조직의 통신 구조에 따라 제품을 만들게 된다.’는 현상이다. 모놀리스로 가게되면 모놀리스 구조의 큰 개발팀이 일해야 하는 구조가 되며, MSA로 가게되면 각각의 서비스 개발팀이 나뉘거나 독립적인 개발이 가능한 구조가 된다. 그런데 반대로 이미 만들어진 시스템 구조가 조직의 통신 구조에 영향을 미치기도 한다. 서비스와 팀이 아직 작을 때 모놀리스를 선택하게 되면 서비스와 팀이 커져서 팀을 나누게 될 때, 적절히 팀을 나눌 수가 없게 된다. 큰 모놀리스 서비스에서 업무 영역을 나누게 되면 커뮤니케이션 비용이 커질 수 밖에 없다. ",
    "url": "/docs/design/msa#%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C-%EC%84%9C%EB%B9%84%EC%8A%A4%EC%9D%98-%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/design/msa#마이크로-서비스의-장점"
  },"633": {
    "doc": "마이크로 서비스(MSA)란? 개념, 장단점과 방향성 이해하기",
    "title": "마이크로 서비스 단점",
    "content": ". | 복잡성 증가 . | 전체 시스템의 복잡성이 증가한다. | . | 테스트 및 디버깅 비용 증가 . | 여러 서비스를 관통하는 acceptance 테스트를 작성하기 더 어렵다. | 이슈 등으로 디버깅이 필요한 경우에도 동일하다. | . | 네트워크를 사용하는 대기시간 . | 각 서비스를 거치기 때문에 아무리 효율적인 기술들(grpc 등)을 사용한다 하더라도 모놀리스에 비해 대기시간이 길어질 수 밖에 없다. | . | 예측할 수 없는 통신 문제 . | 서비스 통신, 네트워크, 서비스 다운 등의 문제에 대한 각각 서비스의 대응을 설계해야 한다. | . | . ",
    "url": "/docs/design/msa#%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C-%EC%84%9C%EB%B9%84%EC%8A%A4-%EB%8B%A8%EC%A0%90",
    
    "relUrl": "/docs/design/msa#마이크로-서비스-단점"
  },"634": {
    "doc": "마이크로 서비스(MSA)란? 개념, 장단점과 방향성 이해하기",
    "title": "결합도와 응집력",
    "content": "서비스는 응집력이 높고 결합도가 낮아야한다. 결합도와 응집력을 이해하는게 중요하다. | 결합도는 한가지를 바꾸면 다른 것도 바꿀 필요가 있는 방식. | 응집력은 관련된 코드를 그룹으러 묶는 방식. | . 구현 결합도 (implementation coupling) . 가장 위험한 형태의 결합도지만 가장 쉽게 결합도를 낮출 수 있다. 위에서 예를 들었던 DB의 공유가 구현 결합도의 가장 고전적인 예시이다. DB를 공유하면 스키마 구조, 쿼리, 행의 내용까지 모두 결합된다. | 인터페이스를 두고 해당 서비스에 요청하는 방식으로 결합을 낮춘다. | . 시간적 결합도 (temporal couping) . 메세지가 전송되는 시점과 메세지가 처리되는 방식이 시간과 관련되어 있는 경우에 대한 결합도이다. | 캐싱등의 해결책이 있을 수 있다. | . 배포 결합도 (deployment coupling) . 배포 결합도가 높은 서비스의 예를 들면 모놀리스이다. 모놀리스에서는 한 곳의 변경으로 전체 배포가 필요하다. | 배포에는 위험이 따르고 위험을 줄이는 방식으로 마이크로 서비스로 배포 결합도를 낮출 수 있다. | . 도메인 결합도 (domain coupling) . 마이크로 서비스에서는 상호작용이 있기 때문에 도메인 결합도는 당연하다. 주문하려면 고객 주문 정보를, 배송하려면 고객 주소 정보를 알아야 한다. 마이크로 서비스에서는 이런 정보들이 각각 다른 마이크로 서비스에 있게되며 필요한 도메인만 사용하는 방식으로 도메인 결합도를 낮춘다. | 꼭 알지 않아도 되는 도메인은 메세지에 보내어 서비스에서 직접 도메인을 알지 않도록 결합도를 낮출수도 있다. | . ",
    "url": "/docs/design/msa#%EA%B2%B0%ED%95%A9%EB%8F%84%EC%99%80-%EC%9D%91%EC%A7%91%EB%A0%A5",
    
    "relUrl": "/docs/design/msa#결합도와-응집력"
  },"635": {
    "doc": "마이크로 서비스(MSA)란? 개념, 장단점과 방향성 이해하기",
    "title": "MSA의 방향",
    "content": "가능한 작은 인터페이스를 유지하는 것이 좋다. 그러나 처음 MSA를 한다면 규모를 작게하기 보단 작게 만들 수 있는 방향으로 모델링하되 컴포넌트의 개수를 너무 작지 않게 가져간다. 그리고 점진적으로 컴포넌트를 늘려갈 수 있도록 한다. ",
    "url": "/docs/design/msa#msa%EC%9D%98-%EB%B0%A9%ED%96%A5",
    
    "relUrl": "/docs/design/msa#msa의-방향"
  },"636": {
    "doc": "마이크로 서비스(MSA)란? 개념, 장단점과 방향성 이해하기",
    "title": "reference",
    "content": ". | 마이크로서비스 도입, 이렇게 한다 1장, 샘 뉴먼 | 마이크로 서비스 아키텍처 1장, 우메쉬 램 샤르마 | . ",
    "url": "/docs/design/msa#reference",
    
    "relUrl": "/docs/design/msa#reference"
  },"637": {
    "doc": "마이크로 서비스(MSA)란? 개념, 장단점과 방향성 이해하기",
    "title": "마이크로 서비스(MSA)란? 개념, 장단점과 방향성 이해하기",
    "content": " ",
    "url": "/docs/design/msa",
    
    "relUrl": "/docs/design/msa"
  },"638": {
    "doc": "이벤트 기반 아키텍처(EDA)란? MSA의 문제점과 EDA의 해결책",
    "title": "이벤트 기반 아키텍처 (EDA, Event Driven Architecture)",
    "content": "The world is Asynchronous - AWS re:Invent 2022 . 애플리케이션이 클라우드 네이티브거나 대규모 분산 환경에서 돌아가면서 메세징을 사용하지 않는다면 버그일 가능성이 높다. - Tim Bray . 실제 세계는 async하게 돌아가고 있고, 이렇게 모델링을 하면 더욱 느슨한 결합을 유지할 수 있다. 마이크로 서비스에서 더 느슨한 결합을 갖기 위해 진화된 architecture. ",
    "url": "/docs/design/eda#%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EA%B8%B0%EB%B0%98-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-eda-event-driven-architecture",
    
    "relUrl": "/docs/design/eda#이벤트-기반-아키텍처-eda-event-driven-architecture"
  },"639": {
    "doc": "이벤트 기반 아키텍처(EDA)란? MSA의 문제점과 EDA의 해결책",
    "title": "특징",
    "content": "EDA는 시스템이 이벤트를 생산/소비 하는 방식으로 서로 통신한다. 소비된 이벤트는 바로 사라지지 않고 같은 메세지를 필요로하는 다른 컨슈머도 가져갈 수 있다. MSA에서 EDA로 나가는 이유는 더 느슨한 결합을 위해서이다. MSA에 event를 도입하면 마이크로 서비스간에 coupling을 없앨 수 있기 때문에 신규 서비스의 확장에 열려있는 구조이다. | sender와 receiver를 추상화 | 응답성 향상 및 종속성 감소 | 서비스를 사용할 수 있을 때까지 메세지를 버퍼링 | . ",
    "url": "/docs/design/eda#%ED%8A%B9%EC%A7%95",
    
    "relUrl": "/docs/design/eda#특징"
  },"640": {
    "doc": "이벤트 기반 아키텍처(EDA)란? MSA의 문제점과 EDA의 해결책",
    "title": "Monolithic vs MSA vs EDA",
    "content": "| 특징 | Monolithic | MSA | EDA | . | 서비스 구조 | 단일 서비스 | 독립적인 서비스 | 독립적인 서비스 | . | 통신 방식 | 프로세스 내 동기/비동기 | 프로세스 간 동기/비동기 | 프로세스 간 비동기 이벤트 | . | 코드베이스 | 단일 코드베이스 | 서비스별 독립 코드베이스 | 서비스별 독립 코드베이스 | . | 데이터베이스 | 단일 데이터베이스 | 서비스별 독립 데이터베이스 | 서비스별 독립 데이터베이스 | . | 배포 및 확장성 | 전체 서비스 배포/확장 | 서비스별 배포/확장 | 서비스별 배포/확장 | . | 운영 복잡성 | 낮음 | 높음 | 높음 | . | 기능 추가 및 수정 복잡성 | 높음 | 낮음 | 낮음 | . | 의존성 | 강하게 결합된 의존성 | 느슨하게 결합된 의존성 | 더 느슨하게 결합된 의존성 | . | 장애 영향도 | 특정 컴포넌트 실패 시 전체 애플리케이션 중단 가능 | 컴포넌트 분리로 장애 격리 | 느슨한 결합으로 더 나은 장애 격리 | . | 기술 스택 | 단일 기술 스택 | 다양한 기술 스택 | 다양한 기술 스택 | . ",
    "url": "/docs/design/eda#monolithic-vs-msa-vs-eda",
    
    "relUrl": "/docs/design/eda#monolithic-vs-msa-vs-eda"
  },"641": {
    "doc": "이벤트 기반 아키텍처(EDA)란? MSA의 문제점과 EDA의 해결책",
    "title": "synchronous MSA의 문제와 EDA의 해결책",
    "content": "synchoronous 마이크로 서비스의 문제는 asynchoronous EDA의 장점이기도 하다. 결합도 . 자신이 할 일을 다른 서비스에 의존한다. 의존관계가 꼬리에 꼬리를 물면 나중에 어느 서비스가 어떤 로직을 담당하는지 파악하기가 어렵다. synchoronous MSA는 implementation coupling은 없지만 temporal coupling을 가지고 있는 구조이다. EDA는 event를 통해 temporal coupling까지 끊어낸다. sender는 event를 발행하고 client에 바로 응답을 줄 수 있으므로 client 응답이 빨라지고 사용자 경험을 좋게 만들 수 있다. 부하와 의존성 확장 . 한 서비스의 확장 가능 여부를 확인할 때 해당 서비스가 의존하는 다른 서비스들이 확장 가능한지 확인해야 한다. 부하가 늘거나 병목이 생기는 경우 장애가 되며 이를 서비스 운영중에 고려해야 한다. EDA의 경우 늘어난 호출이 sender나 receiver에게 병목 등의 이슈로 장애가 되지 않는다. receiver가 consumption 비율을 조절할 수 있다. 장애의 전파와 장애 처리 . synchronous의 경우 장애가 전파된다. 전파되는 장애가 문제가 생기기도 하고 이를 위해 circuit breaker 같은 패턴을 사용할수도 있다. 더 중요한 문제는 실패로 인한 정합성을 위해 실패시 어떻게 처리할지를 정의해야하는데 서비스가 많을수록 복잡하다. EDA의 경우 장애가 전파되지 않는다. 장애로 인한 복구도 해당 event 단위로 복구할 수 있다. 분산 모놀리스 . 서비스가 분산 모놀리스처럼 동작하도록 조합돼서 서비스간 호출이 얽히고 설킨다. 느슨한 결합을 위한 마이크로 서비스이지만 synchronous 이기 때문에 결합이 유지되며 어떤 경우엔 더 복잡하다. EDA의 경우 별개의 event이기 때문에 호출이 명확하다. 그치만 디버깅을 위해서라면 조금 더 헷갈릴 수 있다. ",
    "url": "/docs/design/eda#synchronous-msa%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%99%80-eda%EC%9D%98-%ED%95%B4%EA%B2%B0%EC%B1%85",
    
    "relUrl": "/docs/design/eda#synchronous-msa의-문제와-eda의-해결책"
  },"642": {
    "doc": "이벤트 기반 아키텍처(EDA)란? MSA의 문제점과 EDA의 해결책",
    "title": "EDA에서 고려해야할 점",
    "content": "synchronous MSA의 장점이기도 하다. | 직접 요청 &amp; 응답이 필요한 유즈케이스에선 적절하지 않음 | 네트워크 지연시간 | 보다 더 어려운 구조 | 여러 서비스에 걸친 추적이 용이 | 디버깅과 가시성이 더 좋음 | . ",
    "url": "/docs/design/eda#eda%EC%97%90%EC%84%9C-%EA%B3%A0%EB%A0%A4%ED%95%B4%EC%95%BC%ED%95%A0-%EC%A0%90",
    
    "relUrl": "/docs/design/eda#eda에서-고려해야할-점"
  },"643": {
    "doc": "이벤트 기반 아키텍처(EDA)란? MSA의 문제점과 EDA의 해결책",
    "title": "reference",
    "content": ". | AWS re:Invent 2022 - Keynote with Dr. Werner Vogels | 이벤트 기반 마이크로서비스 구축: 대규모 조직 데이터를 활용하는 기법 1장 | . ",
    "url": "/docs/design/eda#reference",
    
    "relUrl": "/docs/design/eda#reference"
  },"644": {
    "doc": "이벤트 기반 아키텍처(EDA)란? MSA의 문제점과 EDA의 해결책",
    "title": "이벤트 기반 아키텍처(EDA)란? MSA의 문제점과 EDA의 해결책",
    "content": " ",
    "url": "/docs/design/eda",
    
    "relUrl": "/docs/design/eda"
  },"645": {
    "doc": "서버 개발자, 2023 회고",
    "title": "팀 문화 리딩하기",
    "content": "올해는 팀을 옮긴 후 팀의 문화를 만드는데 시간을 많이 쏟은 해였다. 팀 문화가 무너지고 정체된 팀에 문화를 만들자며 파트 리더가 나를 현재 팀으로 보냈다. 연간 회고를 하며 작년 회고를 봤을 때, 이전 팀은 팀 문화를 참 잘 만들어가던 팀이었구나 느낀다. 파트 리더는 ‘문화를 같이 잘 만들어 가는 것과 없는 곳에서 문화를 만드는 것은 다르다’고 ‘문화에 적응하는 사람이 있고 이끄는 사람이 있다. 이끌길 바란다’며 문화가 없는 곳에서 만들 수 있는 경험은 값진 경험이라고 하시며 나를 보냈다. 처음 팀에 와서 팀 문화를 보곤 조금은 착잡했는데 한 해를 돌아보면 나한테는 팀 문화를 리딩해보는 경험을 해보는 해가 됐던 것 같다. 리뷰 문화 만들기 . 처음 팀에 왔을땐 개발팀의 기본이라고 생각하는 리뷰 문화조차 제대로 되지 않아 착잡했다. 때문에 내 첫 목표는 리뷰 문화를 만드는 것이었는데 이런건 글로 정리하기 어렵지만 대강 이렇다. | 리뷰 속도와 리뷰의 질에 대한 (수 차례의) 논의 및 회고 | 리뷰 그라운드 룰 세우기 | 운영, 개발, 문서까지 리뷰하기 | . 의사소통 개선하기 . 생각보다 어떤 무언가를 한다기보단 의사소통을 개선하는데 꾸준히 노력한 것 같다. 슬랙을 통한 의사소통을 더 많이하도록 유도했고, 의사소통에 리액션을 강제?하여 슬랙 리액션을 꼭 달도록 했다. 업무 중에 small talk을 계속해서 팀 분위기도 챙기려고 했는데 사실 이건 내 스타일인 것 같기도하고. 생각보다 더 팀원들 사이의 생각이 달랐다. 더해서 ‘안전감’에 대해 회고 시간에 자주 이야기 했는데, 이런 이야기를 한 명 한 명 들어가면서 생각들을 더 잘 얘기할 수 있는 팀이 되었다. 물론 아직은 부족하지만. 스프린트 . 내가 올해 만든 팀 문화 중 가장 중요한거라면 스프린트를 바꾼 것 같다. 처음 우리팀은 팀 리더가 일을 나누면 각자 알아서 일을 하다가 끝나면 공유했는데, 어떤 팀원은 한 주 내내 혼자 일을 하고 리뷰를 올리기도 했다. 리더를 멤버들이 돌아가면서 하기로 정하고 스프린트 주기, 회의 방식, 문서화, 회고, 스토리 포인트 단위의 추정과 일을 쪼개고 나누는 방식들을 도입했다. 물론 하나씩 차근차근. 개발보다 문화를 바꾸는게 더 어렵다는 생각도 드는데, 내가 답답하게 일할 수 없다보니 방식을 하나씩 바꾸게 됐다. 내가 실질적으로 팀을 이끄는 리더는 아니면서 문화는 내가 바꿔가야 했기 때문에 내 생각보다 더디게 진행되긴 했는데, 우리 팀 리더는 팀 문화에 대한 제안을 드리면 ‘뭐든지 okay’로 답을 주셔서 좋았다. 주변에서 나와 비슷한 상황에서 ‘뭐든지 현재대로’를 원하시는 리더로 고생하는 분도 보았기 때문에 리더가 중요하다는 것을 다시 느꼈다. 팀 문화를 바꾸면서 느낀건 생각보다 ‘좋은 팀’을 만드는데는 시간이 제법 걸린다는 것이다. 내가 시도한 많은 것들이 우리 팀을 더 좋게 만들었지만, 아직 내가 원하는 좋은 팀이 되기까지 가야할 길은 좀 남은 것 같다. ",
    "url": "/docs/retrospect/2023#%ED%8C%80-%EB%AC%B8%ED%99%94-%EB%A6%AC%EB%94%A9%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/retrospect/2023#팀-문화-리딩하기"
  },"646": {
    "doc": "서버 개발자, 2023 회고",
    "title": "새로운 서비스",
    "content": "팀을 옮긴게 처음은 아니지만 동기화 서버 개발자로 구르다가 백업 서버를 담당하게 되었다. 이직을 생각해볼 때 ‘내가 팀을 옮기게 되면 업무를 따라가는데 얼마나 걸릴까?’라는 생각을 종종 했었다. 연간 회고를 준비하면서 최근 설계를 떠올려보면 질문을 하기보단 대부분 설명을 해주고 있는 모습을 볼 때 ‘내가 생각보다 깊이있게 프로젝트를 이해하는데 시간이 오래걸리지 않는구나’를 느꼈다. 동기화 서버에서 백업 서버를 맡게되면서 했던 사내 부검과 회고 내용 중 하나는 ‘나는 동기화 서버 개발에 있어서는 프로였다’라는 말이었는데, 이제는 내 도메인이 동기화에서 백업까지 확장된 것 같다. 백업이랑 동기화는 비슷하면서도 다른 정책들이 있었는데, 이건 나중에 백업 서비스를 회고하면서 적어봐야겠다. 아쉬운 점은 백업이 아닌 gRPC를 비롯한 내가 사용해보지 않은 기술들을 사용하는 새로운 서비스를 경험해보고 싶었는데, 백업 서비스의 요구사항이 많아서 다른 서비스를 하지 못했다. ",
    "url": "/docs/retrospect/2023#%EC%83%88%EB%A1%9C%EC%9A%B4-%EC%84%9C%EB%B9%84%EC%8A%A4",
    
    "relUrl": "/docs/retrospect/2023#새로운-서비스"
  },"647": {
    "doc": "서버 개발자, 2023 회고",
    "title": "리팩토링",
    "content": "리팩토링이야 매일같이 하는거지만 올해는 리팩토링에 대해 다시 생각해봤다. 새로 맡은 서비스는 워낙 레거시 코드가 많아서 손댈 부분이 많았는데, 각잡고 리팩토링을 한 시간도 많았지만 기존 코드를 손대는 모든 작업에서 리팩토링을 꼭 했던 것 같다. 대규모 리팩토링은 이전 팀에서 너무 많이 해서 나한텐 재미없는 작업으로 느껴졌다. 파트 리더께서 조금 더 리팩토링에 대해 탄탄하게 정리해보자는 코멘트를 주셨고 리팩토링에 대한 생각들을 정리할 수 있는 시간들이 된 것 같다. 복합 리팩토링 . 피쳐 개발에 맞춰 code smell을 해결하는 리팩토링이 아니라 프로젝트의 넓은 범위에 영향을 미치는 리팩토링에 대해 마틴 파울러는 ‘복합 리팩토링(big refactoring)’이라는 표현을 사용한다. 리팩토링은 대부분이 리팩토링의 기법들에 대한 내용들이어서 기법이 아니라 복합 리팩토링에서 해야할 작업들에 대한 생각을 정리했다. 다양한 종류의 사용하지 않는 코드 제거에도 시간을 쓰고 이런 종류의 코드도 제거가 되어야 좋다는 생각을 할 수 있었다. 비용을 고려한 리팩토링 . 복합 리팩토링을 하면서는 키 설계나 메세지 전달 방식까지 다시 설계하게 되기도 한다. 올해는 내가 이런 설계에서 비용을 고려해보기 시작했다는 점에서 새롭다. 하루 수십억 단위의 api call 규모의 서비스를 담당하다보니, 모듈 사이에 SQS를 놓을까를 고민하다가 비용을 계산하니 SQS 추가 하나만으로 연간 억 단위가 되어 설계를 변경하기도 했고, 다른 팀원이 제안한 아이디어에 대해 반대하기 위한 근거 중 하나로 아이디어 적용시 추가되는 수십억 단위의 S3 비용을 계산해서 제시하기도 했다. 이전에도 비용을 고려하긴 했으나 자연스럽게 비용을 근거로 설계를 제시하고 반대했던 모습들을 떠올리면 내가 리팩토링과 설계에 있어서 조금 더 성장했나 하는 생각이 든다. MSA . feature를 바쁘게 추가하면서 진행해온 작업들을 돌아봤을 때, 거대한 모놀리스인 우리 서비스를 조금이나마 분리할 수 있는 기회들을 내가 놓쳤다는 생각을 했다. 한 선배와 MSA에 대해 이야기 했는데 한 해를 돌아봤을 때 ‘아 이거 MSA’면 좋았을텐데 싶은 생각들이 드는 것들이 있다. 특히나 하반기에 읽은 마이크로 서비스 도입 이렇게 한다를 생각해봤을 때 점진적으로 MSA로 갔으면 좋았을텐데 하는 후회가 든다. 지금 팀에선 설계를 내가 많이 맡고 있는데, 내가 연초에 MSA의 장점과 모놀리스에서 MSA로 전환하는 방식들에 대해 제대로 이해하지 못했기 때문에 이런 설계를 내지 못했다는 생각이 들어 아쉽다. ",
    "url": "/docs/retrospect/2023#%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81",
    
    "relUrl": "/docs/retrospect/2023#리팩토링"
  },"648": {
    "doc": "서버 개발자, 2023 회고",
    "title": "연사",
    "content": "올해 기회가 되어 슬랙 자동화 봇을 주제로 두 차례의 연사로 설 수 있었다. | 코엑스에서 열린 salesforce live korea | slack 관계사들을 대상으로하는 slack champion day | . 재밌고 새로운 경험들을 해볼 수 있는 시간이어서 좋았고, 이런 기회들을 더 잘 만들어갈 수 있었으면 좋겠다는 생각이 든다. 올해는 리더에 대해서 생각해볼 시간들이 많았다. 팀을 재배치하고 면담을 통해 동기부여를 하는 파트리더의 역할에 대해서 먼저 생각했고. 이전 팀 리더, 현재 팀 리더와 다른 팀 리더의 태도들로 만들어지는 팀의 분위기를 내가 더 잘 볼 수 있는 위치가 된 것 같다. 그리고 팀 문화와 회의, 설계를 주도하다보니 리더의 모습에 대해서도 더 생각하게 됐다. 새로운 경험들을 많이 하게된 해였다. 두 차례의 연사 경험, 새로운 팀으로 옮겨와서 맡게된 새로운 역할들. 기대한 새로운 기술들에 대한 개발 경험을 갖지 못한게 아쉽지만 새로운 역할들을 잘 소화해낸 것 같다. 작은 팀이지만 팀 문화와 설계를 주도하는 자리에서 일을 해본게 재밌었다. 생각보다 잘 맞는 것 같기도 하고. ",
    "url": "/docs/retrospect/2023#%EC%97%B0%EC%82%AC",
    
    "relUrl": "/docs/retrospect/2023#연사"
  },"649": {
    "doc": "서버 개발자, 2023 회고",
    "title": "서버 개발자, 2023 회고",
    "content": "23년은 새로운 팀으로 옮기며 내 능력들을 테스트해볼 수 있는 시간이었다. 한 해를 돌아보니 생각보다 새롭게 경험한 일들이 많다. 그럼에도 돌아보면 아쉬운 것들도 많고. ",
    "url": "/docs/retrospect/2023",
    
    "relUrl": "/docs/retrospect/2023"
  },"650": {
    "doc": "DDD의 기둥 Ubiquitous Language",
    "title": "유비쿼터스, Ubiquitous",
    "content": "유비쿼터스라는 단어는 ‘어디에나 있다. 아주 흔하다’ 라는 말을 의미한다. ",
    "url": "/docs/ddd/strategic/ubiquitous#%EC%9C%A0%EB%B9%84%EC%BF%BC%ED%84%B0%EC%8A%A4-ubiquitous",
    
    "relUrl": "/docs/ddd/strategic/ubiquitous#유비쿼터스-ubiquitous"
  },"651": {
    "doc": "DDD의 기둥 Ubiquitous Language",
    "title": "유비쿼터스 언어",
    "content": "유비쿼터스 언어의 의미도 어디에서나 발견되는 언어라는 의미이다. 그러나 유비쿼터스 언어는 팀 내에 공유된 언어로 팀 내에서 어디에서나 발견되는 언어라고 보는 것이 정확하다. DDD의 개념은 실제 도메인 모델을 코드에 녹이는 것이기 때문에 도메인의 용어(유비쿼터스 언어)들이 정의되는 것이 중요하기 때문이다. 따라서 유비쿼터스 언어는 도메인 전문가와 개발자 모두 공유하는 언어이며, 뿐만 아니라 실제로 해당 프로젝트에 참여하는 모든 사람들이 공유하는 언어이다. 팀 내에서 무슨 역할을 맡더라도 프로젝트에 참여하고 있다면 해당 프로젝트의 유비쿼터스 언어를 사용하게 된다. ",
    "url": "/docs/ddd/strategic/ubiquitous#%EC%9C%A0%EB%B9%84%EC%BF%BC%ED%84%B0%EC%8A%A4-%EC%96%B8%EC%96%B4",
    
    "relUrl": "/docs/ddd/strategic/ubiquitous#유비쿼터스-언어"
  },"652": {
    "doc": "DDD의 기둥 Ubiquitous Language",
    "title": "유비쿼터스 언어의 필요성",
    "content": "도메인에 맞는 소프트웨어를 만들려면 도메인을 설명할 수 있는 방법이 필요하다. 모델과 모델들의 관계, 이벤트, 비즈니스, 모델의 변화를 설명할 수 있는 방법들이 필요하다. 이런 설명을 함께 일관되게 사용하기 위해 필요한 것이 유비쿼터스 언어이다. 유비쿼터스 언어를 사용해 비즈니스 개념이나 프로세스를 쉽게 설명할 수 있다면 올바른 방향으로 언어를 결정해나가고 있다고 볼 수 있다. 반대로 설명에 어려움을 느낀다면 무언가 놓치고 있을 가능성이 높다. ",
    "url": "/docs/ddd/strategic/ubiquitous#%EC%9C%A0%EB%B9%84%EC%BF%BC%ED%84%B0%EC%8A%A4-%EC%96%B8%EC%96%B4%EC%9D%98-%ED%95%84%EC%9A%94%EC%84%B1",
    
    "relUrl": "/docs/ddd/strategic/ubiquitous#유비쿼터스-언어의-필요성"
  },"653": {
    "doc": "DDD의 기둥 Ubiquitous Language",
    "title": "유비쿼터스 언어의 특징",
    "content": "유비쿼터스 언어는 팀에 의해 쓰이는 명사, 형용사, 동사, 등의 풍부한 표현을 포함한다. 팀이 사용하는 모든 문서, 소프트웨어, 테스트는 이 언어를 담고 있으며 이 언어에 맞춰진다. 1. 의사소통 . 팀 내에서 사용하는 용어와 비즈니스 용어를 일치시키고 소프트웨어 모델에 반영한다. 개발자, 비즈니스 전문가를 포함한 모든 팀원들이 동일한 언어로 의사소통할 수 있다. 2. 비즈니스 이해 . 개발자들이 비즈니스 전문가와 의사소통하며 비즈니스를 이해하는 속도가 향상된다. 비즈니스 도메인을 더 깊이 이해할 수 있다. 3. 도메인 복잡성 해결 . 유비쿼터스 언어로 생성한 도메인 모델을 통한 추상화로 복잡한 도메인을 더 이해하기 쉽게 만든다. 역할이 비즈니스 로직에 맞게 명확하게 분리됨을 통해 복잡성이 줄고 이해관계자 간의 이해도를 맞출 수 있다. ",
    "url": "/docs/ddd/strategic/ubiquitous#%EC%9C%A0%EB%B9%84%EC%BF%BC%ED%84%B0%EC%8A%A4-%EC%96%B8%EC%96%B4%EC%9D%98-%ED%8A%B9%EC%A7%95",
    
    "relUrl": "/docs/ddd/strategic/ubiquitous#유비쿼터스-언어의-특징"
  },"654": {
    "doc": "DDD의 기둥 Ubiquitous Language",
    "title": "유비쿼터스 언어를 어떻게 만들까",
    "content": ". | 물리적이고 개념적인 도메인 그림을 그리고 이름과 행동을 붙여보기 | 간단한 정의로 구성된 용어집 만들기 . | 맘에 들지 않더라도 용어집 쓰기. 용어집을 씀으로써 추가적인 용어와 구문을 언어로 끄집어낼 수 있다. | . | 일부 팀원이 작성했다면 만들어진 구문을 리뷰하고 동의하지 못하는 경우가 많으므로 변경이 발생하더라도 대응할 수 있게 준비하기 | . 유비쿼터스 언어를 만드는 것은 도메인 모델을 만드는 것과도 관련이 있다. 도메인 모델을 만들 때 프로젝트를 위해 가장 좋은 언어를 완성하기 위해 합의와 타협을 거치며 토론하고 논쟁한다. 때로는 흥정할 수도 있다. 기존 문서의 참고, 비즈니스 지식의 공유, 기술 표준, 어학 사전들을 참조하는 과정도 지난다. 가장 좋은 개념과 용어와 의미가 무엇인지에만 초점을 맞춘다. ",
    "url": "/docs/ddd/strategic/ubiquitous#%EC%9C%A0%EB%B9%84%EC%BF%BC%ED%84%B0%EC%8A%A4-%EC%96%B8%EC%96%B4%EB%A5%BC-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EA%B9%8C",
    
    "relUrl": "/docs/ddd/strategic/ubiquitous#유비쿼터스-언어를-어떻게-만들까"
  },"655": {
    "doc": "DDD의 기둥 Ubiquitous Language",
    "title": "유비쿼터스 언어 주의사항",
    "content": "보편적으로 사용되고 흔히 보이는 유비쿼터스 언어라는 의미가 엔터프라이즈 전체나 전사적인, 혹은 세계적이거나 보편적인 도메인 언어라는 의미는 아니다. 컨텍스트는 생각보다 작고, 컨텍스트 당 하나의 유비쿼터스 언어가 있다. 유비쿼터스 언어는 바운디드 컨텍스트를 격리시키고 그 안에서 프로젝트를 진행하는 팀 내에서만 유비쿼터스하다. 그러므로 전체 엔터프라이즈나 다른 팀 같이 넓은 범위에서 유비쿼터스 언어를 적용하려고 하면 성공할 수 없고 적절하지 않다. 격리된 컨텍스트 상에서 합의된 유비쿼터스 언어가 아닌 모든 개념을 거부하라. 라고 표현하는데, 이는 모든 도메인 용어들을 합의한 유비쿼터스 언어로 만들자는 말과 동시에 다른 컨텍스트의 유비쿼터스 언어가 합의 없이 침범할 수 없음을 의미한다. ",
    "url": "/docs/ddd/strategic/ubiquitous#%EC%9C%A0%EB%B9%84%EC%BF%BC%ED%84%B0%EC%8A%A4-%EC%96%B8%EC%96%B4-%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD",
    
    "relUrl": "/docs/ddd/strategic/ubiquitous#유비쿼터스-언어-주의사항"
  },"656": {
    "doc": "DDD의 기둥 Ubiquitous Language",
    "title": "유비쿼터스 언어의 변화",
    "content": "언어는 시간이 지남에 따라 크고 작은 변화를 겪으면서 확장되고 변화한다. 언어처럼 유비쿼터스 언어도 성장하고 변화한다. 그렇기 때문에 처음 유비쿼터스 언어를 만드는데 영감을 주었던 결과물들은 시간이 지나면서 쓸모 없어질 가능성이 매우 크다. 그렇기 때문에 결국 유비쿼터스 언어가 가장 지속적으로 유지되고 보장되는 것은 팀원간의 이야기와 코드상의 모델이다. 팀원간의 이야기와 코드가 유비쿼터스 언어의 영속적인 발현이기 때문에 이야기 속의 유비쿼터스 언어에 맞춰 결과물들(그림, 용어집 등의 문서)를 업데이트하기 어렵다면 버릴 수 있어야 한다. 모든 문서를 최신으로 동기화하는 것이 현실적으로 어렵기 때문에 이편이 실용적이며 죄책감을 느낄 필요가 없다. ",
    "url": "/docs/ddd/strategic/ubiquitous#%EC%9C%A0%EB%B9%84%EC%BF%BC%ED%84%B0%EC%8A%A4-%EC%96%B8%EC%96%B4%EC%9D%98-%EB%B3%80%ED%99%94",
    
    "relUrl": "/docs/ddd/strategic/ubiquitous#유비쿼터스-언어의-변화"
  },"657": {
    "doc": "DDD의 기둥 Ubiquitous Language",
    "title": "코드레벨에서의 유비쿼터스 언어",
    "content": "| Possible Viewpoints | Result Code | . | “Who cares? Just code it up.” Um, not even close. | patient.setShotType(ShotTypes.TYPE_FLU); patient.setDose (dose); patient.setNurse(nurse); | . | “We give flu shots to patients.” Better, but misses some important concepts. | patient.giveFlushot(); | . | “Nurses administer flu vaccines to patients in standard doses.” This seems like what we’d like to run with at this time, at least until we learn more. | Vaccine vaccine = vaccines.standardAdultFluDose(); nurse.administerFluVaccine(patient, vaccine); | . 유비쿼터스 언어를 코드레벨에서 적용하는 생각들에 많이 미흡했던 것 같다. 나는 보통 유비쿼터스 언어를 뽑아서 도메인 모델을 만드는데 의의를 많이 뒀었는데, 이번에 다시 Vaughn Vernon의 책을 읽으면서 느낀건 위처럼 코드레벨에서 유비쿼터스 언어를 더 고민할 필요가 있다는 것. reference . | Implement Domain Driven Design, Vaughn Vernon | https://vaadin.com/blog/ddd-part-1-strategic-domain-driven-design | . ",
    "url": "/docs/ddd/strategic/ubiquitous#%EC%BD%94%EB%93%9C%EB%A0%88%EB%B2%A8%EC%97%90%EC%84%9C%EC%9D%98-%EC%9C%A0%EB%B9%84%EC%BF%BC%ED%84%B0%EC%8A%A4-%EC%96%B8%EC%96%B4",
    
    "relUrl": "/docs/ddd/strategic/ubiquitous#코드레벨에서의-유비쿼터스-언어"
  },"658": {
    "doc": "DDD의 기둥 Ubiquitous Language",
    "title": "DDD의 기둥 Ubiquitous Language",
    "content": "It’s one of the two primary pillars of DDD’s strengths. - Vaughn Vernon . Vaughn Vernon의 말처럼 유비쿼터스 언어는 DDD의 가장 강력한 요소 중 하나이며 DDD에서 절대 빠질 수 없는 개념이다. ",
    "url": "/docs/ddd/strategic/ubiquitous",
    
    "relUrl": "/docs/ddd/strategic/ubiquitous"
  },"659": {
    "doc": "kafka 아키텍처 이해하기",
    "title": "메시지 (message)",
    "content": "레코드라고도 부르는 메시지는 카프카를 통해 흐르는 데이터의 기본 요소이다. 메시지는 timestamp, value 그리고 선택적으로 key를 갖는다. 원한다면 custom header를 사용할 수도 있다. key와 value는 각각의 serialize, deserialize를 위해 카프카 특유의 방식으로 상호작용할 수 있다. 메시지가 있다면 브로커에게 메시지를 보내야 한다. ",
    "url": "/docs/message-broker/kafka/architecture#%EB%A9%94%EC%8B%9C%EC%A7%80-message",
    
    "relUrl": "/docs/message-broker/kafka/architecture#메시지-message"
  },"660": {
    "doc": "kafka 아키텍처 이해하기",
    "title": "카프카 아키텍처",
    "content": "| 컴포넌트 | 역할 | . | Producer | 카프카로 메시지를 보낸다 | . | Consumer | 카프카에서 메시지를 조회한다 | . | Topics | 메시지를 브로커에 저장하기 위한 논리적인 이름 | . | ZooKeeper ensemble | 클러스터에서 consensus를 유지하도록 돕는다 | . | Broker | 커밋 로그를 처리한다 (메시지를 disk에 저장한다) | . ",
    "url": "/docs/message-broker/kafka/architecture#%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98",
    
    "relUrl": "/docs/message-broker/kafka/architecture#카프카-아키텍처"
  },"661": {
    "doc": "kafka 아키텍처 이해하기",
    "title": "Producer &amp; Consumer",
    "content": ". Producer는 메시지를 카프카 topic으로 보내는 도구이다. default producer는 없으나 API, Flume, Connect, Streams 등이 사용될 수 있다. Consumer는 카프카에서 메시지를 검색하는 도구다. consumer는 topic을 구독하고 지속적으로 메시지를 polling 한다. ",
    "url": "/docs/message-broker/kafka/architecture#producer--consumer",
    
    "relUrl": "/docs/message-broker/kafka/architecture#producer--consumer"
  },"662": {
    "doc": "kafka 아키텍처 이해하기",
    "title": "Topic",
    "content": "Topic은 Partition이라는 단위로 구성된다. 즉 1개 이상의 partition이 단일 Topic을 구성한다. 카프카의 실제 작업은 대부분 disk에 실제로 구현되는 partition이다. partition replica 중 하나는 leader가 된다. 예시 . 파티션 3개로 된 토픽이 있고, 각 파티션은 3개의 replica를 갖고 있다. 모든 파티션은 각각 leader replica를 선출했을 것이다. 기본적으로 읽고 쓰기는 leader replica에서 발생하고 나머지 replica들은 follower가 되어 데이터를 업데이트 받는다. ",
    "url": "/docs/message-broker/kafka/architecture#topic",
    
    "relUrl": "/docs/message-broker/kafka/architecture#topic"
  },"663": {
    "doc": "kafka 아키텍처 이해하기",
    "title": "ZooKeeper",
    "content": "ZooKeeper는 discovery, configuration, synchronization service를 고가용성으로 제공하는 분산 저장소다. ZooKeeper는 카프카 생태계를 복잡하게 만드는 원인 중 하나다. 참고사항 . 카프카 요구사항을 단순화하기 위해 ZooKeeper 대신 자체 관리되는 Quorum으로 교체하자는 제안이 있고 kafka 3.대의 버전에서 Zookeeper 의존성에서 탈출했다. Zookeeper를 사용하는 사례 중 하나는 앞서 봤던 leader replica가 어떤 파티션인지 합의하는데 사용하는 것이다. ",
    "url": "/docs/message-broker/kafka/architecture#zookeeper",
    
    "relUrl": "/docs/message-broker/kafka/architecture#zookeeper"
  },"664": {
    "doc": "kafka 아키텍처 이해하기",
    "title": "Page Cache",
    "content": ". 카프카는 수백만 개의 메시지를 빠르게 처리할 수 있는데, 이를 가능하게 만드는 핵심 중 하나는 page cache1이다. broker가 JVM heap에 캐시되지 않도록 하여 크기가 큰 heap으로 인해 발생하는 문제2를 방지한다. ",
    "url": "/docs/message-broker/kafka/architecture#page-cache",
    
    "relUrl": "/docs/message-broker/kafka/architecture#page-cache"
  },"665": {
    "doc": "kafka 아키텍처 이해하기",
    "title": "Commit Log",
    "content": "Kafka에서 Commit Log는 Java의 logger의 로그나, DB의 WAL 처럼 숨겨진 세부정보가 아니다. 오히려 kafka의 중심에 위치하며 사용자들은 offset을 사용해서 메시지가 로그의 어디에 위치하는지 찾을 수 있다. Commit Log는 메시지가 항상 로그 마지막에 추가되는 추가 전용 로그이다. 메시지를 읽을 때 그 메시지를 시스템에서 제거하거나 다른 consumer로부터 제외하지 않는다. ",
    "url": "/docs/message-broker/kafka/architecture#commit-log",
    
    "relUrl": "/docs/message-broker/kafka/architecture#commit-log"
  },"666": {
    "doc": "kafka 아키텍처 이해하기",
    "title": "카프카 상위 수준 뷰",
    "content": ". 상위 수준에서 정리한 카프카 뷰. ",
    "url": "/docs/message-broker/kafka/architecture#%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%83%81%EC%9C%84-%EC%88%98%EC%A4%80-%EB%B7%B0",
    
    "relUrl": "/docs/message-broker/kafka/architecture#카프카-상위-수준-뷰"
  },"667": {
    "doc": "kafka 아키텍처 이해하기",
    "title": "reference",
    "content": ". | Kafka In Action 2장 | . | 운영 체제에서 제공하는 메모리 기술 중 하나로, 디스크로부터 읽은 파일이나 블록들을 메모리에 캐시하여 빠르게 액세스할 수 있도록 하는 기술 &#8617; . | 장시간 또는 빈번한 GC로 인해 일시적인 멈춤(Stop The World)이 발생하는 문제 &#8617; . | . ",
    "url": "/docs/message-broker/kafka/architecture#reference",
    
    "relUrl": "/docs/message-broker/kafka/architecture#reference"
  },"668": {
    "doc": "kafka 아키텍처 이해하기",
    "title": "kafka 아키텍처 이해하기",
    "content": " ",
    "url": "/docs/message-broker/kafka/architecture",
    
    "relUrl": "/docs/message-broker/kafka/architecture"
  },"669": {
    "doc": "kafka producer 이해하기",
    "title": "producer option",
    "content": "| 키 | 용도 | . | bootstrap.servers | 시작 시 연결할 하나 이상의 카프카 브로커 | . | acks | 메시지 전달이 성공하기 위한 producer가 요구하는 복제 확인 (acknowledgement)의 수 | . | key.serializer | 키의 직렬화에 사용되는 클래스 | . | value.serializer | 값의 직렬화에 사용되는 클래스 | . ",
    "url": "/docs/message-broker/kafka/producer#producer-option",
    
    "relUrl": "/docs/message-broker/kafka/producer#producer-option"
  },"670": {
    "doc": "kafka producer 이해하기",
    "title": "bootstrap servers",
    "content": "producer는 할당된 파티션의 leader replica에만 쓸 수 있는데, topic과 bootstrap.servers 밖에 모르기 때문에 알고있는 server에 연결한다. producer는 boootstrap.servers를 시작점으로 사용해 모든 후속 쓰기에 사용하는 브로커와 파티션에 대한 메타데이터를 가져온다. 각 브로커들은 클러스터 안의 다른 브로커들도 알고 있기 때문에 producer는 하나의 브로커를 통해 leader를 찾을 수 있다. ",
    "url": "/docs/message-broker/kafka/producer#bootstrap-servers",
    
    "relUrl": "/docs/message-broker/kafka/producer#bootstrap-servers"
  },"671": {
    "doc": "kafka producer 이해하기",
    "title": "acks",
    "content": "acks는 producer가 완료를 받기 전에 partition leader가 follower(replica)로 부터 얼마나 많은 ack를 받아야 하는지에 대한 속성이다. 이 값은 all, -1, 1, 0을 가질 수 있다. acks 0 . acks가 0인 경우 0개의 replica에 ack를 받기 때문에 가장 적은 대기 시간을 얻을 수 있지만 안전한 배달을 보장하진 않는다. acks all . acks가 all 혹은 -1인 경우 leader replica가 모든 replica 들의 ack를 기다린다는 의미이다. 따라서 가장 느린 대기 시간을 갖게 되지만 안전한 배달을 보장한다. acks 1 . acks가 1인 경우 1개의 replica에 ack를 받는다. 즉 leader replica의 수신을 확인하기 때문에 비교적 적당한 안정성과 대기시간을 가질 수 있다. leader가 follower에게 복사본을 만드는 사이에 다운된다면 메시지를 누락할 수 있다. ",
    "url": "/docs/message-broker/kafka/producer#acks",
    
    "relUrl": "/docs/message-broker/kafka/producer#acks"
  },"672": {
    "doc": "kafka producer 이해하기",
    "title": "serializer",
    "content": "카프카의 메시지는 byte array로 저장되기 때문에 serializer가 필요하다. producer의 serializer와 맞는 consumer의 deserializer가 필요하다. StringSerializer, IntegerSerializer와 같이 기본 제공되는 serializer들이 있으며, customSerializer를 만들 수도 있다. 여기서 key가 같으면 동일한 partition으로 전송한다. | partition 수가 늘어나면 다른 partition으로 갈 수도 있다. | key가 null 인 경우 사용 가능한 partition 중 랜덤으로 선택한다. | . ",
    "url": "/docs/message-broker/kafka/producer#serializer",
    
    "relUrl": "/docs/message-broker/kafka/producer#serializer"
  },"673": {
    "doc": "kafka producer 이해하기",
    "title": "timestamp",
    "content": "최신 버전의 producer에서는 event에 대한 timestamp가 포함되어 있다. message.timestamp.type을 CreateTime으로 설정하면 사용자가 직접 작성하거나 현재 시스템 시간으로 전달할 수 있다. LogAppendTime으로 설정하면 브로커 시간이 사용된다. 메시지 전달이 실패하여 재시도 할 수 있기 때문에, 브로커의 시간을 사용할지 producer의 시간을 사용할지 서비스 특성에 맞게 판단해야 한다. ",
    "url": "/docs/message-broker/kafka/producer#timestamp",
    
    "relUrl": "/docs/message-broker/kafka/producer#timestamp"
  },"674": {
    "doc": "kafka producer 이해하기",
    "title": "reference",
    "content": ". | Kafka In Action 4장 | . ",
    "url": "/docs/message-broker/kafka/producer#reference",
    
    "relUrl": "/docs/message-broker/kafka/producer#reference"
  },"675": {
    "doc": "kafka producer 이해하기",
    "title": "kafka producer 이해하기",
    "content": "Producer는 메시지를 카프카 topic으로 보내는 도구이다. ",
    "url": "/docs/message-broker/kafka/producer",
    
    "relUrl": "/docs/message-broker/kafka/producer"
  },"676": {
    "doc": "apache kafka란?",
    "title": "이벤트 스트리밍",
    "content": "카프카는 스스로를 이벤트 스트리밍 플랫폼이라고 소개하고 있다. 이벤트 스트림이란 사람 몸의 중추 신경계 같은 것으로 이벤트 소스(DB, sensor, devices, cloud service, application)에서 이벤트 스트림 형태로 실시간으로 데이터를 캡처하는 방식이다. 검색을 위해 이벤트 스트림을 영구 저장하고 실시간 이벤트 스트림을 조작하고 처리하는 것과 다른 곳으로 라우팅 하는 것도 포함한다. ",
    "url": "/docs/message-broker/kafka/kafka#%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EC%8A%A4%ED%8A%B8%EB%A6%AC%EB%B0%8D",
    
    "relUrl": "/docs/message-broker/kafka/kafka#이벤트-스트리밍"
  },"677": {
    "doc": "apache kafka란?",
    "title": "카프카의 주요 특징",
    "content": ". | 메시지 큐처럼 레코드를 읽고 쓴다. | 내결함성(falut tolerance)로 이벤트 스트림을 지속적이고 안정적으로 저장한다. | 이벤트 스트림이 발생할 때 처리한다. | . 그 외에도 카프카의 여러 특징들이 있다. | 카프카는 시스템으로 들어오고 시스템에서 나가는 데이터 중개인처럼 행동한다. | 프로듀서와 컨슈머 사이에 느슨한 결합을 생성한다. | 데이터 병렬 처리가 가능하다. | 다수의 컨슈머가 있을 수 있다. | . ",
    "url": "/docs/message-broker/kafka/kafka#%EC%B9%B4%ED%94%84%EC%B9%B4%EC%9D%98-%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95",
    
    "relUrl": "/docs/message-broker/kafka/kafka#카프카의-주요-특징"
  },"678": {
    "doc": "apache kafka란?",
    "title": "카프카의 세가지 semantic",
    "content": "1. at-least once semantics . 메시지가 수진 확인될 때까지 재발송된다. 같은 메시지를 한 번 이상 보내어 브로커에 틀림없이 기록되도록 한다. 메시지가 브로커에 쓰였음을 보증받지 못한다면 프로듀서는 메시지를 다시 보낸다. 중복 메시지를 컨슈머가 필터링해야할 수 있지만 가장 안전한 배달방식이다. 2. at-most once semantics . 메시지는 단 한 번 보내며 실패하더라도 재발송하지 않는다. 메시지 전달이 실패하는 경우에도 프로듀서는 다음 메시지로 넘어가고 실패한 메시지를 다시 보내지 않는다. 메시지를 잃어도 괜찮은 경우에 사용할 수 있다. 수신 확인을 하는 것은 결국 시스템 자원을 소모하는 일이고, 메시지를 일부 잃어도 괜찮다면 성능과 비용을 위해 수신확인을 기다리지 않을 수 있다. 3. exactly-once semantics (EOS) . 메시지는 컨슈머에게 단 한 번만 보인다. | 한 번만 발송하는 것이 아니라 한 번만 보이는 것이다. | . 브로커가 하나의 메시지만을 허용하는 방식으로 프로듀서는 at-least once semantics 처럼 수신확인을 하나 컨슈머에게 도달하는 메시지는 하나가 된다. ",
    "url": "/docs/message-broker/kafka/kafka#%EC%B9%B4%ED%94%84%EC%B9%B4%EC%9D%98-%EC%84%B8%EA%B0%80%EC%A7%80-semantic",
    
    "relUrl": "/docs/message-broker/kafka/kafka#카프카의-세가지-semantic"
  },"679": {
    "doc": "apache kafka란?",
    "title": "카프카가 적절한 경우",
    "content": ". | 안정적인 message queue . | kafka 초기의 사용 사례로 일반적인 사례 | . | MSA의 EDA에서의 이벤트 통신 | IoT의 데이터 처리 | . ",
    "url": "/docs/message-broker/kafka/kafka#%EC%B9%B4%ED%94%84%EC%B9%B4%EA%B0%80-%EC%A0%81%EC%A0%88%ED%95%9C-%EA%B2%BD%EC%9A%B0",
    
    "relUrl": "/docs/message-broker/kafka/kafka#카프카가-적절한-경우"
  },"680": {
    "doc": "apache kafka란?",
    "title": "카프카가 적절하지 않을 수 있는 경우",
    "content": ". | 실시간이 아니라 한 달이나 일 년에 한 번 데이터 처리가 필요한 경우 | 메시지가 큰 경우 . | 카프카는 기본적으로 큰 메시지를 보내도록 설계되지 않았다. | 큰 메시지는 메모리 압박이 증가하고 캐시할 수 있는 메시지 수가 줄어 성능이 저하될 수 있다. | . | . ",
    "url": "/docs/message-broker/kafka/kafka#%EC%B9%B4%ED%94%84%EC%B9%B4%EA%B0%80-%EC%A0%81%EC%A0%88%ED%95%98%EC%A7%80-%EC%95%8A%EC%9D%84-%EC%88%98-%EC%9E%88%EB%8A%94-%EA%B2%BD%EC%9A%B0",
    
    "relUrl": "/docs/message-broker/kafka/kafka#카프카가-적절하지-않을-수-있는-경우"
  },"681": {
    "doc": "apache kafka란?",
    "title": "reference",
    "content": ". | https://kafka.apache.org/intro | Kafka In Action 1장 | . | 배치 작업은 enterprise 급일수록 눈처럼 불어나 시스템이 과부하 상태로 빠질 수 있으며 관리를 위한 리소스가 필요하다. &#8617; . | . ",
    "url": "/docs/message-broker/kafka/kafka#reference",
    
    "relUrl": "/docs/message-broker/kafka/kafka#reference"
  },"682": {
    "doc": "apache kafka란?",
    "title": "apache kafka란?",
    "content": "More than 80% of all Fortune 100 companies trust, and use Kafka. - Apache Software Foundation . 카프카는 현재 어떤 산업의 분야에 관계 없이 대부분의 기업에서 사용되고 있다. 카프카를 통해 데이터 플랫폼에 대한 표준이 바뀌고 있는데, 이전엔 ETL과 batch workflow1로 처리하던 작업들이 카프카를 통해 near-real-time 데이터 처리로 가고 있다. 카프카는 작업을 더 명확하고 간단하게 만들면서 MSA와 IoT의 중심에 자리잡고 있다. ",
    "url": "/docs/message-broker/kafka/kafka",
    
    "relUrl": "/docs/message-broker/kafka/kafka"
  },"683": {
    "doc": "kafka consumer 이해하기",
    "title": "consumer option",
    "content": "| 키 | 용도 | . | bootstrap.servers | 시작할 때 연결할 하나 이상의 카프카 브로커 | . | value.deserializer | 값 역직렬화에 필요 | . | key.deserializer | 키 역직력화에 필요 | . | group.id | consumer group에 조인하기 위해 사용되는 ID | . | client.id | 유저를 식별하기 위한 ID | . | heartbeat.interval.ms | consumer가 그룹 코디네이터에게 ping 신호를 보낼 간격 | . ",
    "url": "/docs/message-broker/kafka/consumer#consumer-option",
    
    "relUrl": "/docs/message-broker/kafka/consumer#consumer-option"
  },"684": {
    "doc": "kafka consumer 이해하기",
    "title": "offset",
    "content": "consumer가 브로커에게 보내는 로그의 인덱스 위치로 offset을 사용한다. offset을 통해 로그에서 필요한 메시지의 위치를 알 수 있다. auto.offset.reset을 earliest로 설정하면 처음부터 읽기 때문에 해당 토픽에 대한 모든 메시지를 볼 수 있다. 기본값인 latest로 설정하면 consumer를 시작한 후 보낸 메시지들을 읽는다. topic에 작성된 메시지를 찾기 위해 우선 topic 내에서 파티션을 찾은 다음 인덱스 기반 offset을 찾는다. consumer는 일반적으로 leader replica에서 읽는다. consumer가 어떤 파티션에 연결할지, 파티션의 리더는 어디에 있는지는 각 consumer 그룹에 대해 그룹 코디네이터 역할을 하는 특정 브로커를 통해 알 수 있다. 참고사항 . offset은 항상 각 파티션에 대해 증가한다. 파티션 내에서 각 로그 시퀀스를 갖기 때문에 다른 파티션 간에는 offset 번호가 같아도 괜찮다. 파티션에 offset 0이 표시되면 나중에 해당 메시지가 제거되더라도 offset 번호는 다시 사용되지 않는다. ",
    "url": "/docs/message-broker/kafka/consumer#offset",
    
    "relUrl": "/docs/message-broker/kafka/consumer#offset"
  },"685": {
    "doc": "kafka consumer 이해하기",
    "title": "파티션 수와 consumer",
    "content": "메시지를 읽는데는 파티션의 수도 영향을 미친다. 파티션 수 &lt; consumer 수 . 파티션보다 consumer가 많으면 일부 consumer는 작업을 수행하지 않는다. 여유 consumer는 ready 상태이다. consumer가 예기치 않게 실패하는 경우에도 비슷한 비율의 소비가 필요한 경우가 있다면 consumer가 있을 수 있다. 그룹 코디네이터는 그룹 시작 초기에 어떤 consumer가 어떤 파티션을 읽을지 지정하는 것 뿐만 아니라 consumer가 추가되거나 실패하여 그룹을 종료할 때도 consumer를 할당한다. 참고사항 . Q: 그렇다면 항상 많은 파티션을 사용하면 되는 것 아닌가? . 많은 파티션은 공짜가 아니다. latency를 증가시킬 수 있다. 파티션이 많다면 브로커간에 파티션이 복제될 때까지 기다려야해서 대기시간이 길어질 수 있다. consumer에게 메시지를 전달하기 전에 동기화가 완료된다. consumer에 대해 파티션이 1:1 매핑이 아닌 경우 더 많은 파티션이 할당됨에 따라 메모리 요구가 증가할 수 있다. 파티션 수 &gt; consumer 수 . 하나의 파티션을 두 개의 consumer가 읽을 수 없다. consumer보다 파티션이 많은 경우 필요에 따라 하나의 consumer가 둘 이상의 파티션을 처리한다. 하나의 파티션을 하나의 consumer가 읽는건 하나의 consumer 그룹 내에서의 이야기다. 서로 다른 consumer 그룹에선 각 그룹의 하나의 consumer가 파티션을 읽을 수 있다. 즉 파티션 기준으로 여러 consumer가 있을 수 있지만, 같은 consumer 그룹에서는 하나의 consumer만 있을 수 있다. ",
    "url": "/docs/message-broker/kafka/consumer#%ED%8C%8C%ED%8B%B0%EC%85%98-%EC%88%98%EC%99%80-consumer",
    
    "relUrl": "/docs/message-broker/kafka/consumer#파티션-수와-consumer"
  },"686": {
    "doc": "kafka consumer 이해하기",
    "title": "그룹 코디네이터",
    "content": "그룹 코디네이터는 consumer와 협력해서 특정 consumer 그룹이 읽은 topic 내부의 기록을 유지한다. topic에서 다음 메시지를 읽을 위치를 결정하기 위해 offset을 커밋 좌표로 사용하고 있다. 일반적으로 다른 브로커 서비스에서는 이런 케이스에서 필요한 수만큼 동일한 메시지를 갖는 여러 큐를 갖는다. 그렇지만 kafka는 consumer 그룹마다 코디네이션을 하기 때문에 별도의 논리적인 작업이 필요하다면 새 consumer 그룹을 사용하여 해결할 수 있다. consumer 그룹은 서로 consumer offset에 대한 동일한 코디네이션을 공유하지 않는다. 각 consumer들은 consumer group에 속한다. conumser group의 consumer들은 topic 파티션의 소유권을 공유하며 각 consumer가 해당 토픽의 다른 파티션을 분담하면서 메시지를 읽을 수 있다. 위 그림은 동일한 파티션 집합이 3개의 다른 브로커에 존재하고, kinaction_teamoffka0과 kinaction_teamsetka1이라는 2개의 consumer 그룹이 파티션에서 consume하고 있는 상황이다. 각 그룹의 consumer는 각 브로커의 파티션에서 고유한 데이터 복사본을 가져온다. 다른 그룹이라면 같이 동작하지 않는다. 참고사항 . consumer가 데이터를 사용해도 토픽에서 제거하지 않는다. 그렇기 때문에 consumer group이 다르면 메시지를 가져갈 수 있다. ",
    "url": "/docs/message-broker/kafka/consumer#%EA%B7%B8%EB%A3%B9-%EC%BD%94%EB%94%94%EB%84%A4%EC%9D%B4%ED%84%B0",
    
    "relUrl": "/docs/message-broker/kafka/consumer#그룹-코디네이터"
  },"687": {
    "doc": "kafka consumer 이해하기",
    "title": "heartbeat",
    "content": "consumer가 그룹 코디네이터에게 ping을 하는 것을 heartbeat라고 한다. heartbeat는 consumer가 코디네이터와 통신하여 적절한 시간내에 응답하며 작업하고 있음을 알리는 신호이다. heartbeat가 시간 내에 응답되지 않으면 그룹 코디네이터는 리밸런싱을 시작한다. 리밸런싱이란 consumer간 파티션 소유권을 이전하는 것을 말한다. 참고사항 . heartbeat.interval.ms를 통해 consumer가 heartbeat를 보내는 간격을 설정할 수 있다. heartbeat.interval.ms는 일반적으로 session.timeout.ms의 1/3 이하의 값으로 설정되어야 한다. session.timeout.ms는 클라이언트가 활성화 되어있는지 만료를 체크하는 브로커의 시간이다. ",
    "url": "/docs/message-broker/kafka/consumer#heartbeat",
    
    "relUrl": "/docs/message-broker/kafka/consumer#heartbeat"
  },"688": {
    "doc": "kafka consumer 이해하기",
    "title": "reference",
    "content": ". | Kafka In Action 5장 | https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html | . ",
    "url": "/docs/message-broker/kafka/consumer#reference",
    
    "relUrl": "/docs/message-broker/kafka/consumer#reference"
  },"689": {
    "doc": "kafka consumer 이해하기",
    "title": "kafka consumer 이해하기",
    "content": "consumer는 카프카에서 데이터를 가져와 다른 시스템이나 애플리케이션에 데이터를 제공한다. consumer는 consumer를 추가/제거 함으로써 처리량에 영향을 주기 때문에 중요하다. consumer가 topic에 대해 Push 받지 않고 pull 해온다는 것이 중요하다. topic을 구독하는 방식을 통해 consumer는 자신의 메세지 소비 비율을 통제한다. 구독 방식을 통해 consumer를 항상 가동할 필요 없이 다운되면 다시 수행할 수 있다. 그러나 장시간 다운되선 안된다. (메시지 유실 가능성) . consumer 클라이언트 시작 시 연결을 시도할 수 있는 브로커를 항상 알아야 한다. 메세지를 생성한 직렬 변환기와 일치하는 키와 값에 대한 역직렬 변환기를 사용해야 한다. ",
    "url": "/docs/message-broker/kafka/consumer",
    
    "relUrl": "/docs/message-broker/kafka/consumer"
  },"690": {
    "doc": "8년차 개발자의 개발 면접 질문 리스트",
    "title": "면접자가 면접관에게 질문할 내용들",
    "content": "질문을 적다보니 질문의 내용이 팀과 기술 스택, 개발 문화로 정리된다. 특별히 서버 개발자라고 특정되는 질문보다는 개발자라면 하는 질문의 내용이 비슷한 것 같다. 팀 . | 팀 구성은 어떻게 되나요? | 팀 내에 서버 팀 인력 구성은 어떻게 되나요? | 여러 프로젝트를 같이 관리하게 되기도 하나요? | 채용된다면 어떤 역할을 기대하나요? | . 팀의 구성과 인력 구조는 팀 내에서 소통해야 할 범위와 의사결정이 어떻게 진행되는지를 알 수 있기 때문에 팀에 대한 질문들이 중요한 것 같다. 기술 스택 . | 어떤 기술 스택을 사용하나요? | 어떤 아키텍처를 사용하고 있고 누가 아키텍처를 그리나요? | 형상관리는 어떻게 하나요? | 팀 내에서 새로운 기술을 도입하는 방식이 궁금합니다. | 스터디를 진행하는지와 방식을 알 수 있을까요? | 테스트는 어떻게 하고 있나요? | . 기술 스택은 일반적으론 모집 공고에 적힌 편이다. 나는 아키텍처에 참여를 많이 하는 편이고 관심이 많아 아키텍처에 대한 질문을 넣었다. 그 외에 팀이 성장하기 위해 스터디를 하는지를 물어보면 좋겠고 테스트가 잘 되는지는 프로젝트에 너무 중요하다. 개발 문화 . | 일이 애자일로 진행되는지 궁금합니다. | 그렇다면 애자일 주기는 어떻게 될까요? | 애자일 팀의 범위는 어떻게 될까요? | 회고는 하고 있는지 궁금합니다. | 애자일 스프린트 리더는 누가 맡을까요? | 코드는 공동 소유하고 있나요? | 리뷰는 어떻게 진행되나요? | 업무 강도는 어떤가요? | . 사실 가장 중요한건 개발 문화가 아닌가 생각이 든다. 기술 스택은 비슷해도 좋고 다르다면 배울 수 있어 더 좋지만 개발 문화가 낙후되었다면 일하는 것도 성장하는 것도 어렵기 때문이다. ",
    "url": "/docs/career/interview-question#%EB%A9%B4%EC%A0%91%EC%9E%90%EA%B0%80-%EB%A9%B4%EC%A0%91%EA%B4%80%EC%97%90%EA%B2%8C-%EC%A7%88%EB%AC%B8%ED%95%A0-%EB%82%B4%EC%9A%A9%EB%93%A4",
    
    "relUrl": "/docs/career/interview-question#면접자가-면접관에게-질문할-내용들"
  },"691": {
    "doc": "8년차 개발자의 개발 면접 질문 리스트",
    "title": "면접 후기",
    "content": "짧은 시간의 면접을 통해 준비한 질문을 다 하기 힘든 경우도 있다. 최근 면접에선 내가 준비한 위 질문들을 면접관들께 모두 할 수 있었고, 잘 모르던 회사에 대해 나름대로 깊이 있게 알 수 있게 되었다. 질문을 하다 보면 면접관들이 답변하신 내용에 재차 질문을 하게 되기도 한다. 면접을 자주 보는 편은 아니지만 앞으로도 이 질문들이 더 영양가 있게 업데이트할 수 있으면 좋겠다. ",
    "url": "/docs/career/interview-question#%EB%A9%B4%EC%A0%91-%ED%9B%84%EA%B8%B0",
    
    "relUrl": "/docs/career/interview-question#면접-후기"
  },"692": {
    "doc": "8년차 개발자의 개발 면접 질문 리스트",
    "title": "8년차 개발자의 개발 면접 질문 리스트",
    "content": "어떤 면접이든 면접을 보게 되면 질문을 받은 후엔 질문을 할 시간을 갖게 된다. 면접을 준비할 땐 당연히 받을 질문을 준비하지만, 내 생각엔 받는 질문보다 할 질문이 더 중요하다. 최근 한 곳에 면접을 보게 되었는데 그 회사의 개발팀 내부 분위기를 잘 모르는 상태로 면접을 보게 됐다. 난 궁금한 게 많았고, 어떤 질문을 하는 것이 좋을까 찾아봤는데 괜찮은 질문 리스트를 찾지 못했다. 개발자라면 마땅히 해볼법하고 해야 할 질문들, 그리고 내가 면접을 준비하며 고민했던 질문 내용들을 리스트업 해본다. ",
    "url": "/docs/career/interview-question",
    
    "relUrl": "/docs/career/interview-question"
  },"693": {
    "doc": "link local ip address 개념 명확하게 이해하기",
    "title": "link local ip address",
    "content": "169.254.0.0/16는 RFC 6890에서 Link Local Special Purpose Address로 정의 되었다. Link Local IP Address는 직접 연결된 하위 네트워크 내에서만 유효한 address이다. link local ip는 DHCP 서버나 수동으로 구성된 ip address를 사용할 수 없을 경우 auto configuration을 위한 목적의 인터페이스이다. 정상적으로 routable ip address를 얻게 된 후에는 해당 address를 사용한다. 참고사항 . | link local ip address는 하위 네트워크에서만 유효하므로 네트워크 인프라에서 해당 block 내의 subnet을 생성하면 안된다. | router는 link local ip address를 대상으로 하는 패킷은 전달할 수 없다. | DNS는 link local ip address를 저장해선 안된다. | 169.254.0.0/24 와 169.254.255.0/24의 각각 256개의 ip는 추후 다른 목적으로 사용하기 위해 예약되었기 때문에 사용할 수 없다. | . ",
    "url": "/docs/internet/link-local#link-local-ip-address",
    
    "relUrl": "/docs/internet/link-local#link-local-ip-address"
  },"694": {
    "doc": "link local ip address 개념 명확하게 이해하기",
    "title": "클라우드와 link local ip address",
    "content": "AWS와 같은 cloud service provider는 클라우드의 물리적인 인프라를 제어하기 때문에 모든 인스턴스에 대해 local access가 가능하도록 구성할 수 있다. 다음과 같은 이유로 link local ip address는 자동구성 서비스에 적합하다. | link local ip address는 source와 destination 모두에서 non-forwardable ip 이다. | 클라우드 서비스 내에서 local network으로 연결되어 바이러스로부터 안전하다. | 사용자가 이 주소를 subnet으로 사용할 수 없다. | . 이런 이유로 NTP(Network Time Protocol), IMDS(Instance Metadata Service) 등 클라우드 상의 가상 컴퓨터에 필요한 서비스를 link local ip address를 통해 제공한다. ",
    "url": "/docs/internet/link-local#%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C%EC%99%80-link-local-ip-address",
    
    "relUrl": "/docs/internet/link-local#클라우드와-link-local-ip-address"
  },"695": {
    "doc": "link local ip address 개념 명확하게 이해하기",
    "title": "IMDS (Instance MetaData Service)",
    "content": "클라우드에서 인스턴스의 메타데이터에 접근할 필요가 있는 경우가 있다. 예를 들면 네트워크 구성, 인스턴스 타입, 가용 영역, 인스턴스 정보 등의 메타데이터가 필요할 수 있다. 대부분의 클라우드 플랫폼에서 169.254.169.254를 통해 IMDS에 접근할 수 있다. 169.254.169.254는 클라우드 인스턴스 내에서 접근 가능한 특별한 ip이다. ",
    "url": "/docs/internet/link-local#imds-instance-metadata-service",
    
    "relUrl": "/docs/internet/link-local#imds-instance-metadata-service"
  },"696": {
    "doc": "link local ip address 개념 명확하게 이해하기",
    "title": "reference",
    "content": ". | 169.254.0.0/16, https://www.baeldung.com/linux/cloud-ip-meaning | link local, https://en.wikipedia.org/wiki/Link-local_address | . ",
    "url": "/docs/internet/link-local#reference",
    
    "relUrl": "/docs/internet/link-local#reference"
  },"697": {
    "doc": "link local ip address 개념 명확하게 이해하기",
    "title": "link local ip address 개념 명확하게 이해하기",
    "content": "ip 주소 중 특정 ip들은 특별한 목적으로 사용되도록 설계 되었다. link local ip address는 특별한 목적으로 설계된 ip block이다. ",
    "url": "/docs/internet/link-local",
    
    "relUrl": "/docs/internet/link-local"
  },"698": {
    "doc": "too many open file 이슈 확인하고 해결하기",
    "title": "too many open files in system",
    "content": "open config.property: too many open files in system . too many open files in system는 linux에서 열린 파일 수가 너무 많아서 더 이상 파일을 열 수 없다는 오류 메시지이다. linux에서는 동시에 열 수 있는 파일 수가 제한되어 있고, 이 제한을 초과하여 파일을 열려고 할 때 오류가 발생한다. 오류가 발생하는 이유는 설정된 자원보다 더 많은 요청을 하기 때문이다. 프로세스가 동시에 많은 파일을 열 때 발생할 수 있는데, 주로 이런 경우는 file open 후 close 하지 않는 코드 상의 버그일 가능성이 높다. 버그인지 아닌지 확인하기 위해 linux의 property를 먼저 확인한다. ",
    "url": "/docs/dev-tools/linux/too_many_open_file#too-many-open-files-in-system",
    
    "relUrl": "/docs/dev-tools/linux/too_many_open_file#too-many-open-files-in-system"
  },"699": {
    "doc": "too many open file 이슈 확인하고 해결하기",
    "title": "file open limit 확인하기",
    "content": "file open limit을 확인할 때 user의 resource limit을 체크하는 ulimit을 사용한다. ulimit에는 두 가지 limit이 있다. | hard limit: -H 옵션으로 접근하며, super user만 수정할 수 있는 limit | soft limit: -S 옵션으로 접근하며, 사용자가 hard limit 내에서 변경할 수 있는 limit | . process는 당연히 둘 중 더 작은 limit인 soft limit으로 resource가 제한된다. ulimit -n # 혹은 ulimit -Sn . 다음은 hard limit을 확인한다. ulimit -Hn . 필요하다면 hard limit 보다 작은 값으로 soft limit을 변경한다. ulimit -n 99999 . hard limit 보다 큰 값으로 soft limit을 변경하려고 하면 에러가 발생한다. ",
    "url": "/docs/dev-tools/linux/too_many_open_file#file-open-limit-%ED%99%95%EC%9D%B8%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/dev-tools/linux/too_many_open_file#file-open-limit-확인하기"
  },"700": {
    "doc": "too many open file 이슈 확인하고 해결하기",
    "title": "file open 확인하기",
    "content": "limit을 확인했다면, 어떤 process가 file open을 많이하는지 확인할 필요가 있다. limit이 작고 실제 file open을 많이 하는 케이스도 있겠지만 대부분은 close가 제대로 되지 않으면서 발생하는 케이스가 많다. 어떤 process가 어떤 file을 open 하는지를 보면 이런 이슈를 분리할 수 있다. 정상적인 케이스라면 limit을 늘리면 될 것이고, 그렇지 않다면 버그를 수정하면 된다. 1. file nr . cat /proc/sys/fs/file-nr . file-nr은 3개의 숫자를 갖는다. 순서대로 그 의미는 . | 할당된 file handles 수 | 할당 되었지만 사용되지 않은 file handles 수 | 최대 file handles 수 | . cat /proc/sys/fs/file-nr &amp;&amp; date . 위 명령어를 주기적으로 호출해보면서 file-nr에서 보이는 file 할당 수가 시간이 지날수록 계속 증가한다면 file close가 잘 안되고 있는 것이라고 추정할 수 있다. date와 함께 남기면 시간 별로 file-nr을 추적하기 용이하다. 참고사항 . file-nr의 마지막 값인 최대 file hadles 수는 cat /proc/sys/fs/file-max와도 같은 값이다. 이 값과 ulimit -Hn는 다르다. file-max는 linux 시스템에서 열 수 있는 File descriptor의 최대 수에 대한 설정 값으로 시스템 전체와 모든 프로세스에 적용된다. 반면 ulimit은 사용자나 프로세스 수준의 File descsriptor 제한을 설정한다. 2. lsof . lsof는 list open files 명령어로 open file을 확인할 수 있다. 여기서 pid를 통해 특정 process의 open file을 체크할 수 있다. lsof -p 1234567 # 1234567은 pid로, ps -ef를 통해 이슈가 발생한 pid를 찾아야한다. lsof -p 1234567|wc -l &amp;&amp; date . lsof를 통해 어떤 process가 open file 이슈를 만드는지 그리고 어떤 파일에 대한 open이 계속 남아있고, 증가하는지를 확인할 수 있다. 위와 동일하게 date를 통해 기록을 남기며 특정 process가 이슈를 만드는지 체크할 수 있다. 예시 . lsof -p 1234567 . COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME app-test- 1234567 user 181r REG 259,1 2 4392717 /app/test/config.property app-test- 1234567 user 182r REG 259,1 2 4392717 /app/test/config.property app-test- 1234567 user 183r REG 259,1 2 4392717 /app/test/config.property app-test- 1234567 user 184r REG 259,1 2 4392717 /app/test/config.property app-test- 1234567 user 185r REG 259,1 2 4392717 /app/test/config.property app-test- 1234567 user 186r REG 259,1 2 4392717 /app/test/config.property app-test- 1234567 user 187r REG 259,1 2 4392717 /app/test/config.property . 이번에 내가 겪은 이슈의 lsof 결과이다. 동일한 파일인 config.property에 대해 open이 반복되고 있었고, close 없이 계속해서 open file 수가 증가했다. FD는 File Descriptor의 약자로 181r의 r은 read file이라는 표현이다. 지금 상황은 config.property를 주기적으로 open하고 close 하지 않는 것으로 분석할 수 있다. ",
    "url": "/docs/dev-tools/linux/too_many_open_file#file-open-%ED%99%95%EC%9D%B8%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/dev-tools/linux/too_many_open_file#file-open-확인하기"
  },"701": {
    "doc": "too many open file 이슈 확인하고 해결하기",
    "title": "이슈 처리",
    "content": "이런경우 대부분의 이슈는 반복문 안에서 open file에 대한 close가 의도한대로 동작하지 않아서 발생한다. 이슈 수정 후에 다시 수행하면서 위와 동일한 로직으로 open file이 증가하지 않는 것을 확인할 수 있다. 이번엔 golang에서 만든 코드가 for loop안에 defer close를 잘못 사용하여 발생한 이슈로 close를 적절하게 변경하여 해결했다. ",
    "url": "/docs/dev-tools/linux/too_many_open_file#%EC%9D%B4%EC%8A%88-%EC%B2%98%EB%A6%AC",
    
    "relUrl": "/docs/dev-tools/linux/too_many_open_file#이슈-처리"
  },"702": {
    "doc": "too many open file 이슈 확인하고 해결하기",
    "title": "reference",
    "content": ". | https://docs.kernel.org/admin-guide/sysctl/fs.html#file-max-file-nr | https://www.baeldung.com/linux/error-too-many-open-files | https://www.baeldung.com/linux/soft-limit-hard-limit | . ",
    "url": "/docs/dev-tools/linux/too_many_open_file#reference",
    
    "relUrl": "/docs/dev-tools/linux/too_many_open_file#reference"
  },"703": {
    "doc": "too many open file 이슈 확인하고 해결하기",
    "title": "too many open file 이슈 확인하고 해결하기",
    "content": " ",
    "url": "/docs/dev-tools/linux/too_many_open_file",
    
    "relUrl": "/docs/dev-tools/linux/too_many_open_file"
  },"704": {
    "doc": "객체 지향 설계의 5가지 원칙 SOLID 헷갈리지 않게 예제로 이해하기",
    "title": "SOLID 원칙",
    "content": "우선 SOLID 원칙은 다섯 가지의 객체지향 원칙들의 앞 문자를 따서 만든 원칙이다. | SRP, Single Responsibility Principle, 단일 책임 원칙 | OCP, Open Closed Principle, 개방 폐쇄 원칙 | LSP, Liskov Substitution Principle, 리스코프 치환 원칙 | ISP, Interface Segregation Principle, 인터페이스 분리 원칙 | DIP, Dependency Inversion Principle, 의존 역전 원칙 | . 사실 SOLID 원칙이란 클래스를 어떻게 나누고, 인터페이스로 명세하고 사용하는지에 대한 내용이다. 객체 지향적 개발을 잘 해온 개발자라면 당연한 내용들이어서 ‘이걸 외워야하나?’ 싶었지만 다른 사람들과 얘기할 때 원칙들을 딱 얘기하면 의사소통 비용이 줄어든다. 잘 알고 있는 개념들을 정리하고 자바의 List를 예시로 설명해본다. ",
    "url": "/docs/architecture/solid#solid-%EC%9B%90%EC%B9%99",
    
    "relUrl": "/docs/architecture/solid#solid-원칙"
  },"705": {
    "doc": "객체 지향 설계의 5가지 원칙 SOLID 헷갈리지 않게 예제로 이해하기",
    "title": "SRP, Single Responsibility Principle",
    "content": "단일 책임 원칙은 가장 이해하기 쉬운 원칙이다. 하나의 책임만을 가져야한다는 이름과 아주 걸맞는 원칙이기 때문이다. Class has one job to do. Each change in requirements can be done by changing just one class. - wiki . 클래스는 단 하나의 책임만 가져야 한다. 각 요구사항의 변경은 하나의 클래스의 변경으로 만족되어야 한다. 이 말은 결국 클래스가 단 하나의 책임만 가져야 한다는 말이면서 동시에 하나의 책임이 여러 클래스로 나뉘어선 안된다는 말이다. 결국 여러 책임을 갖지 않도록 하여 결합도를 낮추고, 책임이 온전히 하나의 클래스게 있게 함으로써 응집도를 높히는 원칙이다. 이를 통해 유지보수와 확장이 용이한 구조를 갖는다. 단일 책임 원칙을 지키지 않을 경우 하나의 변경으로 인해 여러 기능에 영향을 미칠 수 있다. 클래스가 단 하나의 책임만 가져야 한다를 어기는 경우 :x: 클래스가 여러 책임을 가짐으로써 하나의 기능 변경으로 인해 여러 기능이 변경될 가능성(위험)이 있다. :x: 클래스를 사용할 때 필요하지 않은 책임까지 갖게된다. 하나의 책임이 여러 클래스로 나뉘어선 안된다 를 어기는 경우 :x: 하나의 기능 변경을 위해 여러 클래스가 바뀌어야 한다. :x: 변경해야 하는 클래스를 놓칠 가능성(위험)이 있다. 객체 지향은 객체를 나누는 것이고, 객체를 나누는 이유는 책임을 명확히하고 재사용하기 위함이다. SRP를 지키지 않는 것은 객체 지향의 이점을 포기하는 것과 같다. 예시 . Java의 ArrayList를 보자. ArrayList는 list 자료구조를 내부적으로 array를 가지고 구현하는 하나의 책임만을 가진다. list에서 제공하는 추가, 삭제, iteration을 구현한다. ArrayList가 array가 아닌 list의 기능을 구현하거나 set 등의 다른 자료구조를 구현했다면 SRP를 위배하는 클래스가 됐을 것이다. ",
    "url": "/docs/architecture/solid#srp-single-responsibility-principle",
    
    "relUrl": "/docs/architecture/solid#srp-single-responsibility-principle"
  },"706": {
    "doc": "객체 지향 설계의 5가지 원칙 SOLID 헷갈리지 않게 예제로 이해하기",
    "title": "OCP, Open Closed Principle",
    "content": "개방 폐쇄 원칙은 내가 맨날 헷갈렸던 원칙이다. “뭘 개방하고 뭘 폐쇄하는데?” 라는 생각을 아주 자주하게 만들었더 원칙. Class is happy (open) to be used by others. Class is not happy (closed) to be changed by others. - wiki . 클래스는 다른 클래스에 의해 사용(확장)되는데 열려 있어야 한다. 클래스는 다른 것들에 의해 변경(수정)되는데 닫혀 있어야 한다. 즉 개방한다는 것은 기능을 추가하는 것에 개방해야한다는 말이고, 폐쇄한다는 것은 기능이 추가될 때 기존의 코드 변경에 폐쇄되어야 한다는 말이다. 이 원칙을 주로 확장으로 표현하는데 이 단어가 나를 더 헷갈리게 만든 것 같다. 원칙적인 OCP는 인터페이스 구현을 통한 확장 뿐 아니라 기능이 추가되는 모든 상황들을 말하고 있다. OCP를 어기는 경우 :x: 클래스간 결합도가 높아지고 코드 변경이 다른 클래스에 영향을 미친다. :x: 재사용성이 감소하고 확장이 어려워진다. 예시 . 다시 ArrayList를 보자. ArrayList는 List 인터페이스를 상속하고 있는데, 이 List 인터페이스에 LinkedList라는 새로운 클래스를 구현하려고 한다. LinkedList 구현으로 인한 기능 추가는 Open이 되며, 구현으로 인해 ArrayList나 List가 수정될 필요는 없으므로 Close한 구조이다. ",
    "url": "/docs/architecture/solid#ocp-open-closed-principle",
    
    "relUrl": "/docs/architecture/solid#ocp-open-closed-principle"
  },"707": {
    "doc": "객체 지향 설계의 5가지 원칙 SOLID 헷갈리지 않게 예제로 이해하기",
    "title": "LSP, Liskov Substitution Principle",
    "content": "“리스코프라는 사람 참 대단하다.” 라는 생각이 들었던 원칙. 굳이 왜 이것만 사람 이름일까 싶긴한데 원칙 자체는 쉽다. Class can be replaced by any of its children. Children classes inherit parent’s behaviours. - wiki . 클래스는 하위 클래스로 대체 될 수 있어야 한다. 즉 하위 클래스는 상위 클래스가 할 수 있는 기능들을 모두 수행할 수 있어야 한다는 말이다. LSP를 어기는 경우 :x: 다형성(Polymorphism)을 보장할 수 없다. :x: 이로 인해 기능을 예측할 수 없고 안정성이 떨어진다. 객체지향에서 가장 중요한 것은 인터페이스를 분리하는 것이고, 이 원칙을 어긴다는 것은 인터페이스를 통해 얻을 수 있는 다형성의 이점을 포기한다는 것이다. LSP를 지키지 않는다는 것은 인터페이스를 사용하지 않는 편이 옳다. 예시 . List와 ArrayList를 보자. 일반적으로 아래와 같이 사용한다. class TestObject { List propertyList; void test(List paramList) { // do something } } . 그치만 이 List들은 ArrayList로 바뀌어도 내부 동작에는 아무런 영향이 없다. 물론 List로 어떤 동작을 하느냐에 따라 어떤 List를 사용하는 것이 성능에 영향을 줄 수는 있지만 동일한 기능들을 수행할 수 있다. class TestObject { ArrayList propertyList; void test(ArrayList paramList) { // do something } } . ",
    "url": "/docs/architecture/solid#lsp-liskov-substitution-principle",
    
    "relUrl": "/docs/architecture/solid#lsp-liskov-substitution-principle"
  },"708": {
    "doc": "객체 지향 설계의 5가지 원칙 SOLID 헷갈리지 않게 예제로 이해하기",
    "title": "ISP, Interface Segregation Principle",
    "content": "“인터페이스를 분리한다는 것은 결국 인터페이스의 기능(책임)을 나눈다는 점에서 SRP에 속한 원칙이 아닌가?” 라는 생각을 했던 원칙. 조금 다른 점은 SRP는 클래스 내부의 책임에 대한 내용이라면 ISP는 인터페이스의 책임에 대한 내용이라고 볼 수 있다. When classes promise each other something, they should separate these promises (interfaces) into many small promises, so it’s easier to understand. - wiki . 클래스가 몇 가지 기능들을 제공하기로 약속되어 있다면 이런 약속들은 이해하기 쉽게 작은 인터페이스들로 나뉘어야 한다는 말이다. 대부분의 객체 지향 언어들은 클래스가 여러 인터페이스를 상속받을 수 있다. 인터페이스를 명확하게 나눔으로써 각 객체가 구현하는 내용들을 명확하게 하고 이해하기 쉽게 한다. 작은 인터페이스들로 나뉘어야 한다를 어기는 경우 :x: 클라이언트가 필요하지 않고 사용하지 않는 함수에도 의존관계를 갖게된다. :x: 인터페이스 변경 시 영향도가 증가한다. :x: 따라서 유연성이 감소하고 테스트가 어려워진다. 결국 다시 인터페이스. 인터페이스를 어떻게 나누어야 올바른지를 제시하는 원칙이다. ISP를 적용하지 않고 인터페이스를 그냥 만든다면 그냥 함수 명세만 적어놓은 것에 불과하다. 예시 . public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable { // ... } . abstract class는 잠시 접어두고 ArrayList는 4가지의 인터페이스를 상속하고 있다. ArrayList는 일단 List라는 약속을 지켜야하고, RandomAccess가 가능해야하고 Clone, Serialize가 가능해야 한다. 이 인터페이스들의 일부가 나뉘어있지 않거나 혹은 전체가 List 인터페이스 속에 있었다고 가정하면 인터페이스 변경에 따라 바뀌어야 할 클래스들이 많아질 것이다. 따라서 명확한 기능에 맞게 인터페이스를 나누는 것이 중요하다. ",
    "url": "/docs/architecture/solid#isp-interface-segregation-principle",
    
    "relUrl": "/docs/architecture/solid#isp-interface-segregation-principle"
  },"709": {
    "doc": "객체 지향 설계의 5가지 원칙 SOLID 헷갈리지 않게 예제로 이해하기",
    "title": "DIP, Dependency Inversion Principle",
    "content": "나는 왜 이게 의존성 역전 원칙인거지? 하는 생각이 많이 들었다. 일반적으로 고수준 클래스가 저수준 클래스에 의존하는데, 이 방향을 interface(추상화)를 통해 의존성 방향을 반대로 한다는 것이다. Layered 아키텍처를 기준으로 생각해보면 고수준이 저수준을 의존하는게 당연하니, 이 방향을 interface로 역전하는 것에 대한 이야기. 나는 MSA가 익숙해서 이게 역전이라고 생각하지 않았던게 이해를 방해했다. When classes talk to each other in a very specific way, they both depend on each other to never change. Instead classes should use promises (interfaces, parents), so classes can change as long as they keep the promise. - wiki . 클래스가 구체적으로 소통한다면 서로에게 의존성이 생기고 바뀔 수 없다. 클래스는 약속을 정의한 인터페이스를 사용하여 약속 안에서 수정 가능하도록 해야한다. 인터페이스를 명확하게 정의하고 인터페이스 안에서 수정이 가능하도록 하자는 방향이다. 여기서 인터페이스란 java interface 뿐 아니라 클라이언트와 약속한 함수 명세들을 의미한다고 보는 편이 맞다. 결국 인터페이스란 클라이언트와의 약속이고, 변경은 최대한 약속을 깨지 않는 선에서 이뤄져야 한다. 인터페이스가 없다면 약속없이 맘대로 쓴다는 것이다. 약속을 정의한 인터페이스를 사용하여 약속 안에서 수정 가능하도록 해야한다를 어기는 경우 :x: 클래스간의 결합도가 높아지고 의존성이 불분명해진다. :x: 변경이 발생할 때마다 클라이언트에도 영향을 줄 수 있다. :x: 따라서 재사용성이 낮아지고 유연성이 떨어진다. 예시 . public interface List&lt;E&gt; extends Collection&lt;E&gt; { Iterator&lt;E&gt; iterator(); // ... } . List 인터페이스는 Iterator 라는 인터페이스에 의존하고 있다. List가 더 고수준이기 때문에 저수준인 Iterator 인터페이스를 의존하는건 당연하지만, CharIterator와 같은 구체적인 클래스에 의존하지 않고 약속된 인터페이스에 의존함으로써 결합도를 낮추고 변경에 유연할 수 있다. ",
    "url": "/docs/architecture/solid#dip-dependency-inversion-principle",
    
    "relUrl": "/docs/architecture/solid#dip-dependency-inversion-principle"
  },"710": {
    "doc": "객체 지향 설계의 5가지 원칙 SOLID 헷갈리지 않게 예제로 이해하기",
    "title": "reference",
    "content": ". | SOLID wiki, https://simple.wikipedia.org/wiki/SOLID_(object-oriented_design) | OCP, https://en.wikipedia.org/wiki/Open%E2%80%93closed_principle | . ",
    "url": "/docs/architecture/solid#reference",
    
    "relUrl": "/docs/architecture/solid#reference"
  },"711": {
    "doc": "객체 지향 설계의 5가지 원칙 SOLID 헷갈리지 않게 예제로 이해하기",
    "title": "객체 지향 설계의 5가지 원칙 SOLID 헷갈리지 않게 예제로 이해하기",
    "content": "SOLID 원칙은 당연하기도 하고 중요하기도 한 객체 지향 설계에서의 기본 원칙이다. SOLID 원칙을 몰랐던 사람은 없겠지만 이걸 헷갈리고 까먹는 사람들은 제법 많다. 나도 그 중 한 명이고. 어떻게 까먹지 않을 수 있을까 고민하다가 예제와 같이 정리해본다. ",
    "url": "/docs/architecture/solid",
    
    "relUrl": "/docs/architecture/solid"
  },"712": {
    "doc": "파이썬에서 root directory를 library로 쉽게 찾는 방법",
    "title": "파이썬에서 root directory를 library로 쉽게 찾는 방법",
    "content": "rootdir . find rootdir add rootdir path for import . 파이썬에서 root directory를 찾기란 쉽지 않다. rootdir library를 통해 root directory를 직관적이고, 빠르고, 쉽게 찾을 수 있다. Usage . | pip install rootdir로 rootdir를 설치한다. | __root__.py를 root path에 추가한다. | import rootdir로 rootdir를 import 한다. | rootdir.root_dir(__file__)로 rootdir을 확인한다. | . example . 만약 root directory가 필요하다면 아래와 같은 코드로 쉽게 확인할 수 있다. 아래 코드를 복사하여 동작을 확인할 수 있다. import rootdir if __name__ == \"__main__\": print(rootdir.root_dir(__file__)) . sample . 아래와 같은 sample project1를 참고하면, rootdir를 더 잘 이해하고 효율적으로 활용할 수 있다. └── example/ ├── a/ │ └── a_1.py ├── b/ │ ├── b_1/ │ │ ├── b_1_1/ │ │ │ └── b_1_1_1.py │ │ └── b_1_2.py │ └── b_2.py ├── main.py └── __root__.py . __root__.py를 추가했다면 어느곳에서든 rootdir를 통해 root directory를 찾을 수 있다. 예를 들면 b_1_1_1.py에서는 아래와 같이 rootdir를 찾을 수 있다. import rootdir if __name__ == \"__main__\": print(rootdir.root_dir(__file__)) . b_1_1_1.py 뿐만 아니라 b_1_2.py, b_2.py 등 어떤 프로젝트에서도 위 코드를 통해 동일하게 rootdir를 찾을 수 있다. | rootdir에 명시된 sample project에서 실제 sample project와 동작을 확인할 수 있다. &#8617; . | . ",
    "url": "/docs/algorithm/language/python/python-rootdir",
    
    "relUrl": "/docs/algorithm/language/python/python-rootdir"
  },"713": {
    "doc": "파이썬에서 다른 폴더 import 쉽게 하기",
    "title": "파이썬에서 다른 폴더 import 쉽게 하기",
    "content": "rootdir . find rootdir add rootdir path for import . 파이썬에서 다른 폴더에 있는 코드를 import 하는 것은 굉장히 불편한 일이다. python에서 import를 하기 위해선 적절한 path를 찾아서 sys.path.append(...)를 통해 추가 해줘야 한다. rootdir library를 통해 root directory를 직관적이고, 빠르고, 쉽게 추가할 수 있다. Usage . | pip install rootdir로 rootdir를 설치한다. | __root__.py를 root path에 추가한다. | import rootdir로 rootdir를 import 한다. | rootdir.root_dependency(__file__)로 rootdir를 추가한다. | . example . 만약 directory 구조의 python 프로젝트여서 다른 directory의 code를 import할 필요가 있다면 아래 코드를 복사하여 path를 추가하고, root directory 기반으로 import를 할 수 있다. import rootdir rootdir.root_dependency(__file__) . rootdir를 통해서 위와 같은 코드로 dependency를 path에 추가하는 것은 directory 구조와 관계 없이 어느 파일에서든 동일하게 import할 수 있다. sample . 아래와 같은 sample project1를 참고하면, rootdir를 더 잘 이해하고 효율적으로 활용할 수 있다. └── example/ ├── a/ │ └── a_1.py ├── b/ │ ├── b_1/ │ │ ├── b_1_1/ │ │ │ └── b_1_1_1.py │ │ └── b_1_2.py │ └── b_2.py ├── main.py └── __root__.py . __root__.py를 추가했다면 어느곳에서든 rootdir를 통해 root directory를 추가하여 import를 쉽게할 수 있다. 예를 들면 b_1_1_1.py에서는 아래와 같이 rootdir의 directory를 추가할 수 있다. import rootdir rootdir.root_dependency(__file__) from a.a_1 import print_a_1 if __name__ == \"__main__\": print(rootdir.root_dir(__file__)) print_a_1() . b_1_1_1.py 뿐만 아니라 b_1_2.py, b_2.py 등 어떤 프로젝트에서도 위 코드를 통해 동일하게 rootdir를 추가하고 동일하게 import 문을 활용할 수 있다. 번거로운 sys.path 추가 작업을 하지 않아도 되며 path 계산도 하지 않아도 된다. | rootdir에 명시된 sample project에서 실제 sample project와 동작을 확인할 수 있다. &#8617; . | . ",
    "url": "/docs/algorithm/language/python/python-import-rootdir",
    
    "relUrl": "/docs/algorithm/language/python/python-import-rootdir"
  },"714": {
    "doc": "DynamoDB Secondary Index: 주의 사항 및 비용 이슈",
    "title": "GSI (Global Secondary Index)",
    "content": "GSI는 이 인덱스에 대한 쿼리가 모든 파티션을 아우르며, 특정 파티션에 국한되지 않고 테이블 전체를 대상으로 쿼리를 수행할 수 있다는 점 때문에 Global 이라는 표현을 사용한다. | 파티션 키와 필요하다면 정렬 키를 가질 수 있으며 이는 원래 테이블의 파티션 키와 정렬 키와는 다른 값이다. | 키 값이 고유할 필요는 없다. | 테이블이 생성될 때 생성되거나 기존 테이블에 추가할 수 있다. | 테이블 생성 이후 삭제될 수 있다. | 최종 일관성만 지원한다. | 읽기 및 쓰기 작업에 대한 처리량(RCU, WCU)을 별도로 설정한다. | 쿼리는 인덱스에 프로젝션된 속성만 반환한다. | GSI는 최대 20개까지 생성할 수 있다. | . GSI의 파티션 . GSI에서는 키 값이 고유할 필요는 없다. 는 이유로, 동일한 key에 여러 데이터를 쌓을 수 있으며 이를 통해 GSI는 메인 테이블에서 할 수 없는 데이터 구조를 가져갈 수 있다. 예를 들면, main table에 name, age, country, passportNo이 있다고 하자. 고유한 값을 위해 primary key를 passportNo로 설정할 수 있을 것이다. 그런데 국가별로 query가 필요한 Usecase가 있다면, country를 GSI의 기본키로 선택할 수 있다. 이렇게 되면 country라는 동일한 key에 대해 고유하지 않은 여러 데이터를 쌓고 가져올 수 있는 구조를 만들 수 있다. 이런 구조가 안전할까? GSI는 내부에서 key를 가지고 샤딩하면서 partition을 나눠주기 때문에 안전하다. 동일한 key로 이론상으로는 제한 없이 데이터를 넣을 수 있는 것이다. 사실 이건 main table도 동일하나, main table에서는 동일한 primary key에 대해 여러 데이터를 가질 수 없다. GSI의 CU (Capacity Unit) . GSI는 main table과 CU가 분리되어 있다. GSI에서 읽을 때, 쓸 때 CU를 각각 소모한다는 것인데, main table 동작과도 연관이 있다. GSI의 RCU의 경우 throttling이 나더라도 main table에 영향을 주지 않는다. GSI의 WCU의 경우 throttling이 나는 경우 main table의 write도 실패하게 된다. DynamoDB는 내부적으로 main table과 변경되는 데이터와 관련된 GSI를 모두 write1 하기 때문에 GSI에 write가 실패하는 경우 main table도 실패하게 된다. 정리하자면 DynamoDB의 write는 GSI의 write로 이어진다. DynamoDB의 update는 경우에 따라 GSI의 delete &amp; write로 이어질 수 있다. 위의 예시를 다시 보면, country가 KR에서 US로 바뀌는 경우 GSI의 KR 키에 프로젝션된 데이터가 delete 되고, US 키에 프로젝션된 데이터가 write 된다. 이 케이스에선 DynamoDB write 하나에 2개의 CU가 소모된다. DynamoDB의 요금에서 상당수를 차지하는 것이 CU이기 때문에 write 한번에 3개의 CU(main table write 1번 + GSI write 2번)을 사용하는 데이터 구조는 비용 측면에서 좋은 방향은 아니다. DynamoDB table에 여러 개의 GSI가 적용될 수 있기 때문에, DynamoDB의 GSI를 설계할 때 비용 측면도 같이 고려될 필요가 있다. ",
    "url": "/docs/aws/dynamo/si#gsi-global-secondary-index",
    
    "relUrl": "/docs/aws/dynamo/si#gsi-global-secondary-index"
  },"715": {
    "doc": "DynamoDB Secondary Index: 주의 사항 및 비용 이슈",
    "title": "LSI (Local Secondary Index)",
    "content": "LSI는 인덱스가 특정 파티션 키를 가진 항목과 같은 테이블 파티션에 위치해 있기 때문에 Local 이라고 표현한다. 즉, 같은 파티션 키 값을 가진 애들에 대한 쿼리로 지정된 파티션 키 값의 데이터만 쿼리할 수 있다. | Local Secondary Index의 파티션 키는 테이블의 파티션 키와 같다. | 테이블이 생성될 때만 생성될 수 있다. | 테이블 생성 이후 삭제될 수 없다. | 최종 일관성과 강력한 일관성을 지원한다. | 별도로 프로비저닝된 처리량이 없이 테이블의 읽기 및 쓰기 용량을 사용한다. | 쿼리는 인덱스에 프로젝션되지 않은 속성을 반환할 수 있다. | 테이블에서 특정 파티션 키를 갖는 모든 항목과 이에 상응하는 Local Secondary Index 항목이 같은 파티션에 저장된다. 이런 항목 모음의 총 크기는 10GB를 초과할 수 없다. | LSI는 최대 5개까지 생성할 수 있다. | . LSI는 명확한 단점들이 있고, GSI 대비 장점이 뚜렷하지 않아 현재는 권장되지 않는다. | LSI의 경우 추가/삭제할 수 없다. | main table의 자원을 같이 사용한다. | partition key 별 10GB의 크기 제한이 존재한다. | . 대신 GSI를 사용하는 것이 좋다. | main table과 GSI table의 상관관계와 GSI CU 부족 시 main table의 영향도를 참고할 수 있다. &#8617; . | . ",
    "url": "/docs/aws/dynamo/si#lsi-local-secondary-index",
    
    "relUrl": "/docs/aws/dynamo/si#lsi-local-secondary-index"
  },"716": {
    "doc": "DynamoDB Secondary Index: 주의 사항 및 비용 이슈",
    "title": "DynamoDB Secondary Index: 주의 사항 및 비용 이슈",
    "content": "DynamoDB의 효율적인 query를 위해서 Secondary Index의 활용이 필요하다. DynamoDB에서는 Secondary Index를 사용하여 기본키 외에 대체키를 통해 테이블에서 데이터를 쿼리할 수 있다. Secondary Index는 아래 내용들을 포함한다. | 대체키 속성, 기본키 속성, 기본 테이블에 포함된 다른 속성의 선택적 하위 세트(프로젝션된 속성) | . DynamoDB는 자동으로 테이블의 기본키를 기반으로 인덱스를 생성하고 테이블이 변경될 때마다 자동으로 모든 인덱스를 업데이트한다. DynamoDB는 GSI, LSI 두 종류의 Secondary Index를 지원한다. LSI는 현재 AWS에서도 사용을 지양하고 있기 때문에 GSI 위주로 개념과 사용하면서 겪었던 주의사항들, LSI를 사용하지 않는 이유를 정리한다. ",
    "url": "/docs/aws/dynamo/si",
    
    "relUrl": "/docs/aws/dynamo/si"
  },"717": {
    "doc": "DynamoDB Streams는 뭐고 언제 사용하는게 좋을까?",
    "title": "DynamoDB Streams",
    "content": "DynamoDB의 변경 사항을 캡처해서 전달하는 DynamoDB의 서비스이다. Streams은 다음과 같은 특징을 갖고 있다. | DynamoDB의 변경 사항 정보를 시간순으로 가지고 있는다. | Streams Record 통해 어떤 데이터가 변경되었는지 확인할 수 있다. | Streams Record는 24시간 동안 데이터를 저장한다. | AWS의 다른 서비스와 쉽게 결합하여 사용할 수 있다. | 활성화/비활성화가 쉬우며 DynamoDB 테이블에 영향을 미치지 않는다. | 전달할 정보를 지정할 수 있다. | KEYS_ONLY, NEW_IMAGE, OLD_IMAGE, NEW_AND_OLD_IMAGE | . | . 모든 변경 사항을 Streams로 받을 수 있기 때문에 Streams의 활용 방안은 다양하다. 데이터 분석이나, 비동기 작업, 데이터 복제, 백업, 이벤트 전달 등의 목적으로도 사용할 수 있다. 그러나 앞서 말했듯 문제는 비용이다. 모든 변경 사항이 Streams로 전달된다는 것은, 모든 변경 사항에 대해 추가 비용이 발생한다는 것이다. ",
    "url": "/docs/aws/dynamo/streams#dynamodb-streams",
    
    "relUrl": "/docs/aws/dynamo/streams#dynamodb-streams"
  },"718": {
    "doc": "DynamoDB Streams는 뭐고 언제 사용하는게 좋을까?",
    "title": "언제 사용하는게 좋을까?",
    "content": "비용에 대한 압박이 없다면 앞서 언급한 데이터 분석, 비동기 작업, 데이터 복제 등의 모든 케이스에서 Streams를 편리하게 사용할 수 있다. 그러나 사용량이 증가함에 따라 가파르게 증가하는 클라우드 비용을 고려했을 때, 단순히 현재 비용이 적다는 이유만으로 Streams를 많이 사용하는 것은 적절하지 않을 수 있다. 이번에 새로운 시스템을 설계하면서 Streams가 아주 적절한 케이스를 발견했다. 우리는 확장성을 고려하여 user table을 DynamoDB로 설계를 하였고 user에 대한 통계를 고려하고 있었다. 통계를 쉽게 뽑기 위해선 다양한 query가 가능한 DB가 필요했다. user DB와 같은 경우 데이터는 무한정 증가할 수 없다. (전세계 인구가 user가 된다고 하더라도 70억에 불과하다.) 동시에 user DB의 경우 데이터 변화가 잦지 않다. 따라서 쌓이는 데이터는 많을 수 있으나, 서비스를 지속하면서 발생하는 Streams 자체는 많지 않은 케이스이다. 인스타그램으로 예시를 들어보자. 인스타그램은 약 15억 사용자를 보유하고 있으며 하루에 약 1억 건의 포스팅이 생긴다고 한다. 포스팅에 대한 데이터를 DynamoDB에 저장하고 Streams를 사용한다면 매일 적어도 1억 건 이상의 Streams Record가 발생하게 될 것이며 이는 비용상 이슈가 될 수 있다. 그러나 15억 사용자를 고려하면 사용자 데이터는 대부분 가입 시나리오에서 업데이트 되며, 그 이후로 변경사항이 잦지 않다. 인스타그램을 서비스하는 수 년 동안 15억 건의 Streams Record가 발생한다고 한다면, 이는 아주 저렴한 비용임을 확인할 수 있다. ",
    "url": "/docs/aws/dynamo/streams#%EC%96%B8%EC%A0%9C-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94%EA%B2%8C-%EC%A2%8B%EC%9D%84%EA%B9%8C",
    
    "relUrl": "/docs/aws/dynamo/streams#언제-사용하는게-좋을까"
  },"719": {
    "doc": "DynamoDB Streams는 뭐고 언제 사용하는게 좋을까?",
    "title": "비용에 대한 계산",
    "content": "일반적으로 많이 사용하는 Streams와 Lambda를 통해 비용을 산정해본다. 비용은 현재 문서를 작성하는 24년 6월 24일 기준으로 aws 비용문서1 기준으로 정리한다. 한국(서울), 미국(오레곤), 유럽(아일랜드)의 비용이 동일했다. Streams . | 매달 첫 DynamoDB Streams 읽기 요청 유닛 250만 건은 무료 | 이후 DynamoDB Streams 읽기 요청 유닛 10만 건당 0.0217 USD | DynamoDB Streams에서 데이터 읽기 작업에 대한 요금을 청구하나 lambda에서 호출하는 경우 무료2 | . Streams의 경우 Lambda와 함께 사용할 경우 읽기 요청에 대한 비용이 발생하지 않는다. Lambda . lambda는 계산이 좀 복잡하다. CPU 초당 요금과, 건당 요금, 메모리 요금을 별도로 과금한다. CPU (x86) 요금 . | 처음 60억GB-초/월 GB-초당 0.0000166667 USD | 다음 90억GB-초/월 GB-초당 0.000015 USD | 다음 150억GB-초/월 GB-초당 0.0000133334 USD | . 호출 건당 요금 . | 요청 1백만 건당 0.20 USD | . 메모리(MB) 1밀리초당 요금 . | 128 0.0000000021 USD | 512 0.0000000083 USD | 1,024 0.0000000167 USD | 1,536 0.0000000250 USD | 2,048 0.0000000333 USD | . 비용 예시 및 계산 . 인스타그램의 user db를 DynamoDB Streams와 Lambda를 사용하여 통계 DB로 연동하는 설계에 대한 비용을 계산해본다. | AWS RDS가 필요하겠지만 이 비용은 여기에 포함하지 않는다. | 시나리오: 15억 건의 유저 데이터가 DynamoDB Streams를 통해 Lambda로 요청된다. | 가정 . | 128MB의 가장 저렴한 메모리를 사용하며, lambda를 1초간 사용한다고 가정한다. | . | 총 비용: $28,450 . | Streams: $0 | CPU 초당 요금: $25,000 (0.0000166667 * 1,500,000,000) | CPU 건당 요금: $300 (0.20 * 1,500) | 메모리 요금: $3,150 (0.0000000021 * 1,500,000,000 * 1,000) | . | . 물론 실제 서비스에서는 유저 변경에 따른 Streams Record 발행이 더 발생할 수 있다. 그러나 서비스를 수 년간 운영하며 Streams 도입 비용 총 $28,000를 지불한다면 서비스 규모 대비 매우 작은 비용이라고 예상된다. 비용 효율화하기 . Streams에서는 Record를 batch로 받음으로써 lambda 비용을 절약할 수 있다. 아래 property를 수정하여 batch로 record를 수신할 수 있다. Batch size3: . | 각 Batch에서 Lambda에 보낼 Record count. | max 10,000개이며 한 번의 호출로 복수 개의 Record가 전달된다. | Payload 한도인 6MB를 넘을 수 없다. | . Batch window3: . | Lambda로 호출되기 전까지 Record를 수집할 시간. (단위 second) | . Batch Size가 1000, Batch window가 10으로 설정했다고 하자. Record를 수집해 1000개가 넘는다면 Lambda가 호출되고, 1000개가 넘지 않으면 10초 후에 Lambda가 호출된다. 참고할 점은 Batch Size와 Window는 Streams 내부의 shard 단위로 동작4 한다는 것이다. 10개의 Shard가 있다면 각각의 shard에 Batch window와 Size가 적용되기 때문에, 10초의 Batch window 동안 10개의 shard가 각각 한 개씩 총 10개의 lambda가 호출될 수 있다. 그렇기 때문에 Batch Size만큼의 데이터를 보낸다고 Batch Size 크기의 Record에 대한 Lambda 호출이 발생하는 것은 아니다. | Streams 비용문서와 Lambda 비용문서를 참고한다. &#8617; . | Streams 사용량 문서에서 Lambda와 함께 용할 때의 비용을 확인할 수 있다. &#8617; . | batch window와 size에 대한 spec 문서에서 property를 확인한다. &#8617; &#8617;2 . | Streams의 shard와 Stremas Batch의 관계를 설명하는 stackoverflow를 참고한다. &#8617; . | . ",
    "url": "/docs/aws/dynamo/streams#%EB%B9%84%EC%9A%A9%EC%97%90-%EB%8C%80%ED%95%9C-%EA%B3%84%EC%82%B0",
    
    "relUrl": "/docs/aws/dynamo/streams#비용에-대한-계산"
  },"720": {
    "doc": "DynamoDB Streams는 뭐고 언제 사용하는게 좋을까?",
    "title": "DynamoDB Streams는 뭐고 언제 사용하는게 좋을까?",
    "content": "서비스가 성숙기에 접어들게 되면, 회사에선 서비스 비용을 줄이기 시작한다. 우리는 성숙기에 접어든지 한참 된 서비스이기 때문에 매년 비용에 대한 압박을 받게 된다. ‘이런 상황에서 DynamoDB의 Streams가 아무리 좋다고 한들, 쓸 수 있을까?’ 라는 생각이 항상 들었다. 그런데 아주 적합한 케이스를 찾았다. 우선 DynamoDB Streams가 뭔지 알아보자. ",
    "url": "/docs/aws/dynamo/streams",
    
    "relUrl": "/docs/aws/dynamo/streams"
  },"721": {
    "doc": "백업을 개발할 때 고려해야할 10 가지 사항들",
    "title": "백업 도메인에서 고려할 사항들",
    "content": ". | 백업과 복원의 시작과 마침을 구분하기 | revision을 고려하기 | 백업의 lifecycle을 관리하기 | 데이터를 잃지 않기 | 복원에 신경 쓰기 | 락은 없어도 될거야 | 어떤 종류의 백업일까 | 자동 백업의 시간 고려하기 | 복원 사용성 이해하기 | 정책 관리하기 | . 용어 정리 . | 용어 | 의미 | . | 백업 | 사용자가 기기의 데이터를 서버에 올리는 프로세스 | . | 자동 백업 | 조건에 따라 백업이 자동으로 진행되는 기능 | . | 복원 | 사용자가 서버에 저장한 데이터를 기기로 가져가는 프로세스 | . | revision | 백업이 여러 차례 반복될 때 각 백업된 데이터를 분리하는 기준 | . | Snapshot | 각 백업 요청으로 저장된 기기의 데이터 | . | Full Backup | 매 백업마다 전체 데이터를 올리는 백업 프로세스 | . | Incremental Backup | 백업 시에 기존 백업에서 추가된 데이터를 올리는 백업 프로세스 | . 1. 백업과 복원의 시작과 마침을 구분하기 . 백업은 각 데이터들을 백업하고 완료된다. 복원도 마찬가지. 백업으로 각 데이터를 받아가는 interface를 만들면 기능은 만족할 수 있다. 큰 데이터를 백업할 때 네트워크에 따라 수 시간이 걸리는 백업이 수 천건 이상의 api 호출로 이뤄질 수 있다. 기준점이 없다면 백업의 기능은 만족하지만 사용자가 백업이 끝난건지, 멈춘건지를 알 수 없다. 그렇지만 백업과 복원의 기준점이 필요하다. 기준점이라는 것은 백업/복원의 시작과 완료. 이 기준점이 없다면 백업이 끝났는지, 문제가 생겼는지를 파악할 수 없다. 성능/이슈/사용성 분석 등의 목적으로 백업과 복원이 시작한 시간과 끝나는 시간을 파악할 수 있어야 한다. 물론 백업 시작/완료의 api가 그저 기준점의 목적으로만 사용되진 않는다. | Snapshot에 대한 처리 등으로 사용할 수 있다. | . 2. revision을 고려하기 . 사용자가 새로운 백업을 요청할 때, 기존 백업과 구분이 되어야 한다. | 백업을 진행 중인 경우에 복원을 하는 경우에는 기존 백업이 복원되어야 한다. | 백업을 진행하다가 멈춘 경우 완료되지 않은 백업이 기존에 완료된 백업을 덮어써서는 안된다. | . 따라서 데이터 키를 설계할 때 revision이 들어가야 한다. revision은 백업 overwrite 등의 케이스에서 위와 같이 visibility를 관리하고 async GC(이전 백업 삭제)를 가능하게 한다. 3. 백업의 lifecycle을 관리하기 . 백업은 데이터가 크니까 삭제가 정확하게 되어야 한다. 큰 데이터가 남아 있다면 비용으로 직결된다. 삭제가 정확하게 되지 않는다면 비용을 쌓아두게 된다. 백업은 lifecycle policy에 따라 수 일에서 수 년까지 데이터가 유지될 수 있다. 따라서 삭제 배치를 통해 async로 지우게 되며 batch 설계는 안정적이고 정확해야 한다. 삭제가 비동기적으로 이뤄지는 만큼 삭제를 놓치기 쉽다. 놓친 삭제는 그만큼의 비용과 추가 작업으로 이어진다. 백업의 특성상 데이터를 지우게 될 때는 특정 백업의 스냅샷이 지워지는 경우가 많다. 따라서 revision을 고려하기에 신경써서 삭제까지 설계가 이어지는게 좋다. 4. 데이터를 잃지 않기 . 너무나도 당연한 얘기지만 백업 서버의 설계 원칙의 가장 첫 번째는 사용자 데이터를 유실하지 않는 것이다. 의외로 서비스를 하다보면 데이터를 잃을 수 있는 상황으로 이어지는 경우가 많다. 새로운 기능을 설계할 때 비용이나 효율성, 운영상의 이슈를 들며 데이터를 잃을 수 있는 가능성이 있는 방향으로 설계를 선택하는 개발자들을 자주 보게 된다. 사용자의 데이터를 백업한다는 것. 사용자의 데이터를 관리한다는 것은 어떤 상황에도 데이터를 잃지 않아야 한다는 것. 유실하지 않는 구조 뿐만 아니라, 언젠가 사람의 실수로 유실할수도 있는 상황 조차 만들지 않는 것이 중요하다. 하나의 예로 운영이나 편의상의 이슈로 배치가 직접 사용자의 데이터의 저장소에 배치가 접근하는 것. 이건 추후 was의 스키마 변경이나 저장소 접근 로직 등의 변화가 배치까지 적용되지 않는 경우 치명적인 사용자 데이터 유실을 초래할 수 있으며 (실제 있었던 이슈), 지양해야 하는 부분이다. 이것들을 챙기면 문제 없는 시스템 이 아니라 아무것도 신경 쓰지 않아도 문제 없는 시스템 으로 최대한 가는 것이 옳다. 5. 복원에 신경 쓰기 . 데이터를 잃지 않기 것과 유사하게 중요한 것은 복원 데이터를 안전하게 내려주는 것이다. 백업과 동기화의 가장 큰 차이점은 백업은 데이터를 보관하는 것이고, 동기화는 데이터를 실시간으로 업데이트 하는 것이다. 따라서 백업은 데이터를 업로드만 한다. 자동 백업 기능이 있다면 데이터는 주기적으로 업로드 되겠지만, 다운로드 되는 경우는 사용자가 복원을 요청할 때 뿐이다. 그렇다는 것은 데이터가 잘못 내려간다면 다음 복원 요청까지 데이터를 고쳐줄 방법이 없다는 것. 이미 복원된 항목을 제외하도록 클라이언트가 구현되어 있다면 다음 복원 요청에서도 고쳐주지 못할지도 모른다. 당연히 데이터는 안정적으로 내려줘야 하지만, 백업의 복원 만큼은 안정적으로 내려주지 못한다면 내려주지 않는게 나을 수 있다. 동기화는 수시로 데이터를 동기화 하기 때문에 잘못 준 데이터를 고쳐줄 수 있는 여지가 더 많다. 6. 락은 없어도 될거야 . 일반 적인 경우에 백업은 대부분 특정 기기의 백업이 되곤 한다. 그렇다는건 여러 기기에서의 동시 요청에 대한 고려를 하지 않아도 된다는 것이다. 동시 요청이 없다는 건 동시 쓰기가 없다는 것. 설계에 따라 락을 잡을 필요가 없을 수도 있다. 그러나 백업(write)과 동시에 복원(read) 요청이 들어올 수는 있다. 반면 동기화의 경우 여러 디바이스, 혹은 여러 사용자의 요청에 의해 동일한 아이템이 수정되는 케이스가 있어 락이 필수이다. 7. 어떤 종류의 백업일까 . backup을 다루는 팀마다 용어는 다르겠지만 백업의 종류는 크게 두 가지1가 있다. | Full Backup - backup 데이터와 관계 없이 전체 백업 | Incremental Backup - backup된 데이터 이후 변경된 데이터만 백업 | . 요구사항과 백업 데이터의 특성에 따라 적절한 백업 종류를 선택해야 한다. 우리는 다른 특성을 갖는 여러 컨텐트를 백업하고 있어 특성에 맞게 두 가지 백업을 모두 사용했다. 8. 자동 백업의 시간 고려하기 . 요즘은 백업을 한다면 자동 백업이라는 옵션이 존재하는 경우가 많다. 보통 자동 백업은 사용자에게 영향을 주지 않기 위해 백업 시간이 조정되는 경우가 많다. 주로 밤이다. 만약 클라이언트가 매일 0시에 자동 백업을 하도록 구현했다면, 모든 백업 트래픽은 0시에 몰리게 된다. 자동 백업 시간은 클라이언트의 개발 사항이지만 서버에서도 체크가 필요하다. 이를 고려하더라도 시간 대에 따른 요청은 어쩔 수 없고, 백업 서비스는 peak와 non-peak의 api 호출량 차이가 크다. 9. 복원 사용성 이해하기 . 복원만의 특성도 있다. 우선 자동 백업의 시간 고려하기와 반대로 복원은 주로 사용자가 깨어 있는 낮 시간에 요청된다. 사용자들은 백업은 여러번 수행하나, 복원은 한 번 혹은 한 번도 하지 않는 경우도 많다. 따라서 백업 대비 복원 요청은 한참 적다. 그러나 백업보다 복원이 사용자에게 더 중요한 경험이기 때문에 복원 기능이 더 잘 관리 되어야 한다. | 백업 지표에 복원이 묻히지 않도록 지표를 분리 / 관리해야 한다. | . 10. 정책 관리하기 . 정책은 사실 모든 도메인에서 중요하다. Enterprise 급 서비스에서는 어떤 서비스든 정책을 정하지 않으면 상식을 넘어서는 어뷰징 유저를 만나게 된다. 우리는 일반적으로 300개 정도의 데이터를 갖는 백업에서 150만 개의 불가능한 데이터를 갖고 있는 어뷰징 유저를 보았다. 그러나 정책이 미리 정해지지 않았다면, 이미 추가된 어뷰징 유저를 처리하기는 어렵고, 어뷰징 유저를 위한 별도의 작업들이 필요할 수 있다. | 백업의 종류에 대한 AWS의 글 참고 &#8617; . | . ",
    "url": "/docs/career/domain/backup#%EB%B0%B1%EC%97%85-%EB%8F%84%EB%A9%94%EC%9D%B8%EC%97%90%EC%84%9C-%EA%B3%A0%EB%A0%A4%ED%95%A0-%EC%82%AC%ED%95%AD%EB%93%A4",
    
    "relUrl": "/docs/career/domain/backup#백업-도메인에서-고려할-사항들"
  },"722": {
    "doc": "백업을 개발할 때 고려해야할 10 가지 사항들",
    "title": "백업을 개발할 때 고려해야할 10 가지 사항들",
    "content": "백업 서비스를 잘 하기 위해서는 백업 도메인에서 고려해야 할 점들을 잘 인지해야 한다. 데이터를 서버에 올리고, 내려받는 점에서 동기화와 다를 것 없어보이지만 백업 서비스만의 특성들이 명확하다. ",
    "url": "/docs/career/domain/backup",
    
    "relUrl": "/docs/career/domain/backup"
  },"723": {
    "doc": "HATEOAS 란? HATEOAS를 사용하는 이유, 사용하지 않을 때의 문제점들",
    "title": "non-HATEOAS",
    "content": "1. 서버에서 데이터를 채워서 내려주는 경우 . Repository를 조회하고 필요한 User에 대한 추가 정보가 필요한 경우 Repository 조회 api에 User의 상세 정보가 추가된다. client는 Repository와 관련된 작은 User 정보를 같이 받는 것으로 시작하지만 요구사항 변화와 시간이 지나며 Repository 조회를 넘어서는 데이터가 반환되게 된다. 이런 요구사항들이 쌓여, Repository 조회 api는 Repository 조회 뿐 아니라 다른 여러 정보를 같이 내려주는 api가 될 수 있다. 문제점 . | api는 의도된 기능 이상의 역할을 수행하게 된다. | api를 이해하기가 어려워진다. | server는 api 지원을 위해 여러 도메인 개념들의 예외 처리를 고려해야 한다. | server는 해당 api의 어떤 값들이 client에서 사용되고 있는지 파악할 수 없다. | 여러 client를 지원하는 경우 client 간에 동일 기능을 제공하는 유사 api set이 생기게 될 수 있다. | . 2. client와 약속된 데이터의 api를 사용하는 경우 . Repository를 조회하고 필요한 User에 대한 추가 정보를 조회하기 위해 client가 약속된 api를 호출하게 된다. 아마 이 api는 get user api일 것이다. Repository에서 얻은 user의 id를 가지고 약속된 User 정보 조회 api를 호출하는 방식이 된다. client는 api endpoint를 하드코딩해서 사용해야 한다. client는 endpoint를 관리하는 주체가 되고 endpoint에 의존하게 된다. 문제점 . | client와 server 간에 endpoint라는 강한 결합이 생기게 된다. | client가 가진 endpoint로 생긴 결합으로 인해 server의 api 변경이 둔해진다. | server에서 api version update를 할 경우 client에 수정이 필요하다. | client와 api를 공유하고 이해시키는 작업이 필요하다. | 여러 client를 지원하는 경우 각 client에 api를 설명하는 overhead가 생긴다. | . ",
    "url": "/docs/apis/rest/hateoas#non-hateoas",
    
    "relUrl": "/docs/apis/rest/hateoas#non-hateoas"
  },"724": {
    "doc": "HATEOAS 란? HATEOAS를 사용하는 이유, 사용하지 않을 때의 문제점들",
    "title": "HATEOAS",
    "content": "Github의 Get Repository 조회 예시 . { \"id\": 1296269, \"node_id\": \"MDEwOlJlcG9zaXRvcnkxMjk2MjY5\", \"name\": \"Hello-World\", \"full_name\": \"octocat/Hello-World\", \"owner\": { \"login\": \"octocat\", \"id\": 1, \"node_id\": \"MDQ6VXNlcjE=\", \"avatar_url\": \"https://github.com/images/error/octocat_happy.gif\", \"gravatar_id\": \"\", \"url\": \"https://api.github.com/users/octocat\", \"html_url\": \"https://github.com/octocat\", \"followers_url\": \"https://api.github.com/users/octocat/followers\", \"following_url\": \"https://api.github.com/users/octocat/following{/other_user}\", \"gists_url\": \"https://api.github.com/users/octocat/gists{/gist_id}\", \"starred_url\": \"https://api.github.com/users/octocat/starred{/owner}{/repo}\", \"subscriptions_url\": \"https://api.github.com/users/octocat/subscriptions\", \"organizations_url\": \"https://api.github.com/users/octocat/orgs\", \"repos_url\": \"https://api.github.com/users/octocat/repos\", \"events_url\": \"https://api.github.com/users/octocat/events{/privacy}\", \"received_events_url\": \"https://api.github.com/users/octocat/received_events\", \"type\": \"User\", \"site_admin\": false } } . Github의 api를 참고해서 Repository를 조회하면 Response에 resource를 확인할 수 있는 Hypermedia url를 포함하여 제공한다. Github api spec을 확인하지 않더라도, 간결한 response에 담겨있는 내용을 명확하게 알 수 있다. owner의 각각의 resource가 필요하다면 각 응답으로 내려온 Hypermedia url을 통해 조회를 이어갈 수 있다. 각 api가 제공하는 resource와 api의 역할은 더 명확해지고 이렇게 HATEOAS는 그 자체로 self descriptive api documentation 역할을 할 수 있다. client와 server 사이에는 client가 원하는 state를 확인하기 위해 확인해야 하는 link가 어느 field의 link인지 알아야 한다는 최소한의 약속만 존재한다. client는 server가 제공하는 link를 따라가며 필요한 resource를 조회하며 상호작용한다. 따라서 client와 server 간의 결합이 최소화 되고 server는 client에 독립적으로 api를 변경할 수 있게 된다. 단점은 client가 link를 따라가며 state를 조회하므로 network overhead가 발생할 수 있다. ",
    "url": "/docs/apis/rest/hateoas#hateoas",
    
    "relUrl": "/docs/apis/rest/hateoas#hateoas"
  },"725": {
    "doc": "HATEOAS 란? HATEOAS를 사용하는 이유, 사용하지 않을 때의 문제점들",
    "title": "HATEOAS 란? HATEOAS를 사용하는 이유, 사용하지 않을 때의 문제점들",
    "content": "HATEOAS는 RESTful 웹 서비스의 설계 원칙 중 하나로 RESTful API을 self descriptive 하게 만들며 client와 server 간의 상호작용을 단순화하고 확장성을 높이는 기술이다. ‘Hypermedia as the Engine of Application State’ 의 약어로 server와 client의 상호작용을 동적으로 하기 위해 Hpyermedia를 사용하는 것을 원칙으로 한다. HATEOAS는 API response로 resource와 관련된 Hypermedia link를 제공하여 다음 동작을 제공된 Hypermedia에 따라 동적으로 결정할 수 있도록 한다. HATEOAS를 왜 쓰는지 이해하기 위해 HATEOAS를 사용하지 않는 경우들의 문제점들을 체크해본다. 비교를 위해 Github의 Repository 조회 api 구현을 예시로 들어본다. 핵심은 하나의 api에서 다른 데이터를 필요로 할 때 데이터가 어떻게 전달되느냐이다. | non-HATEOAS . | 서버에서 데이터를 채워서 내려주는 경우 | client와 약속된 데이터의 api를 사용하는 경우 | . | HATEOAS | . ",
    "url": "/docs/apis/rest/hateoas",
    
    "relUrl": "/docs/apis/rest/hateoas"
  },"726": {
    "doc": "About",
    "title": "About",
    "content": "다양한 종류의 데이터 동기화, 백업과 서비스 서버를 개발하고 있습니다. 하루 수 억건에 달하는 트래픽과 이를 처리하는 서버를 설계하고 개발합니다. ",
    "url": "/about/",
    
    "relUrl": "/about/"
  },"727": {
    "doc": "Algorithm",
    "title": "Algorithm",
    "content": " ",
    "url": "/docs/algorithm",
    
    "relUrl": "/docs/algorithm"
  },"728": {
    "doc": "APIs",
    "title": "APIs",
    "content": " ",
    "url": "/docs/apis/",
    
    "relUrl": "/docs/apis/"
  },"729": {
    "doc": "Architecture",
    "title": "Architecture",
    "content": " ",
    "url": "/docs/design/",
    
    "relUrl": "/docs/design/"
  },"730": {
    "doc": "aws",
    "title": "aws",
    "content": "AWS에서 시행하는 training 과정을 수료하면서 정리한 내용. | Developing on AWS | Advanced Developing on AWS | . 그리고 내가 사용하면서 정리한 내용. ",
    "url": "/docs/aws",
    
    "relUrl": "/docs/aws"
  },"731": {
    "doc": "blog",
    "title": "blog",
    "content": " ",
    "url": "/docs/blog",
    
    "relUrl": "/docs/blog"
  },"732": {
    "doc": "career",
    "title": "career",
    "content": " ",
    "url": "/docs/career/",
    
    "relUrl": "/docs/career/"
  },"733": {
    "doc": "-",
    "title": "-",
    "content": " ",
    "url": "/partition/10",
    
    "relUrl": "/partition/10"
  },"734": {
    "doc": "-",
    "title": "-",
    "content": " ",
    "url": "/partition/20",
    
    "relUrl": "/partition/20"
  },"735": {
    "doc": "-",
    "title": "-",
    "content": " ",
    "url": "/partition/30",
    
    "relUrl": "/partition/30"
  },"736": {
    "doc": "-",
    "title": "-",
    "content": " ",
    "url": "/partition/40",
    
    "relUrl": "/partition/40"
  },"737": {
    "doc": "-",
    "title": "-",
    "content": " ",
    "url": "/partition/50",
    
    "relUrl": "/partition/50"
  },"738": {
    "doc": "-",
    "title": "-",
    "content": " ",
    "url": "/partition/90",
    
    "relUrl": "/partition/90"
  },"739": {
    "doc": "db 개념",
    "title": "db 개념",
    "content": " ",
    "url": "/docs/db/concept",
    
    "relUrl": "/docs/db/concept"
  },"740": {
    "doc": "c++",
    "title": "c++",
    "content": " ",
    "url": "/docs/language/cpp",
    
    "relUrl": "/docs/language/cpp"
  },"741": {
    "doc": "Database",
    "title": "Database",
    "content": " ",
    "url": "/docs/db",
    
    "relUrl": "/docs/db"
  },"742": {
    "doc": "Domain Driven Design",
    "title": "Domain Driven Design",
    "content": "Vaughn Vernon의 IDDD 예제 코드 . | https://github.com/VaughnVernon/IDDD_Samples | . ",
    "url": "/docs/ddd",
    
    "relUrl": "/docs/ddd"
  },"743": {
    "doc": "Tools",
    "title": "Tools",
    "content": " ",
    "url": "/docs/dev-tools/",
    
    "relUrl": "/docs/dev-tools/"
  },"744": {
    "doc": "domain",
    "title": "domain",
    "content": " ",
    "url": "/docs/03.career/domain.html",
    
    "relUrl": "/docs/03.career/domain.html"
  },"745": {
    "doc": "DynamoDB",
    "title": "database option",
    "content": "AWS에는 DynamoDB 외에도 다양한 DB 서비스를 지원하고 있다. RDS: Aurora, PostgreSQL, MySQL, MariaDB, Oracle 등 다양한 관계형 데이터베이스 서비스를 제공한다. RDB를 간편하게 설정하고 크기 조정이 가능하다. DB 관리를 AWS에서 해줘서 서비스에 집중할 수 있다. | ex) 소프트웨어 패치, 데이터베이스 백업 | . Aurora: MySQL, PostgreSQL 호환 RDB로 MySQL보다 최대 5배 빠르며 1/10 수준 비용으로 서비스를 제공함. MySQL, PostgreSQL 보다 더 높은 처리량을 가지며 쉽게 확장/축소할 수 있음. Aurora Serverless 서비스도 있음. Redshift: 완전 관리형 데이터 웨어하우스. (나무위키 웨어하우스 참고. 의사 결정을 위한 데이터 사용) 기존 솔루션 비용의 1/10 미만으로 페타바이트 규모로 확장할 수 있음. 다양한 개방형 형식(csv, json, …) 지원. Neptune: 완전관리형 그래프 데이터베이스. ElastiCache: memCache나 Redis를 관리하는 관리형 상태로 지원하는 서비스. in memory data store, cache를 쉽게 배포/운영할 수 있음. 당연히 메모리를 사용하니까 DB보다 빠른 검색을 지원하고, 성능 향상을 볼 수 있다. Redis나 memcache를 활용하는 것으로 얘네의 장점을 보다 쉽게 적용할 수 있다. ",
    "url": "/docs/aws/dynamo#database-option",
    
    "relUrl": "/docs/aws/dynamo#database-option"
  },"746": {
    "doc": "DynamoDB",
    "title": "DynamoDB 구성",
    "content": "DynamoDB는 테이블, 항목, 속성으로 구성되고 각 항목들은 키 값을 갖는다. | 각각 엑셀의 시트, 행, 열로 생각할 수 있다. | . 스키마가 고정되어 있지 않기 때문에 항목에 속성의 추가가 자유롭다. DynamoDB는 테이블의 항목을 파티션 키에 따라 여러 항목으로 나누고 파티션은 스토리지로 백업되고 리전 내의 복수의 AZ에 자동으로 복제된다. | 파티션 단위로 다른 위치에 저장될 수 있다는 것. | . 데이터에 접근할 때는 파티션 키를 통해 접근하기 때문에 파티션 키는 고유한 값이어야 한다. 정렬 키는 선택적으로 사용되며 동일한 파티션 키를 사용하고 싶다면 정렬 키를 사용하여 파티션 키 + 정렬 키의 값이 고유하도록 구성할 수 있다. | ex) 파티션 키는 sessionId, 정렬 키는 Time으로 동일한 세션에 대해 같은 파티션을 사용하도록 하고 시간에 따라 값을 저장할 수 있다. | . ",
    "url": "/docs/aws/dynamo#dynamodb-%EA%B5%AC%EC%84%B1",
    
    "relUrl": "/docs/aws/dynamo#dynamodb-구성"
  },"747": {
    "doc": "DynamoDB",
    "title": "일관성",
    "content": "DynamoDB는 일관성 수준을 지원한다. 여기서 일관성은 찰나의 시간에 쓰여진 데이터를 받아오는지에 대한 여부이다. 최종적 일관성 - 읽기 작업이 쓰기 작업 이후에 수행되는 경우 약간 오래된 데이터를 반환할 수 있음. 강력한 일관성 - 가장 최신 데이터를 반환. 트랜잭션 - ACID를 요구. 읽고 쓰기가 끝나는 것이 하나의 트랜잭션임을 보장하는 것. (계좌이체) . ",
    "url": "/docs/aws/dynamo#%EC%9D%BC%EA%B4%80%EC%84%B1",
    
    "relUrl": "/docs/aws/dynamo#일관성"
  },"748": {
    "doc": "DynamoDB",
    "title": "처리량",
    "content": "한 번에 들어온 요청에 대해 어느 정도까지 처리할 수 있는지 capacity를 설정할 수 있다. 처리량은 파티션 간에 균등하게 나뉜다. (파티션당 처리량 = capacity / 파티션 수) RCU - 최대 4KB 규모의 객체에 강력한 일관된 읽기를 수행할 수 있는 건수. WCU - 1KB 쓰기를 수행할 수 있는 초당 건수. ",
    "url": "/docs/aws/dynamo#%EC%B2%98%EB%A6%AC%EB%9F%89",
    
    "relUrl": "/docs/aws/dynamo#처리량"
  },"749": {
    "doc": "DynamoDB",
    "title": "글로벌 테이블",
    "content": "하나 이상의 DynamoDB 테이블의 모음으로 단일 AWS 계정이 소유한 복제 테이블이다. 글로벌 테이블에서는 리전당 하나의 복제 테이블만 사용되고 동일한 테이블 이름과 기본 키 스키마를 갖는다. 글로벌 테이블을 사용하면 복제 솔루션을 구축할 필요 없이 완전 관리형 솔루션을 제공한다. DynamoDB에서 해당 리전에 동일한 테이블을 생성하기 위해 모든 작업을 수행하고 진행 중인 데이터 변경을 모두에게 전파한다. 이런 복제에 스트림이 사용된다. 쓰기 일관성에서 동시 업데이트가 발생하는 경우에는 가장 마지막에 설정된 값으로 기록한다. 읽기 일관성에서 최종적 일관성을 지원한다. ",
    "url": "/docs/aws/dynamo#%EA%B8%80%EB%A1%9C%EB%B2%8C-%ED%85%8C%EC%9D%B4%EB%B8%94",
    
    "relUrl": "/docs/aws/dynamo#글로벌-테이블"
  },"750": {
    "doc": "DynamoDB",
    "title": "백업 및 복원",
    "content": "백업, 복원, 특정 시점으로의 복구를 쉽게 할 수 있도록 지원한다. ",
    "url": "/docs/aws/dynamo#%EB%B0%B1%EC%97%85-%EB%B0%8F-%EB%B3%B5%EC%9B%90",
    
    "relUrl": "/docs/aws/dynamo#백업-및-복원"
  },"751": {
    "doc": "DynamoDB",
    "title": "API",
    "content": "제어 작업: DynamoDB 테이블을 생성하고 관리. 데이터 작업: 테이블 데이터에 CRUD 작업을 수행. ",
    "url": "/docs/aws/dynamo#api",
    
    "relUrl": "/docs/aws/dynamo#api"
  },"752": {
    "doc": "DynamoDB",
    "title": "객체 지속성 모델",
    "content": "DynamoDB에 클라이언트 측 객체를 유지할 수 있다. | 테이블에 대한 객체 매핑(클래스 인스턴스)를 지원한다. 객체 지속성 프로그래밍 인터페이스로 이를 지원하는데 이를 통해 CRUD 작업과 쿼리를 실행할 수 있다. | . ",
    "url": "/docs/aws/dynamo#%EA%B0%9D%EC%B2%B4-%EC%A7%80%EC%86%8D%EC%84%B1-%EB%AA%A8%EB%8D%B8",
    
    "relUrl": "/docs/aws/dynamo#객체-지속성-모델"
  },"753": {
    "doc": "DynamoDB",
    "title": "Function",
    "content": "테이블에서 PutItem, GetItem, UpdateItem, DeleteItem으로 항목과 관련한 작업을 수행할 수 있고, Query, Scan 으로 값을 가져올 수 있다. | Query, Scan 작업의 경우 1MB의 데이터라는 기본 페이지 매김 제한으로 반환되는 데이터 양이 제한된다. | Query, Scan 작업의 경우 Limit 파라미터를 통해 반환되는 최대 항목 수를 지정할 수 있다. | . Batch로 데이터를 검색하거나 쓸 때 단일 요청으로 더 높은 처리와 효율적인 시간을 얻어낼 수 있다. 실패시 실패한 테이블과 항목을 재시도한다. BatchGetItem - 여러 테이블에서 최대 100개의 항목으로 이루어진 데이터를 최대 16MB까지 읽음. BatchWriteItem - 여러 테이블에서 최대 25번의 put 또는 delete 요청을 통해 최대 16MB까지 씀. DynamoDB javaSDK method Docs, DynamoDB API reference 참고. ",
    "url": "/docs/aws/dynamo#function",
    
    "relUrl": "/docs/aws/dynamo#function"
  },"754": {
    "doc": "DynamoDB",
    "title": "그외 참고 사항",
    "content": "예약어 자리 표시자 - 표현식에서 속성 이름을 위한 자리 표시자. (AWS Docs 참고) . 리터럴 값 자리 표시자 - 표현식에서 속성 값을 위한 자리 표시자. (AWS Docs 참고) 조건부 쓰기 수행 - ConditionExpression을 만족하면 쓰기를 수행. (AWS Docs 참고) 처리량 예외 처리 - 처리량이 초과하면 provisionedThroughputExceededException으로 알림을 전송하도록 CloudWatch 경보 설정. (AWS Docs 참고) . ",
    "url": "/docs/aws/dynamo#%EA%B7%B8%EC%99%B8-%EC%B0%B8%EA%B3%A0-%EC%82%AC%ED%95%AD",
    
    "relUrl": "/docs/aws/dynamo#그외-참고-사항"
  },"755": {
    "doc": "DynamoDB",
    "title": "효율성 확보",
    "content": "데이터를 고려하여 파티션 키가 분산될 수 있도록 구현한다. | 파티션 키에 따라 파티션이 나뉘며 경우에 따라 어떤 파티션엔 데이터가 적고 어떤 파티션엔 극도로 많아 작업 처리가 느려질 수 있다. 균일하게 파티션을 분배하여 처리를 분산시키는 것이 처리량을 극대화. | . 핫 데이터(자주 사용)와 콜드 데이터(자주 사용하지 않음)을 분리한다. | 자주 사용되는 데이터는 처리량이 더 높은 테이블에 별도로 저장한다거나 오래된 데이터를 다른 스토리지로 이동하는 등의 방식. | . 다수의 속성을 갖는 테이블 대신 일대다 테이블을 사용한다. | 최소한의 정보가 필요한 경우에도 쓸데없이 대량의 데이터를 가져오게 되는 문제를 해결. | 항목 크기가 DynamoDB의 최대 항목 크기를 초과하는 문제를 막을 수 있음. | . 자주 액세스하는 속성을 별도 테이블에 저장한다. | 큰 항목에 자주 액세스 하지만 큰 속성을 다 사용하지 않는다면 자주 사용되는 별도의 테이블을 분리하여 처리량을 개선. | . 로컬 보조 인덱스를 가능한 작게 유지한다. | 로컬 보조 인덱스는 스토리지와 테이블의 처리량을 사용하기 때문에 자주 쿼리하는 속성에 대해서만 생성하도록 함. | 전체 테이블을 포함하지 않는 스파스 인덱스를 사용하여 효율성을 높임. | . 메모리 가속인 DAX(DynamoDB Accelerator)를 추가한다. (app - (DAX) - DynamoDB 구조) . | 캐싱서비스로 밀리초 단위의 응답속도를 마이크로초 단위까지 줄일 수 있음. | DynamoDB와 호환되어 변경사항이 크지 않음. | read가 많은 경우 처리량을 줄여 비용을 절감시킴. | . ",
    "url": "/docs/aws/dynamo#%ED%9A%A8%EC%9C%A8%EC%84%B1-%ED%99%95%EB%B3%B4",
    
    "relUrl": "/docs/aws/dynamo#효율성-확보"
  },"756": {
    "doc": "DynamoDB",
    "title": "DynamoDB",
    "content": "DynamoDB는 완전 관리형 NoSQL DB 서비스으로 NoSQL의 특징을 갖는다. 리전 기반 서비스로 AZ에 문제가 생기더라도 다른쪽에서 정상적으로 동작한다. 완전 관리형 서비스로 사용자가 관리할 것이 거의 없다. | EC2에 os/db 설치 이후 db 서버로 쓸 수도 있지만 이런 서비스를 이용하면 초기세팅/소프트웨어 패치/운영 등을 신경쓰지 않아도 되서 더 편리함. | . 데이터 볼륨이 증가하고 애플리케이션 성능 요구가 증가하면 DynamoDB는 자동 분할로 처리량을 충족하고 규모에 관계없이 낮은 지연 시간(보통 10밀리초 미만)을 유지한다. IAM의 계정 권한 관리로 세분화된 접근 제어가 가능하다. 문서의 저장, 쿼리 및 업데이트를 지원하여 Json 문서를 테이블에 바로 저장할 수 있고 관련한 작업을 효율적으로 진행할 수 있다. ",
    "url": "/docs/aws/dynamo",
    
    "relUrl": "/docs/aws/dynamo"
  },"757": {
    "doc": "envoy proxy",
    "title": "envoy proxy",
    "content": " ",
    "url": "/docs/apis/envoy",
    
    "relUrl": "/docs/apis/envoy"
  },"758": {
    "doc": "error & bug",
    "title": "error & bug",
    "content": " ",
    "url": "/docs/error-bug",
    
    "relUrl": "/docs/error-bug"
  },"759": {
    "doc": "Etc",
    "title": "Etc",
    "content": " ",
    "url": "/docs/etc",
    
    "relUrl": "/docs/etc"
  },"760": {
    "doc": "flutter",
    "title": "flutter",
    "content": " ",
    "url": "/docs/flutter",
    
    "relUrl": "/docs/flutter"
  },"761": {
    "doc": "Garbage Collection",
    "title": "Garbage Collection",
    "content": " ",
    "url": "/docs/java/gc",
    
    "relUrl": "/docs/java/gc"
  },"762": {
    "doc": "GraphQL",
    "title": "GraphQL",
    "content": " ",
    "url": "/docs/apis/graphql",
    
    "relUrl": "/docs/apis/graphql"
  },"763": {
    "doc": "http",
    "title": "http",
    "content": " ",
    "url": "/docs/internet/http",
    
    "relUrl": "/docs/internet/http"
  },"764": {
    "doc": "Intellij",
    "title": "Intellij",
    "content": " ",
    "url": "/docs/dev-tools/intellij",
    
    "relUrl": "/docs/dev-tools/intellij"
  },"765": {
    "doc": "internet",
    "title": "internet",
    "content": " ",
    "url": "/docs/internet",
    
    "relUrl": "/docs/internet"
  },"766": {
    "doc": "이슈",
    "title": "이슈",
    "content": " ",
    "url": "/docs/java/issue",
    
    "relUrl": "/docs/java/issue"
  },"767": {
    "doc": "Java",
    "title": "Java",
    "content": " ",
    "url": "/docs/java",
    
    "relUrl": "/docs/java"
  },"768": {
    "doc": "Spring JPA",
    "title": "Spring JPA",
    "content": " ",
    "url": "/docs/spring/jpa",
    
    "relUrl": "/docs/spring/jpa"
  },"769": {
    "doc": "kafka",
    "title": "kafka",
    "content": " ",
    "url": "/docs/message-broker/kafka",
    
    "relUrl": "/docs/message-broker/kafka"
  },"770": {
    "doc": "kivy",
    "title": "kivy",
    "content": "kivy - interactive applications and games in python second edition . kivy로 간단한 게임을 만들어가는 과정과 이에 대한 설명을 하는 책이다. practice code에서 예제코드를 받을 수 있다. 책과 별개로 공부한 내용과, 책의 내용들을 챕터별로 정리한 것. ",
    "url": "/docs/kivy",
    
    "relUrl": "/docs/kivy"
  },"771": {
    "doc": "kotlin in action 정리하기",
    "title": "kotlin in action 정리하기",
    "content": " ",
    "url": "/docs/kotlin/kotlin-in-action",
    
    "relUrl": "/docs/kotlin/kotlin-in-action"
  },"772": {
    "doc": "Kotlin",
    "title": "Kotlin",
    "content": " ",
    "url": "/docs/kotlin",
    
    "relUrl": "/docs/kotlin"
  },"773": {
    "doc": "language",
    "title": "language",
    "content": " ",
    "url": "/docs/language",
    
    "relUrl": "/docs/language"
  },"774": {
    "doc": "Java 라이브러리",
    "title": "Java 라이브러리",
    "content": " ",
    "url": "/docs/java/library",
    
    "relUrl": "/docs/java/library"
  },"775": {
    "doc": "linux",
    "title": "linux",
    "content": " ",
    "url": "/docs/dev-tools/linux",
    
    "relUrl": "/docs/dev-tools/linux"
  },"776": {
    "doc": "Message Broker",
    "title": "Message Broker",
    "content": " ",
    "url": "/docs/message-broker",
    
    "relUrl": "/docs/message-broker"
  },"777": {
    "doc": "OAuth",
    "title": "OAuth",
    "content": " ",
    "url": "/docs/apis/oauth",
    
    "relUrl": "/docs/apis/oauth"
  },"778": {
    "doc": "oci",
    "title": "oci",
    "content": " ",
    "url": "/docs/oci",
    
    "relUrl": "/docs/oci"
  },"779": {
    "doc": "PM",
    "title": "PM",
    "content": " ",
    "url": "/docs/service-management",
    
    "relUrl": "/docs/service-management"
  },"780": {
    "doc": "python",
    "title": "python",
    "content": " ",
    "url": "/docs/49.language/python.html",
    
    "relUrl": "/docs/49.language/python.html"
  },"781": {
    "doc": "Refactoring",
    "title": "Refactoring",
    "content": " ",
    "url": "/docs/refactoring/",
    
    "relUrl": "/docs/refactoring/"
  },"782": {
    "doc": "retrospect",
    "title": "retrospect",
    "content": " ",
    "url": "/docs/retrospect/",
    
    "relUrl": "/docs/retrospect/"
  },"783": {
    "doc": "S3",
    "title": "storage option",
    "content": "AWS에서는 용도에 따라 S3 외에도 다양한 storage 서비스를 제공한다. (storage class 참고) . Glacier: 데이터를 저장하는데 저렴하며 내구성이 우수한 아카이브 스토리지. 저장하는 비용이 저렴하다는 장점이 있고, 데이터를 가져오는데 비용이 많이 들고 데이터를 받아오는데 시간이 오래걸린다는 단점이 있다. 주로 중요하지만 잘 사용하지 않는 데이터를 저장한다. EFS: 전통적인 파일 스토리지. 공유 개념을 지원한다. EBS: 블록 기반의 스토리지. EC2 인스턴스에 외장하드를 네트워크로 붙이는 식으로 사용. Storage Gateway: S3, Glacier, EBS 등의 스토리지 인프라 사이에 원활하고 안전한 통합이 이루어지도록 지원한다. | ex) S3 주 데이터를 저장하고 Glacier에 보관하도록 사용. | . ",
    "url": "/docs/aws/s3#storage-option",
    
    "relUrl": "/docs/aws/s3#storage-option"
  },"784": {
    "doc": "S3",
    "title": "구성요소",
    "content": "S3는 버킷과 객체로 이루어져 있다. 버킷: 버킷은 말 그대로 객체를 담는 바구니다. 전세계적으로 고유한 이름을 가져야 한다. | 3~63자의 사이즈와 a-z, 0-9, ‘-‘만을 사용한다. | . 객체: 버킷에 저장되는 파일로 어떤 종류의 파일도 객체가 될 수 있다. 객체는 고유한 키와 메타데이터를 갖는다. 키를 통해 객체를 업로드/검색한다. 개층구조(폴더의 개념)가 존재하지 않는데, 키에 prefix(/)를 통해 폴더 개념을 지원할 수 있다. | prog/java/collections.jtml을 통해 prog/java의 폴더 개념을 갖도록 객체를 구분. | 실제로는 계층구조가 없지만 사용자가 있는 것처럼 활용. 메타데이터는 시스템 메타데이터와 유저 메타데이터가 있으며 시스템 메타데이터는 생성 날짜, 크기 등의 정보를 포함한다. 객체의 key, metadata 참고. | . ",
    "url": "/docs/aws/s3#%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C",
    
    "relUrl": "/docs/aws/s3#구성요소"
  },"785": {
    "doc": "S3",
    "title": "versioning",
    "content": "S3는 동일한 이름의 파일을 넣으면 덮어쓰게 된다. 이런 문제를 해결하기 위해 versioning을 지원한다. | 각 버킷 &gt; property &gt; versioning 을 하면 version에 따른 동일한 이름의 파일을 저장하도록할 수 있음. | . version id는 객체의 metadata에 존재한다. 기본적으로 S3는 versioning을 비활성화되어 있는데 versioning을 한 번 켜면 끌 수 없으므로 데이터 관리 측면에서 코드상에서 충분히 고려가 되야한다. | 버전 별 데이터가 계속해서 쌓일 수 있음. | . ",
    "url": "/docs/aws/s3#versioning",
    
    "relUrl": "/docs/aws/s3#versioning"
  },"786": {
    "doc": "S3",
    "title": "URL",
    "content": "기본 경로 . | http://s3.[리전 엔드포인트].amazonaws.com/[버킷 이름]/[객체 파일 명] | . 가상 호스팅 . | http://[버킷 이름]s3.amazonaws.com/[객체 파일 명] | . aws의 주소가 들어가서 실 사용자에게 aws 서비스로 오해받을 수도 있을 것이고 이를 해결하기 위한 가상 호스팅도 존재한다. (AWS Virtual Hosting 참고) . ",
    "url": "/docs/aws/s3#url",
    
    "relUrl": "/docs/aws/s3#url"
  },"787": {
    "doc": "S3",
    "title": "객체 작업",
    "content": "Put: 단일 업로드 &lt;= 5GB, 멀티 파트 업로드 &lt;= 5TB 지원. 인터넷은 비교적 신뢰성이 떨어지기 때문에 100 MB를 넘는 경우 멀티 파트 업로드를 권장한다. 멀티 파트 업로드는 각 파트가 개별적으로 업로드 되고 업로드에 실패하면 실패한 파트만 재전송할 수 있다. Get: 완전한 객체 가져오는 것과 필요하다면 바이트 범위를 지정하여 객체의 일부를 가져올 수 있다. Select: S3에서 파일에 대한 format(csv, json)을 지정하여 원하는 값만을 가져올 수 있다. 큰 파일의 일부만 필요한 경우 파일 전체를 받는 낭비를 줄일 수 있다. 성능과 비용에서 효과를 볼 수 있다. (AWS select 참고) . delete: 단일 객체나 여러 객체를 삭제하는데 사용한다. versioning이 활성화 된 경우는 versionId도 같이 명시하여 삭제한다. versioning이 활성화 된 경우에 key만 지정하면 현재 버전의 객체에 delete marker가 추가되고, 삭제 마커가 있는 객체를 검색하려고 하면 404 error가 발생한다. ",
    "url": "/docs/aws/s3#%EA%B0%9D%EC%B2%B4-%EC%9E%91%EC%97%85",
    
    "relUrl": "/docs/aws/s3#객체-작업"
  },"788": {
    "doc": "S3",
    "title": "미리 서명된 URL",
    "content": "기본적으로 객체와 버킷은 모두 private. AWS 보안 자격 증명이나 권한 없이 객체를 업로드 하기를 원하는 경우 미리 서명된 URL을 사용할 수 있다. 다른 작업 수행을 위한 권한을 열지 않고 PUT/GET 에 대한 액세스를 제공. 생성할 때 자격 증명 등의 데이터를 받고, URL을 생성하는 사용자의 권한을 사용하여 액세스함. 지정된 기간 동안만 유효함. (최대 1주) . ",
    "url": "/docs/aws/s3#%EB%AF%B8%EB%A6%AC-%EC%84%9C%EB%AA%85%EB%90%9C-url",
    
    "relUrl": "/docs/aws/s3#미리-서명된-url"
  },"789": {
    "doc": "S3",
    "title": "암호화",
    "content": "전송 데이터 암호화를 할 수 있다. 서버에 저장하는 데이터를 암호화 할 수 있다. | S3가 관리하는 키. | KMS(key 관리 서비스)가 관리하는 키. | 사용자가 설정한 키. | . ",
    "url": "/docs/aws/s3#%EC%95%94%ED%98%B8%ED%99%94",
    
    "relUrl": "/docs/aws/s3#암호화"
  },"790": {
    "doc": "S3",
    "title": "ACL(Access Control List)",
    "content": "S3 ACL에서 객체나 버킷 수준에서 접근 가능한 권한 부여할 수 있다. 버킷의 ACL을 바꾸거나 설정하더라도 그 내부의 객체는 이와 별개이다. ",
    "url": "/docs/aws/s3#aclaccess-control-list",
    
    "relUrl": "/docs/aws/s3#aclaccess-control-list"
  },"791": {
    "doc": "S3",
    "title": "CORS (Cross Origin Resource Sharing)",
    "content": "제한된 리소스를 최초 자원이 서비스된 도메인 밖의 다른 도메인으로부터 요청할 수 있게 허용하는 구조이다. S3에서는 CORS를 지원하며 활성화하여 사용할 수 있다. (AWS CORS 시나리오 및 구성 방법 참고) . ",
    "url": "/docs/aws/s3#cors-cross-origin-resource-sharing",
    
    "relUrl": "/docs/aws/s3#cors-cross-origin-resource-sharing"
  },"792": {
    "doc": "S3",
    "title": "성능 개선 방향",
    "content": "애플리케이션 설계에서 가능한 경우 버킷과 키 이름을 캐시. 가장 가까운 버킷 리전을 선택. S3에 저자된 데이터를 압축하여 전송되는 데이터와 사용되는 스토리지 크기를 줄이는 방향. AWS CloudFront와 같은 CDN(콘텐츠 전송 네트워크)를 통해 효율적으로 콘텐츠 배포. ",
    "url": "/docs/aws/s3#%EC%84%B1%EB%8A%A5-%EA%B0%9C%EC%84%A0-%EB%B0%A9%ED%96%A5",
    
    "relUrl": "/docs/aws/s3#성능-개선-방향"
  },"793": {
    "doc": "S3",
    "title": "무결성 체크",
    "content": "GET/PUT으로 검색한 객체의 MD5 체크섬을 확인하여 전송 중 데이터 손상을 확인한다. | AWS SDK는 PUT 작업시 MD5 체크섬을 자동으로 지정. S3는 MD5 체크섬을 다시 계산하고 이를 지정된 값과 비교. | . ",
    "url": "/docs/aws/s3#%EB%AC%B4%EA%B2%B0%EC%84%B1-%EC%B2%B4%ED%81%AC",
    
    "relUrl": "/docs/aws/s3#무결성-체크"
  },"794": {
    "doc": "S3",
    "title": "오류 코드",
    "content": "S3 응답에 대해 오류 코드가 나온 경우 처리를 해주어야 한다. 400 error - 해당 작업을 수행할 수 없음. 500 error - 해당 작업을 재시도할 수 있음. ",
    "url": "/docs/aws/s3#%EC%98%A4%EB%A5%98-%EC%BD%94%EB%93%9C",
    
    "relUrl": "/docs/aws/s3#오류-코드"
  },"795": {
    "doc": "S3",
    "title": "S3",
    "content": "AWS에서 대표적으로 사용되는 스토리지 서비스로 완전 관리형 서비스이다. 원하는 양의 데이터를 저장할 수 있고 웹기반으로 어디서든 접근할 수 있는 스토리지. 매우 안전하고 안정적이며 확장 가능한 객체 스토리지. (eleven-nine) . 콘텐츠 저장 및 배포, 백업 및 아카이빙, 빅 데이터 분석, 재해 복구, 정적 웹 사이트 호스팅에서 사용될 수 있다. | 리전 기반이어서 정적 호스팅에선 EC2보다 더 안정적으로 지원 가능하다. | . EC2는 AZ 기반이지만 S3는 리전 기반이어서 AZ가 문제가 생겨도 더 안전하게 지원할 수 있다. 또한 CRR(교차 리전 복제)으로 모든 S3 객체를 다른 AWS 리전에 위치한 대산 버킷으로 자동 복제하여 안전성을 보장한다. S3는 객체 스토리지 구조를 갖는다. 전통적인 파일시스템: dir &gt; dir &gt; dir &gt; files 방식의 search. 파일이 많아지고 길어질수록 검색 속도가 늦어짐. 객체 스토리지: dir 구조를 갖지 않고 파일을 찾아감. 파일이 많아져도 균일한 속도를 유지함. ",
    "url": "/docs/aws/s3",
    
    "relUrl": "/docs/aws/s3"
  },"796": {
    "doc": "사이트",
    "title": "사이트",
    "content": " ",
    "url": "/docs/dev-tools/site",
    
    "relUrl": "/docs/dev-tools/site"
  },"797": {
    "doc": "슬랙",
    "title": "슬랙",
    "content": " ",
    "url": "/docs/dev-tools/slack",
    
    "relUrl": "/docs/dev-tools/slack"
  },"798": {
    "doc": "Spring",
    "title": "Spring",
    "content": " ",
    "url": "/docs/spring",
    
    "relUrl": "/docs/spring"
  },"799": {
    "doc": "전략적 설계",
    "title": "전략적 설계",
    "content": " ",
    "url": "/docs/ddd/strategic",
    
    "relUrl": "/docs/ddd/strategic"
  },"800": {
    "doc": "전술적 설계",
    "title": "전술적 설계",
    "content": " ",
    "url": "/docs/ddd/tactical",
    
    "relUrl": "/docs/ddd/tactical"
  },"801": {
    "doc": "TDD",
    "title": "TDD",
    "content": " ",
    "url": "/docs/extreme-programming/tdd",
    
    "relUrl": "/docs/extreme-programming/tdd"
  },"802": {
    "doc": "linux commands",
    "title": "linux commands",
    "content": "linux 개발에 유용한 terminal 리스트 . ",
    "url": "/docs/dev-tools/linux-commands",
    
    "relUrl": "/docs/dev-tools/linux-commands"
  },"803": {
    "doc": "Test",
    "title": "Test",
    "content": " ",
    "url": "/docs/test",
    
    "relUrl": "/docs/test"
  },"804": {
    "doc": "주제회고",
    "title": "주제회고",
    "content": " ",
    "url": "/docs/02.retrospect/theme.html",
    
    "relUrl": "/docs/02.retrospect/theme.html"
  },"805": {
    "doc": "Java Tips",
    "title": "Java Tips",
    "content": " ",
    "url": "/docs/java/tip",
    
    "relUrl": "/docs/java/tip"
  },"806": {
    "doc": "vue",
    "title": "vue",
    "content": " ",
    "url": "/docs/vue",
    
    "relUrl": "/docs/vue"
  }
}
